diff --git a/.venv/bin/activate b/.venv/bin/activate
new file mode 100644
index 0000000..d3d2dd0
--- /dev/null
+++ b/.venv/bin/activate
@@ -0,0 +1,76 @@
+# This file must be used with "source bin/activate" *from bash*
+# you cannot run it directly
+
+deactivate () {
+    # reset old environment variables
+    if [ -n "${_OLD_VIRTUAL_PATH:-}" ] ; then
+        PATH="${_OLD_VIRTUAL_PATH:-}"
+        export PATH
+        unset _OLD_VIRTUAL_PATH
+    fi
+    if [ -n "${_OLD_VIRTUAL_PYTHONHOME:-}" ] ; then
+        PYTHONHOME="${_OLD_VIRTUAL_PYTHONHOME:-}"
+        export PYTHONHOME
+        unset _OLD_VIRTUAL_PYTHONHOME
+    fi
+
+    # This should detect bash and zsh, which have a hash command that must
+    # be called to get it to forget past commands.  Without forgetting
+    # past commands the $PATH changes we made may not be respected
+    if [ -n "${BASH:-}" -o -n "${ZSH_VERSION:-}" ] ; then
+        hash -r
+    fi
+
+    if [ -n "${_OLD_VIRTUAL_PS1:-}" ] ; then
+        PS1="${_OLD_VIRTUAL_PS1:-}"
+        export PS1
+        unset _OLD_VIRTUAL_PS1
+    fi
+
+    unset VIRTUAL_ENV
+    if [ ! "$1" = "nondestructive" ] ; then
+    # Self destruct!
+        unset -f deactivate
+    fi
+}
+
+# unset irrelevant variables
+deactivate nondestructive
+
+VIRTUAL_ENV="/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv"
+export VIRTUAL_ENV
+
+_OLD_VIRTUAL_PATH="$PATH"
+PATH="$VIRTUAL_ENV/bin:$PATH"
+export PATH
+
+# unset PYTHONHOME if set
+# this will fail if PYTHONHOME is set to the empty string (which is bad anyway)
+# could use `if (set -u; : $PYTHONHOME) ;` in bash
+if [ -n "${PYTHONHOME:-}" ] ; then
+    _OLD_VIRTUAL_PYTHONHOME="${PYTHONHOME:-}"
+    unset PYTHONHOME
+fi
+
+if [ -z "${VIRTUAL_ENV_DISABLE_PROMPT:-}" ] ; then
+    _OLD_VIRTUAL_PS1="${PS1:-}"
+    if [ "x(.venv) " != x ] ; then
+	PS1="(.venv) ${PS1:-}"
+    else
+    if [ "`basename \"$VIRTUAL_ENV\"`" = "__" ] ; then
+        # special case for Aspen magic directories
+        # see http://www.zetadev.com/software/aspen/
+        PS1="[`basename \`dirname \"$VIRTUAL_ENV\"\``] $PS1"
+    else
+        PS1="(`basename \"$VIRTUAL_ENV\"`)$PS1"
+    fi
+    fi
+    export PS1
+fi
+
+# This should detect bash and zsh, which have a hash command that must
+# be called to get it to forget past commands.  Without forgetting
+# past commands the $PATH changes we made may not be respected
+if [ -n "${BASH:-}" -o -n "${ZSH_VERSION:-}" ] ; then
+    hash -r
+fi
diff --git a/.venv/bin/activate.csh b/.venv/bin/activate.csh
new file mode 100644
index 0000000..6a95aeb
--- /dev/null
+++ b/.venv/bin/activate.csh
@@ -0,0 +1,37 @@
+# This file must be used with "source bin/activate.csh" *from csh*.
+# You cannot run it directly.
+# Created by Davide Di Blasi <davidedb@gmail.com>.
+# Ported to Python 3.3 venv by Andrew Svetlov <andrew.svetlov@gmail.com>
+
+alias deactivate 'test $?_OLD_VIRTUAL_PATH != 0 && setenv PATH "$_OLD_VIRTUAL_PATH" && unset _OLD_VIRTUAL_PATH; rehash; test $?_OLD_VIRTUAL_PROMPT != 0 && set prompt="$_OLD_VIRTUAL_PROMPT" && unset _OLD_VIRTUAL_PROMPT; unsetenv VIRTUAL_ENV; test "\!:*" != "nondestructive" && unalias deactivate'
+
+# Unset irrelevant variables.
+deactivate nondestructive
+
+setenv VIRTUAL_ENV "/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv"
+
+set _OLD_VIRTUAL_PATH="$PATH"
+setenv PATH "$VIRTUAL_ENV/bin:$PATH"
+
+
+set _OLD_VIRTUAL_PROMPT="$prompt"
+
+if (! "$?VIRTUAL_ENV_DISABLE_PROMPT") then
+    if (".venv" != "") then
+        set env_name = ".venv"
+    else
+        if (`basename "VIRTUAL_ENV"` == "__") then
+            # special case for Aspen magic directories
+            # see http://www.zetadev.com/software/aspen/
+            set env_name = `basename \`dirname "$VIRTUAL_ENV"\``
+        else
+            set env_name = `basename "$VIRTUAL_ENV"`
+        endif
+    endif
+    set prompt = "[$env_name] $prompt"
+    unset env_name
+endif
+
+alias pydoc python -m pydoc
+
+rehash
diff --git a/.venv/bin/activate.fish b/.venv/bin/activate.fish
new file mode 100644
index 0000000..48bc180
--- /dev/null
+++ b/.venv/bin/activate.fish
@@ -0,0 +1,75 @@
+# This file must be used with ". bin/activate.fish" *from fish* (http://fishshell.org)
+# you cannot run it directly
+
+function deactivate  -d "Exit virtualenv and return to normal shell environment"
+    # reset old environment variables
+    if test -n "$_OLD_VIRTUAL_PATH"
+        set -gx PATH $_OLD_VIRTUAL_PATH
+        set -e _OLD_VIRTUAL_PATH
+    end
+    if test -n "$_OLD_VIRTUAL_PYTHONHOME"
+        set -gx PYTHONHOME $_OLD_VIRTUAL_PYTHONHOME
+        set -e _OLD_VIRTUAL_PYTHONHOME
+    end
+
+    if test -n "$_OLD_FISH_PROMPT_OVERRIDE"
+        functions -e fish_prompt
+        set -e _OLD_FISH_PROMPT_OVERRIDE
+        functions -c _old_fish_prompt fish_prompt
+        functions -e _old_fish_prompt
+    end
+
+    set -e VIRTUAL_ENV
+    if test "$argv[1]" != "nondestructive"
+        # Self destruct!
+        functions -e deactivate
+    end
+end
+
+# unset irrelevant variables
+deactivate nondestructive
+
+set -gx VIRTUAL_ENV "/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv"
+
+set -gx _OLD_VIRTUAL_PATH $PATH
+set -gx PATH "$VIRTUAL_ENV/bin" $PATH
+
+# unset PYTHONHOME if set
+if set -q PYTHONHOME
+    set -gx _OLD_VIRTUAL_PYTHONHOME $PYTHONHOME
+    set -e PYTHONHOME
+end
+
+if test -z "$VIRTUAL_ENV_DISABLE_PROMPT"
+    # fish uses a function instead of an env var to generate the prompt.
+
+    # save the current fish_prompt function as the function _old_fish_prompt
+    functions -c fish_prompt _old_fish_prompt
+
+    # with the original prompt function renamed, we can override with our own.
+    function fish_prompt
+        # Save the return status of the last command
+        set -l old_status $status
+
+        # Prompt override?
+        if test -n "(.venv) "
+            printf "%s%s" "(.venv) " (set_color normal)
+        else
+            # ...Otherwise, prepend env
+            set -l _checkbase (basename "$VIRTUAL_ENV")
+            if test $_checkbase = "__"
+                # special case for Aspen magic directories
+                # see http://www.zetadev.com/software/aspen/
+                printf "%s[%s]%s " (set_color -b blue white) (basename (dirname "$VIRTUAL_ENV")) (set_color normal)
+            else
+                printf "%s(%s)%s" (set_color -b blue white) (basename "$VIRTUAL_ENV") (set_color normal)
+            end
+        end
+
+        # Restore the return status of the previous command.
+        echo "exit $old_status" | .
+        _old_fish_prompt
+    end
+
+    set -gx _OLD_FISH_PROMPT_OVERRIDE "$VIRTUAL_ENV"
+end
diff --git a/.venv/bin/convert-caffe2-to-onnx b/.venv/bin/convert-caffe2-to-onnx
new file mode 100755
index 0000000..6b59294
--- /dev/null
+++ b/.venv/bin/convert-caffe2-to-onnx
@@ -0,0 +1,8 @@
+#!/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/bin/python3
+# -*- coding: utf-8 -*-
+import re
+import sys
+from caffe2.python.onnx.bin.conversion import caffe2_to_onnx
+if __name__ == '__main__':
+    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
+    sys.exit(caffe2_to_onnx())
diff --git a/.venv/bin/convert-onnx-to-caffe2 b/.venv/bin/convert-onnx-to-caffe2
new file mode 100755
index 0000000..754b2c8
--- /dev/null
+++ b/.venv/bin/convert-onnx-to-caffe2
@@ -0,0 +1,8 @@
+#!/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/bin/python3
+# -*- coding: utf-8 -*-
+import re
+import sys
+from caffe2.python.onnx.bin.conversion import onnx_to_caffe2
+if __name__ == '__main__':
+    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
+    sys.exit(onnx_to_caffe2())
diff --git a/.venv/bin/easy_install b/.venv/bin/easy_install
new file mode 100755
index 0000000..4a23cde
--- /dev/null
+++ b/.venv/bin/easy_install
@@ -0,0 +1,10 @@
+#!/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/bin/python3
+# -*- coding: utf-8 -*-
+import re
+import sys
+
+from setuptools.command.easy_install import main
+
+if __name__ == '__main__':
+    sys.argv[0] = re.sub(r'(-script\.pyw?|\.exe)?$', '', sys.argv[0])
+    sys.exit(main())
diff --git a/.venv/bin/easy_install-3.7 b/.venv/bin/easy_install-3.7
new file mode 100755
index 0000000..4a23cde
--- /dev/null
+++ b/.venv/bin/easy_install-3.7
@@ -0,0 +1,10 @@
+#!/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/bin/python3
+# -*- coding: utf-8 -*-
+import re
+import sys
+
+from setuptools.command.easy_install import main
+
+if __name__ == '__main__':
+    sys.argv[0] = re.sub(r'(-script\.pyw?|\.exe)?$', '', sys.argv[0])
+    sys.exit(main())
diff --git a/.venv/bin/f2py b/.venv/bin/f2py
new file mode 100755
index 0000000..c2a421f
--- /dev/null
+++ b/.venv/bin/f2py
@@ -0,0 +1,8 @@
+#!/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/bin/python3
+# -*- coding: utf-8 -*-
+import re
+import sys
+from numpy.f2py.f2py2e import main
+if __name__ == '__main__':
+    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
+    sys.exit(main())
diff --git a/.venv/bin/f2py3 b/.venv/bin/f2py3
new file mode 100755
index 0000000..c2a421f
--- /dev/null
+++ b/.venv/bin/f2py3
@@ -0,0 +1,8 @@
+#!/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/bin/python3
+# -*- coding: utf-8 -*-
+import re
+import sys
+from numpy.f2py.f2py2e import main
+if __name__ == '__main__':
+    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
+    sys.exit(main())
diff --git a/.venv/bin/f2py3.7 b/.venv/bin/f2py3.7
new file mode 100755
index 0000000..c2a421f
--- /dev/null
+++ b/.venv/bin/f2py3.7
@@ -0,0 +1,8 @@
+#!/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/bin/python3
+# -*- coding: utf-8 -*-
+import re
+import sys
+from numpy.f2py.f2py2e import main
+if __name__ == '__main__':
+    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
+    sys.exit(main())
diff --git a/.venv/bin/jsondiff b/.venv/bin/jsondiff
new file mode 100755
index 0000000..1a9567e
--- /dev/null
+++ b/.venv/bin/jsondiff
@@ -0,0 +1,39 @@
+#!/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/bin/python3
+# -*- coding: utf-8 -*-
+
+from __future__ import print_function
+
+import sys
+import json
+import jsonpatch
+import argparse
+
+
+parser = argparse.ArgumentParser(description='Diff two JSON files')
+parser.add_argument('FILE1', type=argparse.FileType('r'))
+parser.add_argument('FILE2', type=argparse.FileType('r'))
+parser.add_argument('--indent', type=int, default=None,
+                    help='Indent output by n spaces')
+parser.add_argument('-v', '--version', action='version',
+                    version='%(prog)s ' + jsonpatch.__version__)
+
+
+def main():
+    try:
+        diff_files()
+    except KeyboardInterrupt:
+        sys.exit(1)
+
+
+def diff_files():
+    """ Diffs two JSON files and prints a patch """
+    args = parser.parse_args()
+    doc1 = json.load(args.FILE1)
+    doc2 = json.load(args.FILE2)
+    patch = jsonpatch.make_patch(doc1, doc2)
+    if patch.patch:
+        print(json.dumps(patch.patch, indent=args.indent))
+        sys.exit(1)
+
+if __name__ == "__main__":
+    main()
diff --git a/.venv/bin/jsonpatch b/.venv/bin/jsonpatch
new file mode 100755
index 0000000..e7382e9
--- /dev/null
+++ b/.venv/bin/jsonpatch
@@ -0,0 +1,107 @@
+#!/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/bin/python3
+# -*- coding: utf-8 -*-
+
+import sys
+import os.path
+import json
+import jsonpatch
+import tempfile
+import argparse
+
+
+parser = argparse.ArgumentParser(
+    description='Apply a JSON patch on a JSON file')
+parser.add_argument('ORIGINAL', type=argparse.FileType('r'),
+                    help='Original file')
+parser.add_argument('PATCH', type=argparse.FileType('r'),
+                    nargs='?', default=sys.stdin,
+                    help='Patch file (read from stdin if omitted)')
+parser.add_argument('--indent', type=int, default=None,
+                    help='Indent output by n spaces')
+parser.add_argument('-b', '--backup', action='store_true',
+                    help='Back up ORIGINAL if modifying in-place')
+parser.add_argument('-i', '--in-place', action='store_true',
+                    help='Modify ORIGINAL in-place instead of to stdout')
+parser.add_argument('-v', '--version', action='version',
+                    version='%(prog)s ' + jsonpatch.__version__)
+parser.add_argument('-u', '--preserve-unicode', action='store_true',
+                    help='Output Unicode character as-is without using Code Point')
+
+def main():
+    try:
+        patch_files()
+    except KeyboardInterrupt:
+        sys.exit(1)
+
+
+def patch_files():
+    """ Diffs two JSON files and prints a patch """
+    args = parser.parse_args()
+    doc = json.load(args.ORIGINAL)
+    patch = json.load(args.PATCH)
+    result = jsonpatch.apply_patch(doc, patch)
+
+    if args.in_place:
+        dirname = os.path.abspath(os.path.dirname(args.ORIGINAL.name))
+
+        try:
+            # Attempt to replace the file atomically.  We do this by
+            # creating a temporary file in the same directory as the
+            # original file so we can atomically move the new file over
+            # the original later.  (This is done in the same directory
+	    # because atomic renames do not work across mount points.)
+
+            fd, pathname = tempfile.mkstemp(dir=dirname)
+            fp = os.fdopen(fd, 'w')
+            atomic = True
+
+        except OSError:
+            # We failed to create the temporary file for an atomic
+            # replace, so fall back to non-atomic mode by backing up
+            # the original (if desired) and writing a new file.
+
+            if args.backup:
+                os.rename(args.ORIGINAL.name, args.ORIGINAL.name + '.orig')
+            fp = open(args.ORIGINAL.name, 'w')
+            atomic = False
+
+    else:
+        # Since we're not replacing the original file in-place, write
+        # the modified JSON to stdout instead.
+
+        fp = sys.stdout
+
+    # By this point we have some sort of file object we can write the 
+    # modified JSON to.
+    
+    json.dump(result, fp, indent=args.indent, ensure_ascii=not(args.preserve_unicode))
+    fp.write('\n')
+
+    if args.in_place:
+        # Close the new file.  If we aren't replacing atomically, this
+        # is our last step, since everything else is already in place.
+
+        fp.close()
+
+        if atomic:
+            try:
+                # Complete the atomic replace by linking the original
+                # to a backup (if desired), fixing up the permissions
+                # on the temporary file, and moving it into place.
+
+                if args.backup:
+                    os.link(args.ORIGINAL.name, args.ORIGINAL.name + '.orig')
+                os.chmod(pathname, os.stat(args.ORIGINAL.name).st_mode)
+                os.rename(pathname, args.ORIGINAL.name)
+
+            except OSError:
+                # In the event we could not actually do the atomic
+                # replace, unlink the original to move it out of the
+                # way and finally move the temporary file into place.
+                
+                os.unlink(args.ORIGINAL.name)
+                os.rename(pathname, args.ORIGINAL.name)
+
+
+if __name__ == "__main__":
+    main()
diff --git a/.venv/bin/jsonpointer b/.venv/bin/jsonpointer
new file mode 100755
index 0000000..b0384e4
--- /dev/null
+++ b/.venv/bin/jsonpointer
@@ -0,0 +1,69 @@
+#!/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/bin/python3
+# -*- coding: utf-8 -*-
+
+from __future__ import print_function
+
+import sys
+import os.path
+import json
+import jsonpointer
+import argparse
+
+
+parser = argparse.ArgumentParser(
+    description='Resolve a JSON pointer on JSON files')
+
+# Accept pointer as argument or as file
+ptr_group = parser.add_mutually_exclusive_group(required=True)
+
+ptr_group.add_argument('-f', '--pointer-file', type=argparse.FileType('r'),
+                       nargs='?',
+                       help='File containing a JSON pointer expression')
+
+ptr_group.add_argument('POINTER',  type=str, nargs='?',
+                       help='A JSON pointer expression')
+
+parser.add_argument('FILE', type=argparse.FileType('r'), nargs='+',
+                    help='Files for which the pointer should be resolved')
+parser.add_argument('--indent', type=int, default=None,
+                    help='Indent output by n spaces')
+parser.add_argument('-v', '--version', action='version',
+                    version='%(prog)s ' + jsonpointer.__version__)
+
+
+def main():
+    try:
+        resolve_files()
+    except KeyboardInterrupt:
+        sys.exit(1)
+
+
+def parse_pointer(args):
+    if args.POINTER:
+        ptr = args.POINTER
+    elif args.pointer_file:
+        ptr = args.pointer_file.read().strip()
+    else:
+        parser.print_usage()
+        sys.exit(1)
+
+    return ptr
+
+
+def resolve_files():
+    """ Resolve a JSON pointer on JSON files """
+    args = parser.parse_args()
+
+    ptr = parse_pointer(args)
+
+    for f in args.FILE:
+        doc = json.load(f)
+        try:
+            result = jsonpointer.resolve_pointer(doc, ptr)
+            print(json.dumps(result, indent=args.indent))
+        except jsonpointer.JsonPointerException as e:
+            print('Could not resolve pointer: %s' % str(e), file=sys.stderr)
+
+
+if __name__ == "__main__":
+    main()
diff --git a/.venv/bin/normalizer b/.venv/bin/normalizer
new file mode 100755
index 0000000..819084f
--- /dev/null
+++ b/.venv/bin/normalizer
@@ -0,0 +1,8 @@
+#!/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/bin/python3
+# -*- coding: utf-8 -*-
+import re
+import sys
+from charset_normalizer.cli.normalizer import cli_detect
+if __name__ == '__main__':
+    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
+    sys.exit(cli_detect())
diff --git a/.venv/bin/pip b/.venv/bin/pip
new file mode 100755
index 0000000..5bbf62c
--- /dev/null
+++ b/.venv/bin/pip
@@ -0,0 +1,10 @@
+#!/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/bin/python3
+# -*- coding: utf-8 -*-
+import re
+import sys
+
+from pip._internal.cli.main import main
+
+if __name__ == '__main__':
+    sys.argv[0] = re.sub(r'(-script\.pyw?|\.exe)?$', '', sys.argv[0])
+    sys.exit(main())
diff --git a/.venv/bin/pip3 b/.venv/bin/pip3
new file mode 100755
index 0000000..5bbf62c
--- /dev/null
+++ b/.venv/bin/pip3
@@ -0,0 +1,10 @@
+#!/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/bin/python3
+# -*- coding: utf-8 -*-
+import re
+import sys
+
+from pip._internal.cli.main import main
+
+if __name__ == '__main__':
+    sys.argv[0] = re.sub(r'(-script\.pyw?|\.exe)?$', '', sys.argv[0])
+    sys.exit(main())
diff --git a/.venv/bin/pip3.7 b/.venv/bin/pip3.7
new file mode 100755
index 0000000..5bbf62c
--- /dev/null
+++ b/.venv/bin/pip3.7
@@ -0,0 +1,10 @@
+#!/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/bin/python3
+# -*- coding: utf-8 -*-
+import re
+import sys
+
+from pip._internal.cli.main import main
+
+if __name__ == '__main__':
+    sys.argv[0] = re.sub(r'(-script\.pyw?|\.exe)?$', '', sys.argv[0])
+    sys.exit(main())
diff --git a/.venv/bin/python b/.venv/bin/python
new file mode 120000
index 0000000..b8a0adb
--- /dev/null
+++ b/.venv/bin/python
@@ -0,0 +1 @@
+python3
\ No newline at end of file
diff --git a/.venv/bin/python3 b/.venv/bin/python3
new file mode 120000
index 0000000..8f70ccc
--- /dev/null
+++ b/.venv/bin/python3
@@ -0,0 +1 @@
+/usr/local/pytorch/1.1-cuda10/pytorch-1.1-cuda10-venv/bin/python3
\ No newline at end of file
diff --git a/.venv/bin/shortuuid b/.venv/bin/shortuuid
new file mode 100755
index 0000000..0241d22
--- /dev/null
+++ b/.venv/bin/shortuuid
@@ -0,0 +1,8 @@
+#!/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/bin/python3
+# -*- coding: utf-8 -*-
+import re
+import sys
+from shortuuid import cli
+if __name__ == '__main__':
+    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
+    sys.exit(cli.main())
diff --git a/.venv/bin/torchrun b/.venv/bin/torchrun
new file mode 100755
index 0000000..91182cd
--- /dev/null
+++ b/.venv/bin/torchrun
@@ -0,0 +1,8 @@
+#!/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/bin/python3
+# -*- coding: utf-8 -*-
+import re
+import sys
+from torch.distributed.run import main
+if __name__ == '__main__':
+    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
+    sys.exit(main())
diff --git a/.venv/bin/visdom b/.venv/bin/visdom
new file mode 100755
index 0000000..c150f70
--- /dev/null
+++ b/.venv/bin/visdom
@@ -0,0 +1,12 @@
+#!/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/bin/python3
+# EASY-INSTALL-ENTRY-SCRIPT: 'visdom==0.1.8.9','console_scripts','visdom'
+__requires__ = 'visdom==0.1.8.9'
+import re
+import sys
+from pkg_resources import load_entry_point
+
+if __name__ == '__main__':
+    sys.argv[0] = re.sub(r'(-script\.pyw?|\.exe)?$', '', sys.argv[0])
+    sys.exit(
+        load_entry_point('visdom==0.1.8.9', 'console_scripts', 'visdom')()
+    )
diff --git a/.venv/bin/wandb b/.venv/bin/wandb
new file mode 100755
index 0000000..f93acd9
--- /dev/null
+++ b/.venv/bin/wandb
@@ -0,0 +1,8 @@
+#!/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/bin/python3
+# -*- coding: utf-8 -*-
+import re
+import sys
+from wandb.cli.cli import cli
+if __name__ == '__main__':
+    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
+    sys.exit(cli())
diff --git a/.venv/bin/wb b/.venv/bin/wb
new file mode 100755
index 0000000..f93acd9
--- /dev/null
+++ b/.venv/bin/wb
@@ -0,0 +1,8 @@
+#!/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/bin/python3
+# -*- coding: utf-8 -*-
+import re
+import sys
+from wandb.cli.cli import cli
+if __name__ == '__main__':
+    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
+    sys.exit(cli())
diff --git a/.venv/bin/wsdump b/.venv/bin/wsdump
new file mode 100755
index 0000000..0aec4d7
--- /dev/null
+++ b/.venv/bin/wsdump
@@ -0,0 +1,8 @@
+#!/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/bin/python3
+# -*- coding: utf-8 -*-
+import re
+import sys
+from websocket._wsdump import main
+if __name__ == '__main__':
+    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
+    sys.exit(main())
diff --git a/.venv/lib/python3.7/site-packages/COPYING b/.venv/lib/python3.7/site-packages/COPYING
new file mode 100644
index 0000000..c14f01b
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/COPYING
@@ -0,0 +1,29 @@
+Copyright (c) 2011, Stavros Korokithakis
+All rights reserved.
+
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+
+Redistributions of source code must retain the above copyright notice,
+this list of conditions and the following disclaimer.
+
+Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in the
+documentation and/or other materials provided with the distribution.
+
+Neither the name of Stochastic Technologies nor the names of its
+contributors may be used to endorse or promote products derived from
+this software without specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
diff --git a/.venv/lib/python3.7/site-packages/GitPython-3.1.27.dist-info/AUTHORS b/.venv/lib/python3.7/site-packages/GitPython-3.1.27.dist-info/AUTHORS
new file mode 100644
index 0000000..55d6818
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/GitPython-3.1.27.dist-info/AUTHORS
@@ -0,0 +1,48 @@
+GitPython was originally written by Michael Trier.
+GitPython 0.2 was partially (re)written by Sebastian Thiel, based on 0.1.6 and git-dulwich.
+
+Contributors are:
+
+-Michael Trier <mtrier _at_ gmail.com>
+-Alan Briolat
+-Florian Apolloner <florian _at_ apolloner.eu>
+-David Aguilar <davvid _at_ gmail.com>
+-Jelmer Vernooij <jelmer _at_ samba.org>
+-Steve Frécinaux <code _at_ istique.net>
+-Kai Lautaportti <kai _at_ lautaportti.fi>
+-Paul Sowden <paul _at_ idontsmoke.co.uk>
+-Sebastian Thiel <byronimo _at_ gmail.com>
+-Jonathan Chu <jonathan.chu _at_ me.com>
+-Vincent Driessen <me _at_ nvie.com>
+-Phil Elson <pelson _dot_ pub _at_ gmail.com>
+-Bernard `Guyzmo` Pratz <guyzmo+gitpython+pub@m0g.net>
+-Timothy B. Hartman <tbhartman _at_ gmail.com>
+-Konstantin Popov <konstantin.popov.89 _at_ yandex.ru>
+-Peter Jones <pjones _at_ redhat.com>
+-Anson Mansfield <anson.mansfield _at_ gmail.com>
+-Ken Odegard <ken.odegard _at_ gmail.com>
+-Alexis Horgix Chotard
+-Piotr Babij <piotr.babij _at_ gmail.com>
+-Mikuláš Poul <mikulaspoul _at_ gmail.com>
+-Charles Bouchard-Légaré <cblegare.atl _at_ ntis.ca>
+-Yaroslav Halchenko <debian _at_ onerussian.com>
+-Tim Swast <swast _at_ google.com>
+-William Luc Ritchie
+-David Host <hostdm _at_ outlook.com>
+-A. Jesse Jiryu Davis <jesse _at_ emptysquare.net>
+-Steven Whitman <ninloot _at_ gmail.com>
+-Stefan Stancu <stefan.stancu _at_ gmail.com>
+-César Izurieta <cesar _at_ caih.org>
+-Arthur Milchior <arthur _at_ milchior.fr>
+-Anil Khatri <anil.soccer.khatri _at_ gmail.com>
+-JJ Graham <thetwoj _at_ gmail.com>
+-Ben Thayer <ben _at_ benthayer.com>
+-Dries Kennes <admin _at_ dries007.net>
+-Pratik Anurag <panurag247365 _at_ gmail.com>
+-Harmon <harmon.public _at_ gmail.com>
+-Liam Beguin <liambeguin _at_ gmail.com>
+-Ram Rachum <ram _at_ rachum.com>
+-Alba Mendez <me _at_ alba.sh>
+-Robert Westman <robert _at_ byteflux.io>
+-Hugo van Kemenade
+Portions derived from other open source works and are clearly marked.
diff --git a/.venv/lib/python3.7/site-packages/GitPython-3.1.27.dist-info/INSTALLER b/.venv/lib/python3.7/site-packages/GitPython-3.1.27.dist-info/INSTALLER
new file mode 100644
index 0000000..a1b589e
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/GitPython-3.1.27.dist-info/INSTALLER
@@ -0,0 +1 @@
+pip
diff --git a/.venv/lib/python3.7/site-packages/GitPython-3.1.27.dist-info/LICENSE b/.venv/lib/python3.7/site-packages/GitPython-3.1.27.dist-info/LICENSE
new file mode 100644
index 0000000..5a9a6f8
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/GitPython-3.1.27.dist-info/LICENSE
@@ -0,0 +1,30 @@
+Copyright (C) 2008, 2009 Michael Trier and contributors
+All rights reserved.
+
+Redistribution and use in source and binary forms, with or without 
+modification, are permitted provided that the following conditions 
+are met:
+
+* Redistributions of source code must retain the above copyright 
+notice, this list of conditions and the following disclaimer.
+
+* Redistributions in binary form must reproduce the above copyright 
+notice, this list of conditions and the following disclaimer in the 
+documentation and/or other materials provided with the distribution.
+
+* Neither the name of the GitPython project nor the names of 
+its contributors may be used to endorse or promote products derived 
+from this software without specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS 
+"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT 
+LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR 
+A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT 
+OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, 
+SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED 
+TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR 
+PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF 
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING 
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS 
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
diff --git a/.venv/lib/python3.7/site-packages/GitPython-3.1.27.dist-info/METADATA b/.venv/lib/python3.7/site-packages/GitPython-3.1.27.dist-info/METADATA
new file mode 100644
index 0000000..8a04eba
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/GitPython-3.1.27.dist-info/METADATA
@@ -0,0 +1,33 @@
+Metadata-Version: 2.1
+Name: GitPython
+Version: 3.1.27
+Summary: GitPython is a python library used to interact with Git repositories
+Home-page: https://github.com/gitpython-developers/GitPython
+Author: Sebastian Thiel, Michael Trier
+Author-email: byronimo@gmail.com, mtrier@gmail.com
+License: BSD
+Platform: UNKNOWN
+Classifier: Development Status :: 5 - Production/Stable
+Classifier: Environment :: Console
+Classifier: Intended Audience :: Developers
+Classifier: License :: OSI Approved :: BSD License
+Classifier: Operating System :: OS Independent
+Classifier: Operating System :: POSIX
+Classifier: Operating System :: Microsoft :: Windows
+Classifier: Operating System :: MacOS :: MacOS X
+Classifier: Typing :: Typed
+Classifier: Programming Language :: Python
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.7
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
+Requires-Python: >=3.7
+Description-Content-Type: text/markdown
+License-File: LICENSE
+License-File: AUTHORS
+Requires-Dist: gitdb (<5,>=4.0.1)
+Requires-Dist: typing-extensions (>=3.7.4.3) ; python_version < "3.8"
+
+GitPython is a python library used to interact with Git repositories
+
diff --git a/.venv/lib/python3.7/site-packages/GitPython-3.1.27.dist-info/RECORD b/.venv/lib/python3.7/site-packages/GitPython-3.1.27.dist-info/RECORD
new file mode 100644
index 0000000..3836672
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/GitPython-3.1.27.dist-info/RECORD
@@ -0,0 +1,82 @@
+GitPython-3.1.27.dist-info/AUTHORS,sha256=vjnd09wZL3p1v8gB5lsk4nj-2nDyHcZEzY_MKrZQyco,1936
+GitPython-3.1.27.dist-info/INSTALLER,sha256=zuuue4knoyJ-UwPPXg8fezS7VCrXJQrAP7zeNuwvFQg,4
+GitPython-3.1.27.dist-info/LICENSE,sha256=_WV__CzvY9JceMq3gI1BTdA6KC5jiTSR_RHDL5i-Z_s,1521
+GitPython-3.1.27.dist-info/METADATA,sha256=h9Z-ZVEP5r7UES4v0wOH-dyhekIRG0qBBg_7VX5zAFc,1289
+GitPython-3.1.27.dist-info/RECORD,,
+GitPython-3.1.27.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+GitPython-3.1.27.dist-info/top_level.txt,sha256=0hzDuIp8obv624V3GmbqsagBWkk8ohtGU-Bc1PmTT0o,4
+git/__init__.py,sha256=LIqmpO0UYXoia_6ymWif0fdDpVN1apyh-yuzD1Qmkog,2500
+git/__pycache__/__init__.cpython-37.pyc,,
+git/__pycache__/cmd.cpython-37.pyc,,
+git/__pycache__/compat.cpython-37.pyc,,
+git/__pycache__/config.cpython-37.pyc,,
+git/__pycache__/db.cpython-37.pyc,,
+git/__pycache__/diff.cpython-37.pyc,,
+git/__pycache__/exc.cpython-37.pyc,,
+git/__pycache__/remote.cpython-37.pyc,,
+git/__pycache__/types.cpython-37.pyc,,
+git/__pycache__/util.cpython-37.pyc,,
+git/cmd.py,sha256=8QI5KptzHzAEGzfMg2FtQrPaggMAzv_YKwF4-rGhJRI,51897
+git/compat.py,sha256=A__j0NDexK9vm-IP59CveY7V_Epef9Km4wH94nykvGs,2244
+git/config.py,sha256=ABfTzzFy82NkwTKHreMbJF78JC43dAR385LbrUhnc84,34506
+git/db.py,sha256=Ji8Zrdq5Gvo3Hm54gBB7DXFYJE0SgPmoHyAp_5RI3s0,2255
+git/diff.py,sha256=nzQ2ZtSFrvcpgTvKBKlheLLZGdLgmW3xbwjaZQtaJBQ,22587
+git/exc.py,sha256=rtiF2l2ZONIih_yF3DZ_WuDXAocdq0inhjQzGJq5T7o,6079
+git/index/__init__.py,sha256=43ovvVNocVRNiQd4fLqvUMuGGmwhBQ9SsiQ46vkvk1E,89
+git/index/__pycache__/__init__.cpython-37.pyc,,
+git/index/__pycache__/base.cpython-37.pyc,,
+git/index/__pycache__/fun.cpython-37.pyc,,
+git/index/__pycache__/typ.cpython-37.pyc,,
+git/index/__pycache__/util.cpython-37.pyc,,
+git/index/base.py,sha256=-MV0W-PyJwCYxFb-Klbooaay3uDm-sr8xHAiK_4lXaU,57001
+git/index/fun.py,sha256=Ac9zLk2JAnayb4Gl9QpJ8S2CzNqWDfxFhZT2S9bhWX8,16431
+git/index/typ.py,sha256=8-yL3QhdHXkVaDHfUuk4Kmks1Comrq547Kg48m6H2gA,5516
+git/index/util.py,sha256=t3llCo90s1L_OgPYIqah5AuVU6043XKTaQrmJtUeYjU,3454
+git/objects/__init__.py,sha256=1uMoWicK_mgiQIaikCMsX7uiRWc9US4XUXCouSmH4Dk,703
+git/objects/__pycache__/__init__.cpython-37.pyc,,
+git/objects/__pycache__/base.cpython-37.pyc,,
+git/objects/__pycache__/blob.cpython-37.pyc,,
+git/objects/__pycache__/commit.cpython-37.pyc,,
+git/objects/__pycache__/fun.cpython-37.pyc,,
+git/objects/__pycache__/tag.cpython-37.pyc,,
+git/objects/__pycache__/tree.cpython-37.pyc,,
+git/objects/__pycache__/util.cpython-37.pyc,,
+git/objects/base.py,sha256=qLgh-OStkOke3yKgwq2ZNFTC45Qsl1UTSI1-fdjR8-w,7759
+git/objects/blob.py,sha256=nXCRt885vuNjI6VRw_fXOZSgQfD9PjXPg3XZIRZkIfM,987
+git/objects/commit.py,sha256=-dXHQvop5HXIqQjuMYIFMNLL2AY9y0a7Gw3ayG8OAHY,25869
+git/objects/fun.py,sha256=vSmm8p4_6ZMOh3Vtwbi65gP1vIFczXF2hXtgHclP-EY,8542
+git/objects/submodule/__init__.py,sha256=OsMeiex7cG6ev2f35IaJ5csH-eXchSoNKCt4HXUG5Ws,93
+git/objects/submodule/__pycache__/__init__.cpython-37.pyc,,
+git/objects/submodule/__pycache__/base.cpython-37.pyc,,
+git/objects/submodule/__pycache__/root.cpython-37.pyc,,
+git/objects/submodule/__pycache__/util.cpython-37.pyc,,
+git/objects/submodule/base.py,sha256=QOZfeU4mQVyGFLKGWS8YTRD8DtN_lVjhtPsw6N9Upqs,58774
+git/objects/submodule/root.py,sha256=cy7wRBLJwqNXGm6bK0tgEucYX7lx-KNQS-WTTlEXvig,18288
+git/objects/submodule/util.py,sha256=iX1EYGDhVrr1PG8729zQPm2GL47FkE9MPqPYC8C_h-o,3358
+git/objects/tag.py,sha256=mqlDG5UyScqHEnwDXRBPwbMcPrTZnhMiezpDM7DkEss,3764
+git/objects/tree.py,sha256=ly7fgePvItjB-B69AvdlFXrekH8MixOMauO31sCpg7E,14292
+git/objects/util.py,sha256=gx1jzp1oiqdlADrWu6oorIF3FwXJZtaprzxPlyY9u8I,22466
+git/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+git/refs/__init__.py,sha256=PMF97jMUcivbCCEJnl2zTs-YtECNFp8rL8GHK8AitXU,203
+git/refs/__pycache__/__init__.cpython-37.pyc,,
+git/refs/__pycache__/head.cpython-37.pyc,,
+git/refs/__pycache__/log.cpython-37.pyc,,
+git/refs/__pycache__/reference.cpython-37.pyc,,
+git/refs/__pycache__/remote.cpython-37.pyc,,
+git/refs/__pycache__/symbolic.cpython-37.pyc,,
+git/refs/__pycache__/tag.cpython-37.pyc,,
+git/refs/head.py,sha256=UbIuWCb9WI87DZY6puX92YaHLDnh-D6DkONwDjyxcvM,9626
+git/refs/log.py,sha256=8ZTiE7KV4SVAlx14xR7xVG1uh_jFgsSNZ_6QSMh4vpA,12061
+git/refs/reference.py,sha256=28aB_lnYLKIXx2wvy_y87P0EDIuNiCsGLgBmV-29qP0,5405
+git/refs/remote.py,sha256=3iSjMHPlQCUA3QacJ-CHK60yihCmGeyVnuTh-zTq7qo,2556
+git/refs/symbolic.py,sha256=nBmwXAK48w-vmFq-tAl40XlemKsPxiu7aDnyctlWA5o,29739
+git/refs/tag.py,sha256=xboM_oFCFXakpZvvb-bn4GgLcsddPvNIuEK9E3gNuNs,4273
+git/remote.py,sha256=VohJ7s27AC0RCP8EgG-_oMjTE1nxOqnQTHSulhqglnY,41704
+git/repo/__init__.py,sha256=XMpdeowJRtTEd80jAcrKSQfMu2JZGMfPlpuIYHG2ZCk,80
+git/repo/__pycache__/__init__.cpython-37.pyc,,
+git/repo/__pycache__/base.cpython-37.pyc,,
+git/repo/__pycache__/fun.cpython-37.pyc,,
+git/repo/base.py,sha256=mF3lmjtg81KQfst2RZad290fp-bwsEG28dEh7NYkmf0,51847
+git/repo/fun.py,sha256=yjsY_sna6XaUzB0ZANiIMwu97QMxWAWpWtoj4pynqg4,12713
+git/types.py,sha256=L9yBmFn6XUdV9BJgnKSwXPcYEPj9mACl7VuIi7FcNQ8,3072
+git/util.py,sha256=AAebYTIADbA46Iu5rsUqCvCPAM2w-PlbMp2-sm6Wdok,39531
diff --git a/.venv/lib/python3.7/site-packages/GitPython-3.1.27.dist-info/WHEEL b/.venv/lib/python3.7/site-packages/GitPython-3.1.27.dist-info/WHEEL
new file mode 100644
index 0000000..becc9a6
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/GitPython-3.1.27.dist-info/WHEEL
@@ -0,0 +1,5 @@
+Wheel-Version: 1.0
+Generator: bdist_wheel (0.37.1)
+Root-Is-Purelib: true
+Tag: py3-none-any
+
diff --git a/.venv/lib/python3.7/site-packages/GitPython-3.1.27.dist-info/top_level.txt b/.venv/lib/python3.7/site-packages/GitPython-3.1.27.dist-info/top_level.txt
new file mode 100644
index 0000000..5664e30
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/GitPython-3.1.27.dist-info/top_level.txt
@@ -0,0 +1 @@
+git
diff --git a/.venv/lib/python3.7/site-packages/PIL/BdfFontFile.py b/.venv/lib/python3.7/site-packages/PIL/BdfFontFile.py
new file mode 100644
index 0000000..102b72e
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/BdfFontFile.py
@@ -0,0 +1,110 @@
+#
+# The Python Imaging Library
+# $Id$
+#
+# bitmap distribution font (bdf) file parser
+#
+# history:
+# 1996-05-16 fl   created (as bdf2pil)
+# 1997-08-25 fl   converted to FontFile driver
+# 2001-05-25 fl   removed bogus __init__ call
+# 2002-11-20 fl   robustification (from Kevin Cazabon, Dmitry Vasiliev)
+# 2003-04-22 fl   more robustification (from Graham Dumpleton)
+#
+# Copyright (c) 1997-2003 by Secret Labs AB.
+# Copyright (c) 1997-2003 by Fredrik Lundh.
+#
+# See the README file for information on usage and redistribution.
+#
+
+"""
+Parse X Bitmap Distribution Format (BDF)
+"""
+
+
+from . import FontFile, Image
+
+bdf_slant = {
+    "R": "Roman",
+    "I": "Italic",
+    "O": "Oblique",
+    "RI": "Reverse Italic",
+    "RO": "Reverse Oblique",
+    "OT": "Other",
+}
+
+bdf_spacing = {"P": "Proportional", "M": "Monospaced", "C": "Cell"}
+
+
+def bdf_char(f):
+    # skip to STARTCHAR
+    while True:
+        s = f.readline()
+        if not s:
+            return None
+        if s[:9] == b"STARTCHAR":
+            break
+    id = s[9:].strip().decode("ascii")
+
+    # load symbol properties
+    props = {}
+    while True:
+        s = f.readline()
+        if not s or s[:6] == b"BITMAP":
+            break
+        i = s.find(b" ")
+        props[s[:i].decode("ascii")] = s[i + 1 : -1].decode("ascii")
+
+    # load bitmap
+    bitmap = []
+    while True:
+        s = f.readline()
+        if not s or s[:7] == b"ENDCHAR":
+            break
+        bitmap.append(s[:-1])
+    bitmap = b"".join(bitmap)
+
+    [x, y, l, d] = [int(p) for p in props["BBX"].split()]
+    [dx, dy] = [int(p) for p in props["DWIDTH"].split()]
+
+    bbox = (dx, dy), (l, -d - y, x + l, -d), (0, 0, x, y)
+
+    try:
+        im = Image.frombytes("1", (x, y), bitmap, "hex", "1")
+    except ValueError:
+        # deal with zero-width characters
+        im = Image.new("1", (x, y))
+
+    return id, int(props["ENCODING"]), bbox, im
+
+
+class BdfFontFile(FontFile.FontFile):
+    """Font file plugin for the X11 BDF format."""
+
+    def __init__(self, fp):
+        super().__init__()
+
+        s = fp.readline()
+        if s[:13] != b"STARTFONT 2.1":
+            raise SyntaxError("not a valid BDF file")
+
+        props = {}
+        comments = []
+
+        while True:
+            s = fp.readline()
+            if not s or s[:13] == b"ENDPROPERTIES":
+                break
+            i = s.find(b" ")
+            props[s[:i].decode("ascii")] = s[i + 1 : -1].decode("ascii")
+            if s[:i] in [b"COMMENT", b"COPYRIGHT"]:
+                if s.find(b"LogicalFontDescription") < 0:
+                    comments.append(s[i + 1 : -1].decode("ascii"))
+
+        while True:
+            c = bdf_char(fp)
+            if not c:
+                break
+            id, ch, (xy, dst, src), im = c
+            if 0 <= ch < len(self.glyph):
+                self.glyph[ch] = xy, dst, src, im
diff --git a/.venv/lib/python3.7/site-packages/PIL/BlpImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/BlpImagePlugin.py
new file mode 100644
index 0000000..7b78597
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/BlpImagePlugin.py
@@ -0,0 +1,428 @@
+"""
+Blizzard Mipmap Format (.blp)
+Jerome Leclanche <jerome@leclan.ch>
+
+The contents of this file are hereby released in the public domain (CC0)
+Full text of the CC0 license:
+  https://creativecommons.org/publicdomain/zero/1.0/
+
+BLP1 files, used mostly in Warcraft III, are not fully supported.
+All types of BLP2 files used in World of Warcraft are supported.
+
+The BLP file structure consists of a header, up to 16 mipmaps of the
+texture
+
+Texture sizes must be powers of two, though the two dimensions do
+not have to be equal; 512x256 is valid, but 512x200 is not.
+The first mipmap (mipmap #0) is the full size image; each subsequent
+mipmap halves both dimensions. The final mipmap should be 1x1.
+
+BLP files come in many different flavours:
+* JPEG-compressed (type == 0) - only supported for BLP1.
+* RAW images (type == 1, encoding == 1). Each mipmap is stored as an
+  array of 8-bit values, one per pixel, left to right, top to bottom.
+  Each value is an index to the palette.
+* DXT-compressed (type == 1, encoding == 2):
+- DXT1 compression is used if alpha_encoding == 0.
+  - An additional alpha bit is used if alpha_depth == 1.
+  - DXT3 compression is used if alpha_encoding == 1.
+  - DXT5 compression is used if alpha_encoding == 7.
+"""
+
+import struct
+from io import BytesIO
+
+from . import Image, ImageFile
+
+BLP_FORMAT_JPEG = 0
+
+BLP_ENCODING_UNCOMPRESSED = 1
+BLP_ENCODING_DXT = 2
+BLP_ENCODING_UNCOMPRESSED_RAW_BGRA = 3
+
+BLP_ALPHA_ENCODING_DXT1 = 0
+BLP_ALPHA_ENCODING_DXT3 = 1
+BLP_ALPHA_ENCODING_DXT5 = 7
+
+
+def unpack_565(i):
+    return (((i >> 11) & 0x1F) << 3, ((i >> 5) & 0x3F) << 2, (i & 0x1F) << 3)
+
+
+def decode_dxt1(data, alpha=False):
+    """
+    input: one "row" of data (i.e. will produce 4*width pixels)
+    """
+
+    blocks = len(data) // 8  # number of blocks in row
+    ret = (bytearray(), bytearray(), bytearray(), bytearray())
+
+    for block in range(blocks):
+        # Decode next 8-byte block.
+        idx = block * 8
+        color0, color1, bits = struct.unpack_from("<HHI", data, idx)
+
+        r0, g0, b0 = unpack_565(color0)
+        r1, g1, b1 = unpack_565(color1)
+
+        # Decode this block into 4x4 pixels
+        # Accumulate the results onto our 4 row accumulators
+        for j in range(4):
+            for i in range(4):
+                # get next control op and generate a pixel
+
+                control = bits & 3
+                bits = bits >> 2
+
+                a = 0xFF
+                if control == 0:
+                    r, g, b = r0, g0, b0
+                elif control == 1:
+                    r, g, b = r1, g1, b1
+                elif control == 2:
+                    if color0 > color1:
+                        r = (2 * r0 + r1) // 3
+                        g = (2 * g0 + g1) // 3
+                        b = (2 * b0 + b1) // 3
+                    else:
+                        r = (r0 + r1) // 2
+                        g = (g0 + g1) // 2
+                        b = (b0 + b1) // 2
+                elif control == 3:
+                    if color0 > color1:
+                        r = (2 * r1 + r0) // 3
+                        g = (2 * g1 + g0) // 3
+                        b = (2 * b1 + b0) // 3
+                    else:
+                        r, g, b, a = 0, 0, 0, 0
+
+                if alpha:
+                    ret[j].extend([r, g, b, a])
+                else:
+                    ret[j].extend([r, g, b])
+
+    return ret
+
+
+def decode_dxt3(data):
+    """
+    input: one "row" of data (i.e. will produce 4*width pixels)
+    """
+
+    blocks = len(data) // 16  # number of blocks in row
+    ret = (bytearray(), bytearray(), bytearray(), bytearray())
+
+    for block in range(blocks):
+        idx = block * 16
+        block = data[idx : idx + 16]
+        # Decode next 16-byte block.
+        bits = struct.unpack_from("<8B", block)
+        color0, color1 = struct.unpack_from("<HH", block, 8)
+
+        (code,) = struct.unpack_from("<I", block, 12)
+
+        r0, g0, b0 = unpack_565(color0)
+        r1, g1, b1 = unpack_565(color1)
+
+        for j in range(4):
+            high = False  # Do we want the higher bits?
+            for i in range(4):
+                alphacode_index = (4 * j + i) // 2
+                a = bits[alphacode_index]
+                if high:
+                    high = False
+                    a >>= 4
+                else:
+                    high = True
+                    a &= 0xF
+                a *= 17  # We get a value between 0 and 15
+
+                color_code = (code >> 2 * (4 * j + i)) & 0x03
+
+                if color_code == 0:
+                    r, g, b = r0, g0, b0
+                elif color_code == 1:
+                    r, g, b = r1, g1, b1
+                elif color_code == 2:
+                    r = (2 * r0 + r1) // 3
+                    g = (2 * g0 + g1) // 3
+                    b = (2 * b0 + b1) // 3
+                elif color_code == 3:
+                    r = (2 * r1 + r0) // 3
+                    g = (2 * g1 + g0) // 3
+                    b = (2 * b1 + b0) // 3
+
+                ret[j].extend([r, g, b, a])
+
+    return ret
+
+
+def decode_dxt5(data):
+    """
+    input: one "row" of data (i.e. will produce 4 * width pixels)
+    """
+
+    blocks = len(data) // 16  # number of blocks in row
+    ret = (bytearray(), bytearray(), bytearray(), bytearray())
+
+    for block in range(blocks):
+        idx = block * 16
+        block = data[idx : idx + 16]
+        # Decode next 16-byte block.
+        a0, a1 = struct.unpack_from("<BB", block)
+
+        bits = struct.unpack_from("<6B", block, 2)
+        alphacode1 = bits[2] | (bits[3] << 8) | (bits[4] << 16) | (bits[5] << 24)
+        alphacode2 = bits[0] | (bits[1] << 8)
+
+        color0, color1 = struct.unpack_from("<HH", block, 8)
+
+        (code,) = struct.unpack_from("<I", block, 12)
+
+        r0, g0, b0 = unpack_565(color0)
+        r1, g1, b1 = unpack_565(color1)
+
+        for j in range(4):
+            for i in range(4):
+                # get next control op and generate a pixel
+                alphacode_index = 3 * (4 * j + i)
+
+                if alphacode_index <= 12:
+                    alphacode = (alphacode2 >> alphacode_index) & 0x07
+                elif alphacode_index == 15:
+                    alphacode = (alphacode2 >> 15) | ((alphacode1 << 1) & 0x06)
+                else:  # alphacode_index >= 18 and alphacode_index <= 45
+                    alphacode = (alphacode1 >> (alphacode_index - 16)) & 0x07
+
+                if alphacode == 0:
+                    a = a0
+                elif alphacode == 1:
+                    a = a1
+                elif a0 > a1:
+                    a = ((8 - alphacode) * a0 + (alphacode - 1) * a1) // 7
+                elif alphacode == 6:
+                    a = 0
+                elif alphacode == 7:
+                    a = 255
+                else:
+                    a = ((6 - alphacode) * a0 + (alphacode - 1) * a1) // 5
+
+                color_code = (code >> 2 * (4 * j + i)) & 0x03
+
+                if color_code == 0:
+                    r, g, b = r0, g0, b0
+                elif color_code == 1:
+                    r, g, b = r1, g1, b1
+                elif color_code == 2:
+                    r = (2 * r0 + r1) // 3
+                    g = (2 * g0 + g1) // 3
+                    b = (2 * b0 + b1) // 3
+                elif color_code == 3:
+                    r = (2 * r1 + r0) // 3
+                    g = (2 * g1 + g0) // 3
+                    b = (2 * b1 + b0) // 3
+
+                ret[j].extend([r, g, b, a])
+
+    return ret
+
+
+class BLPFormatError(NotImplementedError):
+    pass
+
+
+class BlpImageFile(ImageFile.ImageFile):
+    """
+    Blizzard Mipmap Format
+    """
+
+    format = "BLP"
+    format_description = "Blizzard Mipmap Format"
+
+    def _open(self):
+        self.magic = self.fp.read(4)
+        self._read_blp_header()
+
+        if self.magic == b"BLP1":
+            decoder = "BLP1"
+            self.mode = "RGB"
+        elif self.magic == b"BLP2":
+            decoder = "BLP2"
+            self.mode = "RGBA" if self._blp_alpha_depth else "RGB"
+        else:
+            raise BLPFormatError(f"Bad BLP magic {repr(self.magic)}")
+
+        self.tile = [(decoder, (0, 0) + self.size, 0, (self.mode, 0, 1))]
+
+    def _read_blp_header(self):
+        (self._blp_compression,) = struct.unpack("<i", self.fp.read(4))
+
+        (self._blp_encoding,) = struct.unpack("<b", self.fp.read(1))
+        (self._blp_alpha_depth,) = struct.unpack("<b", self.fp.read(1))
+        (self._blp_alpha_encoding,) = struct.unpack("<b", self.fp.read(1))
+        (self._blp_mips,) = struct.unpack("<b", self.fp.read(1))
+
+        self._size = struct.unpack("<II", self.fp.read(8))
+
+        if self.magic == b"BLP1":
+            # Only present for BLP1
+            (self._blp_encoding,) = struct.unpack("<i", self.fp.read(4))
+            (self._blp_subtype,) = struct.unpack("<i", self.fp.read(4))
+
+        self._blp_offsets = struct.unpack("<16I", self.fp.read(16 * 4))
+        self._blp_lengths = struct.unpack("<16I", self.fp.read(16 * 4))
+
+
+class _BLPBaseDecoder(ImageFile.PyDecoder):
+    _pulls_fd = True
+
+    def decode(self, buffer):
+        try:
+            self.fd.seek(0)
+            self.magic = self.fd.read(4)
+            self._read_blp_header()
+            self._load()
+        except struct.error as e:
+            raise OSError("Truncated Blp file") from e
+        return 0, 0
+
+    def _safe_read(self, length):
+        return ImageFile._safe_read(self.fd, length)
+
+    def _read_palette(self):
+        ret = []
+        for i in range(256):
+            try:
+                b, g, r, a = struct.unpack("<4B", self._safe_read(4))
+            except struct.error:
+                break
+            ret.append((b, g, r, a))
+        return ret
+
+    def _read_blp_header(self):
+        (self._blp_compression,) = struct.unpack("<i", self._safe_read(4))
+
+        (self._blp_encoding,) = struct.unpack("<b", self._safe_read(1))
+        (self._blp_alpha_depth,) = struct.unpack("<b", self._safe_read(1))
+        (self._blp_alpha_encoding,) = struct.unpack("<b", self._safe_read(1))
+        (self._blp_mips,) = struct.unpack("<b", self._safe_read(1))
+
+        self.size = struct.unpack("<II", self._safe_read(8))
+
+        if self.magic == b"BLP1":
+            # Only present for BLP1
+            (self._blp_encoding,) = struct.unpack("<i", self._safe_read(4))
+            (self._blp_subtype,) = struct.unpack("<i", self._safe_read(4))
+
+        self._blp_offsets = struct.unpack("<16I", self._safe_read(16 * 4))
+        self._blp_lengths = struct.unpack("<16I", self._safe_read(16 * 4))
+
+
+class BLP1Decoder(_BLPBaseDecoder):
+    def _load(self):
+        if self._blp_compression == BLP_FORMAT_JPEG:
+            self._decode_jpeg_stream()
+
+        elif self._blp_compression == 1:
+            if self._blp_encoding in (4, 5):
+                data = bytearray()
+                palette = self._read_palette()
+                _data = BytesIO(self._safe_read(self._blp_lengths[0]))
+                while True:
+                    try:
+                        (offset,) = struct.unpack("<B", _data.read(1))
+                    except struct.error:
+                        break
+                    b, g, r, a = palette[offset]
+                    data.extend([r, g, b])
+
+                self.set_as_raw(bytes(data))
+            else:
+                raise BLPFormatError(
+                    f"Unsupported BLP encoding {repr(self._blp_encoding)}"
+                )
+        else:
+            raise BLPFormatError(
+                f"Unsupported BLP compression {repr(self._blp_encoding)}"
+            )
+
+    def _decode_jpeg_stream(self):
+        from PIL.JpegImagePlugin import JpegImageFile
+
+        (jpeg_header_size,) = struct.unpack("<I", self._safe_read(4))
+        jpeg_header = self._safe_read(jpeg_header_size)
+        self._safe_read(self._blp_offsets[0] - self.fd.tell())  # What IS this?
+        data = self._safe_read(self._blp_lengths[0])
+        data = jpeg_header + data
+        data = BytesIO(data)
+        image = JpegImageFile(data)
+        Image._decompression_bomb_check(image.size)
+        self.tile = image.tile  # :/
+        self.fd = image.fp
+        self.mode = image.mode
+
+
+class BLP2Decoder(_BLPBaseDecoder):
+    def _load(self):
+        palette = self._read_palette()
+
+        data = bytearray()
+        self.fd.seek(self._blp_offsets[0])
+
+        if self._blp_compression == 1:
+            # Uncompressed or DirectX compression
+
+            if self._blp_encoding == BLP_ENCODING_UNCOMPRESSED:
+                _data = BytesIO(self._safe_read(self._blp_lengths[0]))
+                while True:
+                    try:
+                        (offset,) = struct.unpack("<B", _data.read(1))
+                    except struct.error:
+                        break
+                    b, g, r, a = palette[offset]
+                    data.extend((r, g, b))
+
+            elif self._blp_encoding == BLP_ENCODING_DXT:
+                if self._blp_alpha_encoding == BLP_ALPHA_ENCODING_DXT1:
+                    linesize = (self.size[0] + 3) // 4 * 8
+                    for yb in range((self.size[1] + 3) // 4):
+                        for d in decode_dxt1(
+                            self._safe_read(linesize), alpha=bool(self._blp_alpha_depth)
+                        ):
+                            data += d
+
+                elif self._blp_alpha_encoding == BLP_ALPHA_ENCODING_DXT3:
+                    linesize = (self.size[0] + 3) // 4 * 16
+                    for yb in range((self.size[1] + 3) // 4):
+                        for d in decode_dxt3(self._safe_read(linesize)):
+                            data += d
+
+                elif self._blp_alpha_encoding == BLP_ALPHA_ENCODING_DXT5:
+                    linesize = (self.size[0] + 3) // 4 * 16
+                    for yb in range((self.size[1] + 3) // 4):
+                        for d in decode_dxt5(self._safe_read(linesize)):
+                            data += d
+                else:
+                    raise BLPFormatError(
+                        f"Unsupported alpha encoding {repr(self._blp_alpha_encoding)}"
+                    )
+            else:
+                raise BLPFormatError(f"Unknown BLP encoding {repr(self._blp_encoding)}")
+
+        else:
+            raise BLPFormatError(
+                f"Unknown BLP compression {repr(self._blp_compression)}"
+            )
+
+        self.set_as_raw(bytes(data))
+
+
+def _accept(prefix):
+    return prefix[:4] in (b"BLP1", b"BLP2")
+
+
+Image.register_open(BlpImageFile.format, BlpImageFile, _accept)
+Image.register_extension(BlpImageFile.format, ".blp")
+
+Image.register_decoder("BLP1", BLP1Decoder)
+Image.register_decoder("BLP2", BLP2Decoder)
diff --git a/.venv/lib/python3.7/site-packages/PIL/BmpImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/BmpImagePlugin.py
new file mode 100644
index 0000000..7a7ad38
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/BmpImagePlugin.py
@@ -0,0 +1,380 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# BMP file handler
+#
+# Windows (and OS/2) native bitmap storage format.
+#
+# history:
+# 1995-09-01 fl   Created
+# 1996-04-30 fl   Added save
+# 1997-08-27 fl   Fixed save of 1-bit images
+# 1998-03-06 fl   Load P images as L where possible
+# 1998-07-03 fl   Load P images as 1 where possible
+# 1998-12-29 fl   Handle small palettes
+# 2002-12-30 fl   Fixed load of 1-bit palette images
+# 2003-04-21 fl   Fixed load of 1-bit monochrome images
+# 2003-04-23 fl   Added limited support for BI_BITFIELDS compression
+#
+# Copyright (c) 1997-2003 by Secret Labs AB
+# Copyright (c) 1995-2003 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+
+from . import Image, ImageFile, ImagePalette
+from ._binary import i16le as i16
+from ._binary import i32le as i32
+from ._binary import o8
+from ._binary import o16le as o16
+from ._binary import o32le as o32
+
+#
+# --------------------------------------------------------------------
+# Read BMP file
+
+BIT2MODE = {
+    # bits => mode, rawmode
+    1: ("P", "P;1"),
+    4: ("P", "P;4"),
+    8: ("P", "P"),
+    16: ("RGB", "BGR;15"),
+    24: ("RGB", "BGR"),
+    32: ("RGB", "BGRX"),
+}
+
+
+def _accept(prefix):
+    return prefix[:2] == b"BM"
+
+
+def _dib_accept(prefix):
+    return i32(prefix) in [12, 40, 64, 108, 124]
+
+
+# =============================================================================
+# Image plugin for the Windows BMP format.
+# =============================================================================
+class BmpImageFile(ImageFile.ImageFile):
+    """Image plugin for the Windows Bitmap format (BMP)"""
+
+    # ------------------------------------------------------------- Description
+    format_description = "Windows Bitmap"
+    format = "BMP"
+
+    # -------------------------------------------------- BMP Compression values
+    COMPRESSIONS = {"RAW": 0, "RLE8": 1, "RLE4": 2, "BITFIELDS": 3, "JPEG": 4, "PNG": 5}
+    for k, v in COMPRESSIONS.items():
+        vars()[k] = v
+
+    def _bitmap(self, header=0, offset=0):
+        """Read relevant info about the BMP"""
+        read, seek = self.fp.read, self.fp.seek
+        if header:
+            seek(header)
+        file_info = {}
+        # read bmp header size @offset 14 (this is part of the header size)
+        file_info["header_size"] = i32(read(4))
+        file_info["direction"] = -1
+
+        # -------------------- If requested, read header at a specific position
+        # read the rest of the bmp header, without its size
+        header_data = ImageFile._safe_read(self.fp, file_info["header_size"] - 4)
+
+        # -------------------------------------------------- IBM OS/2 Bitmap v1
+        # ----- This format has different offsets because of width/height types
+        if file_info["header_size"] == 12:
+            file_info["width"] = i16(header_data, 0)
+            file_info["height"] = i16(header_data, 2)
+            file_info["planes"] = i16(header_data, 4)
+            file_info["bits"] = i16(header_data, 6)
+            file_info["compression"] = self.RAW
+            file_info["palette_padding"] = 3
+
+        # --------------------------------------------- Windows Bitmap v2 to v5
+        # v3, OS/2 v2, v4, v5
+        elif file_info["header_size"] in (40, 64, 108, 124):
+            file_info["y_flip"] = header_data[7] == 0xFF
+            file_info["direction"] = 1 if file_info["y_flip"] else -1
+            file_info["width"] = i32(header_data, 0)
+            file_info["height"] = (
+                i32(header_data, 4)
+                if not file_info["y_flip"]
+                else 2 ** 32 - i32(header_data, 4)
+            )
+            file_info["planes"] = i16(header_data, 8)
+            file_info["bits"] = i16(header_data, 10)
+            file_info["compression"] = i32(header_data, 12)
+            # byte size of pixel data
+            file_info["data_size"] = i32(header_data, 16)
+            file_info["pixels_per_meter"] = (
+                i32(header_data, 20),
+                i32(header_data, 24),
+            )
+            file_info["colors"] = i32(header_data, 28)
+            file_info["palette_padding"] = 4
+            self.info["dpi"] = tuple(x / 39.3701 for x in file_info["pixels_per_meter"])
+            if file_info["compression"] == self.BITFIELDS:
+                if len(header_data) >= 52:
+                    for idx, mask in enumerate(
+                        ["r_mask", "g_mask", "b_mask", "a_mask"]
+                    ):
+                        file_info[mask] = i32(header_data, 36 + idx * 4)
+                else:
+                    # 40 byte headers only have the three components in the
+                    # bitfields masks, ref:
+                    # https://msdn.microsoft.com/en-us/library/windows/desktop/dd183376(v=vs.85).aspx
+                    # See also
+                    # https://github.com/python-pillow/Pillow/issues/1293
+                    # There is a 4th component in the RGBQuad, in the alpha
+                    # location, but it is listed as a reserved component,
+                    # and it is not generally an alpha channel
+                    file_info["a_mask"] = 0x0
+                    for mask in ["r_mask", "g_mask", "b_mask"]:
+                        file_info[mask] = i32(read(4))
+                file_info["rgb_mask"] = (
+                    file_info["r_mask"],
+                    file_info["g_mask"],
+                    file_info["b_mask"],
+                )
+                file_info["rgba_mask"] = (
+                    file_info["r_mask"],
+                    file_info["g_mask"],
+                    file_info["b_mask"],
+                    file_info["a_mask"],
+                )
+        else:
+            raise OSError(f"Unsupported BMP header type ({file_info['header_size']})")
+
+        # ------------------ Special case : header is reported 40, which
+        # ---------------------- is shorter than real size for bpp >= 16
+        self._size = file_info["width"], file_info["height"]
+
+        # ------- If color count was not found in the header, compute from bits
+        file_info["colors"] = (
+            file_info["colors"]
+            if file_info.get("colors", 0)
+            else (1 << file_info["bits"])
+        )
+        if offset == 14 + file_info["header_size"] and file_info["bits"] <= 8:
+            offset += 4 * file_info["colors"]
+
+        # ---------------------- Check bit depth for unusual unsupported values
+        self.mode, raw_mode = BIT2MODE.get(file_info["bits"], (None, None))
+        if self.mode is None:
+            raise OSError(f"Unsupported BMP pixel depth ({file_info['bits']})")
+
+        # ---------------- Process BMP with Bitfields compression (not palette)
+        if file_info["compression"] == self.BITFIELDS:
+            SUPPORTED = {
+                32: [
+                    (0xFF0000, 0xFF00, 0xFF, 0x0),
+                    (0xFF0000, 0xFF00, 0xFF, 0xFF000000),
+                    (0xFF, 0xFF00, 0xFF0000, 0xFF000000),
+                    (0x0, 0x0, 0x0, 0x0),
+                    (0xFF000000, 0xFF0000, 0xFF00, 0x0),
+                ],
+                24: [(0xFF0000, 0xFF00, 0xFF)],
+                16: [(0xF800, 0x7E0, 0x1F), (0x7C00, 0x3E0, 0x1F)],
+            }
+            MASK_MODES = {
+                (32, (0xFF0000, 0xFF00, 0xFF, 0x0)): "BGRX",
+                (32, (0xFF000000, 0xFF0000, 0xFF00, 0x0)): "XBGR",
+                (32, (0xFF, 0xFF00, 0xFF0000, 0xFF000000)): "RGBA",
+                (32, (0xFF0000, 0xFF00, 0xFF, 0xFF000000)): "BGRA",
+                (32, (0x0, 0x0, 0x0, 0x0)): "BGRA",
+                (24, (0xFF0000, 0xFF00, 0xFF)): "BGR",
+                (16, (0xF800, 0x7E0, 0x1F)): "BGR;16",
+                (16, (0x7C00, 0x3E0, 0x1F)): "BGR;15",
+            }
+            if file_info["bits"] in SUPPORTED:
+                if (
+                    file_info["bits"] == 32
+                    and file_info["rgba_mask"] in SUPPORTED[file_info["bits"]]
+                ):
+                    raw_mode = MASK_MODES[(file_info["bits"], file_info["rgba_mask"])]
+                    self.mode = "RGBA" if "A" in raw_mode else self.mode
+                elif (
+                    file_info["bits"] in (24, 16)
+                    and file_info["rgb_mask"] in SUPPORTED[file_info["bits"]]
+                ):
+                    raw_mode = MASK_MODES[(file_info["bits"], file_info["rgb_mask"])]
+                else:
+                    raise OSError("Unsupported BMP bitfields layout")
+            else:
+                raise OSError("Unsupported BMP bitfields layout")
+        elif file_info["compression"] == self.RAW:
+            if file_info["bits"] == 32 and header == 22:  # 32-bit .cur offset
+                raw_mode, self.mode = "BGRA", "RGBA"
+        else:
+            raise OSError(f"Unsupported BMP compression ({file_info['compression']})")
+
+        # --------------- Once the header is processed, process the palette/LUT
+        if self.mode == "P":  # Paletted for 1, 4 and 8 bit images
+
+            # ---------------------------------------------------- 1-bit images
+            if not (0 < file_info["colors"] <= 65536):
+                raise OSError(f"Unsupported BMP Palette size ({file_info['colors']})")
+            else:
+                padding = file_info["palette_padding"]
+                palette = read(padding * file_info["colors"])
+                greyscale = True
+                indices = (
+                    (0, 255)
+                    if file_info["colors"] == 2
+                    else list(range(file_info["colors"]))
+                )
+
+                # ----------------- Check if greyscale and ignore palette if so
+                for ind, val in enumerate(indices):
+                    rgb = palette[ind * padding : ind * padding + 3]
+                    if rgb != o8(val) * 3:
+                        greyscale = False
+
+                # ------- If all colors are grey, white or black, ditch palette
+                if greyscale:
+                    self.mode = "1" if file_info["colors"] == 2 else "L"
+                    raw_mode = self.mode
+                else:
+                    self.mode = "P"
+                    self.palette = ImagePalette.raw(
+                        "BGRX" if padding == 4 else "BGR", palette
+                    )
+
+        # ---------------------------- Finally set the tile data for the plugin
+        self.info["compression"] = file_info["compression"]
+        self.tile = [
+            (
+                "raw",
+                (0, 0, file_info["width"], file_info["height"]),
+                offset or self.fp.tell(),
+                (
+                    raw_mode,
+                    ((file_info["width"] * file_info["bits"] + 31) >> 3) & (~3),
+                    file_info["direction"],
+                ),
+            )
+        ]
+
+    def _open(self):
+        """Open file, check magic number and read header"""
+        # read 14 bytes: magic number, filesize, reserved, header final offset
+        head_data = self.fp.read(14)
+        # choke if the file does not have the required magic bytes
+        if not _accept(head_data):
+            raise SyntaxError("Not a BMP file")
+        # read the start position of the BMP image data (u32)
+        offset = i32(head_data, 10)
+        # load bitmap information (offset=raster info)
+        self._bitmap(offset=offset)
+
+
+# =============================================================================
+# Image plugin for the DIB format (BMP alias)
+# =============================================================================
+class DibImageFile(BmpImageFile):
+
+    format = "DIB"
+    format_description = "Windows Bitmap"
+
+    def _open(self):
+        self._bitmap()
+
+
+#
+# --------------------------------------------------------------------
+# Write BMP file
+
+
+SAVE = {
+    "1": ("1", 1, 2),
+    "L": ("L", 8, 256),
+    "P": ("P", 8, 256),
+    "RGB": ("BGR", 24, 0),
+    "RGBA": ("BGRA", 32, 0),
+}
+
+
+def _dib_save(im, fp, filename):
+    _save(im, fp, filename, False)
+
+
+def _save(im, fp, filename, bitmap_header=True):
+    try:
+        rawmode, bits, colors = SAVE[im.mode]
+    except KeyError as e:
+        raise OSError(f"cannot write mode {im.mode} as BMP") from e
+
+    info = im.encoderinfo
+
+    dpi = info.get("dpi", (96, 96))
+
+    # 1 meter == 39.3701 inches
+    ppm = tuple(map(lambda x: int(x * 39.3701 + 0.5), dpi))
+
+    stride = ((im.size[0] * bits + 7) // 8 + 3) & (~3)
+    header = 40  # or 64 for OS/2 version 2
+    image = stride * im.size[1]
+
+    # bitmap header
+    if bitmap_header:
+        offset = 14 + header + colors * 4
+        file_size = offset + image
+        if file_size > 2 ** 32 - 1:
+            raise ValueError("File size is too large for the BMP format")
+        fp.write(
+            b"BM"  # file type (magic)
+            + o32(file_size)  # file size
+            + o32(0)  # reserved
+            + o32(offset)  # image data offset
+        )
+
+    # bitmap info header
+    fp.write(
+        o32(header)  # info header size
+        + o32(im.size[0])  # width
+        + o32(im.size[1])  # height
+        + o16(1)  # planes
+        + o16(bits)  # depth
+        + o32(0)  # compression (0=uncompressed)
+        + o32(image)  # size of bitmap
+        + o32(ppm[0])  # resolution
+        + o32(ppm[1])  # resolution
+        + o32(colors)  # colors used
+        + o32(colors)  # colors important
+    )
+
+    fp.write(b"\0" * (header - 40))  # padding (for OS/2 format)
+
+    if im.mode == "1":
+        for i in (0, 255):
+            fp.write(o8(i) * 4)
+    elif im.mode == "L":
+        for i in range(256):
+            fp.write(o8(i) * 4)
+    elif im.mode == "P":
+        fp.write(im.im.getpalette("RGB", "BGRX"))
+
+    ImageFile._save(im, fp, [("raw", (0, 0) + im.size, 0, (rawmode, stride, -1))])
+
+
+#
+# --------------------------------------------------------------------
+# Registry
+
+
+Image.register_open(BmpImageFile.format, BmpImageFile, _accept)
+Image.register_save(BmpImageFile.format, _save)
+
+Image.register_extension(BmpImageFile.format, ".bmp")
+
+Image.register_mime(BmpImageFile.format, "image/bmp")
+
+Image.register_open(DibImageFile.format, DibImageFile, _dib_accept)
+Image.register_save(DibImageFile.format, _dib_save)
+
+Image.register_extension(DibImageFile.format, ".dib")
+
+Image.register_mime(DibImageFile.format, "image/bmp")
diff --git a/.venv/lib/python3.7/site-packages/PIL/BufrStubImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/BufrStubImagePlugin.py
new file mode 100644
index 0000000..48f21e1
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/BufrStubImagePlugin.py
@@ -0,0 +1,73 @@
+#
+# The Python Imaging Library
+# $Id$
+#
+# BUFR stub adapter
+#
+# Copyright (c) 1996-2003 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+from . import Image, ImageFile
+
+_handler = None
+
+
+def register_handler(handler):
+    """
+    Install application-specific BUFR image handler.
+
+    :param handler: Handler object.
+    """
+    global _handler
+    _handler = handler
+
+
+# --------------------------------------------------------------------
+# Image adapter
+
+
+def _accept(prefix):
+    return prefix[:4] == b"BUFR" or prefix[:4] == b"ZCZC"
+
+
+class BufrStubImageFile(ImageFile.StubImageFile):
+
+    format = "BUFR"
+    format_description = "BUFR"
+
+    def _open(self):
+
+        offset = self.fp.tell()
+
+        if not _accept(self.fp.read(4)):
+            raise SyntaxError("Not a BUFR file")
+
+        self.fp.seek(offset)
+
+        # make something up
+        self.mode = "F"
+        self._size = 1, 1
+
+        loader = self._load()
+        if loader:
+            loader.open(self)
+
+    def _load(self):
+        return _handler
+
+
+def _save(im, fp, filename):
+    if _handler is None or not hasattr("_handler", "save"):
+        raise OSError("BUFR save handler not installed")
+    _handler.save(im, fp, filename)
+
+
+# --------------------------------------------------------------------
+# Registry
+
+Image.register_open(BufrStubImageFile.format, BufrStubImageFile, _accept)
+Image.register_save(BufrStubImageFile.format, _save)
+
+Image.register_extension(BufrStubImageFile.format, ".bufr")
diff --git a/.venv/lib/python3.7/site-packages/PIL/ContainerIO.py b/.venv/lib/python3.7/site-packages/PIL/ContainerIO.py
new file mode 100644
index 0000000..45e80b3
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ContainerIO.py
@@ -0,0 +1,120 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# a class to read from a container file
+#
+# History:
+# 1995-06-18 fl     Created
+# 1995-09-07 fl     Added readline(), readlines()
+#
+# Copyright (c) 1997-2001 by Secret Labs AB
+# Copyright (c) 1995 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+
+import io
+
+
+class ContainerIO:
+    """
+    A file object that provides read access to a part of an existing
+    file (for example a TAR file).
+    """
+
+    def __init__(self, file, offset, length):
+        """
+        Create file object.
+
+        :param file: Existing file.
+        :param offset: Start of region, in bytes.
+        :param length: Size of region, in bytes.
+        """
+        self.fh = file
+        self.pos = 0
+        self.offset = offset
+        self.length = length
+        self.fh.seek(offset)
+
+    ##
+    # Always false.
+
+    def isatty(self):
+        return False
+
+    def seek(self, offset, mode=io.SEEK_SET):
+        """
+        Move file pointer.
+
+        :param offset: Offset in bytes.
+        :param mode: Starting position. Use 0 for beginning of region, 1
+           for current offset, and 2 for end of region.  You cannot move
+           the pointer outside the defined region.
+        """
+        if mode == 1:
+            self.pos = self.pos + offset
+        elif mode == 2:
+            self.pos = self.length + offset
+        else:
+            self.pos = offset
+        # clamp
+        self.pos = max(0, min(self.pos, self.length))
+        self.fh.seek(self.offset + self.pos)
+
+    def tell(self):
+        """
+        Get current file pointer.
+
+        :returns: Offset from start of region, in bytes.
+        """
+        return self.pos
+
+    def read(self, n=0):
+        """
+        Read data.
+
+        :param n: Number of bytes to read. If omitted or zero,
+            read until end of region.
+        :returns: An 8-bit string.
+        """
+        if n:
+            n = min(n, self.length - self.pos)
+        else:
+            n = self.length - self.pos
+        if not n:  # EOF
+            return b"" if "b" in self.fh.mode else ""
+        self.pos = self.pos + n
+        return self.fh.read(n)
+
+    def readline(self):
+        """
+        Read a line of text.
+
+        :returns: An 8-bit string.
+        """
+        s = b"" if "b" in self.fh.mode else ""
+        newline_character = b"\n" if "b" in self.fh.mode else "\n"
+        while True:
+            c = self.read(1)
+            if not c:
+                break
+            s = s + c
+            if c == newline_character:
+                break
+        return s
+
+    def readlines(self):
+        """
+        Read multiple lines of text.
+
+        :returns: A list of 8-bit strings.
+        """
+        lines = []
+        while True:
+            s = self.readline()
+            if not s:
+                break
+            lines.append(s)
+        return lines
diff --git a/.venv/lib/python3.7/site-packages/PIL/CurImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/CurImagePlugin.py
new file mode 100644
index 0000000..42af5ca
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/CurImagePlugin.py
@@ -0,0 +1,75 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# Windows Cursor support for PIL
+#
+# notes:
+#       uses BmpImagePlugin.py to read the bitmap data.
+#
+# history:
+#       96-05-27 fl     Created
+#
+# Copyright (c) Secret Labs AB 1997.
+# Copyright (c) Fredrik Lundh 1996.
+#
+# See the README file for information on usage and redistribution.
+#
+from . import BmpImagePlugin, Image
+from ._binary import i16le as i16
+from ._binary import i32le as i32
+
+#
+# --------------------------------------------------------------------
+
+
+def _accept(prefix):
+    return prefix[:4] == b"\0\0\2\0"
+
+
+##
+# Image plugin for Windows Cursor files.
+
+
+class CurImageFile(BmpImagePlugin.BmpImageFile):
+
+    format = "CUR"
+    format_description = "Windows Cursor"
+
+    def _open(self):
+
+        offset = self.fp.tell()
+
+        # check magic
+        s = self.fp.read(6)
+        if not _accept(s):
+            raise SyntaxError("not a CUR file")
+
+        # pick the largest cursor in the file
+        m = b""
+        for i in range(i16(s, 4)):
+            s = self.fp.read(16)
+            if not m:
+                m = s
+            elif s[0] > m[0] and s[1] > m[1]:
+                m = s
+        if not m:
+            raise TypeError("No cursors were found")
+
+        # load as bitmap
+        self._bitmap(i32(m, 12) + offset)
+
+        # patch up the bitmap height
+        self._size = self.size[0], self.size[1] // 2
+        d, e, o, a = self.tile[0]
+        self.tile[0] = d, (0, 0) + self.size, o, a
+
+        return
+
+
+#
+# --------------------------------------------------------------------
+
+Image.register_open(CurImageFile.format, CurImageFile, _accept)
+
+Image.register_extension(CurImageFile.format, ".cur")
diff --git a/.venv/lib/python3.7/site-packages/PIL/DcxImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/DcxImagePlugin.py
new file mode 100644
index 0000000..de21db8
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/DcxImagePlugin.py
@@ -0,0 +1,89 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# DCX file handling
+#
+# DCX is a container file format defined by Intel, commonly used
+# for fax applications.  Each DCX file consists of a directory
+# (a list of file offsets) followed by a set of (usually 1-bit)
+# PCX files.
+#
+# History:
+# 1995-09-09 fl   Created
+# 1996-03-20 fl   Properly derived from PcxImageFile.
+# 1998-07-15 fl   Renamed offset attribute to avoid name clash
+# 2002-07-30 fl   Fixed file handling
+#
+# Copyright (c) 1997-98 by Secret Labs AB.
+# Copyright (c) 1995-96 by Fredrik Lundh.
+#
+# See the README file for information on usage and redistribution.
+#
+
+from . import Image
+from ._binary import i32le as i32
+from .PcxImagePlugin import PcxImageFile
+
+MAGIC = 0x3ADE68B1  # QUIZ: what's this value, then?
+
+
+def _accept(prefix):
+    return len(prefix) >= 4 and i32(prefix) == MAGIC
+
+
+##
+# Image plugin for the Intel DCX format.
+
+
+class DcxImageFile(PcxImageFile):
+
+    format = "DCX"
+    format_description = "Intel DCX"
+    _close_exclusive_fp_after_loading = False
+
+    def _open(self):
+
+        # Header
+        s = self.fp.read(4)
+        if not _accept(s):
+            raise SyntaxError("not a DCX file")
+
+        # Component directory
+        self._offset = []
+        for i in range(1024):
+            offset = i32(self.fp.read(4))
+            if not offset:
+                break
+            self._offset.append(offset)
+
+        self.__fp = self.fp
+        self.frame = None
+        self.n_frames = len(self._offset)
+        self.is_animated = self.n_frames > 1
+        self.seek(0)
+
+    def seek(self, frame):
+        if not self._seek_check(frame):
+            return
+        self.frame = frame
+        self.fp = self.__fp
+        self.fp.seek(self._offset[frame])
+        PcxImageFile._open(self)
+
+    def tell(self):
+        return self.frame
+
+    def _close__fp(self):
+        try:
+            if self.__fp != self.fp:
+                self.__fp.close()
+        except AttributeError:
+            pass
+        finally:
+            self.__fp = None
+
+
+Image.register_open(DcxImageFile.format, DcxImageFile, _accept)
+
+Image.register_extension(DcxImageFile.format, ".dcx")
diff --git a/.venv/lib/python3.7/site-packages/PIL/DdsImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/DdsImagePlugin.py
new file mode 100644
index 0000000..260924f
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/DdsImagePlugin.py
@@ -0,0 +1,247 @@
+"""
+A Pillow loader for .dds files (S3TC-compressed aka DXTC)
+Jerome Leclanche <jerome@leclan.ch>
+
+Documentation:
+  https://web.archive.org/web/20170802060935/http://oss.sgi.com/projects/ogl-sample/registry/EXT/texture_compression_s3tc.txt
+
+The contents of this file are hereby released in the public domain (CC0)
+Full text of the CC0 license:
+  https://creativecommons.org/publicdomain/zero/1.0/
+"""
+
+import struct
+from io import BytesIO
+
+from . import Image, ImageFile
+from ._binary import o32le as o32
+
+# Magic ("DDS ")
+DDS_MAGIC = 0x20534444
+
+# DDS flags
+DDSD_CAPS = 0x1
+DDSD_HEIGHT = 0x2
+DDSD_WIDTH = 0x4
+DDSD_PITCH = 0x8
+DDSD_PIXELFORMAT = 0x1000
+DDSD_MIPMAPCOUNT = 0x20000
+DDSD_LINEARSIZE = 0x80000
+DDSD_DEPTH = 0x800000
+
+# DDS caps
+DDSCAPS_COMPLEX = 0x8
+DDSCAPS_TEXTURE = 0x1000
+DDSCAPS_MIPMAP = 0x400000
+
+DDSCAPS2_CUBEMAP = 0x200
+DDSCAPS2_CUBEMAP_POSITIVEX = 0x400
+DDSCAPS2_CUBEMAP_NEGATIVEX = 0x800
+DDSCAPS2_CUBEMAP_POSITIVEY = 0x1000
+DDSCAPS2_CUBEMAP_NEGATIVEY = 0x2000
+DDSCAPS2_CUBEMAP_POSITIVEZ = 0x4000
+DDSCAPS2_CUBEMAP_NEGATIVEZ = 0x8000
+DDSCAPS2_VOLUME = 0x200000
+
+# Pixel Format
+DDPF_ALPHAPIXELS = 0x1
+DDPF_ALPHA = 0x2
+DDPF_FOURCC = 0x4
+DDPF_PALETTEINDEXED8 = 0x20
+DDPF_RGB = 0x40
+DDPF_LUMINANCE = 0x20000
+
+
+# dds.h
+
+DDS_FOURCC = DDPF_FOURCC
+DDS_RGB = DDPF_RGB
+DDS_RGBA = DDPF_RGB | DDPF_ALPHAPIXELS
+DDS_LUMINANCE = DDPF_LUMINANCE
+DDS_LUMINANCEA = DDPF_LUMINANCE | DDPF_ALPHAPIXELS
+DDS_ALPHA = DDPF_ALPHA
+DDS_PAL8 = DDPF_PALETTEINDEXED8
+
+DDS_HEADER_FLAGS_TEXTURE = DDSD_CAPS | DDSD_HEIGHT | DDSD_WIDTH | DDSD_PIXELFORMAT
+DDS_HEADER_FLAGS_MIPMAP = DDSD_MIPMAPCOUNT
+DDS_HEADER_FLAGS_VOLUME = DDSD_DEPTH
+DDS_HEADER_FLAGS_PITCH = DDSD_PITCH
+DDS_HEADER_FLAGS_LINEARSIZE = DDSD_LINEARSIZE
+
+DDS_HEIGHT = DDSD_HEIGHT
+DDS_WIDTH = DDSD_WIDTH
+
+DDS_SURFACE_FLAGS_TEXTURE = DDSCAPS_TEXTURE
+DDS_SURFACE_FLAGS_MIPMAP = DDSCAPS_COMPLEX | DDSCAPS_MIPMAP
+DDS_SURFACE_FLAGS_CUBEMAP = DDSCAPS_COMPLEX
+
+DDS_CUBEMAP_POSITIVEX = DDSCAPS2_CUBEMAP | DDSCAPS2_CUBEMAP_POSITIVEX
+DDS_CUBEMAP_NEGATIVEX = DDSCAPS2_CUBEMAP | DDSCAPS2_CUBEMAP_NEGATIVEX
+DDS_CUBEMAP_POSITIVEY = DDSCAPS2_CUBEMAP | DDSCAPS2_CUBEMAP_POSITIVEY
+DDS_CUBEMAP_NEGATIVEY = DDSCAPS2_CUBEMAP | DDSCAPS2_CUBEMAP_NEGATIVEY
+DDS_CUBEMAP_POSITIVEZ = DDSCAPS2_CUBEMAP | DDSCAPS2_CUBEMAP_POSITIVEZ
+DDS_CUBEMAP_NEGATIVEZ = DDSCAPS2_CUBEMAP | DDSCAPS2_CUBEMAP_NEGATIVEZ
+
+
+# DXT1
+DXT1_FOURCC = 0x31545844
+
+# DXT3
+DXT3_FOURCC = 0x33545844
+
+# DXT5
+DXT5_FOURCC = 0x35545844
+
+
+# dxgiformat.h
+
+DXGI_FORMAT_R8G8B8A8_TYPELESS = 27
+DXGI_FORMAT_R8G8B8A8_UNORM = 28
+DXGI_FORMAT_R8G8B8A8_UNORM_SRGB = 29
+DXGI_FORMAT_BC5_TYPELESS = 82
+DXGI_FORMAT_BC5_UNORM = 83
+DXGI_FORMAT_BC5_SNORM = 84
+DXGI_FORMAT_BC7_TYPELESS = 97
+DXGI_FORMAT_BC7_UNORM = 98
+DXGI_FORMAT_BC7_UNORM_SRGB = 99
+
+
+class DdsImageFile(ImageFile.ImageFile):
+    format = "DDS"
+    format_description = "DirectDraw Surface"
+
+    def _open(self):
+        magic, header_size = struct.unpack("<II", self.fp.read(8))
+        if header_size != 124:
+            raise OSError(f"Unsupported header size {repr(header_size)}")
+        header_bytes = self.fp.read(header_size - 4)
+        if len(header_bytes) != 120:
+            raise OSError(f"Incomplete header: {len(header_bytes)} bytes")
+        header = BytesIO(header_bytes)
+
+        flags, height, width = struct.unpack("<3I", header.read(12))
+        self._size = (width, height)
+        self.mode = "RGBA"
+
+        pitch, depth, mipmaps = struct.unpack("<3I", header.read(12))
+        struct.unpack("<11I", header.read(44))  # reserved
+
+        # pixel format
+        pfsize, pfflags = struct.unpack("<2I", header.read(8))
+        fourcc = header.read(4)
+        (bitcount,) = struct.unpack("<I", header.read(4))
+        masks = struct.unpack("<4I", header.read(16))
+        if pfflags & DDPF_RGB:
+            # Texture contains uncompressed RGB data
+            masks = {mask: ["R", "G", "B", "A"][i] for i, mask in enumerate(masks)}
+            rawmode = ""
+            if bitcount == 32:
+                rawmode += masks[0xFF000000]
+            else:
+                self.mode = "RGB"
+            rawmode += masks[0xFF0000] + masks[0xFF00] + masks[0xFF]
+
+            self.tile = [("raw", (0, 0) + self.size, 0, (rawmode[::-1], 0, 1))]
+        else:
+            data_start = header_size + 4
+            n = 0
+            if fourcc == b"DXT1":
+                self.pixel_format = "DXT1"
+                n = 1
+            elif fourcc == b"DXT3":
+                self.pixel_format = "DXT3"
+                n = 2
+            elif fourcc == b"DXT5":
+                self.pixel_format = "DXT5"
+                n = 3
+            elif fourcc == b"BC5S":
+                self.pixel_format = "BC5S"
+                n = 5
+                self.mode = "RGB"
+            elif fourcc == b"DX10":
+                data_start += 20
+                # ignoring flags which pertain to volume textures and cubemaps
+                (dxgi_format,) = struct.unpack("<I", self.fp.read(4))
+                self.fp.read(16)
+                if dxgi_format in (DXGI_FORMAT_BC5_TYPELESS, DXGI_FORMAT_BC5_UNORM):
+                    self.pixel_format = "BC5"
+                    n = 5
+                    self.mode = "RGB"
+                elif dxgi_format == DXGI_FORMAT_BC5_SNORM:
+                    self.pixel_format = "BC5S"
+                    n = 5
+                    self.mode = "RGB"
+                elif dxgi_format in (DXGI_FORMAT_BC7_TYPELESS, DXGI_FORMAT_BC7_UNORM):
+                    self.pixel_format = "BC7"
+                    n = 7
+                elif dxgi_format == DXGI_FORMAT_BC7_UNORM_SRGB:
+                    self.pixel_format = "BC7"
+                    self.info["gamma"] = 1 / 2.2
+                    n = 7
+                elif dxgi_format in (
+                    DXGI_FORMAT_R8G8B8A8_TYPELESS,
+                    DXGI_FORMAT_R8G8B8A8_UNORM,
+                    DXGI_FORMAT_R8G8B8A8_UNORM_SRGB,
+                ):
+                    self.tile = [("raw", (0, 0) + self.size, 0, ("RGBA", 0, 1))]
+                    if dxgi_format == DXGI_FORMAT_R8G8B8A8_UNORM_SRGB:
+                        self.info["gamma"] = 1 / 2.2
+                    return
+                else:
+                    raise NotImplementedError(
+                        f"Unimplemented DXGI format {dxgi_format}"
+                    )
+            else:
+                raise NotImplementedError(f"Unimplemented pixel format {repr(fourcc)}")
+
+            self.tile = [
+                ("bcn", (0, 0) + self.size, data_start, (n, self.pixel_format))
+            ]
+
+    def load_seek(self, pos):
+        pass
+
+
+def _save(im, fp, filename):
+    if im.mode not in ("RGB", "RGBA"):
+        raise OSError(f"cannot write mode {im.mode} as DDS")
+
+    fp.write(
+        o32(DDS_MAGIC)
+        + o32(124)  # header size
+        + o32(
+            DDSD_CAPS | DDSD_HEIGHT | DDSD_WIDTH | DDSD_PITCH | DDSD_PIXELFORMAT
+        )  # flags
+        + o32(im.height)
+        + o32(im.width)
+        + o32((im.width * (32 if im.mode == "RGBA" else 24) + 7) // 8)  # pitch
+        + o32(0)  # depth
+        + o32(0)  # mipmaps
+        + o32(0) * 11  # reserved
+        + o32(32)  # pfsize
+        + o32(DDS_RGBA if im.mode == "RGBA" else DDPF_RGB)  # pfflags
+        + o32(0)  # fourcc
+        + o32(32 if im.mode == "RGBA" else 24)  # bitcount
+        + o32(0xFF0000)  # rbitmask
+        + o32(0xFF00)  # gbitmask
+        + o32(0xFF)  # bbitmask
+        + o32(0xFF000000 if im.mode == "RGBA" else 0)  # abitmask
+        + o32(DDSCAPS_TEXTURE)  # dwCaps
+        + o32(0)  # dwCaps2
+        + o32(0)  # dwCaps3
+        + o32(0)  # dwCaps4
+        + o32(0)  # dwReserved2
+    )
+    if im.mode == "RGBA":
+        r, g, b, a = im.split()
+        im = Image.merge("RGBA", (a, r, g, b))
+    ImageFile._save(im, fp, [("raw", (0, 0) + im.size, 0, (im.mode[::-1], 0, 1))])
+
+
+def _accept(prefix):
+    return prefix[:4] == b"DDS "
+
+
+Image.register_open(DdsImageFile.format, DdsImageFile, _accept)
+Image.register_save(DdsImageFile.format, _save)
+Image.register_extension(DdsImageFile.format, ".dds")
diff --git a/.venv/lib/python3.7/site-packages/PIL/EpsImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/EpsImagePlugin.py
new file mode 100644
index 0000000..5d99202
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/EpsImagePlugin.py
@@ -0,0 +1,411 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# EPS file handling
+#
+# History:
+# 1995-09-01 fl   Created (0.1)
+# 1996-05-18 fl   Don't choke on "atend" fields, Ghostscript interface (0.2)
+# 1996-08-22 fl   Don't choke on floating point BoundingBox values
+# 1996-08-23 fl   Handle files from Macintosh (0.3)
+# 2001-02-17 fl   Use 're' instead of 'regex' (Python 2.1) (0.4)
+# 2003-09-07 fl   Check gs.close status (from Federico Di Gregorio) (0.5)
+# 2014-05-07 e    Handling of EPS with binary preview and fixed resolution
+#                 resizing
+#
+# Copyright (c) 1997-2003 by Secret Labs AB.
+# Copyright (c) 1995-2003 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+import io
+import os
+import re
+import subprocess
+import sys
+import tempfile
+
+from . import Image, ImageFile
+from ._binary import i32le as i32
+
+#
+# --------------------------------------------------------------------
+
+split = re.compile(r"^%%([^:]*):[ \t]*(.*)[ \t]*$")
+field = re.compile(r"^%[%!\w]([^:]*)[ \t]*$")
+
+gs_windows_binary = None
+if sys.platform.startswith("win"):
+    import shutil
+
+    for binary in ("gswin32c", "gswin64c", "gs"):
+        if shutil.which(binary) is not None:
+            gs_windows_binary = binary
+            break
+    else:
+        gs_windows_binary = False
+
+
+def has_ghostscript():
+    if gs_windows_binary:
+        return True
+    if not sys.platform.startswith("win"):
+        try:
+            subprocess.check_call(["gs", "--version"], stdout=subprocess.DEVNULL)
+            return True
+        except OSError:
+            # No Ghostscript
+            pass
+    return False
+
+
+def Ghostscript(tile, size, fp, scale=1, transparency=False):
+    """Render an image using Ghostscript"""
+
+    # Unpack decoder tile
+    decoder, tile, offset, data = tile[0]
+    length, bbox = data
+
+    # Hack to support hi-res rendering
+    scale = int(scale) or 1
+    # orig_size = size
+    # orig_bbox = bbox
+    size = (size[0] * scale, size[1] * scale)
+    # resolution is dependent on bbox and size
+    res = (
+        72.0 * size[0] / (bbox[2] - bbox[0]),
+        72.0 * size[1] / (bbox[3] - bbox[1]),
+    )
+
+    out_fd, outfile = tempfile.mkstemp()
+    os.close(out_fd)
+
+    infile_temp = None
+    if hasattr(fp, "name") and os.path.exists(fp.name):
+        infile = fp.name
+    else:
+        in_fd, infile_temp = tempfile.mkstemp()
+        os.close(in_fd)
+        infile = infile_temp
+
+        # Ignore length and offset!
+        # Ghostscript can read it
+        # Copy whole file to read in Ghostscript
+        with open(infile_temp, "wb") as f:
+            # fetch length of fp
+            fp.seek(0, io.SEEK_END)
+            fsize = fp.tell()
+            # ensure start position
+            # go back
+            fp.seek(0)
+            lengthfile = fsize
+            while lengthfile > 0:
+                s = fp.read(min(lengthfile, 100 * 1024))
+                if not s:
+                    break
+                lengthfile -= len(s)
+                f.write(s)
+
+    device = "pngalpha" if transparency else "ppmraw"
+
+    # Build Ghostscript command
+    command = [
+        "gs",
+        "-q",  # quiet mode
+        "-g%dx%d" % size,  # set output geometry (pixels)
+        "-r%fx%f" % res,  # set input DPI (dots per inch)
+        "-dBATCH",  # exit after processing
+        "-dNOPAUSE",  # don't pause between pages
+        "-dSAFER",  # safe mode
+        f"-sDEVICE={device}",
+        f"-sOutputFile={outfile}",  # output file
+        # adjust for image origin
+        "-c",
+        f"{-bbox[0]} {-bbox[1]} translate",
+        "-f",
+        infile,  # input file
+        # showpage (see https://bugs.ghostscript.com/show_bug.cgi?id=698272)
+        "-c",
+        "showpage",
+    ]
+
+    if gs_windows_binary is not None:
+        if not gs_windows_binary:
+            raise OSError("Unable to locate Ghostscript on paths")
+        command[0] = gs_windows_binary
+
+    # push data through Ghostscript
+    try:
+        startupinfo = None
+        if sys.platform.startswith("win"):
+            startupinfo = subprocess.STARTUPINFO()
+            startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
+        subprocess.check_call(command, startupinfo=startupinfo)
+        out_im = Image.open(outfile)
+        out_im.load()
+    finally:
+        try:
+            os.unlink(outfile)
+            if infile_temp:
+                os.unlink(infile_temp)
+        except OSError:
+            pass
+
+    im = out_im.im.copy()
+    out_im.close()
+    return im
+
+
+class PSFile:
+    """
+    Wrapper for bytesio object that treats either CR or LF as end of line.
+    """
+
+    def __init__(self, fp):
+        self.fp = fp
+        self.char = None
+
+    def seek(self, offset, whence=io.SEEK_SET):
+        self.char = None
+        self.fp.seek(offset, whence)
+
+    def readline(self):
+        s = [self.char or b""]
+        self.char = None
+
+        c = self.fp.read(1)
+        while (c not in b"\r\n") and len(c):
+            s.append(c)
+            c = self.fp.read(1)
+
+        self.char = self.fp.read(1)
+        # line endings can be 1 or 2 of \r \n, in either order
+        if self.char in b"\r\n":
+            self.char = None
+
+        return b"".join(s).decode("latin-1")
+
+
+def _accept(prefix):
+    return prefix[:4] == b"%!PS" or (len(prefix) >= 4 and i32(prefix) == 0xC6D3D0C5)
+
+
+##
+# Image plugin for Encapsulated PostScript.  This plugin supports only
+# a few variants of this format.
+
+
+class EpsImageFile(ImageFile.ImageFile):
+    """EPS File Parser for the Python Imaging Library"""
+
+    format = "EPS"
+    format_description = "Encapsulated Postscript"
+
+    mode_map = {1: "L", 2: "LAB", 3: "RGB", 4: "CMYK"}
+
+    def _open(self):
+        (length, offset) = self._find_offset(self.fp)
+
+        # Rewrap the open file pointer in something that will
+        # convert line endings and decode to latin-1.
+        fp = PSFile(self.fp)
+
+        # go to offset - start of "%!PS"
+        fp.seek(offset)
+
+        box = None
+
+        self.mode = "RGB"
+        self._size = 1, 1  # FIXME: huh?
+
+        #
+        # Load EPS header
+
+        s_raw = fp.readline()
+        s = s_raw.strip("\r\n")
+
+        while s_raw:
+            if s:
+                if len(s) > 255:
+                    raise SyntaxError("not an EPS file")
+
+                try:
+                    m = split.match(s)
+                except re.error as e:
+                    raise SyntaxError("not an EPS file") from e
+
+                if m:
+                    k, v = m.group(1, 2)
+                    self.info[k] = v
+                    if k == "BoundingBox":
+                        try:
+                            # Note: The DSC spec says that BoundingBox
+                            # fields should be integers, but some drivers
+                            # put floating point values there anyway.
+                            box = [int(float(i)) for i in v.split()]
+                            self._size = box[2] - box[0], box[3] - box[1]
+                            self.tile = [
+                                ("eps", (0, 0) + self.size, offset, (length, box))
+                            ]
+                        except Exception:
+                            pass
+
+                else:
+                    m = field.match(s)
+                    if m:
+                        k = m.group(1)
+
+                        if k == "EndComments":
+                            break
+                        if k[:8] == "PS-Adobe":
+                            self.info[k[:8]] = k[9:]
+                        else:
+                            self.info[k] = ""
+                    elif s[0] == "%":
+                        # handle non-DSC PostScript comments that some
+                        # tools mistakenly put in the Comments section
+                        pass
+                    else:
+                        raise OSError("bad EPS header")
+
+            s_raw = fp.readline()
+            s = s_raw.strip("\r\n")
+
+            if s and s[:1] != "%":
+                break
+
+        #
+        # Scan for an "ImageData" descriptor
+
+        while s[:1] == "%":
+
+            if len(s) > 255:
+                raise SyntaxError("not an EPS file")
+
+            if s[:11] == "%ImageData:":
+                # Encoded bitmapped image.
+                x, y, bi, mo = s[11:].split(None, 7)[:4]
+
+                if int(bi) != 8:
+                    break
+                try:
+                    self.mode = self.mode_map[int(mo)]
+                except ValueError:
+                    break
+
+                self._size = int(x), int(y)
+                return
+
+            s = fp.readline().strip("\r\n")
+            if not s:
+                break
+
+        if not box:
+            raise OSError("cannot determine EPS bounding box")
+
+    def _find_offset(self, fp):
+
+        s = fp.read(160)
+
+        if s[:4] == b"%!PS":
+            # for HEAD without binary preview
+            fp.seek(0, io.SEEK_END)
+            length = fp.tell()
+            offset = 0
+        elif i32(s, 0) == 0xC6D3D0C5:
+            # FIX for: Some EPS file not handled correctly / issue #302
+            # EPS can contain binary data
+            # or start directly with latin coding
+            # more info see:
+            # https://web.archive.org/web/20160528181353/http://partners.adobe.com/public/developer/en/ps/5002.EPSF_Spec.pdf
+            offset = i32(s, 4)
+            length = i32(s, 8)
+        else:
+            raise SyntaxError("not an EPS file")
+
+        return (length, offset)
+
+    def load(self, scale=1, transparency=False):
+        # Load EPS via Ghostscript
+        if not self.tile:
+            return
+        self.im = Ghostscript(self.tile, self.size, self.fp, scale, transparency)
+        self.mode = self.im.mode
+        self._size = self.im.size
+        self.tile = []
+
+    def load_seek(self, *args, **kwargs):
+        # we can't incrementally load, so force ImageFile.parser to
+        # use our custom load method by defining this method.
+        pass
+
+
+#
+# --------------------------------------------------------------------
+
+
+def _save(im, fp, filename, eps=1):
+    """EPS Writer for the Python Imaging Library."""
+
+    #
+    # make sure image data is available
+    im.load()
+
+    #
+    # determine PostScript image mode
+    if im.mode == "L":
+        operator = (8, 1, b"image")
+    elif im.mode == "RGB":
+        operator = (8, 3, b"false 3 colorimage")
+    elif im.mode == "CMYK":
+        operator = (8, 4, b"false 4 colorimage")
+    else:
+        raise ValueError("image mode is not supported")
+
+    if eps:
+        #
+        # write EPS header
+        fp.write(b"%!PS-Adobe-3.0 EPSF-3.0\n")
+        fp.write(b"%%Creator: PIL 0.1 EpsEncode\n")
+        # fp.write("%%CreationDate: %s"...)
+        fp.write(b"%%%%BoundingBox: 0 0 %d %d\n" % im.size)
+        fp.write(b"%%Pages: 1\n")
+        fp.write(b"%%EndComments\n")
+        fp.write(b"%%Page: 1 1\n")
+        fp.write(b"%%ImageData: %d %d " % im.size)
+        fp.write(b'%d %d 0 1 1 "%s"\n' % operator)
+
+    #
+    # image header
+    fp.write(b"gsave\n")
+    fp.write(b"10 dict begin\n")
+    fp.write(b"/buf %d string def\n" % (im.size[0] * operator[1]))
+    fp.write(b"%d %d scale\n" % im.size)
+    fp.write(b"%d %d 8\n" % im.size)  # <= bits
+    fp.write(b"[%d 0 0 -%d 0 %d]\n" % (im.size[0], im.size[1], im.size[1]))
+    fp.write(b"{ currentfile buf readhexstring pop } bind\n")
+    fp.write(operator[2] + b"\n")
+    if hasattr(fp, "flush"):
+        fp.flush()
+
+    ImageFile._save(im, fp, [("eps", (0, 0) + im.size, 0, None)])
+
+    fp.write(b"\n%%%%EndBinary\n")
+    fp.write(b"grestore end\n")
+    if hasattr(fp, "flush"):
+        fp.flush()
+
+
+#
+# --------------------------------------------------------------------
+
+
+Image.register_open(EpsImageFile.format, EpsImageFile, _accept)
+
+Image.register_save(EpsImageFile.format, _save)
+
+Image.register_extensions(EpsImageFile.format, [".ps", ".eps"])
+
+Image.register_mime(EpsImageFile.format, "application/postscript")
diff --git a/.venv/lib/python3.7/site-packages/PIL/ExifTags.py b/.venv/lib/python3.7/site-packages/PIL/ExifTags.py
new file mode 100644
index 0000000..7da2dda
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ExifTags.py
@@ -0,0 +1,331 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# EXIF tags
+#
+# Copyright (c) 2003 by Secret Labs AB
+#
+# See the README file for information on usage and redistribution.
+#
+
+"""
+This module provides constants and clear-text names for various
+well-known EXIF tags.
+"""
+
+
+TAGS = {
+    # possibly incomplete
+    0x0001: "InteropIndex",
+    0x000B: "ProcessingSoftware",
+    0x00FE: "NewSubfileType",
+    0x00FF: "SubfileType",
+    0x0100: "ImageWidth",
+    0x0101: "ImageLength",
+    0x0102: "BitsPerSample",
+    0x0103: "Compression",
+    0x0106: "PhotometricInterpretation",
+    0x0107: "Thresholding",
+    0x0108: "CellWidth",
+    0x0109: "CellLength",
+    0x010A: "FillOrder",
+    0x010D: "DocumentName",
+    0x010E: "ImageDescription",
+    0x010F: "Make",
+    0x0110: "Model",
+    0x0111: "StripOffsets",
+    0x0112: "Orientation",
+    0x0115: "SamplesPerPixel",
+    0x0116: "RowsPerStrip",
+    0x0117: "StripByteCounts",
+    0x0118: "MinSampleValue",
+    0x0119: "MaxSampleValue",
+    0x011A: "XResolution",
+    0x011B: "YResolution",
+    0x011C: "PlanarConfiguration",
+    0x011D: "PageName",
+    0x0120: "FreeOffsets",
+    0x0121: "FreeByteCounts",
+    0x0122: "GrayResponseUnit",
+    0x0123: "GrayResponseCurve",
+    0x0124: "T4Options",
+    0x0125: "T6Options",
+    0x0128: "ResolutionUnit",
+    0x0129: "PageNumber",
+    0x012D: "TransferFunction",
+    0x0131: "Software",
+    0x0132: "DateTime",
+    0x013B: "Artist",
+    0x013C: "HostComputer",
+    0x013D: "Predictor",
+    0x013E: "WhitePoint",
+    0x013F: "PrimaryChromaticities",
+    0x0140: "ColorMap",
+    0x0141: "HalftoneHints",
+    0x0142: "TileWidth",
+    0x0143: "TileLength",
+    0x0144: "TileOffsets",
+    0x0145: "TileByteCounts",
+    0x014A: "SubIFDs",
+    0x014C: "InkSet",
+    0x014D: "InkNames",
+    0x014E: "NumberOfInks",
+    0x0150: "DotRange",
+    0x0151: "TargetPrinter",
+    0x0152: "ExtraSamples",
+    0x0153: "SampleFormat",
+    0x0154: "SMinSampleValue",
+    0x0155: "SMaxSampleValue",
+    0x0156: "TransferRange",
+    0x0157: "ClipPath",
+    0x0158: "XClipPathUnits",
+    0x0159: "YClipPathUnits",
+    0x015A: "Indexed",
+    0x015B: "JPEGTables",
+    0x015F: "OPIProxy",
+    0x0200: "JPEGProc",
+    0x0201: "JpegIFOffset",
+    0x0202: "JpegIFByteCount",
+    0x0203: "JpegRestartInterval",
+    0x0205: "JpegLosslessPredictors",
+    0x0206: "JpegPointTransforms",
+    0x0207: "JpegQTables",
+    0x0208: "JpegDCTables",
+    0x0209: "JpegACTables",
+    0x0211: "YCbCrCoefficients",
+    0x0212: "YCbCrSubSampling",
+    0x0213: "YCbCrPositioning",
+    0x0214: "ReferenceBlackWhite",
+    0x02BC: "XMLPacket",
+    0x1000: "RelatedImageFileFormat",
+    0x1001: "RelatedImageWidth",
+    0x1002: "RelatedImageLength",
+    0x4746: "Rating",
+    0x4749: "RatingPercent",
+    0x800D: "ImageID",
+    0x828D: "CFARepeatPatternDim",
+    0x828E: "CFAPattern",
+    0x828F: "BatteryLevel",
+    0x8298: "Copyright",
+    0x829A: "ExposureTime",
+    0x829D: "FNumber",
+    0x83BB: "IPTCNAA",
+    0x8649: "ImageResources",
+    0x8769: "ExifOffset",
+    0x8773: "InterColorProfile",
+    0x8822: "ExposureProgram",
+    0x8824: "SpectralSensitivity",
+    0x8825: "GPSInfo",
+    0x8827: "ISOSpeedRatings",
+    0x8828: "OECF",
+    0x8829: "Interlace",
+    0x882A: "TimeZoneOffset",
+    0x882B: "SelfTimerMode",
+    0x8830: "SensitivityType",
+    0x8831: "StandardOutputSensitivity",
+    0x8832: "RecommendedExposureIndex",
+    0x8833: "ISOSpeed",
+    0x8834: "ISOSpeedLatitudeyyy",
+    0x8835: "ISOSpeedLatitudezzz",
+    0x9000: "ExifVersion",
+    0x9003: "DateTimeOriginal",
+    0x9004: "DateTimeDigitized",
+    0x9010: "OffsetTime",
+    0x9011: "OffsetTimeOriginal",
+    0x9012: "OffsetTimeDigitized",
+    0x9101: "ComponentsConfiguration",
+    0x9102: "CompressedBitsPerPixel",
+    0x9201: "ShutterSpeedValue",
+    0x9202: "ApertureValue",
+    0x9203: "BrightnessValue",
+    0x9204: "ExposureBiasValue",
+    0x9205: "MaxApertureValue",
+    0x9206: "SubjectDistance",
+    0x9207: "MeteringMode",
+    0x9208: "LightSource",
+    0x9209: "Flash",
+    0x920A: "FocalLength",
+    0x920B: "FlashEnergy",
+    0x920C: "SpatialFrequencyResponse",
+    0x920D: "Noise",
+    0x9211: "ImageNumber",
+    0x9212: "SecurityClassification",
+    0x9213: "ImageHistory",
+    0x9214: "SubjectLocation",
+    0x9215: "ExposureIndex",
+    0x9216: "TIFF/EPStandardID",
+    0x927C: "MakerNote",
+    0x9286: "UserComment",
+    0x9290: "SubsecTime",
+    0x9291: "SubsecTimeOriginal",
+    0x9292: "SubsecTimeDigitized",
+    0x9400: "AmbientTemperature",
+    0x9401: "Humidity",
+    0x9402: "Pressure",
+    0x9403: "WaterDepth",
+    0x9404: "Acceleration",
+    0x9405: "CameraElevationAngle",
+    0x9C9B: "XPTitle",
+    0x9C9C: "XPComment",
+    0x9C9D: "XPAuthor",
+    0x9C9E: "XPKeywords",
+    0x9C9F: "XPSubject",
+    0xA000: "FlashPixVersion",
+    0xA001: "ColorSpace",
+    0xA002: "ExifImageWidth",
+    0xA003: "ExifImageHeight",
+    0xA004: "RelatedSoundFile",
+    0xA005: "ExifInteroperabilityOffset",
+    0xA20B: "FlashEnergy",
+    0xA20C: "SpatialFrequencyResponse",
+    0xA20E: "FocalPlaneXResolution",
+    0xA20F: "FocalPlaneYResolution",
+    0xA210: "FocalPlaneResolutionUnit",
+    0xA214: "SubjectLocation",
+    0xA215: "ExposureIndex",
+    0xA217: "SensingMethod",
+    0xA300: "FileSource",
+    0xA301: "SceneType",
+    0xA302: "CFAPattern",
+    0xA401: "CustomRendered",
+    0xA402: "ExposureMode",
+    0xA403: "WhiteBalance",
+    0xA404: "DigitalZoomRatio",
+    0xA405: "FocalLengthIn35mmFilm",
+    0xA406: "SceneCaptureType",
+    0xA407: "GainControl",
+    0xA408: "Contrast",
+    0xA409: "Saturation",
+    0xA40A: "Sharpness",
+    0xA40B: "DeviceSettingDescription",
+    0xA40C: "SubjectDistanceRange",
+    0xA420: "ImageUniqueID",
+    0xA430: "CameraOwnerName",
+    0xA431: "BodySerialNumber",
+    0xA432: "LensSpecification",
+    0xA433: "LensMake",
+    0xA434: "LensModel",
+    0xA435: "LensSerialNumber",
+    0xA460: "CompositeImage",
+    0xA461: "CompositeImageCount",
+    0xA462: "CompositeImageExposureTimes",
+    0xA500: "Gamma",
+    0xC4A5: "PrintImageMatching",
+    0xC612: "DNGVersion",
+    0xC613: "DNGBackwardVersion",
+    0xC614: "UniqueCameraModel",
+    0xC615: "LocalizedCameraModel",
+    0xC616: "CFAPlaneColor",
+    0xC617: "CFALayout",
+    0xC618: "LinearizationTable",
+    0xC619: "BlackLevelRepeatDim",
+    0xC61A: "BlackLevel",
+    0xC61B: "BlackLevelDeltaH",
+    0xC61C: "BlackLevelDeltaV",
+    0xC61D: "WhiteLevel",
+    0xC61E: "DefaultScale",
+    0xC61F: "DefaultCropOrigin",
+    0xC620: "DefaultCropSize",
+    0xC621: "ColorMatrix1",
+    0xC622: "ColorMatrix2",
+    0xC623: "CameraCalibration1",
+    0xC624: "CameraCalibration2",
+    0xC625: "ReductionMatrix1",
+    0xC626: "ReductionMatrix2",
+    0xC627: "AnalogBalance",
+    0xC628: "AsShotNeutral",
+    0xC629: "AsShotWhiteXY",
+    0xC62A: "BaselineExposure",
+    0xC62B: "BaselineNoise",
+    0xC62C: "BaselineSharpness",
+    0xC62D: "BayerGreenSplit",
+    0xC62E: "LinearResponseLimit",
+    0xC62F: "CameraSerialNumber",
+    0xC630: "LensInfo",
+    0xC631: "ChromaBlurRadius",
+    0xC632: "AntiAliasStrength",
+    0xC633: "ShadowScale",
+    0xC634: "DNGPrivateData",
+    0xC635: "MakerNoteSafety",
+    0xC65A: "CalibrationIlluminant1",
+    0xC65B: "CalibrationIlluminant2",
+    0xC65C: "BestQualityScale",
+    0xC65D: "RawDataUniqueID",
+    0xC68B: "OriginalRawFileName",
+    0xC68C: "OriginalRawFileData",
+    0xC68D: "ActiveArea",
+    0xC68E: "MaskedAreas",
+    0xC68F: "AsShotICCProfile",
+    0xC690: "AsShotPreProfileMatrix",
+    0xC691: "CurrentICCProfile",
+    0xC692: "CurrentPreProfileMatrix",
+    0xC6BF: "ColorimetricReference",
+    0xC6F3: "CameraCalibrationSignature",
+    0xC6F4: "ProfileCalibrationSignature",
+    0xC6F6: "AsShotProfileName",
+    0xC6F7: "NoiseReductionApplied",
+    0xC6F8: "ProfileName",
+    0xC6F9: "ProfileHueSatMapDims",
+    0xC6FA: "ProfileHueSatMapData1",
+    0xC6FB: "ProfileHueSatMapData2",
+    0xC6FC: "ProfileToneCurve",
+    0xC6FD: "ProfileEmbedPolicy",
+    0xC6FE: "ProfileCopyright",
+    0xC714: "ForwardMatrix1",
+    0xC715: "ForwardMatrix2",
+    0xC716: "PreviewApplicationName",
+    0xC717: "PreviewApplicationVersion",
+    0xC718: "PreviewSettingsName",
+    0xC719: "PreviewSettingsDigest",
+    0xC71A: "PreviewColorSpace",
+    0xC71B: "PreviewDateTime",
+    0xC71C: "RawImageDigest",
+    0xC71D: "OriginalRawFileDigest",
+    0xC71E: "SubTileBlockSize",
+    0xC71F: "RowInterleaveFactor",
+    0xC725: "ProfileLookTableDims",
+    0xC726: "ProfileLookTableData",
+    0xC740: "OpcodeList1",
+    0xC741: "OpcodeList2",
+    0xC74E: "OpcodeList3",
+    0xC761: "NoiseProfile",
+}
+"""Maps EXIF tags to tag names."""
+
+
+GPSTAGS = {
+    0: "GPSVersionID",
+    1: "GPSLatitudeRef",
+    2: "GPSLatitude",
+    3: "GPSLongitudeRef",
+    4: "GPSLongitude",
+    5: "GPSAltitudeRef",
+    6: "GPSAltitude",
+    7: "GPSTimeStamp",
+    8: "GPSSatellites",
+    9: "GPSStatus",
+    10: "GPSMeasureMode",
+    11: "GPSDOP",
+    12: "GPSSpeedRef",
+    13: "GPSSpeed",
+    14: "GPSTrackRef",
+    15: "GPSTrack",
+    16: "GPSImgDirectionRef",
+    17: "GPSImgDirection",
+    18: "GPSMapDatum",
+    19: "GPSDestLatitudeRef",
+    20: "GPSDestLatitude",
+    21: "GPSDestLongitudeRef",
+    22: "GPSDestLongitude",
+    23: "GPSDestBearingRef",
+    24: "GPSDestBearing",
+    25: "GPSDestDistanceRef",
+    26: "GPSDestDistance",
+    27: "GPSProcessingMethod",
+    28: "GPSAreaInformation",
+    29: "GPSDateStamp",
+    30: "GPSDifferential",
+    31: "GPSHPositioningError",
+}
+"""Maps EXIF GPS tags to tag names."""
diff --git a/.venv/lib/python3.7/site-packages/PIL/FitsStubImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/FitsStubImagePlugin.py
new file mode 100644
index 0000000..a3a94cf
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/FitsStubImagePlugin.py
@@ -0,0 +1,100 @@
+#
+# The Python Imaging Library
+# $Id$
+#
+# FITS stub adapter
+#
+# Copyright (c) 1998-2003 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+from . import Image, ImageFile
+
+_handler = None
+
+
+def register_handler(handler):
+    """
+    Install application-specific FITS image handler.
+
+    :param handler: Handler object.
+    """
+    global _handler
+    _handler = handler
+
+
+# --------------------------------------------------------------------
+# Image adapter
+
+
+def _accept(prefix):
+    return prefix[:6] == b"SIMPLE"
+
+
+class FITSStubImageFile(ImageFile.StubImageFile):
+
+    format = "FITS"
+    format_description = "FITS"
+
+    def _open(self):
+        offset = self.fp.tell()
+
+        headers = {}
+        while True:
+            header = self.fp.read(80)
+            if not header:
+                raise OSError("Truncated FITS file")
+            keyword = header[:8].strip()
+            if keyword == b"END":
+                break
+            value = header[8:].strip()
+            if value.startswith(b"="):
+                value = value[1:].strip()
+            if not headers and (not _accept(keyword) or value != b"T"):
+                raise SyntaxError("Not a FITS file")
+            headers[keyword] = value
+
+        naxis = int(headers[b"NAXIS"])
+        if naxis == 0:
+            raise ValueError("No image data")
+        elif naxis == 1:
+            self._size = 1, int(headers[b"NAXIS1"])
+        else:
+            self._size = int(headers[b"NAXIS1"]), int(headers[b"NAXIS2"])
+
+        number_of_bits = int(headers[b"BITPIX"])
+        if number_of_bits == 8:
+            self.mode = "L"
+        elif number_of_bits == 16:
+            self.mode = "I"
+            # rawmode = "I;16S"
+        elif number_of_bits == 32:
+            self.mode = "I"
+        elif number_of_bits in (-32, -64):
+            self.mode = "F"
+            # rawmode = "F" if number_of_bits == -32 else "F;64F"
+
+        self.fp.seek(offset)
+
+        loader = self._load()
+        if loader:
+            loader.open(self)
+
+    def _load(self):
+        return _handler
+
+
+def _save(im, fp, filename):
+    if _handler is None or not hasattr("_handler", "save"):
+        raise OSError("FITS save handler not installed")
+    _handler.save(im, fp, filename)
+
+
+# --------------------------------------------------------------------
+# Registry
+
+Image.register_open(FITSStubImageFile.format, FITSStubImageFile, _accept)
+Image.register_save(FITSStubImageFile.format, _save)
+
+Image.register_extensions(FITSStubImageFile.format, [".fit", ".fits"])
diff --git a/.venv/lib/python3.7/site-packages/PIL/FliImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/FliImagePlugin.py
new file mode 100644
index 0000000..f2d4857
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/FliImagePlugin.py
@@ -0,0 +1,171 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# FLI/FLC file handling.
+#
+# History:
+#       95-09-01 fl     Created
+#       97-01-03 fl     Fixed parser, setup decoder tile
+#       98-07-15 fl     Renamed offset attribute to avoid name clash
+#
+# Copyright (c) Secret Labs AB 1997-98.
+# Copyright (c) Fredrik Lundh 1995-97.
+#
+# See the README file for information on usage and redistribution.
+#
+
+
+from . import Image, ImageFile, ImagePalette
+from ._binary import i16le as i16
+from ._binary import i32le as i32
+from ._binary import o8
+
+#
+# decoder
+
+
+def _accept(prefix):
+    return len(prefix) >= 6 and i16(prefix, 4) in [0xAF11, 0xAF12]
+
+
+##
+# Image plugin for the FLI/FLC animation format.  Use the <b>seek</b>
+# method to load individual frames.
+
+
+class FliImageFile(ImageFile.ImageFile):
+
+    format = "FLI"
+    format_description = "Autodesk FLI/FLC Animation"
+    _close_exclusive_fp_after_loading = False
+
+    def _open(self):
+
+        # HEAD
+        s = self.fp.read(128)
+        if not (
+            _accept(s)
+            and i16(s, 14) in [0, 3]  # flags
+            and s[20:22] == b"\x00\x00"  # reserved
+        ):
+            raise SyntaxError("not an FLI/FLC file")
+
+        # frames
+        self.n_frames = i16(s, 6)
+        self.is_animated = self.n_frames > 1
+
+        # image characteristics
+        self.mode = "P"
+        self._size = i16(s, 8), i16(s, 10)
+
+        # animation speed
+        duration = i32(s, 16)
+        magic = i16(s, 4)
+        if magic == 0xAF11:
+            duration = (duration * 1000) // 70
+        self.info["duration"] = duration
+
+        # look for palette
+        palette = [(a, a, a) for a in range(256)]
+
+        s = self.fp.read(16)
+
+        self.__offset = 128
+
+        if i16(s, 4) == 0xF100:
+            # prefix chunk; ignore it
+            self.__offset = self.__offset + i32(s)
+            s = self.fp.read(16)
+
+        if i16(s, 4) == 0xF1FA:
+            # look for palette chunk
+            s = self.fp.read(6)
+            if i16(s, 4) == 11:
+                self._palette(palette, 2)
+            elif i16(s, 4) == 4:
+                self._palette(palette, 0)
+
+        palette = [o8(r) + o8(g) + o8(b) for (r, g, b) in palette]
+        self.palette = ImagePalette.raw("RGB", b"".join(palette))
+
+        # set things up to decode first frame
+        self.__frame = -1
+        self.__fp = self.fp
+        self.__rewind = self.fp.tell()
+        self.seek(0)
+
+    def _palette(self, palette, shift):
+        # load palette
+
+        i = 0
+        for e in range(i16(self.fp.read(2))):
+            s = self.fp.read(2)
+            i = i + s[0]
+            n = s[1]
+            if n == 0:
+                n = 256
+            s = self.fp.read(n * 3)
+            for n in range(0, len(s), 3):
+                r = s[n] << shift
+                g = s[n + 1] << shift
+                b = s[n + 2] << shift
+                palette[i] = (r, g, b)
+                i += 1
+
+    def seek(self, frame):
+        if not self._seek_check(frame):
+            return
+        if frame < self.__frame:
+            self._seek(0)
+
+        for f in range(self.__frame + 1, frame + 1):
+            self._seek(f)
+
+    def _seek(self, frame):
+        if frame == 0:
+            self.__frame = -1
+            self.__fp.seek(self.__rewind)
+            self.__offset = 128
+        else:
+            # ensure that the previous frame was loaded
+            self.load()
+
+        if frame != self.__frame + 1:
+            raise ValueError(f"cannot seek to frame {frame}")
+        self.__frame = frame
+
+        # move to next frame
+        self.fp = self.__fp
+        self.fp.seek(self.__offset)
+
+        s = self.fp.read(4)
+        if not s:
+            raise EOFError
+
+        framesize = i32(s)
+
+        self.decodermaxblock = framesize
+        self.tile = [("fli", (0, 0) + self.size, self.__offset, None)]
+
+        self.__offset += framesize
+
+    def tell(self):
+        return self.__frame
+
+    def _close__fp(self):
+        try:
+            if self.__fp != self.fp:
+                self.__fp.close()
+        except AttributeError:
+            pass
+        finally:
+            self.__fp = None
+
+
+#
+# registry
+
+Image.register_open(FliImageFile.format, FliImageFile, _accept)
+
+Image.register_extensions(FliImageFile.format, [".fli", ".flc"])
diff --git a/.venv/lib/python3.7/site-packages/PIL/FontFile.py b/.venv/lib/python3.7/site-packages/PIL/FontFile.py
new file mode 100644
index 0000000..c5fc80b
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/FontFile.py
@@ -0,0 +1,111 @@
+#
+# The Python Imaging Library
+# $Id$
+#
+# base class for raster font file parsers
+#
+# history:
+# 1997-06-05 fl   created
+# 1997-08-19 fl   restrict image width
+#
+# Copyright (c) 1997-1998 by Secret Labs AB
+# Copyright (c) 1997-1998 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+
+import os
+
+from . import Image, _binary
+
+WIDTH = 800
+
+
+def puti16(fp, values):
+    """Write network order (big-endian) 16-bit sequence"""
+    for v in values:
+        if v < 0:
+            v += 65536
+        fp.write(_binary.o16be(v))
+
+
+class FontFile:
+    """Base class for raster font file handlers."""
+
+    bitmap = None
+
+    def __init__(self):
+
+        self.info = {}
+        self.glyph = [None] * 256
+
+    def __getitem__(self, ix):
+        return self.glyph[ix]
+
+    def compile(self):
+        """Create metrics and bitmap"""
+
+        if self.bitmap:
+            return
+
+        # create bitmap large enough to hold all data
+        h = w = maxwidth = 0
+        lines = 1
+        for glyph in self:
+            if glyph:
+                d, dst, src, im = glyph
+                h = max(h, src[3] - src[1])
+                w = w + (src[2] - src[0])
+                if w > WIDTH:
+                    lines += 1
+                    w = src[2] - src[0]
+                maxwidth = max(maxwidth, w)
+
+        xsize = maxwidth
+        ysize = lines * h
+
+        if xsize == 0 and ysize == 0:
+            return ""
+
+        self.ysize = h
+
+        # paste glyphs into bitmap
+        self.bitmap = Image.new("1", (xsize, ysize))
+        self.metrics = [None] * 256
+        x = y = 0
+        for i in range(256):
+            glyph = self[i]
+            if glyph:
+                d, dst, src, im = glyph
+                xx = src[2] - src[0]
+                # yy = src[3] - src[1]
+                x0, y0 = x, y
+                x = x + xx
+                if x > WIDTH:
+                    x, y = 0, y + h
+                    x0, y0 = x, y
+                    x = xx
+                s = src[0] + x0, src[1] + y0, src[2] + x0, src[3] + y0
+                self.bitmap.paste(im.crop(src), s)
+                self.metrics[i] = d, dst, s
+
+    def save(self, filename):
+        """Save font"""
+
+        self.compile()
+
+        # font data
+        self.bitmap.save(os.path.splitext(filename)[0] + ".pbm", "PNG")
+
+        # font metrics
+        with open(os.path.splitext(filename)[0] + ".pil", "wb") as fp:
+            fp.write(b"PILfont\n")
+            fp.write(f";;;;;;{self.ysize};\n".encode("ascii"))  # HACK!!!
+            fp.write(b"DATA\n")
+            for id in range(256):
+                m = self.metrics[id]
+                if not m:
+                    puti16(fp, [0] * 10)
+                else:
+                    puti16(fp, m[0] + m[1] + m[2])
diff --git a/.venv/lib/python3.7/site-packages/PIL/FpxImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/FpxImagePlugin.py
new file mode 100644
index 0000000..5e38546
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/FpxImagePlugin.py
@@ -0,0 +1,242 @@
+#
+# THIS IS WORK IN PROGRESS
+#
+# The Python Imaging Library.
+# $Id$
+#
+# FlashPix support for PIL
+#
+# History:
+# 97-01-25 fl   Created (reads uncompressed RGB images only)
+#
+# Copyright (c) Secret Labs AB 1997.
+# Copyright (c) Fredrik Lundh 1997.
+#
+# See the README file for information on usage and redistribution.
+#
+import olefile
+
+from . import Image, ImageFile
+from ._binary import i32le as i32
+
+# we map from colour field tuples to (mode, rawmode) descriptors
+MODES = {
+    # opacity
+    (0x00007FFE): ("A", "L"),
+    # monochrome
+    (0x00010000,): ("L", "L"),
+    (0x00018000, 0x00017FFE): ("RGBA", "LA"),
+    # photo YCC
+    (0x00020000, 0x00020001, 0x00020002): ("RGB", "YCC;P"),
+    (0x00028000, 0x00028001, 0x00028002, 0x00027FFE): ("RGBA", "YCCA;P"),
+    # standard RGB (NIFRGB)
+    (0x00030000, 0x00030001, 0x00030002): ("RGB", "RGB"),
+    (0x00038000, 0x00038001, 0x00038002, 0x00037FFE): ("RGBA", "RGBA"),
+}
+
+
+#
+# --------------------------------------------------------------------
+
+
+def _accept(prefix):
+    return prefix[:8] == olefile.MAGIC
+
+
+##
+# Image plugin for the FlashPix images.
+
+
+class FpxImageFile(ImageFile.ImageFile):
+
+    format = "FPX"
+    format_description = "FlashPix"
+
+    def _open(self):
+        #
+        # read the OLE directory and see if this is a likely
+        # to be a FlashPix file
+
+        try:
+            self.ole = olefile.OleFileIO(self.fp)
+        except OSError as e:
+            raise SyntaxError("not an FPX file; invalid OLE file") from e
+
+        if self.ole.root.clsid != "56616700-C154-11CE-8553-00AA00A1F95B":
+            raise SyntaxError("not an FPX file; bad root CLSID")
+
+        self._open_index(1)
+
+    def _open_index(self, index=1):
+        #
+        # get the Image Contents Property Set
+
+        prop = self.ole.getproperties(
+            [f"Data Object Store {index:06d}", "\005Image Contents"]
+        )
+
+        # size (highest resolution)
+
+        self._size = prop[0x1000002], prop[0x1000003]
+
+        size = max(self.size)
+        i = 1
+        while size > 64:
+            size = size / 2
+            i += 1
+        self.maxid = i - 1
+
+        # mode.  instead of using a single field for this, flashpix
+        # requires you to specify the mode for each channel in each
+        # resolution subimage, and leaves it to the decoder to make
+        # sure that they all match.  for now, we'll cheat and assume
+        # that this is always the case.
+
+        id = self.maxid << 16
+
+        s = prop[0x2000002 | id]
+
+        colors = []
+        bands = i32(s, 4)
+        if bands > 4:
+            raise OSError("Invalid number of bands")
+        for i in range(bands):
+            # note: for now, we ignore the "uncalibrated" flag
+            colors.append(i32(s, 8 + i * 4) & 0x7FFFFFFF)
+
+        self.mode, self.rawmode = MODES[tuple(colors)]
+
+        # load JPEG tables, if any
+        self.jpeg = {}
+        for i in range(256):
+            id = 0x3000001 | (i << 16)
+            if id in prop:
+                self.jpeg[i] = prop[id]
+
+        self._open_subimage(1, self.maxid)
+
+    def _open_subimage(self, index=1, subimage=0):
+        #
+        # setup tile descriptors for a given subimage
+
+        stream = [
+            f"Data Object Store {index:06d}",
+            f"Resolution {subimage:04d}",
+            "Subimage 0000 Header",
+        ]
+
+        fp = self.ole.openstream(stream)
+
+        # skip prefix
+        fp.read(28)
+
+        # header stream
+        s = fp.read(36)
+
+        size = i32(s, 4), i32(s, 8)
+        # tilecount = i32(s, 12)
+        tilesize = i32(s, 16), i32(s, 20)
+        # channels = i32(s, 24)
+        offset = i32(s, 28)
+        length = i32(s, 32)
+
+        if size != self.size:
+            raise OSError("subimage mismatch")
+
+        # get tile descriptors
+        fp.seek(28 + offset)
+        s = fp.read(i32(s, 12) * length)
+
+        x = y = 0
+        xsize, ysize = size
+        xtile, ytile = tilesize
+        self.tile = []
+
+        for i in range(0, len(s), length):
+
+            compression = i32(s, i + 8)
+
+            if compression == 0:
+                self.tile.append(
+                    (
+                        "raw",
+                        (x, y, x + xtile, y + ytile),
+                        i32(s, i) + 28,
+                        (self.rawmode),
+                    )
+                )
+
+            elif compression == 1:
+
+                # FIXME: the fill decoder is not implemented
+                self.tile.append(
+                    (
+                        "fill",
+                        (x, y, x + xtile, y + ytile),
+                        i32(s, i) + 28,
+                        (self.rawmode, s[12:16]),
+                    )
+                )
+
+            elif compression == 2:
+
+                internal_color_conversion = s[14]
+                jpeg_tables = s[15]
+                rawmode = self.rawmode
+
+                if internal_color_conversion:
+                    # The image is stored as usual (usually YCbCr).
+                    if rawmode == "RGBA":
+                        # For "RGBA", data is stored as YCbCrA based on
+                        # negative RGB. The following trick works around
+                        # this problem :
+                        jpegmode, rawmode = "YCbCrK", "CMYK"
+                    else:
+                        jpegmode = None  # let the decoder decide
+
+                else:
+                    # The image is stored as defined by rawmode
+                    jpegmode = rawmode
+
+                self.tile.append(
+                    (
+                        "jpeg",
+                        (x, y, x + xtile, y + ytile),
+                        i32(s, i) + 28,
+                        (rawmode, jpegmode),
+                    )
+                )
+
+                # FIXME: jpeg tables are tile dependent; the prefix
+                # data must be placed in the tile descriptor itself!
+
+                if jpeg_tables:
+                    self.tile_prefix = self.jpeg[jpeg_tables]
+
+            else:
+                raise OSError("unknown/invalid compression")
+
+            x = x + xtile
+            if x >= xsize:
+                x, y = 0, y + ytile
+                if y >= ysize:
+                    break  # isn't really required
+
+        self.stream = stream
+        self.fp = None
+
+    def load(self):
+
+        if not self.fp:
+            self.fp = self.ole.openstream(self.stream[:2] + ["Subimage 0000 Data"])
+
+        return ImageFile.ImageFile.load(self)
+
+
+#
+# --------------------------------------------------------------------
+
+
+Image.register_open(FpxImageFile.format, FpxImageFile, _accept)
+
+Image.register_extension(FpxImageFile.format, ".fpx")
diff --git a/.venv/lib/python3.7/site-packages/PIL/FtexImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/FtexImagePlugin.py
new file mode 100644
index 0000000..3b16903
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/FtexImagePlugin.py
@@ -0,0 +1,106 @@
+"""
+A Pillow loader for .ftc and .ftu files (FTEX)
+Jerome Leclanche <jerome@leclan.ch>
+
+The contents of this file are hereby released in the public domain (CC0)
+Full text of the CC0 license:
+  https://creativecommons.org/publicdomain/zero/1.0/
+
+Independence War 2: Edge Of Chaos - Texture File Format - 16 October 2001
+
+The textures used for 3D objects in Independence War 2: Edge Of Chaos are in a
+packed custom format called FTEX. This file format uses file extensions FTC
+and FTU.
+* FTC files are compressed textures (using standard texture compression).
+* FTU files are not compressed.
+Texture File Format
+The FTC and FTU texture files both use the same format. This
+has the following structure:
+{header}
+{format_directory}
+{data}
+Where:
+{header} = {
+    u32:magic,
+    u32:version,
+    u32:width,
+    u32:height,
+    u32:mipmap_count,
+    u32:format_count
+}
+
+* The "magic" number is "FTEX".
+* "width" and "height" are the dimensions of the texture.
+* "mipmap_count" is the number of mipmaps in the texture.
+* "format_count" is the number of texture formats (different versions of the
+same texture) in this file.
+
+{format_directory} = format_count * { u32:format, u32:where }
+
+The format value is 0 for DXT1 compressed textures and 1 for 24-bit RGB
+uncompressed textures.
+The texture data for a format starts at the position "where" in the file.
+
+Each set of texture data in the file has the following structure:
+{data} = format_count * { u32:mipmap_size, mipmap_size * { u8 } }
+* "mipmap_size" is the number of bytes in that mip level. For compressed
+textures this is the size of the texture data compressed with DXT1. For 24 bit
+uncompressed textures, this is 3 * width * height. Following this are the image
+bytes for that mipmap level.
+
+Note: All data is stored in little-Endian (Intel) byte order.
+"""
+
+import struct
+from io import BytesIO
+
+from . import Image, ImageFile
+
+MAGIC = b"FTEX"
+FORMAT_DXT1 = 0
+FORMAT_UNCOMPRESSED = 1
+
+
+class FtexImageFile(ImageFile.ImageFile):
+    format = "FTEX"
+    format_description = "Texture File Format (IW2:EOC)"
+
+    def _open(self):
+        struct.unpack("<I", self.fp.read(4))  # magic
+        struct.unpack("<i", self.fp.read(4))  # version
+        self._size = struct.unpack("<2i", self.fp.read(8))
+        mipmap_count, format_count = struct.unpack("<2i", self.fp.read(8))
+
+        self.mode = "RGB"
+
+        # Only support single-format files.
+        # I don't know of any multi-format file.
+        assert format_count == 1
+
+        format, where = struct.unpack("<2i", self.fp.read(8))
+        self.fp.seek(where)
+        (mipmap_size,) = struct.unpack("<i", self.fp.read(4))
+
+        data = self.fp.read(mipmap_size)
+
+        if format == FORMAT_DXT1:
+            self.mode = "RGBA"
+            self.tile = [("bcn", (0, 0) + self.size, 0, (1))]
+        elif format == FORMAT_UNCOMPRESSED:
+            self.tile = [("raw", (0, 0) + self.size, 0, ("RGB", 0, 1))]
+        else:
+            raise ValueError(f"Invalid texture compression format: {repr(format)}")
+
+        self.fp.close()
+        self.fp = BytesIO(data)
+
+    def load_seek(self, pos):
+        pass
+
+
+def _accept(prefix):
+    return prefix[:4] == MAGIC
+
+
+Image.register_open(FtexImageFile.format, FtexImageFile, _accept)
+Image.register_extensions(FtexImageFile.format, [".ftc", ".ftu"])
diff --git a/.venv/lib/python3.7/site-packages/PIL/GbrImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/GbrImagePlugin.py
new file mode 100644
index 0000000..0f23060
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/GbrImagePlugin.py
@@ -0,0 +1,100 @@
+#
+# The Python Imaging Library
+#
+# load a GIMP brush file
+#
+# History:
+#       96-03-14 fl     Created
+#       16-01-08 es     Version 2
+#
+# Copyright (c) Secret Labs AB 1997.
+# Copyright (c) Fredrik Lundh 1996.
+# Copyright (c) Eric Soroos 2016.
+#
+# See the README file for information on usage and redistribution.
+#
+#
+# See https://github.com/GNOME/gimp/blob/mainline/devel-docs/gbr.txt for
+# format documentation.
+#
+# This code Interprets version 1 and 2 .gbr files.
+# Version 1 files are obsolete, and should not be used for new
+#   brushes.
+# Version 2 files are saved by GIMP v2.8 (at least)
+# Version 3 files have a format specifier of 18 for 16bit floats in
+#   the color depth field. This is currently unsupported by Pillow.
+
+from . import Image, ImageFile
+from ._binary import i32be as i32
+
+
+def _accept(prefix):
+    return len(prefix) >= 8 and i32(prefix, 0) >= 20 and i32(prefix, 4) in (1, 2)
+
+
+##
+# Image plugin for the GIMP brush format.
+
+
+class GbrImageFile(ImageFile.ImageFile):
+
+    format = "GBR"
+    format_description = "GIMP brush file"
+
+    def _open(self):
+        header_size = i32(self.fp.read(4))
+        version = i32(self.fp.read(4))
+        if header_size < 20:
+            raise SyntaxError("not a GIMP brush")
+        if version not in (1, 2):
+            raise SyntaxError(f"Unsupported GIMP brush version: {version}")
+
+        width = i32(self.fp.read(4))
+        height = i32(self.fp.read(4))
+        color_depth = i32(self.fp.read(4))
+        if width <= 0 or height <= 0:
+            raise SyntaxError("not a GIMP brush")
+        if color_depth not in (1, 4):
+            raise SyntaxError(f"Unsupported GIMP brush color depth: {color_depth}")
+
+        if version == 1:
+            comment_length = header_size - 20
+        else:
+            comment_length = header_size - 28
+            magic_number = self.fp.read(4)
+            if magic_number != b"GIMP":
+                raise SyntaxError("not a GIMP brush, bad magic number")
+            self.info["spacing"] = i32(self.fp.read(4))
+
+        comment = self.fp.read(comment_length)[:-1]
+
+        if color_depth == 1:
+            self.mode = "L"
+        else:
+            self.mode = "RGBA"
+
+        self._size = width, height
+
+        self.info["comment"] = comment
+
+        # Image might not be small
+        Image._decompression_bomb_check(self.size)
+
+        # Data is an uncompressed block of w * h * bytes/pixel
+        self._data_size = width * height * color_depth
+
+    def load(self):
+        if self.im:
+            # Already loaded
+            return
+
+        self.im = Image.core.new(self.mode, self.size)
+        self.frombytes(self.fp.read(self._data_size))
+
+
+#
+# registry
+
+
+Image.register_open(GbrImageFile.format, GbrImageFile, _accept)
+Image.register_extension(GbrImageFile.format, ".gbr")
diff --git a/.venv/lib/python3.7/site-packages/PIL/GdImageFile.py b/.venv/lib/python3.7/site-packages/PIL/GdImageFile.py
new file mode 100644
index 0000000..9c34ada
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/GdImageFile.py
@@ -0,0 +1,90 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# GD file handling
+#
+# History:
+# 1996-04-12 fl   Created
+#
+# Copyright (c) 1997 by Secret Labs AB.
+# Copyright (c) 1996 by Fredrik Lundh.
+#
+# See the README file for information on usage and redistribution.
+#
+
+
+"""
+.. note::
+    This format cannot be automatically recognized, so the
+    class is not registered for use with :py:func:`PIL.Image.open()`.  To open a
+    gd file, use the :py:func:`PIL.GdImageFile.open()` function instead.
+
+.. warning::
+    THE GD FORMAT IS NOT DESIGNED FOR DATA INTERCHANGE.  This
+    implementation is provided for convenience and demonstrational
+    purposes only.
+"""
+
+
+from . import ImageFile, ImagePalette, UnidentifiedImageError
+from ._binary import i16be as i16
+from ._binary import i32be as i32
+
+
+class GdImageFile(ImageFile.ImageFile):
+    """
+    Image plugin for the GD uncompressed format.  Note that this format
+    is not supported by the standard :py:func:`PIL.Image.open()` function.  To use
+    this plugin, you have to import the :py:mod:`PIL.GdImageFile` module and
+    use the :py:func:`PIL.GdImageFile.open()` function.
+    """
+
+    format = "GD"
+    format_description = "GD uncompressed images"
+
+    def _open(self):
+
+        # Header
+        s = self.fp.read(1037)
+
+        if not i16(s) in [65534, 65535]:
+            raise SyntaxError("Not a valid GD 2.x .gd file")
+
+        self.mode = "L"  # FIXME: "P"
+        self._size = i16(s, 2), i16(s, 4)
+
+        trueColor = s[6]
+        trueColorOffset = 2 if trueColor else 0
+
+        # transparency index
+        tindex = i32(s, 7 + trueColorOffset)
+        if tindex < 256:
+            self.info["transparency"] = tindex
+
+        self.palette = ImagePalette.raw(
+            "XBGR", s[7 + trueColorOffset + 4 : 7 + trueColorOffset + 4 + 256 * 4]
+        )
+
+        self.tile = [
+            ("raw", (0, 0) + self.size, 7 + trueColorOffset + 4 + 256 * 4, ("L", 0, 1))
+        ]
+
+
+def open(fp, mode="r"):
+    """
+    Load texture from a GD image file.
+
+    :param filename: GD file name, or an opened file handle.
+    :param mode: Optional mode.  In this version, if the mode argument
+        is given, it must be "r".
+    :returns: An image instance.
+    :raises OSError: If the image could not be read.
+    """
+    if mode != "r":
+        raise ValueError("bad mode")
+
+    try:
+        return GdImageFile(fp)
+    except SyntaxError as e:
+        raise UnidentifiedImageError("cannot identify this image file") from e
diff --git a/.venv/lib/python3.7/site-packages/PIL/GifImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/GifImagePlugin.py
new file mode 100644
index 0000000..8c2180b
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/GifImagePlugin.py
@@ -0,0 +1,987 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# GIF file handling
+#
+# History:
+# 1995-09-01 fl   Created
+# 1996-12-14 fl   Added interlace support
+# 1996-12-30 fl   Added animation support
+# 1997-01-05 fl   Added write support, fixed local colour map bug
+# 1997-02-23 fl   Make sure to load raster data in getdata()
+# 1997-07-05 fl   Support external decoder (0.4)
+# 1998-07-09 fl   Handle all modes when saving (0.5)
+# 1998-07-15 fl   Renamed offset attribute to avoid name clash
+# 2001-04-16 fl   Added rewind support (seek to frame 0) (0.6)
+# 2001-04-17 fl   Added palette optimization (0.7)
+# 2002-06-06 fl   Added transparency support for save (0.8)
+# 2004-02-24 fl   Disable interlacing for small images
+#
+# Copyright (c) 1997-2004 by Secret Labs AB
+# Copyright (c) 1995-2004 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+import itertools
+import math
+import os
+import subprocess
+
+from . import Image, ImageChops, ImageFile, ImagePalette, ImageSequence
+from ._binary import i16le as i16
+from ._binary import o8
+from ._binary import o16le as o16
+
+# --------------------------------------------------------------------
+# Identify/read GIF files
+
+
+def _accept(prefix):
+    return prefix[:6] in [b"GIF87a", b"GIF89a"]
+
+
+##
+# Image plugin for GIF images.  This plugin supports both GIF87 and
+# GIF89 images.
+
+
+class GifImageFile(ImageFile.ImageFile):
+
+    format = "GIF"
+    format_description = "Compuserve GIF"
+    _close_exclusive_fp_after_loading = False
+
+    global_palette = None
+
+    def data(self):
+        s = self.fp.read(1)
+        if s and s[0]:
+            return self.fp.read(s[0])
+        return None
+
+    def _open(self):
+
+        # Screen
+        s = self.fp.read(13)
+        if not _accept(s):
+            raise SyntaxError("not a GIF file")
+
+        self.info["version"] = s[:6]
+        self._size = i16(s, 6), i16(s, 8)
+        self.tile = []
+        flags = s[10]
+        bits = (flags & 7) + 1
+
+        if flags & 128:
+            # get global palette
+            self.info["background"] = s[11]
+            # check if palette contains colour indices
+            p = self.fp.read(3 << bits)
+            for i in range(0, len(p), 3):
+                if not (i // 3 == p[i] == p[i + 1] == p[i + 2]):
+                    p = ImagePalette.raw("RGB", p)
+                    self.global_palette = self.palette = p
+                    break
+
+        self.__fp = self.fp  # FIXME: hack
+        self.__rewind = self.fp.tell()
+        self._n_frames = None
+        self._is_animated = None
+        self._seek(0)  # get ready to read first frame
+
+    @property
+    def n_frames(self):
+        if self._n_frames is None:
+            current = self.tell()
+            try:
+                while True:
+                    self.seek(self.tell() + 1)
+            except EOFError:
+                self._n_frames = self.tell() + 1
+            self.seek(current)
+        return self._n_frames
+
+    @property
+    def is_animated(self):
+        if self._is_animated is None:
+            if self._n_frames is not None:
+                self._is_animated = self._n_frames != 1
+            else:
+                current = self.tell()
+
+                try:
+                    self.seek(1)
+                    self._is_animated = True
+                except EOFError:
+                    self._is_animated = False
+
+                self.seek(current)
+        return self._is_animated
+
+    def seek(self, frame):
+        if not self._seek_check(frame):
+            return
+        if frame < self.__frame:
+            self.im = None
+            self._seek(0)
+
+        last_frame = self.__frame
+        for f in range(self.__frame + 1, frame + 1):
+            try:
+                self._seek(f)
+            except EOFError as e:
+                self.seek(last_frame)
+                raise EOFError("no more images in GIF file") from e
+
+    def _seek(self, frame):
+
+        if frame == 0:
+            # rewind
+            self.__offset = 0
+            self.dispose = None
+            self.dispose_extent = [0, 0, 0, 0]  # x0, y0, x1, y1
+            self.__frame = -1
+            self.__fp.seek(self.__rewind)
+            self.disposal_method = 0
+        else:
+            # ensure that the previous frame was loaded
+            if self.tile:
+                self.load()
+
+        if frame != self.__frame + 1:
+            raise ValueError(f"cannot seek to frame {frame}")
+        self.__frame = frame
+
+        self.tile = []
+
+        self.fp = self.__fp
+        if self.__offset:
+            # backup to last frame
+            self.fp.seek(self.__offset)
+            while self.data():
+                pass
+            self.__offset = 0
+
+        if self.__frame == 1:
+            self.pyaccess = None
+            if "transparency" in self.info:
+                self.mode = "RGBA"
+                self.im.putpalettealpha(self.info["transparency"], 0)
+                self.im = self.im.convert("RGBA", Image.FLOYDSTEINBERG)
+
+                del self.info["transparency"]
+            else:
+                self.mode = "RGB"
+                self.im = self.im.convert("RGB", Image.FLOYDSTEINBERG)
+        if self.dispose:
+            self.im.paste(self.dispose, self.dispose_extent)
+
+        palette = None
+
+        info = {}
+        frame_transparency = None
+        interlace = None
+        while True:
+
+            s = self.fp.read(1)
+            if not s or s == b";":
+                break
+
+            elif s == b"!":
+                #
+                # extensions
+                #
+                s = self.fp.read(1)
+                block = self.data()
+                if s[0] == 249:
+                    #
+                    # graphic control extension
+                    #
+                    flags = block[0]
+                    if flags & 1:
+                        frame_transparency = block[3]
+                    info["duration"] = i16(block, 1) * 10
+
+                    # disposal method - find the value of bits 4 - 6
+                    dispose_bits = 0b00011100 & flags
+                    dispose_bits = dispose_bits >> 2
+                    if dispose_bits:
+                        # only set the dispose if it is not
+                        # unspecified. I'm not sure if this is
+                        # correct, but it seems to prevent the last
+                        # frame from looking odd for some animations
+                        self.disposal_method = dispose_bits
+                elif s[0] == 254:
+                    #
+                    # comment extension
+                    #
+                    while block:
+                        if "comment" in info:
+                            info["comment"] += block
+                        else:
+                            info["comment"] = block
+                        block = self.data()
+                    continue
+                elif s[0] == 255:
+                    #
+                    # application extension
+                    #
+                    info["extension"] = block, self.fp.tell()
+                    if block[:11] == b"NETSCAPE2.0":
+                        block = self.data()
+                        if len(block) >= 3 and block[0] == 1:
+                            info["loop"] = i16(block, 1)
+                while self.data():
+                    pass
+
+            elif s == b",":
+                #
+                # local image
+                #
+                s = self.fp.read(9)
+
+                # extent
+                x0, y0 = i16(s, 0), i16(s, 2)
+                x1, y1 = x0 + i16(s, 4), y0 + i16(s, 6)
+                if x1 > self.size[0] or y1 > self.size[1]:
+                    self._size = max(x1, self.size[0]), max(y1, self.size[1])
+                self.dispose_extent = x0, y0, x1, y1
+                flags = s[8]
+
+                interlace = (flags & 64) != 0
+
+                if flags & 128:
+                    bits = (flags & 7) + 1
+                    palette = ImagePalette.raw("RGB", self.fp.read(3 << bits))
+
+                # image data
+                bits = self.fp.read(1)[0]
+                self.__offset = self.fp.tell()
+                break
+
+            else:
+                pass
+                # raise OSError, "illegal GIF tag `%x`" % s[0]
+
+        frame_palette = palette or self.global_palette
+
+        def _rgb(color):
+            if frame_palette:
+                color = tuple(frame_palette.palette[color * 3 : color * 3 + 3])
+            else:
+                color = (color, color, color)
+            return color
+
+        try:
+            if self.disposal_method < 2:
+                # do not dispose or none specified
+                self.dispose = None
+            elif self.disposal_method == 2:
+                # replace with background colour
+
+                # only dispose the extent in this frame
+                x0, y0, x1, y1 = self.dispose_extent
+                dispose_size = (x1 - x0, y1 - y0)
+
+                Image._decompression_bomb_check(dispose_size)
+
+                # by convention, attempt to use transparency first
+                color = self.info.get("transparency", frame_transparency)
+                if color is not None:
+                    dispose_mode = "RGBA"
+                    color = _rgb(color) + (0,)
+                else:
+                    dispose_mode = "RGB"
+                    color = _rgb(self.info.get("background", 0))
+                self.dispose = Image.core.fill(dispose_mode, dispose_size, color)
+            else:
+                # replace with previous contents
+                if self.im:
+                    # only dispose the extent in this frame
+                    self.dispose = self._crop(self.im, self.dispose_extent)
+                elif frame_transparency is not None:
+                    x0, y0, x1, y1 = self.dispose_extent
+                    dispose_size = (x1 - x0, y1 - y0)
+
+                    Image._decompression_bomb_check(dispose_size)
+                    self.dispose = Image.core.fill(
+                        "RGBA", dispose_size, _rgb(frame_transparency) + (0,)
+                    )
+        except AttributeError:
+            pass
+
+        if interlace is not None:
+            if frame == 0 and frame_transparency is not None:
+                self.info["transparency"] = frame_transparency
+            self.tile = [
+                (
+                    "gif",
+                    (x0, y0, x1, y1),
+                    self.__offset,
+                    (bits, interlace),
+                )
+            ]
+        else:
+            # self.__fp = None
+            raise EOFError
+
+        for k in ["duration", "comment", "extension", "loop"]:
+            if k in info:
+                self.info[k] = info[k]
+            elif k in self.info:
+                del self.info[k]
+
+        if frame == 0:
+            self.mode = "P" if frame_palette else "L"
+
+            if self.mode == "P" and not palette:
+                from copy import copy
+
+                palette = copy(self.global_palette)
+            self.palette = palette
+        else:
+            self._frame_palette = frame_palette
+            self._frame_transparency = frame_transparency
+
+    def load_prepare(self):
+        if self.__frame == 0:
+            if "transparency" in self.info:
+                self.im = Image.core.fill(
+                    self.mode, self.size, self.info["transparency"]
+                )
+        else:
+            self._prev_im = self.im
+            if self._frame_palette:
+                self.mode = "P"
+                self.im = Image.core.fill("P", self.size, self._frame_transparency or 0)
+                self.im.putpalette(*self._frame_palette.getdata())
+                self._frame_palette = None
+            else:
+                self.mode = "L"
+                self.im = None
+
+        super().load_prepare()
+
+    def load_end(self):
+        if self.__frame == 0:
+            return
+        if self._frame_transparency is not None:
+            self.im.putpalettealpha(self._frame_transparency, 0)
+            frame_im = self.im.convert("RGBA")
+        else:
+            frame_im = self.im.convert("RGB")
+        frame_im = self._crop(frame_im, self.dispose_extent)
+
+        self.im = self._prev_im
+        self.mode = self.im.mode
+        if frame_im.mode == "RGBA":
+            self.im.paste(frame_im, self.dispose_extent, frame_im)
+        else:
+            self.im.paste(frame_im, self.dispose_extent)
+
+    def tell(self):
+        return self.__frame
+
+    def _close__fp(self):
+        try:
+            if self.__fp != self.fp:
+                self.__fp.close()
+        except AttributeError:
+            pass
+        finally:
+            self.__fp = None
+
+
+# --------------------------------------------------------------------
+# Write GIF files
+
+
+RAWMODE = {"1": "L", "L": "L", "P": "P"}
+
+
+def _normalize_mode(im, initial_call=False):
+    """
+    Takes an image (or frame), returns an image in a mode that is appropriate
+    for saving in a Gif.
+
+    It may return the original image, or it may return an image converted to
+    palette or 'L' mode.
+
+    UNDONE: What is the point of mucking with the initial call palette, for
+    an image that shouldn't have a palette, or it would be a mode 'P' and
+    get returned in the RAWMODE clause.
+
+    :param im: Image object
+    :param initial_call: Default false, set to true for a single frame.
+    :returns: Image object
+    """
+    if im.mode in RAWMODE:
+        im.load()
+        return im
+    if Image.getmodebase(im.mode) == "RGB":
+        if initial_call:
+            palette_size = 256
+            if im.palette:
+                palette_size = len(im.palette.getdata()[1]) // 3
+            im = im.convert("P", palette=Image.ADAPTIVE, colors=palette_size)
+            if im.palette.mode == "RGBA":
+                for rgba in im.palette.colors.keys():
+                    if rgba[3] == 0:
+                        im.info["transparency"] = im.palette.colors[rgba]
+                        break
+            return im
+        else:
+            return im.convert("P")
+    return im.convert("L")
+
+
+def _normalize_palette(im, palette, info):
+    """
+    Normalizes the palette for image.
+      - Sets the palette to the incoming palette, if provided.
+      - Ensures that there's a palette for L mode images
+      - Optimizes the palette if necessary/desired.
+
+    :param im: Image object
+    :param palette: bytes object containing the source palette, or ....
+    :param info: encoderinfo
+    :returns: Image object
+    """
+    source_palette = None
+    if palette:
+        # a bytes palette
+        if isinstance(palette, (bytes, bytearray, list)):
+            source_palette = bytearray(palette[:768])
+        if isinstance(palette, ImagePalette.ImagePalette):
+            source_palette = bytearray(palette.palette)
+
+    if im.mode == "P":
+        if not source_palette:
+            source_palette = im.im.getpalette("RGB")[:768]
+    else:  # L-mode
+        if not source_palette:
+            source_palette = bytearray(i // 3 for i in range(768))
+        im.palette = ImagePalette.ImagePalette("RGB", palette=source_palette)
+
+    if palette:
+        used_palette_colors = []
+        for i in range(0, len(source_palette), 3):
+            source_color = tuple(source_palette[i : i + 3])
+            try:
+                index = im.palette.colors[source_color]
+            except KeyError:
+                index = None
+            used_palette_colors.append(index)
+        for i, index in enumerate(used_palette_colors):
+            if index is None:
+                for j in range(len(used_palette_colors)):
+                    if j not in used_palette_colors:
+                        used_palette_colors[i] = j
+                        break
+        im = im.remap_palette(used_palette_colors)
+    else:
+        used_palette_colors = _get_optimize(im, info)
+        if used_palette_colors is not None:
+            return im.remap_palette(used_palette_colors, source_palette)
+
+    im.palette.palette = source_palette
+    return im
+
+
+def _write_single_frame(im, fp, palette):
+    im_out = _normalize_mode(im, True)
+    for k, v in im_out.info.items():
+        im.encoderinfo.setdefault(k, v)
+    im_out = _normalize_palette(im_out, palette, im.encoderinfo)
+
+    for s in _get_global_header(im_out, im.encoderinfo):
+        fp.write(s)
+
+    # local image header
+    flags = 0
+    if get_interlace(im):
+        flags = flags | 64
+    _write_local_header(fp, im, (0, 0), flags)
+
+    im_out.encoderconfig = (8, get_interlace(im))
+    ImageFile._save(im_out, fp, [("gif", (0, 0) + im.size, 0, RAWMODE[im_out.mode])])
+
+    fp.write(b"\0")  # end of image data
+
+
+def _write_multiple_frames(im, fp, palette):
+
+    duration = im.encoderinfo.get("duration", im.info.get("duration"))
+    disposal = im.encoderinfo.get("disposal", im.info.get("disposal"))
+
+    im_frames = []
+    frame_count = 0
+    background_im = None
+    for imSequence in itertools.chain([im], im.encoderinfo.get("append_images", [])):
+        for im_frame in ImageSequence.Iterator(imSequence):
+            # a copy is required here since seek can still mutate the image
+            im_frame = _normalize_mode(im_frame.copy())
+            if frame_count == 0:
+                for k, v in im_frame.info.items():
+                    im.encoderinfo.setdefault(k, v)
+            im_frame = _normalize_palette(im_frame, palette, im.encoderinfo)
+
+            encoderinfo = im.encoderinfo.copy()
+            if isinstance(duration, (list, tuple)):
+                encoderinfo["duration"] = duration[frame_count]
+            if isinstance(disposal, (list, tuple)):
+                encoderinfo["disposal"] = disposal[frame_count]
+            frame_count += 1
+
+            if im_frames:
+                # delta frame
+                previous = im_frames[-1]
+                if encoderinfo.get("disposal") == 2:
+                    if background_im is None:
+                        color = im.encoderinfo.get(
+                            "transparency", im.info.get("transparency", (0, 0, 0))
+                        )
+                        background = _get_background(im_frame, color)
+                        background_im = Image.new("P", im_frame.size, background)
+                        background_im.putpalette(im_frames[0]["im"].palette)
+                    base_im = background_im
+                else:
+                    base_im = previous["im"]
+                if _get_palette_bytes(im_frame) == _get_palette_bytes(base_im):
+                    delta = ImageChops.subtract_modulo(im_frame, base_im)
+                else:
+                    delta = ImageChops.subtract_modulo(
+                        im_frame.convert("RGB"), base_im.convert("RGB")
+                    )
+                bbox = delta.getbbox()
+                if not bbox:
+                    # This frame is identical to the previous frame
+                    if duration:
+                        previous["encoderinfo"]["duration"] += encoderinfo["duration"]
+                    continue
+            else:
+                bbox = None
+            im_frames.append({"im": im_frame, "bbox": bbox, "encoderinfo": encoderinfo})
+
+    if len(im_frames) > 1:
+        for frame_data in im_frames:
+            im_frame = frame_data["im"]
+            if not frame_data["bbox"]:
+                # global header
+                for s in _get_global_header(im_frame, frame_data["encoderinfo"]):
+                    fp.write(s)
+                offset = (0, 0)
+            else:
+                # compress difference
+                if not palette:
+                    frame_data["encoderinfo"]["include_color_table"] = True
+
+                im_frame = im_frame.crop(frame_data["bbox"])
+                offset = frame_data["bbox"][:2]
+            _write_frame_data(fp, im_frame, offset, frame_data["encoderinfo"])
+        return True
+    elif "duration" in im.encoderinfo and isinstance(
+        im.encoderinfo["duration"], (list, tuple)
+    ):
+        # Since multiple frames will not be written, add together the frame durations
+        im.encoderinfo["duration"] = sum(im.encoderinfo["duration"])
+
+
+def _save_all(im, fp, filename):
+    _save(im, fp, filename, save_all=True)
+
+
+def _save(im, fp, filename, save_all=False):
+    # header
+    if "palette" in im.encoderinfo or "palette" in im.info:
+        palette = im.encoderinfo.get("palette", im.info.get("palette"))
+    else:
+        palette = None
+        im.encoderinfo["optimize"] = im.encoderinfo.get("optimize", True)
+
+    if not save_all or not _write_multiple_frames(im, fp, palette):
+        _write_single_frame(im, fp, palette)
+
+    fp.write(b";")  # end of file
+
+    if hasattr(fp, "flush"):
+        fp.flush()
+
+
+def get_interlace(im):
+    interlace = im.encoderinfo.get("interlace", 1)
+
+    # workaround for @PIL153
+    if min(im.size) < 16:
+        interlace = 0
+
+    return interlace
+
+
+def _write_local_header(fp, im, offset, flags):
+    transparent_color_exists = False
+    try:
+        transparency = im.encoderinfo["transparency"]
+    except KeyError:
+        pass
+    else:
+        transparency = int(transparency)
+        # optimize the block away if transparent color is not used
+        transparent_color_exists = True
+
+        used_palette_colors = _get_optimize(im, im.encoderinfo)
+        if used_palette_colors is not None:
+            # adjust the transparency index after optimize
+            try:
+                transparency = used_palette_colors.index(transparency)
+            except ValueError:
+                transparent_color_exists = False
+
+    if "duration" in im.encoderinfo:
+        duration = int(im.encoderinfo["duration"] / 10)
+    else:
+        duration = 0
+
+    disposal = int(im.encoderinfo.get("disposal", 0))
+
+    if transparent_color_exists or duration != 0 or disposal:
+        packed_flag = 1 if transparent_color_exists else 0
+        packed_flag |= disposal << 2
+        if not transparent_color_exists:
+            transparency = 0
+
+        fp.write(
+            b"!"
+            + o8(249)  # extension intro
+            + o8(4)  # length
+            + o8(packed_flag)  # packed fields
+            + o16(duration)  # duration
+            + o8(transparency)  # transparency index
+            + o8(0)
+        )
+
+    if "comment" in im.encoderinfo and 1 <= len(im.encoderinfo["comment"]):
+        fp.write(b"!" + o8(254))  # extension intro
+        comment = im.encoderinfo["comment"]
+        if isinstance(comment, str):
+            comment = comment.encode()
+        for i in range(0, len(comment), 255):
+            subblock = comment[i : i + 255]
+            fp.write(o8(len(subblock)) + subblock)
+        fp.write(o8(0))
+    if "loop" in im.encoderinfo:
+        number_of_loops = im.encoderinfo["loop"]
+        fp.write(
+            b"!"
+            + o8(255)  # extension intro
+            + o8(11)
+            + b"NETSCAPE2.0"
+            + o8(3)
+            + o8(1)
+            + o16(number_of_loops)  # number of loops
+            + o8(0)
+        )
+    include_color_table = im.encoderinfo.get("include_color_table")
+    if include_color_table:
+        palette_bytes = _get_palette_bytes(im)
+        color_table_size = _get_color_table_size(palette_bytes)
+        if color_table_size:
+            flags = flags | 128  # local color table flag
+            flags = flags | color_table_size
+
+    fp.write(
+        b","
+        + o16(offset[0])  # offset
+        + o16(offset[1])
+        + o16(im.size[0])  # size
+        + o16(im.size[1])
+        + o8(flags)  # flags
+    )
+    if include_color_table and color_table_size:
+        fp.write(_get_header_palette(palette_bytes))
+    fp.write(o8(8))  # bits
+
+
+def _save_netpbm(im, fp, filename):
+
+    # Unused by default.
+    # To use, uncomment the register_save call at the end of the file.
+    #
+    # If you need real GIF compression and/or RGB quantization, you
+    # can use the external NETPBM/PBMPLUS utilities.  See comments
+    # below for information on how to enable this.
+    tempfile = im._dump()
+
+    try:
+        with open(filename, "wb") as f:
+            if im.mode != "RGB":
+                subprocess.check_call(
+                    ["ppmtogif", tempfile], stdout=f, stderr=subprocess.DEVNULL
+                )
+            else:
+                # Pipe ppmquant output into ppmtogif
+                # "ppmquant 256 %s | ppmtogif > %s" % (tempfile, filename)
+                quant_cmd = ["ppmquant", "256", tempfile]
+                togif_cmd = ["ppmtogif"]
+                quant_proc = subprocess.Popen(
+                    quant_cmd, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL
+                )
+                togif_proc = subprocess.Popen(
+                    togif_cmd,
+                    stdin=quant_proc.stdout,
+                    stdout=f,
+                    stderr=subprocess.DEVNULL,
+                )
+
+                # Allow ppmquant to receive SIGPIPE if ppmtogif exits
+                quant_proc.stdout.close()
+
+                retcode = quant_proc.wait()
+                if retcode:
+                    raise subprocess.CalledProcessError(retcode, quant_cmd)
+
+                retcode = togif_proc.wait()
+                if retcode:
+                    raise subprocess.CalledProcessError(retcode, togif_cmd)
+    finally:
+        try:
+            os.unlink(tempfile)
+        except OSError:
+            pass
+
+
+# Force optimization so that we can test performance against
+# cases where it took lots of memory and time previously.
+_FORCE_OPTIMIZE = False
+
+
+def _get_optimize(im, info):
+    """
+    Palette optimization is a potentially expensive operation.
+
+    This function determines if the palette should be optimized using
+    some heuristics, then returns the list of palette entries in use.
+
+    :param im: Image object
+    :param info: encoderinfo
+    :returns: list of indexes of palette entries in use, or None
+    """
+    if im.mode in ("P", "L") and info and info.get("optimize", 0):
+        # Potentially expensive operation.
+
+        # The palette saves 3 bytes per color not used, but palette
+        # lengths are restricted to 3*(2**N) bytes. Max saving would
+        # be 768 -> 6 bytes if we went all the way down to 2 colors.
+        # * If we're over 128 colors, we can't save any space.
+        # * If there aren't any holes, it's not worth collapsing.
+        # * If we have a 'large' image, the palette is in the noise.
+
+        # create the new palette if not every color is used
+        optimise = _FORCE_OPTIMIZE or im.mode == "L"
+        if optimise or im.width * im.height < 512 * 512:
+            # check which colors are used
+            used_palette_colors = []
+            for i, count in enumerate(im.histogram()):
+                if count:
+                    used_palette_colors.append(i)
+
+            if optimise or (
+                len(used_palette_colors) <= 128
+                and max(used_palette_colors) > len(used_palette_colors)
+            ):
+                return used_palette_colors
+
+
+def _get_color_table_size(palette_bytes):
+    # calculate the palette size for the header
+    if not palette_bytes:
+        return 0
+    elif len(palette_bytes) < 9:
+        return 1
+    else:
+        return math.ceil(math.log(len(palette_bytes) // 3, 2)) - 1
+
+
+def _get_header_palette(palette_bytes):
+    """
+    Returns the palette, null padded to the next power of 2 (*3) bytes
+    suitable for direct inclusion in the GIF header
+
+    :param palette_bytes: Unpadded palette bytes, in RGBRGB form
+    :returns: Null padded palette
+    """
+    color_table_size = _get_color_table_size(palette_bytes)
+
+    # add the missing amount of bytes
+    # the palette has to be 2<<n in size
+    actual_target_size_diff = (2 << color_table_size) - len(palette_bytes) // 3
+    if actual_target_size_diff > 0:
+        palette_bytes += o8(0) * 3 * actual_target_size_diff
+    return palette_bytes
+
+
+def _get_palette_bytes(im):
+    """
+    Gets the palette for inclusion in the gif header
+
+    :param im: Image object
+    :returns: Bytes, len<=768 suitable for inclusion in gif header
+    """
+    return im.palette.palette
+
+
+def _get_background(im, infoBackground):
+    background = 0
+    if infoBackground:
+        background = infoBackground
+        if isinstance(background, tuple):
+            # WebPImagePlugin stores an RGBA value in info["background"]
+            # So it must be converted to the same format as GifImagePlugin's
+            # info["background"] - a global color table index
+            try:
+                background = im.palette.getcolor(background, im)
+            except ValueError as e:
+                if str(e) == "cannot allocate more than 256 colors":
+                    # If all 256 colors are in use,
+                    # then there is no need for the background color
+                    return 0
+                else:
+                    raise
+    return background
+
+
+def _get_global_header(im, info):
+    """Return a list of strings representing a GIF header"""
+
+    # Header Block
+    # https://www.matthewflickinger.com/lab/whatsinagif/bits_and_bytes.asp
+
+    version = b"87a"
+    for extensionKey in ["transparency", "duration", "loop", "comment"]:
+        if info and extensionKey in info:
+            if (extensionKey == "duration" and info[extensionKey] == 0) or (
+                extensionKey == "comment" and not (1 <= len(info[extensionKey]) <= 255)
+            ):
+                continue
+            version = b"89a"
+            break
+    else:
+        if im.info.get("version") == b"89a":
+            version = b"89a"
+
+    background = _get_background(im, info.get("background"))
+
+    palette_bytes = _get_palette_bytes(im)
+    color_table_size = _get_color_table_size(palette_bytes)
+
+    return [
+        b"GIF"  # signature
+        + version  # version
+        + o16(im.size[0])  # canvas width
+        + o16(im.size[1]),  # canvas height
+        # Logical Screen Descriptor
+        # size of global color table + global color table flag
+        o8(color_table_size + 128),  # packed fields
+        # background + reserved/aspect
+        o8(background) + o8(0),
+        # Global Color Table
+        _get_header_palette(palette_bytes),
+    ]
+
+
+def _write_frame_data(fp, im_frame, offset, params):
+    try:
+        im_frame.encoderinfo = params
+
+        # local image header
+        _write_local_header(fp, im_frame, offset, 0)
+
+        ImageFile._save(
+            im_frame, fp, [("gif", (0, 0) + im_frame.size, 0, RAWMODE[im_frame.mode])]
+        )
+
+        fp.write(b"\0")  # end of image data
+    finally:
+        del im_frame.encoderinfo
+
+
+# --------------------------------------------------------------------
+# Legacy GIF utilities
+
+
+def getheader(im, palette=None, info=None):
+    """
+    Legacy Method to get Gif data from image.
+
+    Warning:: May modify image data.
+
+    :param im: Image object
+    :param palette: bytes object containing the source palette, or ....
+    :param info: encoderinfo
+    :returns: tuple of(list of header items, optimized palette)
+
+    """
+    used_palette_colors = _get_optimize(im, info)
+
+    if info is None:
+        info = {}
+
+    if "background" not in info and "background" in im.info:
+        info["background"] = im.info["background"]
+
+    im_mod = _normalize_palette(im, palette, info)
+    im.palette = im_mod.palette
+    im.im = im_mod.im
+    header = _get_global_header(im, info)
+
+    return header, used_palette_colors
+
+
+# To specify duration, add the time in milliseconds to getdata(),
+# e.g. getdata(im_frame, duration=1000)
+def getdata(im, offset=(0, 0), **params):
+    """
+    Legacy Method
+
+    Return a list of strings representing this image.
+    The first string is a local image header, the rest contains
+    encoded image data.
+
+    :param im: Image object
+    :param offset: Tuple of (x, y) pixels. Defaults to (0,0)
+    :param \\**params: E.g. duration or other encoder info parameters
+    :returns: List of Bytes containing gif encoded frame data
+
+    """
+
+    class Collector:
+        data = []
+
+        def write(self, data):
+            self.data.append(data)
+
+    im.load()  # make sure raster data is available
+
+    fp = Collector()
+
+    _write_frame_data(fp, im, offset, params)
+
+    return fp.data
+
+
+# --------------------------------------------------------------------
+# Registry
+
+Image.register_open(GifImageFile.format, GifImageFile, _accept)
+Image.register_save(GifImageFile.format, _save)
+Image.register_save_all(GifImageFile.format, _save_all)
+Image.register_extension(GifImageFile.format, ".gif")
+Image.register_mime(GifImageFile.format, "image/gif")
+
+#
+# Uncomment the following line if you wish to use NETPBM/PBMPLUS
+# instead of the built-in "uncompressed" GIF encoder
+
+# Image.register_save(GifImageFile.format, _save_netpbm)
diff --git a/.venv/lib/python3.7/site-packages/PIL/GimpGradientFile.py b/.venv/lib/python3.7/site-packages/PIL/GimpGradientFile.py
new file mode 100644
index 0000000..7ab7f99
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/GimpGradientFile.py
@@ -0,0 +1,140 @@
+#
+# Python Imaging Library
+# $Id$
+#
+# stuff to read (and render) GIMP gradient files
+#
+# History:
+#       97-08-23 fl     Created
+#
+# Copyright (c) Secret Labs AB 1997.
+# Copyright (c) Fredrik Lundh 1997.
+#
+# See the README file for information on usage and redistribution.
+#
+
+"""
+Stuff to translate curve segments to palette values (derived from
+the corresponding code in GIMP, written by Federico Mena Quintero.
+See the GIMP distribution for more information.)
+"""
+
+
+from math import log, pi, sin, sqrt
+
+from ._binary import o8
+
+EPSILON = 1e-10
+""""""  # Enable auto-doc for data member
+
+
+def linear(middle, pos):
+    if pos <= middle:
+        if middle < EPSILON:
+            return 0.0
+        else:
+            return 0.5 * pos / middle
+    else:
+        pos = pos - middle
+        middle = 1.0 - middle
+        if middle < EPSILON:
+            return 1.0
+        else:
+            return 0.5 + 0.5 * pos / middle
+
+
+def curved(middle, pos):
+    return pos ** (log(0.5) / log(max(middle, EPSILON)))
+
+
+def sine(middle, pos):
+    return (sin((-pi / 2.0) + pi * linear(middle, pos)) + 1.0) / 2.0
+
+
+def sphere_increasing(middle, pos):
+    return sqrt(1.0 - (linear(middle, pos) - 1.0) ** 2)
+
+
+def sphere_decreasing(middle, pos):
+    return 1.0 - sqrt(1.0 - linear(middle, pos) ** 2)
+
+
+SEGMENTS = [linear, curved, sine, sphere_increasing, sphere_decreasing]
+""""""  # Enable auto-doc for data member
+
+
+class GradientFile:
+
+    gradient = None
+
+    def getpalette(self, entries=256):
+
+        palette = []
+
+        ix = 0
+        x0, x1, xm, rgb0, rgb1, segment = self.gradient[ix]
+
+        for i in range(entries):
+
+            x = i / (entries - 1)
+
+            while x1 < x:
+                ix += 1
+                x0, x1, xm, rgb0, rgb1, segment = self.gradient[ix]
+
+            w = x1 - x0
+
+            if w < EPSILON:
+                scale = segment(0.5, 0.5)
+            else:
+                scale = segment((xm - x0) / w, (x - x0) / w)
+
+            # expand to RGBA
+            r = o8(int(255 * ((rgb1[0] - rgb0[0]) * scale + rgb0[0]) + 0.5))
+            g = o8(int(255 * ((rgb1[1] - rgb0[1]) * scale + rgb0[1]) + 0.5))
+            b = o8(int(255 * ((rgb1[2] - rgb0[2]) * scale + rgb0[2]) + 0.5))
+            a = o8(int(255 * ((rgb1[3] - rgb0[3]) * scale + rgb0[3]) + 0.5))
+
+            # add to palette
+            palette.append(r + g + b + a)
+
+        return b"".join(palette), "RGBA"
+
+
+class GimpGradientFile(GradientFile):
+    """File handler for GIMP's gradient format."""
+
+    def __init__(self, fp):
+
+        if fp.readline()[:13] != b"GIMP Gradient":
+            raise SyntaxError("not a GIMP gradient file")
+
+        line = fp.readline()
+
+        # GIMP 1.2 gradient files don't contain a name, but GIMP 1.3 files do
+        if line.startswith(b"Name: "):
+            line = fp.readline().strip()
+
+        count = int(line)
+
+        gradient = []
+
+        for i in range(count):
+
+            s = fp.readline().split()
+            w = [float(x) for x in s[:11]]
+
+            x0, x1 = w[0], w[2]
+            xm = w[1]
+            rgb0 = w[3:7]
+            rgb1 = w[7:11]
+
+            segment = SEGMENTS[int(s[11])]
+            cspace = int(s[12])
+
+            if cspace != 0:
+                raise OSError("cannot handle HSV colour space")
+
+            gradient.append((x0, x1, xm, rgb0, rgb1, segment))
+
+        self.gradient = gradient
diff --git a/.venv/lib/python3.7/site-packages/PIL/GimpPaletteFile.py b/.venv/lib/python3.7/site-packages/PIL/GimpPaletteFile.py
new file mode 100644
index 0000000..10fd3ad
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/GimpPaletteFile.py
@@ -0,0 +1,56 @@
+#
+# Python Imaging Library
+# $Id$
+#
+# stuff to read GIMP palette files
+#
+# History:
+# 1997-08-23 fl     Created
+# 2004-09-07 fl     Support GIMP 2.0 palette files.
+#
+# Copyright (c) Secret Labs AB 1997-2004.  All rights reserved.
+# Copyright (c) Fredrik Lundh 1997-2004.
+#
+# See the README file for information on usage and redistribution.
+#
+
+import re
+
+from ._binary import o8
+
+
+class GimpPaletteFile:
+    """File handler for GIMP's palette format."""
+
+    rawmode = "RGB"
+
+    def __init__(self, fp):
+
+        self.palette = [o8(i) * 3 for i in range(256)]
+
+        if fp.readline()[:12] != b"GIMP Palette":
+            raise SyntaxError("not a GIMP palette file")
+
+        for i in range(256):
+
+            s = fp.readline()
+            if not s:
+                break
+
+            # skip fields and comment lines
+            if re.match(br"\w+:|#", s):
+                continue
+            if len(s) > 100:
+                raise SyntaxError("bad palette file")
+
+            v = tuple(map(int, s.split()[:3]))
+            if len(v) != 3:
+                raise ValueError("bad palette entry")
+
+            self.palette[i] = o8(v[0]) + o8(v[1]) + o8(v[2])
+
+        self.palette = b"".join(self.palette)
+
+    def getpalette(self):
+
+        return self.palette, self.rawmode
diff --git a/.venv/lib/python3.7/site-packages/PIL/GribStubImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/GribStubImagePlugin.py
new file mode 100644
index 0000000..b9bdd16
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/GribStubImagePlugin.py
@@ -0,0 +1,73 @@
+#
+# The Python Imaging Library
+# $Id$
+#
+# GRIB stub adapter
+#
+# Copyright (c) 1996-2003 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+from . import Image, ImageFile
+
+_handler = None
+
+
+def register_handler(handler):
+    """
+    Install application-specific GRIB image handler.
+
+    :param handler: Handler object.
+    """
+    global _handler
+    _handler = handler
+
+
+# --------------------------------------------------------------------
+# Image adapter
+
+
+def _accept(prefix):
+    return prefix[0:4] == b"GRIB" and prefix[7] == 1
+
+
+class GribStubImageFile(ImageFile.StubImageFile):
+
+    format = "GRIB"
+    format_description = "GRIB"
+
+    def _open(self):
+
+        offset = self.fp.tell()
+
+        if not _accept(self.fp.read(8)):
+            raise SyntaxError("Not a GRIB file")
+
+        self.fp.seek(offset)
+
+        # make something up
+        self.mode = "F"
+        self._size = 1, 1
+
+        loader = self._load()
+        if loader:
+            loader.open(self)
+
+    def _load(self):
+        return _handler
+
+
+def _save(im, fp, filename):
+    if _handler is None or not hasattr("_handler", "save"):
+        raise OSError("GRIB save handler not installed")
+    _handler.save(im, fp, filename)
+
+
+# --------------------------------------------------------------------
+# Registry
+
+Image.register_open(GribStubImageFile.format, GribStubImageFile, _accept)
+Image.register_save(GribStubImageFile.format, _save)
+
+Image.register_extension(GribStubImageFile.format, ".grib")
diff --git a/.venv/lib/python3.7/site-packages/PIL/Hdf5StubImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/Hdf5StubImagePlugin.py
new file mode 100644
index 0000000..362f2d3
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/Hdf5StubImagePlugin.py
@@ -0,0 +1,73 @@
+#
+# The Python Imaging Library
+# $Id$
+#
+# HDF5 stub adapter
+#
+# Copyright (c) 2000-2003 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+from . import Image, ImageFile
+
+_handler = None
+
+
+def register_handler(handler):
+    """
+    Install application-specific HDF5 image handler.
+
+    :param handler: Handler object.
+    """
+    global _handler
+    _handler = handler
+
+
+# --------------------------------------------------------------------
+# Image adapter
+
+
+def _accept(prefix):
+    return prefix[:8] == b"\x89HDF\r\n\x1a\n"
+
+
+class HDF5StubImageFile(ImageFile.StubImageFile):
+
+    format = "HDF5"
+    format_description = "HDF5"
+
+    def _open(self):
+
+        offset = self.fp.tell()
+
+        if not _accept(self.fp.read(8)):
+            raise SyntaxError("Not an HDF file")
+
+        self.fp.seek(offset)
+
+        # make something up
+        self.mode = "F"
+        self._size = 1, 1
+
+        loader = self._load()
+        if loader:
+            loader.open(self)
+
+    def _load(self):
+        return _handler
+
+
+def _save(im, fp, filename):
+    if _handler is None or not hasattr("_handler", "save"):
+        raise OSError("HDF5 save handler not installed")
+    _handler.save(im, fp, filename)
+
+
+# --------------------------------------------------------------------
+# Registry
+
+Image.register_open(HDF5StubImageFile.format, HDF5StubImageFile, _accept)
+Image.register_save(HDF5StubImageFile.format, _save)
+
+Image.register_extensions(HDF5StubImageFile.format, [".h5", ".hdf"])
diff --git a/.venv/lib/python3.7/site-packages/PIL/IcnsImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/IcnsImagePlugin.py
new file mode 100644
index 0000000..6412d1c
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/IcnsImagePlugin.py
@@ -0,0 +1,391 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# macOS icns file decoder, based on icns.py by Bob Ippolito.
+#
+# history:
+# 2004-10-09 fl   Turned into a PIL plugin; removed 2.3 dependencies.
+# 2020-04-04      Allow saving on all operating systems.
+#
+# Copyright (c) 2004 by Bob Ippolito.
+# Copyright (c) 2004 by Secret Labs.
+# Copyright (c) 2004 by Fredrik Lundh.
+# Copyright (c) 2014 by Alastair Houghton.
+# Copyright (c) 2020 by Pan Jing.
+#
+# See the README file for information on usage and redistribution.
+#
+
+import io
+import os
+import struct
+import sys
+
+from PIL import Image, ImageFile, PngImagePlugin, features
+
+enable_jpeg2k = features.check_codec("jpg_2000")
+if enable_jpeg2k:
+    from PIL import Jpeg2KImagePlugin
+
+MAGIC = b"icns"
+HEADERSIZE = 8
+
+
+def nextheader(fobj):
+    return struct.unpack(">4sI", fobj.read(HEADERSIZE))
+
+
+def read_32t(fobj, start_length, size):
+    # The 128x128 icon seems to have an extra header for some reason.
+    (start, length) = start_length
+    fobj.seek(start)
+    sig = fobj.read(4)
+    if sig != b"\x00\x00\x00\x00":
+        raise SyntaxError("Unknown signature, expecting 0x00000000")
+    return read_32(fobj, (start + 4, length - 4), size)
+
+
+def read_32(fobj, start_length, size):
+    """
+    Read a 32bit RGB icon resource.  Seems to be either uncompressed or
+    an RLE packbits-like scheme.
+    """
+    (start, length) = start_length
+    fobj.seek(start)
+    pixel_size = (size[0] * size[2], size[1] * size[2])
+    sizesq = pixel_size[0] * pixel_size[1]
+    if length == sizesq * 3:
+        # uncompressed ("RGBRGBGB")
+        indata = fobj.read(length)
+        im = Image.frombuffer("RGB", pixel_size, indata, "raw", "RGB", 0, 1)
+    else:
+        # decode image
+        im = Image.new("RGB", pixel_size, None)
+        for band_ix in range(3):
+            data = []
+            bytesleft = sizesq
+            while bytesleft > 0:
+                byte = fobj.read(1)
+                if not byte:
+                    break
+                byte = byte[0]
+                if byte & 0x80:
+                    blocksize = byte - 125
+                    byte = fobj.read(1)
+                    for i in range(blocksize):
+                        data.append(byte)
+                else:
+                    blocksize = byte + 1
+                    data.append(fobj.read(blocksize))
+                bytesleft -= blocksize
+                if bytesleft <= 0:
+                    break
+            if bytesleft != 0:
+                raise SyntaxError(f"Error reading channel [{repr(bytesleft)} left]")
+            band = Image.frombuffer("L", pixel_size, b"".join(data), "raw", "L", 0, 1)
+            im.im.putband(band.im, band_ix)
+    return {"RGB": im}
+
+
+def read_mk(fobj, start_length, size):
+    # Alpha masks seem to be uncompressed
+    start = start_length[0]
+    fobj.seek(start)
+    pixel_size = (size[0] * size[2], size[1] * size[2])
+    sizesq = pixel_size[0] * pixel_size[1]
+    band = Image.frombuffer("L", pixel_size, fobj.read(sizesq), "raw", "L", 0, 1)
+    return {"A": band}
+
+
+def read_png_or_jpeg2000(fobj, start_length, size):
+    (start, length) = start_length
+    fobj.seek(start)
+    sig = fobj.read(12)
+    if sig[:8] == b"\x89PNG\x0d\x0a\x1a\x0a":
+        fobj.seek(start)
+        im = PngImagePlugin.PngImageFile(fobj)
+        Image._decompression_bomb_check(im.size)
+        return {"RGBA": im}
+    elif (
+        sig[:4] == b"\xff\x4f\xff\x51"
+        or sig[:4] == b"\x0d\x0a\x87\x0a"
+        or sig == b"\x00\x00\x00\x0cjP  \x0d\x0a\x87\x0a"
+    ):
+        if not enable_jpeg2k:
+            raise ValueError(
+                "Unsupported icon subimage format (rebuild PIL "
+                "with JPEG 2000 support to fix this)"
+            )
+        # j2k, jpc or j2c
+        fobj.seek(start)
+        jp2kstream = fobj.read(length)
+        f = io.BytesIO(jp2kstream)
+        im = Jpeg2KImagePlugin.Jpeg2KImageFile(f)
+        Image._decompression_bomb_check(im.size)
+        if im.mode != "RGBA":
+            im = im.convert("RGBA")
+        return {"RGBA": im}
+    else:
+        raise ValueError("Unsupported icon subimage format")
+
+
+class IcnsFile:
+
+    SIZES = {
+        (512, 512, 2): [(b"ic10", read_png_or_jpeg2000)],
+        (512, 512, 1): [(b"ic09", read_png_or_jpeg2000)],
+        (256, 256, 2): [(b"ic14", read_png_or_jpeg2000)],
+        (256, 256, 1): [(b"ic08", read_png_or_jpeg2000)],
+        (128, 128, 2): [(b"ic13", read_png_or_jpeg2000)],
+        (128, 128, 1): [
+            (b"ic07", read_png_or_jpeg2000),
+            (b"it32", read_32t),
+            (b"t8mk", read_mk),
+        ],
+        (64, 64, 1): [(b"icp6", read_png_or_jpeg2000)],
+        (32, 32, 2): [(b"ic12", read_png_or_jpeg2000)],
+        (48, 48, 1): [(b"ih32", read_32), (b"h8mk", read_mk)],
+        (32, 32, 1): [
+            (b"icp5", read_png_or_jpeg2000),
+            (b"il32", read_32),
+            (b"l8mk", read_mk),
+        ],
+        (16, 16, 2): [(b"ic11", read_png_or_jpeg2000)],
+        (16, 16, 1): [
+            (b"icp4", read_png_or_jpeg2000),
+            (b"is32", read_32),
+            (b"s8mk", read_mk),
+        ],
+    }
+
+    def __init__(self, fobj):
+        """
+        fobj is a file-like object as an icns resource
+        """
+        # signature : (start, length)
+        self.dct = dct = {}
+        self.fobj = fobj
+        sig, filesize = nextheader(fobj)
+        if sig != MAGIC:
+            raise SyntaxError("not an icns file")
+        i = HEADERSIZE
+        while i < filesize:
+            sig, blocksize = nextheader(fobj)
+            if blocksize <= 0:
+                raise SyntaxError("invalid block header")
+            i += HEADERSIZE
+            blocksize -= HEADERSIZE
+            dct[sig] = (i, blocksize)
+            fobj.seek(blocksize, io.SEEK_CUR)
+            i += blocksize
+
+    def itersizes(self):
+        sizes = []
+        for size, fmts in self.SIZES.items():
+            for (fmt, reader) in fmts:
+                if fmt in self.dct:
+                    sizes.append(size)
+                    break
+        return sizes
+
+    def bestsize(self):
+        sizes = self.itersizes()
+        if not sizes:
+            raise SyntaxError("No 32bit icon resources found")
+        return max(sizes)
+
+    def dataforsize(self, size):
+        """
+        Get an icon resource as {channel: array}.  Note that
+        the arrays are bottom-up like windows bitmaps and will likely
+        need to be flipped or transposed in some way.
+        """
+        dct = {}
+        for code, reader in self.SIZES[size]:
+            desc = self.dct.get(code)
+            if desc is not None:
+                dct.update(reader(self.fobj, desc, size))
+        return dct
+
+    def getimage(self, size=None):
+        if size is None:
+            size = self.bestsize()
+        if len(size) == 2:
+            size = (size[0], size[1], 1)
+        channels = self.dataforsize(size)
+
+        im = channels.get("RGBA", None)
+        if im:
+            return im
+
+        im = channels.get("RGB").copy()
+        try:
+            im.putalpha(channels["A"])
+        except KeyError:
+            pass
+        return im
+
+
+##
+# Image plugin for Mac OS icons.
+
+
+class IcnsImageFile(ImageFile.ImageFile):
+    """
+    PIL image support for Mac OS .icns files.
+    Chooses the best resolution, but will possibly load
+    a different size image if you mutate the size attribute
+    before calling 'load'.
+
+    The info dictionary has a key 'sizes' that is a list
+    of sizes that the icns file has.
+    """
+
+    format = "ICNS"
+    format_description = "Mac OS icns resource"
+
+    def _open(self):
+        self.icns = IcnsFile(self.fp)
+        self.mode = "RGBA"
+        self.info["sizes"] = self.icns.itersizes()
+        self.best_size = self.icns.bestsize()
+        self.size = (
+            self.best_size[0] * self.best_size[2],
+            self.best_size[1] * self.best_size[2],
+        )
+
+    @property
+    def size(self):
+        return self._size
+
+    @size.setter
+    def size(self, value):
+        info_size = value
+        if info_size not in self.info["sizes"] and len(info_size) == 2:
+            info_size = (info_size[0], info_size[1], 1)
+        if (
+            info_size not in self.info["sizes"]
+            and len(info_size) == 3
+            and info_size[2] == 1
+        ):
+            simple_sizes = [
+                (size[0] * size[2], size[1] * size[2]) for size in self.info["sizes"]
+            ]
+            if value in simple_sizes:
+                info_size = self.info["sizes"][simple_sizes.index(value)]
+        if info_size not in self.info["sizes"]:
+            raise ValueError("This is not one of the allowed sizes of this image")
+        self._size = value
+
+    def load(self):
+        if len(self.size) == 3:
+            self.best_size = self.size
+            self.size = (
+                self.best_size[0] * self.best_size[2],
+                self.best_size[1] * self.best_size[2],
+            )
+
+        Image.Image.load(self)
+        if self.im and self.im.size == self.size:
+            # Already loaded
+            return
+        self.load_prepare()
+        # This is likely NOT the best way to do it, but whatever.
+        im = self.icns.getimage(self.best_size)
+
+        # If this is a PNG or JPEG 2000, it won't be loaded yet
+        im.load()
+
+        self.im = im.im
+        self.mode = im.mode
+        self.size = im.size
+        self.load_end()
+
+
+def _save(im, fp, filename):
+    """
+    Saves the image as a series of PNG files,
+    that are then combined into a .icns file.
+    """
+    if hasattr(fp, "flush"):
+        fp.flush()
+
+    sizes = {
+        b"ic07": 128,
+        b"ic08": 256,
+        b"ic09": 512,
+        b"ic10": 1024,
+        b"ic11": 32,
+        b"ic12": 64,
+        b"ic13": 256,
+        b"ic14": 512,
+    }
+    provided_images = {im.width: im for im in im.encoderinfo.get("append_images", [])}
+    size_streams = {}
+    for size in set(sizes.values()):
+        image = (
+            provided_images[size]
+            if size in provided_images
+            else im.resize((size, size))
+        )
+
+        temp = io.BytesIO()
+        image.save(temp, "png")
+        size_streams[size] = temp.getvalue()
+
+    entries = []
+    for type, size in sizes.items():
+        stream = size_streams[size]
+        entries.append(
+            {"type": type, "size": HEADERSIZE + len(stream), "stream": stream}
+        )
+
+    # Header
+    fp.write(MAGIC)
+    file_length = HEADERSIZE  # Header
+    file_length += HEADERSIZE + 8 * len(entries)  # TOC
+    file_length += sum(entry["size"] for entry in entries)
+    fp.write(struct.pack(">i", file_length))
+
+    # TOC
+    fp.write(b"TOC ")
+    fp.write(struct.pack(">i", HEADERSIZE + len(entries) * HEADERSIZE))
+    for entry in entries:
+        fp.write(entry["type"])
+        fp.write(struct.pack(">i", entry["size"]))
+
+    # Data
+    for entry in entries:
+        fp.write(entry["type"])
+        fp.write(struct.pack(">i", entry["size"]))
+        fp.write(entry["stream"])
+
+    if hasattr(fp, "flush"):
+        fp.flush()
+
+
+def _accept(prefix):
+    return prefix[:4] == MAGIC
+
+
+Image.register_open(IcnsImageFile.format, IcnsImageFile, _accept)
+Image.register_extension(IcnsImageFile.format, ".icns")
+
+Image.register_save(IcnsImageFile.format, _save)
+Image.register_mime(IcnsImageFile.format, "image/icns")
+
+if __name__ == "__main__":
+    if len(sys.argv) < 2:
+        print("Syntax: python3 IcnsImagePlugin.py [file]")
+        sys.exit()
+
+    with open(sys.argv[1], "rb") as fp:
+        imf = IcnsImageFile(fp)
+        for size in imf.info["sizes"]:
+            imf.size = size
+            imf.save("out-%s-%s-%s.png" % size)
+        with Image.open(sys.argv[1]) as im:
+            im.save("out.png")
+        if sys.platform == "windows":
+            os.startfile("out.png")
diff --git a/.venv/lib/python3.7/site-packages/PIL/IcoImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/IcoImagePlugin.py
new file mode 100644
index 0000000..d9ff9b5
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/IcoImagePlugin.py
@@ -0,0 +1,339 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# Windows Icon support for PIL
+#
+# History:
+#       96-05-27 fl     Created
+#
+# Copyright (c) Secret Labs AB 1997.
+# Copyright (c) Fredrik Lundh 1996.
+#
+# See the README file for information on usage and redistribution.
+#
+
+# This plugin is a refactored version of Win32IconImagePlugin by Bryan Davis
+# <casadebender@gmail.com>.
+# https://code.google.com/archive/p/casadebender/wikis/Win32IconImagePlugin.wiki
+#
+# Icon format references:
+#   * https://en.wikipedia.org/wiki/ICO_(file_format)
+#   * https://msdn.microsoft.com/en-us/library/ms997538.aspx
+
+
+import struct
+import warnings
+from io import BytesIO
+from math import ceil, log
+
+from . import BmpImagePlugin, Image, ImageFile, PngImagePlugin
+from ._binary import i16le as i16
+from ._binary import i32le as i32
+from ._binary import o32le as o32
+
+#
+# --------------------------------------------------------------------
+
+_MAGIC = b"\0\0\1\0"
+
+
+def _save(im, fp, filename):
+    fp.write(_MAGIC)  # (2+2)
+    sizes = im.encoderinfo.get(
+        "sizes",
+        [(16, 16), (24, 24), (32, 32), (48, 48), (64, 64), (128, 128), (256, 256)],
+    )
+    width, height = im.size
+    sizes = filter(
+        lambda x: False
+        if (x[0] > width or x[1] > height or x[0] > 256 or x[1] > 256)
+        else True,
+        sizes,
+    )
+    sizes = list(sizes)
+    fp.write(struct.pack("<H", len(sizes)))  # idCount(2)
+    offset = fp.tell() + len(sizes) * 16
+    bmp = im.encoderinfo.get("bitmap_format") == "bmp"
+    provided_images = {im.size: im for im in im.encoderinfo.get("append_images", [])}
+    for size in sizes:
+        width, height = size
+        # 0 means 256
+        fp.write(struct.pack("B", width if width < 256 else 0))  # bWidth(1)
+        fp.write(struct.pack("B", height if height < 256 else 0))  # bHeight(1)
+        fp.write(b"\0")  # bColorCount(1)
+        fp.write(b"\0")  # bReserved(1)
+        fp.write(b"\0\0")  # wPlanes(2)
+
+        tmp = provided_images.get(size)
+        if not tmp:
+            # TODO: invent a more convenient method for proportional scalings
+            tmp = im.copy()
+            tmp.thumbnail(size, Image.LANCZOS, reducing_gap=None)
+        bits = BmpImagePlugin.SAVE[tmp.mode][1] if bmp else 32
+        fp.write(struct.pack("<H", bits))  # wBitCount(2)
+
+        image_io = BytesIO()
+        if bmp:
+            tmp.save(image_io, "dib")
+
+            if bits != 32:
+                and_mask = Image.new("1", tmp.size)
+                ImageFile._save(
+                    and_mask, image_io, [("raw", (0, 0) + tmp.size, 0, ("1", 0, -1))]
+                )
+        else:
+            tmp.save(image_io, "png")
+        image_io.seek(0)
+        image_bytes = image_io.read()
+        if bmp:
+            image_bytes = image_bytes[:8] + o32(height * 2) + image_bytes[12:]
+        bytes_len = len(image_bytes)
+        fp.write(struct.pack("<I", bytes_len))  # dwBytesInRes(4)
+        fp.write(struct.pack("<I", offset))  # dwImageOffset(4)
+        current = fp.tell()
+        fp.seek(offset)
+        fp.write(image_bytes)
+        offset = offset + bytes_len
+        fp.seek(current)
+
+
+def _accept(prefix):
+    return prefix[:4] == _MAGIC
+
+
+class IcoFile:
+    def __init__(self, buf):
+        """
+        Parse image from file-like object containing ico file data
+        """
+
+        # check magic
+        s = buf.read(6)
+        if not _accept(s):
+            raise SyntaxError("not an ICO file")
+
+        self.buf = buf
+        self.entry = []
+
+        # Number of items in file
+        self.nb_items = i16(s, 4)
+
+        # Get headers for each item
+        for i in range(self.nb_items):
+            s = buf.read(16)
+
+            icon_header = {
+                "width": s[0],
+                "height": s[1],
+                "nb_color": s[2],  # No. of colors in image (0 if >=8bpp)
+                "reserved": s[3],
+                "planes": i16(s, 4),
+                "bpp": i16(s, 6),
+                "size": i32(s, 8),
+                "offset": i32(s, 12),
+            }
+
+            # See Wikipedia
+            for j in ("width", "height"):
+                if not icon_header[j]:
+                    icon_header[j] = 256
+
+            # See Wikipedia notes about color depth.
+            # We need this just to differ images with equal sizes
+            icon_header["color_depth"] = (
+                icon_header["bpp"]
+                or (
+                    icon_header["nb_color"] != 0
+                    and ceil(log(icon_header["nb_color"], 2))
+                )
+                or 256
+            )
+
+            icon_header["dim"] = (icon_header["width"], icon_header["height"])
+            icon_header["square"] = icon_header["width"] * icon_header["height"]
+
+            self.entry.append(icon_header)
+
+        self.entry = sorted(self.entry, key=lambda x: x["color_depth"])
+        # ICO images are usually squares
+        # self.entry = sorted(self.entry, key=lambda x: x['width'])
+        self.entry = sorted(self.entry, key=lambda x: x["square"])
+        self.entry.reverse()
+
+    def sizes(self):
+        """
+        Get a list of all available icon sizes and color depths.
+        """
+        return {(h["width"], h["height"]) for h in self.entry}
+
+    def getentryindex(self, size, bpp=False):
+        for (i, h) in enumerate(self.entry):
+            if size == h["dim"] and (bpp is False or bpp == h["color_depth"]):
+                return i
+        return 0
+
+    def getimage(self, size, bpp=False):
+        """
+        Get an image from the icon
+        """
+        return self.frame(self.getentryindex(size, bpp))
+
+    def frame(self, idx):
+        """
+        Get an image from frame idx
+        """
+
+        header = self.entry[idx]
+
+        self.buf.seek(header["offset"])
+        data = self.buf.read(8)
+        self.buf.seek(header["offset"])
+
+        if data[:8] == PngImagePlugin._MAGIC:
+            # png frame
+            im = PngImagePlugin.PngImageFile(self.buf)
+            Image._decompression_bomb_check(im.size)
+        else:
+            # XOR + AND mask bmp frame
+            im = BmpImagePlugin.DibImageFile(self.buf)
+            Image._decompression_bomb_check(im.size)
+
+            # change tile dimension to only encompass XOR image
+            im._size = (im.size[0], int(im.size[1] / 2))
+            d, e, o, a = im.tile[0]
+            im.tile[0] = d, (0, 0) + im.size, o, a
+
+            # figure out where AND mask image starts
+            bpp = header["bpp"]
+            if 32 == bpp:
+                # 32-bit color depth icon image allows semitransparent areas
+                # PIL's DIB format ignores transparency bits, recover them.
+                # The DIB is packed in BGRX byte order where X is the alpha
+                # channel.
+
+                # Back up to start of bmp data
+                self.buf.seek(o)
+                # extract every 4th byte (eg. 3,7,11,15,...)
+                alpha_bytes = self.buf.read(im.size[0] * im.size[1] * 4)[3::4]
+
+                # convert to an 8bpp grayscale image
+                mask = Image.frombuffer(
+                    "L",  # 8bpp
+                    im.size,  # (w, h)
+                    alpha_bytes,  # source chars
+                    "raw",  # raw decoder
+                    ("L", 0, -1),  # 8bpp inverted, unpadded, reversed
+                )
+            else:
+                # get AND image from end of bitmap
+                w = im.size[0]
+                if (w % 32) > 0:
+                    # bitmap row data is aligned to word boundaries
+                    w += 32 - (im.size[0] % 32)
+
+                # the total mask data is
+                # padded row size * height / bits per char
+
+                total_bytes = int((w * im.size[1]) / 8)
+                and_mask_offset = header["offset"] + header["size"] - total_bytes
+
+                self.buf.seek(and_mask_offset)
+                mask_data = self.buf.read(total_bytes)
+
+                # convert raw data to image
+                mask = Image.frombuffer(
+                    "1",  # 1 bpp
+                    im.size,  # (w, h)
+                    mask_data,  # source chars
+                    "raw",  # raw decoder
+                    ("1;I", int(w / 8), -1),  # 1bpp inverted, padded, reversed
+                )
+
+                # now we have two images, im is XOR image and mask is AND image
+
+            # apply mask image as alpha channel
+            im = im.convert("RGBA")
+            im.putalpha(mask)
+
+        return im
+
+
+##
+# Image plugin for Windows Icon files.
+
+
+class IcoImageFile(ImageFile.ImageFile):
+    """
+    PIL read-only image support for Microsoft Windows .ico files.
+
+    By default the largest resolution image in the file will be loaded. This
+    can be changed by altering the 'size' attribute before calling 'load'.
+
+    The info dictionary has a key 'sizes' that is a list of the sizes available
+    in the icon file.
+
+    Handles classic, XP and Vista icon formats.
+
+    When saving, PNG compression is used. Support for this was only added in
+    Windows Vista. If you are unable to view the icon in Windows, convert the
+    image to "RGBA" mode before saving.
+
+    This plugin is a refactored version of Win32IconImagePlugin by Bryan Davis
+    <casadebender@gmail.com>.
+    https://code.google.com/archive/p/casadebender/wikis/Win32IconImagePlugin.wiki
+    """
+
+    format = "ICO"
+    format_description = "Windows Icon"
+
+    def _open(self):
+        self.ico = IcoFile(self.fp)
+        self.info["sizes"] = self.ico.sizes()
+        self.size = self.ico.entry[0]["dim"]
+        self.load()
+
+    @property
+    def size(self):
+        return self._size
+
+    @size.setter
+    def size(self, value):
+        if value not in self.info["sizes"]:
+            raise ValueError("This is not one of the allowed sizes of this image")
+        self._size = value
+
+    def load(self):
+        if self.im and self.im.size == self.size:
+            # Already loaded
+            return
+        im = self.ico.getimage(self.size)
+        # if tile is PNG, it won't really be loaded yet
+        im.load()
+        self.im = im.im
+        self.mode = im.mode
+        if im.size != self.size:
+            warnings.warn("Image was not the expected size")
+
+            index = self.ico.getentryindex(self.size)
+            sizes = list(self.info["sizes"])
+            sizes[index] = im.size
+            self.info["sizes"] = set(sizes)
+
+            self.size = im.size
+
+    def load_seek(self):
+        # Flag the ImageFile.Parser so that it
+        # just does all the decode at the end.
+        pass
+
+
+#
+# --------------------------------------------------------------------
+
+
+Image.register_open(IcoImageFile.format, IcoImageFile, _accept)
+Image.register_save(IcoImageFile.format, _save)
+Image.register_extension(IcoImageFile.format, ".ico")
+
+Image.register_mime(IcoImageFile.format, "image/x-icon")
diff --git a/.venv/lib/python3.7/site-packages/PIL/ImImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/ImImagePlugin.py
new file mode 100644
index 0000000..1dfc808
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ImImagePlugin.py
@@ -0,0 +1,376 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# IFUNC IM file handling for PIL
+#
+# history:
+# 1995-09-01 fl   Created.
+# 1997-01-03 fl   Save palette images
+# 1997-01-08 fl   Added sequence support
+# 1997-01-23 fl   Added P and RGB save support
+# 1997-05-31 fl   Read floating point images
+# 1997-06-22 fl   Save floating point images
+# 1997-08-27 fl   Read and save 1-bit images
+# 1998-06-25 fl   Added support for RGB+LUT images
+# 1998-07-02 fl   Added support for YCC images
+# 1998-07-15 fl   Renamed offset attribute to avoid name clash
+# 1998-12-29 fl   Added I;16 support
+# 2001-02-17 fl   Use 're' instead of 'regex' (Python 2.1) (0.7)
+# 2003-09-26 fl   Added LA/PA support
+#
+# Copyright (c) 1997-2003 by Secret Labs AB.
+# Copyright (c) 1995-2001 by Fredrik Lundh.
+#
+# See the README file for information on usage and redistribution.
+#
+
+
+import os
+import re
+
+from . import Image, ImageFile, ImagePalette
+
+# --------------------------------------------------------------------
+# Standard tags
+
+COMMENT = "Comment"
+DATE = "Date"
+EQUIPMENT = "Digitalization equipment"
+FRAMES = "File size (no of images)"
+LUT = "Lut"
+NAME = "Name"
+SCALE = "Scale (x,y)"
+SIZE = "Image size (x*y)"
+MODE = "Image type"
+
+TAGS = {
+    COMMENT: 0,
+    DATE: 0,
+    EQUIPMENT: 0,
+    FRAMES: 0,
+    LUT: 0,
+    NAME: 0,
+    SCALE: 0,
+    SIZE: 0,
+    MODE: 0,
+}
+
+OPEN = {
+    # ifunc93/p3cfunc formats
+    "0 1 image": ("1", "1"),
+    "L 1 image": ("1", "1"),
+    "Greyscale image": ("L", "L"),
+    "Grayscale image": ("L", "L"),
+    "RGB image": ("RGB", "RGB;L"),
+    "RLB image": ("RGB", "RLB"),
+    "RYB image": ("RGB", "RLB"),
+    "B1 image": ("1", "1"),
+    "B2 image": ("P", "P;2"),
+    "B4 image": ("P", "P;4"),
+    "X 24 image": ("RGB", "RGB"),
+    "L 32 S image": ("I", "I;32"),
+    "L 32 F image": ("F", "F;32"),
+    # old p3cfunc formats
+    "RGB3 image": ("RGB", "RGB;T"),
+    "RYB3 image": ("RGB", "RYB;T"),
+    # extensions
+    "LA image": ("LA", "LA;L"),
+    "PA image": ("LA", "PA;L"),
+    "RGBA image": ("RGBA", "RGBA;L"),
+    "RGBX image": ("RGBX", "RGBX;L"),
+    "CMYK image": ("CMYK", "CMYK;L"),
+    "YCC image": ("YCbCr", "YCbCr;L"),
+}
+
+# ifunc95 extensions
+for i in ["8", "8S", "16", "16S", "32", "32F"]:
+    OPEN[f"L {i} image"] = ("F", f"F;{i}")
+    OPEN[f"L*{i} image"] = ("F", f"F;{i}")
+for i in ["16", "16L", "16B"]:
+    OPEN[f"L {i} image"] = (f"I;{i}", f"I;{i}")
+    OPEN[f"L*{i} image"] = (f"I;{i}", f"I;{i}")
+for i in ["32S"]:
+    OPEN[f"L {i} image"] = ("I", f"I;{i}")
+    OPEN[f"L*{i} image"] = ("I", f"I;{i}")
+for i in range(2, 33):
+    OPEN[f"L*{i} image"] = ("F", f"F;{i}")
+
+
+# --------------------------------------------------------------------
+# Read IM directory
+
+split = re.compile(br"^([A-Za-z][^:]*):[ \t]*(.*)[ \t]*$")
+
+
+def number(s):
+    try:
+        return int(s)
+    except ValueError:
+        return float(s)
+
+
+##
+# Image plugin for the IFUNC IM file format.
+
+
+class ImImageFile(ImageFile.ImageFile):
+
+    format = "IM"
+    format_description = "IFUNC Image Memory"
+    _close_exclusive_fp_after_loading = False
+
+    def _open(self):
+
+        # Quick rejection: if there's not an LF among the first
+        # 100 bytes, this is (probably) not a text header.
+
+        if b"\n" not in self.fp.read(100):
+            raise SyntaxError("not an IM file")
+        self.fp.seek(0)
+
+        n = 0
+
+        # Default values
+        self.info[MODE] = "L"
+        self.info[SIZE] = (512, 512)
+        self.info[FRAMES] = 1
+
+        self.rawmode = "L"
+
+        while True:
+
+            s = self.fp.read(1)
+
+            # Some versions of IFUNC uses \n\r instead of \r\n...
+            if s == b"\r":
+                continue
+
+            if not s or s == b"\0" or s == b"\x1A":
+                break
+
+            # FIXME: this may read whole file if not a text file
+            s = s + self.fp.readline()
+
+            if len(s) > 100:
+                raise SyntaxError("not an IM file")
+
+            if s[-2:] == b"\r\n":
+                s = s[:-2]
+            elif s[-1:] == b"\n":
+                s = s[:-1]
+
+            try:
+                m = split.match(s)
+            except re.error as e:
+                raise SyntaxError("not an IM file") from e
+
+            if m:
+
+                k, v = m.group(1, 2)
+
+                # Don't know if this is the correct encoding,
+                # but a decent guess (I guess)
+                k = k.decode("latin-1", "replace")
+                v = v.decode("latin-1", "replace")
+
+                # Convert value as appropriate
+                if k in [FRAMES, SCALE, SIZE]:
+                    v = v.replace("*", ",")
+                    v = tuple(map(number, v.split(",")))
+                    if len(v) == 1:
+                        v = v[0]
+                elif k == MODE and v in OPEN:
+                    v, self.rawmode = OPEN[v]
+
+                # Add to dictionary. Note that COMMENT tags are
+                # combined into a list of strings.
+                if k == COMMENT:
+                    if k in self.info:
+                        self.info[k].append(v)
+                    else:
+                        self.info[k] = [v]
+                else:
+                    self.info[k] = v
+
+                if k in TAGS:
+                    n += 1
+
+            else:
+
+                raise SyntaxError(
+                    "Syntax error in IM header: " + s.decode("ascii", "replace")
+                )
+
+        if not n:
+            raise SyntaxError("Not an IM file")
+
+        # Basic attributes
+        self._size = self.info[SIZE]
+        self.mode = self.info[MODE]
+
+        # Skip forward to start of image data
+        while s and s[0:1] != b"\x1A":
+            s = self.fp.read(1)
+        if not s:
+            raise SyntaxError("File truncated")
+
+        if LUT in self.info:
+            # convert lookup table to palette or lut attribute
+            palette = self.fp.read(768)
+            greyscale = 1  # greyscale palette
+            linear = 1  # linear greyscale palette
+            for i in range(256):
+                if palette[i] == palette[i + 256] == palette[i + 512]:
+                    if palette[i] != i:
+                        linear = 0
+                else:
+                    greyscale = 0
+            if self.mode in ["L", "LA", "P", "PA"]:
+                if greyscale:
+                    if not linear:
+                        self.lut = list(palette[:256])
+                else:
+                    if self.mode in ["L", "P"]:
+                        self.mode = self.rawmode = "P"
+                    elif self.mode in ["LA", "PA"]:
+                        self.mode = "PA"
+                        self.rawmode = "PA;L"
+                    self.palette = ImagePalette.raw("RGB;L", palette)
+            elif self.mode == "RGB":
+                if not greyscale or not linear:
+                    self.lut = list(palette)
+
+        self.frame = 0
+
+        self.__offset = offs = self.fp.tell()
+
+        self.__fp = self.fp  # FIXME: hack
+
+        if self.rawmode[:2] == "F;":
+
+            # ifunc95 formats
+            try:
+                # use bit decoder (if necessary)
+                bits = int(self.rawmode[2:])
+                if bits not in [8, 16, 32]:
+                    self.tile = [("bit", (0, 0) + self.size, offs, (bits, 8, 3, 0, -1))]
+                    return
+            except ValueError:
+                pass
+
+        if self.rawmode in ["RGB;T", "RYB;T"]:
+            # Old LabEye/3PC files.  Would be very surprised if anyone
+            # ever stumbled upon such a file ;-)
+            size = self.size[0] * self.size[1]
+            self.tile = [
+                ("raw", (0, 0) + self.size, offs, ("G", 0, -1)),
+                ("raw", (0, 0) + self.size, offs + size, ("R", 0, -1)),
+                ("raw", (0, 0) + self.size, offs + 2 * size, ("B", 0, -1)),
+            ]
+        else:
+            # LabEye/IFUNC files
+            self.tile = [("raw", (0, 0) + self.size, offs, (self.rawmode, 0, -1))]
+
+    @property
+    def n_frames(self):
+        return self.info[FRAMES]
+
+    @property
+    def is_animated(self):
+        return self.info[FRAMES] > 1
+
+    def seek(self, frame):
+        if not self._seek_check(frame):
+            return
+
+        self.frame = frame
+
+        if self.mode == "1":
+            bits = 1
+        else:
+            bits = 8 * len(self.mode)
+
+        size = ((self.size[0] * bits + 7) // 8) * self.size[1]
+        offs = self.__offset + frame * size
+
+        self.fp = self.__fp
+
+        self.tile = [("raw", (0, 0) + self.size, offs, (self.rawmode, 0, -1))]
+
+    def tell(self):
+        return self.frame
+
+    def _close__fp(self):
+        try:
+            if self.__fp != self.fp:
+                self.__fp.close()
+        except AttributeError:
+            pass
+        finally:
+            self.__fp = None
+
+
+#
+# --------------------------------------------------------------------
+# Save IM files
+
+
+SAVE = {
+    # mode: (im type, raw mode)
+    "1": ("0 1", "1"),
+    "L": ("Greyscale", "L"),
+    "LA": ("LA", "LA;L"),
+    "P": ("Greyscale", "P"),
+    "PA": ("LA", "PA;L"),
+    "I": ("L 32S", "I;32S"),
+    "I;16": ("L 16", "I;16"),
+    "I;16L": ("L 16L", "I;16L"),
+    "I;16B": ("L 16B", "I;16B"),
+    "F": ("L 32F", "F;32F"),
+    "RGB": ("RGB", "RGB;L"),
+    "RGBA": ("RGBA", "RGBA;L"),
+    "RGBX": ("RGBX", "RGBX;L"),
+    "CMYK": ("CMYK", "CMYK;L"),
+    "YCbCr": ("YCC", "YCbCr;L"),
+}
+
+
+def _save(im, fp, filename):
+
+    try:
+        image_type, rawmode = SAVE[im.mode]
+    except KeyError as e:
+        raise ValueError(f"Cannot save {im.mode} images as IM") from e
+
+    frames = im.encoderinfo.get("frames", 1)
+
+    fp.write(f"Image type: {image_type} image\r\n".encode("ascii"))
+    if filename:
+        # Each line must be 100 characters or less,
+        # or: SyntaxError("not an IM file")
+        # 8 characters are used for "Name: " and "\r\n"
+        # Keep just the filename, ditch the potentially overlong path
+        name, ext = os.path.splitext(os.path.basename(filename))
+        name = "".join([name[: 92 - len(ext)], ext])
+
+        fp.write(f"Name: {name}\r\n".encode("ascii"))
+    fp.write(("Image size (x*y): %d*%d\r\n" % im.size).encode("ascii"))
+    fp.write(f"File size (no of images): {frames}\r\n".encode("ascii"))
+    if im.mode in ["P", "PA"]:
+        fp.write(b"Lut: 1\r\n")
+    fp.write(b"\000" * (511 - fp.tell()) + b"\032")
+    if im.mode in ["P", "PA"]:
+        fp.write(im.im.getpalette("RGB", "RGB;L"))  # 768 bytes
+    ImageFile._save(im, fp, [("raw", (0, 0) + im.size, 0, (rawmode, 0, -1))])
+
+
+#
+# --------------------------------------------------------------------
+# Registry
+
+
+Image.register_open(ImImageFile.format, ImImageFile)
+Image.register_save(ImImageFile.format, _save)
+
+Image.register_extension(ImImageFile.format, ".im")
diff --git a/.venv/lib/python3.7/site-packages/PIL/Image.py b/.venv/lib/python3.7/site-packages/PIL/Image.py
new file mode 100644
index 0000000..e5ea25f
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/Image.py
@@ -0,0 +1,3576 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# the Image class wrapper
+#
+# partial release history:
+# 1995-09-09 fl   Created
+# 1996-03-11 fl   PIL release 0.0 (proof of concept)
+# 1996-04-30 fl   PIL release 0.1b1
+# 1999-07-28 fl   PIL release 1.0 final
+# 2000-06-07 fl   PIL release 1.1
+# 2000-10-20 fl   PIL release 1.1.1
+# 2001-05-07 fl   PIL release 1.1.2
+# 2002-03-15 fl   PIL release 1.1.3
+# 2003-05-10 fl   PIL release 1.1.4
+# 2005-03-28 fl   PIL release 1.1.5
+# 2006-12-02 fl   PIL release 1.1.6
+# 2009-11-15 fl   PIL release 1.1.7
+#
+# Copyright (c) 1997-2009 by Secret Labs AB.  All rights reserved.
+# Copyright (c) 1995-2009 by Fredrik Lundh.
+#
+# See the README file for information on usage and redistribution.
+#
+
+import atexit
+import builtins
+import io
+import logging
+import math
+import numbers
+import os
+import re
+import struct
+import sys
+import tempfile
+import warnings
+from collections.abc import Callable, MutableMapping
+from pathlib import Path
+
+try:
+    import defusedxml.ElementTree as ElementTree
+except ImportError:
+    ElementTree = None
+
+# VERSION was removed in Pillow 6.0.0.
+# PILLOW_VERSION was removed in Pillow 9.0.0.
+# Use __version__ instead.
+from . import ImageMode, TiffTags, UnidentifiedImageError, __version__, _plugins
+from ._binary import i32le
+from ._util import deferred_error, isPath
+
+
+def __getattr__(name):
+    categories = {"NORMAL": 0, "SEQUENCE": 1, "CONTAINER": 2}
+    if name in categories:
+        warnings.warn(
+            "Image categories are deprecated and will be removed in Pillow 10 "
+            "(2023-07-01). Use is_animated instead.",
+            DeprecationWarning,
+            stacklevel=2,
+        )
+        return categories[name]
+    raise AttributeError(f"module '{__name__}' has no attribute '{name}'")
+
+
+logger = logging.getLogger(__name__)
+
+
+class DecompressionBombWarning(RuntimeWarning):
+    pass
+
+
+class DecompressionBombError(Exception):
+    pass
+
+
+# Limit to around a quarter gigabyte for a 24-bit (3 bpp) image
+MAX_IMAGE_PIXELS = int(1024 * 1024 * 1024 // 4 // 3)
+
+
+try:
+    # If the _imaging C module is not present, Pillow will not load.
+    # Note that other modules should not refer to _imaging directly;
+    # import Image and use the Image.core variable instead.
+    # Also note that Image.core is not a publicly documented interface,
+    # and should be considered private and subject to change.
+    from . import _imaging as core
+
+    if __version__ != getattr(core, "PILLOW_VERSION", None):
+        raise ImportError(
+            "The _imaging extension was built for another version of Pillow or PIL:\n"
+            f"Core version: {getattr(core, 'PILLOW_VERSION', None)}\n"
+            f"Pillow version: {__version__}"
+        )
+
+except ImportError as v:
+    core = deferred_error(ImportError("The _imaging C module is not installed."))
+    # Explanations for ways that we know we might have an import error
+    if str(v).startswith("Module use of python"):
+        # The _imaging C module is present, but not compiled for
+        # the right version (windows only).  Print a warning, if
+        # possible.
+        warnings.warn(
+            "The _imaging extension was built for another version of Python.",
+            RuntimeWarning,
+        )
+    elif str(v).startswith("The _imaging extension"):
+        warnings.warn(str(v), RuntimeWarning)
+    # Fail here anyway. Don't let people run with a mostly broken Pillow.
+    # see docs/porting.rst
+    raise
+
+
+# works everywhere, win for pypy, not cpython
+USE_CFFI_ACCESS = hasattr(sys, "pypy_version_info")
+try:
+    import cffi
+except ImportError:
+    cffi = None
+
+
+def isImageType(t):
+    """
+    Checks if an object is an image object.
+
+    .. warning::
+
+       This function is for internal use only.
+
+    :param t: object to check if it's an image
+    :returns: True if the object is an image
+    """
+    return hasattr(t, "im")
+
+
+#
+# Constants
+
+# transpose
+FLIP_LEFT_RIGHT = 0
+FLIP_TOP_BOTTOM = 1
+ROTATE_90 = 2
+ROTATE_180 = 3
+ROTATE_270 = 4
+TRANSPOSE = 5
+TRANSVERSE = 6
+
+# transforms (also defined in Imaging.h)
+AFFINE = 0
+EXTENT = 1
+PERSPECTIVE = 2
+QUAD = 3
+MESH = 4
+
+# resampling filters (also defined in Imaging.h)
+NEAREST = NONE = 0
+BOX = 4
+BILINEAR = LINEAR = 2
+HAMMING = 5
+BICUBIC = CUBIC = 3
+LANCZOS = ANTIALIAS = 1
+
+_filters_support = {BOX: 0.5, BILINEAR: 1.0, HAMMING: 1.0, BICUBIC: 2.0, LANCZOS: 3.0}
+
+
+# dithers
+NEAREST = NONE = 0
+ORDERED = 1  # Not yet implemented
+RASTERIZE = 2  # Not yet implemented
+FLOYDSTEINBERG = 3  # default
+
+# palettes/quantizers
+WEB = 0
+ADAPTIVE = 1
+
+MEDIANCUT = 0
+MAXCOVERAGE = 1
+FASTOCTREE = 2
+LIBIMAGEQUANT = 3
+
+if hasattr(core, "DEFAULT_STRATEGY"):
+    DEFAULT_STRATEGY = core.DEFAULT_STRATEGY
+    FILTERED = core.FILTERED
+    HUFFMAN_ONLY = core.HUFFMAN_ONLY
+    RLE = core.RLE
+    FIXED = core.FIXED
+
+
+# --------------------------------------------------------------------
+# Registries
+
+ID = []
+OPEN = {}
+MIME = {}
+SAVE = {}
+SAVE_ALL = {}
+EXTENSION = {}
+DECODERS = {}
+ENCODERS = {}
+
+# --------------------------------------------------------------------
+# Modes
+
+if sys.byteorder == "little":
+    _ENDIAN = "<"
+else:
+    _ENDIAN = ">"
+
+_MODE_CONV = {
+    # official modes
+    "1": ("|b1", None),  # Bits need to be extended to bytes
+    "L": ("|u1", None),
+    "LA": ("|u1", 2),
+    "I": (_ENDIAN + "i4", None),
+    "F": (_ENDIAN + "f4", None),
+    "P": ("|u1", None),
+    "RGB": ("|u1", 3),
+    "RGBX": ("|u1", 4),
+    "RGBA": ("|u1", 4),
+    "CMYK": ("|u1", 4),
+    "YCbCr": ("|u1", 3),
+    "LAB": ("|u1", 3),  # UNDONE - unsigned |u1i1i1
+    "HSV": ("|u1", 3),
+    # I;16 == I;16L, and I;32 == I;32L
+    "I;16": ("<u2", None),
+    "I;16B": (">u2", None),
+    "I;16L": ("<u2", None),
+    "I;16S": ("<i2", None),
+    "I;16BS": (">i2", None),
+    "I;16LS": ("<i2", None),
+    "I;32": ("<u4", None),
+    "I;32B": (">u4", None),
+    "I;32L": ("<u4", None),
+    "I;32S": ("<i4", None),
+    "I;32BS": (">i4", None),
+    "I;32LS": ("<i4", None),
+}
+
+
+def _conv_type_shape(im):
+    typ, extra = _MODE_CONV[im.mode]
+    if extra is None:
+        return (im.size[1], im.size[0]), typ
+    else:
+        return (im.size[1], im.size[0], extra), typ
+
+
+MODES = ["1", "CMYK", "F", "HSV", "I", "L", "LAB", "P", "RGB", "RGBA", "RGBX", "YCbCr"]
+
+# raw modes that may be memory mapped.  NOTE: if you change this, you
+# may have to modify the stride calculation in map.c too!
+_MAPMODES = ("L", "P", "RGBX", "RGBA", "CMYK", "I;16", "I;16L", "I;16B")
+
+
+def getmodebase(mode):
+    """
+    Gets the "base" mode for given mode.  This function returns "L" for
+    images that contain grayscale data, and "RGB" for images that
+    contain color data.
+
+    :param mode: Input mode.
+    :returns: "L" or "RGB".
+    :exception KeyError: If the input mode was not a standard mode.
+    """
+    return ImageMode.getmode(mode).basemode
+
+
+def getmodetype(mode):
+    """
+    Gets the storage type mode.  Given a mode, this function returns a
+    single-layer mode suitable for storing individual bands.
+
+    :param mode: Input mode.
+    :returns: "L", "I", or "F".
+    :exception KeyError: If the input mode was not a standard mode.
+    """
+    return ImageMode.getmode(mode).basetype
+
+
+def getmodebandnames(mode):
+    """
+    Gets a list of individual band names.  Given a mode, this function returns
+    a tuple containing the names of individual bands (use
+    :py:method:`~PIL.Image.getmodetype` to get the mode used to store each
+    individual band.
+
+    :param mode: Input mode.
+    :returns: A tuple containing band names.  The length of the tuple
+        gives the number of bands in an image of the given mode.
+    :exception KeyError: If the input mode was not a standard mode.
+    """
+    return ImageMode.getmode(mode).bands
+
+
+def getmodebands(mode):
+    """
+    Gets the number of individual bands for this mode.
+
+    :param mode: Input mode.
+    :returns: The number of bands in this mode.
+    :exception KeyError: If the input mode was not a standard mode.
+    """
+    return len(ImageMode.getmode(mode).bands)
+
+
+# --------------------------------------------------------------------
+# Helpers
+
+_initialized = 0
+
+
+def preinit():
+    """Explicitly load standard file format drivers."""
+
+    global _initialized
+    if _initialized >= 1:
+        return
+
+    try:
+        from . import BmpImagePlugin
+
+        assert BmpImagePlugin
+    except ImportError:
+        pass
+    try:
+        from . import GifImagePlugin
+
+        assert GifImagePlugin
+    except ImportError:
+        pass
+    try:
+        from . import JpegImagePlugin
+
+        assert JpegImagePlugin
+    except ImportError:
+        pass
+    try:
+        from . import PpmImagePlugin
+
+        assert PpmImagePlugin
+    except ImportError:
+        pass
+    try:
+        from . import PngImagePlugin
+
+        assert PngImagePlugin
+    except ImportError:
+        pass
+    # try:
+    #     import TiffImagePlugin
+    #     assert TiffImagePlugin
+    # except ImportError:
+    #     pass
+
+    _initialized = 1
+
+
+def init():
+    """
+    Explicitly initializes the Python Imaging Library. This function
+    loads all available file format drivers.
+    """
+
+    global _initialized
+    if _initialized >= 2:
+        return 0
+
+    for plugin in _plugins:
+        try:
+            logger.debug("Importing %s", plugin)
+            __import__(f"PIL.{plugin}", globals(), locals(), [])
+        except ImportError as e:
+            logger.debug("Image: failed to import %s: %s", plugin, e)
+
+    if OPEN or SAVE:
+        _initialized = 2
+        return 1
+
+
+# --------------------------------------------------------------------
+# Codec factories (used by tobytes/frombytes and ImageFile.load)
+
+
+def _getdecoder(mode, decoder_name, args, extra=()):
+
+    # tweak arguments
+    if args is None:
+        args = ()
+    elif not isinstance(args, tuple):
+        args = (args,)
+
+    try:
+        decoder = DECODERS[decoder_name]
+    except KeyError:
+        pass
+    else:
+        return decoder(mode, *args + extra)
+
+    try:
+        # get decoder
+        decoder = getattr(core, decoder_name + "_decoder")
+    except AttributeError as e:
+        raise OSError(f"decoder {decoder_name} not available") from e
+    return decoder(mode, *args + extra)
+
+
+def _getencoder(mode, encoder_name, args, extra=()):
+
+    # tweak arguments
+    if args is None:
+        args = ()
+    elif not isinstance(args, tuple):
+        args = (args,)
+
+    try:
+        encoder = ENCODERS[encoder_name]
+    except KeyError:
+        pass
+    else:
+        return encoder(mode, *args + extra)
+
+    try:
+        # get encoder
+        encoder = getattr(core, encoder_name + "_encoder")
+    except AttributeError as e:
+        raise OSError(f"encoder {encoder_name} not available") from e
+    return encoder(mode, *args + extra)
+
+
+# --------------------------------------------------------------------
+# Simple expression analyzer
+
+
+def coerce_e(value):
+    return value if isinstance(value, _E) else _E(value)
+
+
+class _E:
+    def __init__(self, data):
+        self.data = data
+
+    def __add__(self, other):
+        return _E((self.data, "__add__", coerce_e(other).data))
+
+    def __mul__(self, other):
+        return _E((self.data, "__mul__", coerce_e(other).data))
+
+
+def _getscaleoffset(expr):
+    stub = ["stub"]
+    data = expr(_E(stub)).data
+    try:
+        (a, b, c) = data  # simplified syntax
+        if a is stub and b == "__mul__" and isinstance(c, numbers.Number):
+            return c, 0.0
+        if a is stub and b == "__add__" and isinstance(c, numbers.Number):
+            return 1.0, c
+    except TypeError:
+        pass
+    try:
+        ((a, b, c), d, e) = data  # full syntax
+        if (
+            a is stub
+            and b == "__mul__"
+            and isinstance(c, numbers.Number)
+            and d == "__add__"
+            and isinstance(e, numbers.Number)
+        ):
+            return c, e
+    except TypeError:
+        pass
+    raise ValueError("illegal expression")
+
+
+# --------------------------------------------------------------------
+# Implementation wrapper
+
+
+class Image:
+    """
+    This class represents an image object.  To create
+    :py:class:`~PIL.Image.Image` objects, use the appropriate factory
+    functions.  There's hardly ever any reason to call the Image constructor
+    directly.
+
+    * :py:func:`~PIL.Image.open`
+    * :py:func:`~PIL.Image.new`
+    * :py:func:`~PIL.Image.frombytes`
+    """
+
+    format = None
+    format_description = None
+    _close_exclusive_fp_after_loading = True
+
+    def __init__(self):
+        # FIXME: take "new" parameters / other image?
+        # FIXME: turn mode and size into delegating properties?
+        self.im = None
+        self.mode = ""
+        self._size = (0, 0)
+        self.palette = None
+        self.info = {}
+        self._category = 0
+        self.readonly = 0
+        self.pyaccess = None
+        self._exif = None
+
+    def __getattr__(self, name):
+        if name == "category":
+            warnings.warn(
+                "Image categories are deprecated and will be removed in Pillow 10 "
+                "(2023-07-01). Use is_animated instead.",
+                DeprecationWarning,
+                stacklevel=2,
+            )
+            return self._category
+        raise AttributeError(name)
+
+    @property
+    def width(self):
+        return self.size[0]
+
+    @property
+    def height(self):
+        return self.size[1]
+
+    @property
+    def size(self):
+        return self._size
+
+    def _new(self, im):
+        new = Image()
+        new.im = im
+        new.mode = im.mode
+        new._size = im.size
+        if im.mode in ("P", "PA"):
+            if self.palette:
+                new.palette = self.palette.copy()
+            else:
+                from . import ImagePalette
+
+                new.palette = ImagePalette.ImagePalette()
+        new.info = self.info.copy()
+        return new
+
+    # Context manager support
+    def __enter__(self):
+        return self
+
+    def __exit__(self, *args):
+        if hasattr(self, "fp") and getattr(self, "_exclusive_fp", False):
+            if hasattr(self, "_close__fp"):
+                self._close__fp()
+            if self.fp:
+                self.fp.close()
+        self.fp = None
+
+    def close(self):
+        """
+        Closes the file pointer, if possible.
+
+        This operation will destroy the image core and release its memory.
+        The image data will be unusable afterward.
+
+        This function is required to close images that have multiple frames or
+        have not had their file read and closed by the
+        :py:meth:`~PIL.Image.Image.load` method. See :ref:`file-handling` for
+        more information.
+        """
+        try:
+            if hasattr(self, "_close__fp"):
+                self._close__fp()
+            if self.fp:
+                self.fp.close()
+            self.fp = None
+        except Exception as msg:
+            logger.debug("Error closing: %s", msg)
+
+        if getattr(self, "map", None):
+            self.map = None
+
+        # Instead of simply setting to None, we're setting up a
+        # deferred error that will better explain that the core image
+        # object is gone.
+        self.im = deferred_error(ValueError("Operation on closed image"))
+
+    def _copy(self):
+        self.load()
+        self.im = self.im.copy()
+        self.pyaccess = None
+        self.readonly = 0
+
+    def _ensure_mutable(self):
+        if self.readonly:
+            self._copy()
+        else:
+            self.load()
+
+    def _dump(self, file=None, format=None, **options):
+        suffix = ""
+        if format:
+            suffix = "." + format
+
+        if not file:
+            f, filename = tempfile.mkstemp(suffix)
+            os.close(f)
+        else:
+            filename = file
+            if not filename.endswith(suffix):
+                filename = filename + suffix
+
+        self.load()
+
+        if not format or format == "PPM":
+            self.im.save_ppm(filename)
+        else:
+            self.save(filename, format, **options)
+
+        return filename
+
+    def __eq__(self, other):
+        return (
+            self.__class__ is other.__class__
+            and self.mode == other.mode
+            and self.size == other.size
+            and self.info == other.info
+            and self._category == other._category
+            and self.readonly == other.readonly
+            and self.getpalette() == other.getpalette()
+            and self.tobytes() == other.tobytes()
+        )
+
+    def __repr__(self):
+        return "<%s.%s image mode=%s size=%dx%d at 0x%X>" % (
+            self.__class__.__module__,
+            self.__class__.__name__,
+            self.mode,
+            self.size[0],
+            self.size[1],
+            id(self),
+        )
+
+    def _repr_png_(self):
+        """iPython display hook support
+
+        :returns: png version of the image as bytes
+        """
+        b = io.BytesIO()
+        try:
+            self.save(b, "PNG")
+        except Exception as e:
+            raise ValueError("Could not save to PNG for display") from e
+        return b.getvalue()
+
+    class _ArrayData:
+        def __init__(self, new):
+            self.__array_interface__ = new
+
+    def __array__(self, dtype=None):
+        # numpy array interface support
+        import numpy as np
+
+        new = {}
+        shape, typestr = _conv_type_shape(self)
+        new["shape"] = shape
+        new["typestr"] = typestr
+        new["version"] = 3
+        if self.mode == "1":
+            # Binary images need to be extended from bits to bytes
+            # See: https://github.com/python-pillow/Pillow/issues/350
+            new["data"] = self.tobytes("raw", "L")
+        else:
+            new["data"] = self.tobytes()
+
+        return np.array(self._ArrayData(new), dtype)
+
+    def __getstate__(self):
+        return [self.info, self.mode, self.size, self.getpalette(), self.tobytes()]
+
+    def __setstate__(self, state):
+        Image.__init__(self)
+        self.tile = []
+        info, mode, size, palette, data = state
+        self.info = info
+        self.mode = mode
+        self._size = size
+        self.im = core.new(mode, size)
+        if mode in ("L", "LA", "P", "PA") and palette:
+            self.putpalette(palette)
+        self.frombytes(data)
+
+    def tobytes(self, encoder_name="raw", *args):
+        """
+        Return image as a bytes object.
+
+        .. warning::
+
+            This method returns the raw image data from the internal
+            storage.  For compressed image data (e.g. PNG, JPEG) use
+            :meth:`~.save`, with a BytesIO parameter for in-memory
+            data.
+
+        :param encoder_name: What encoder to use.  The default is to
+                             use the standard "raw" encoder.
+        :param args: Extra arguments to the encoder.
+        :returns: A :py:class:`bytes` object.
+        """
+
+        # may pass tuple instead of argument list
+        if len(args) == 1 and isinstance(args[0], tuple):
+            args = args[0]
+
+        if encoder_name == "raw" and args == ():
+            args = self.mode
+
+        self.load()
+
+        # unpack data
+        e = _getencoder(self.mode, encoder_name, args)
+        e.setimage(self.im)
+
+        bufsize = max(65536, self.size[0] * 4)  # see RawEncode.c
+
+        data = []
+        while True:
+            l, s, d = e.encode(bufsize)
+            data.append(d)
+            if s:
+                break
+        if s < 0:
+            raise RuntimeError(f"encoder error {s} in tobytes")
+
+        return b"".join(data)
+
+    def tobitmap(self, name="image"):
+        """
+        Returns the image converted to an X11 bitmap.
+
+        .. note:: This method only works for mode "1" images.
+
+        :param name: The name prefix to use for the bitmap variables.
+        :returns: A string containing an X11 bitmap.
+        :raises ValueError: If the mode is not "1"
+        """
+
+        self.load()
+        if self.mode != "1":
+            raise ValueError("not a bitmap")
+        data = self.tobytes("xbm")
+        return b"".join(
+            [
+                f"#define {name}_width {self.size[0]}\n".encode("ascii"),
+                f"#define {name}_height {self.size[1]}\n".encode("ascii"),
+                f"static char {name}_bits[] = {{\n".encode("ascii"),
+                data,
+                b"};",
+            ]
+        )
+
+    def frombytes(self, data, decoder_name="raw", *args):
+        """
+        Loads this image with pixel data from a bytes object.
+
+        This method is similar to the :py:func:`~PIL.Image.frombytes` function,
+        but loads data into this image instead of creating a new image object.
+        """
+
+        # may pass tuple instead of argument list
+        if len(args) == 1 and isinstance(args[0], tuple):
+            args = args[0]
+
+        # default format
+        if decoder_name == "raw" and args == ():
+            args = self.mode
+
+        # unpack data
+        d = _getdecoder(self.mode, decoder_name, args)
+        d.setimage(self.im)
+        s = d.decode(data)
+
+        if s[0] >= 0:
+            raise ValueError("not enough image data")
+        if s[1] != 0:
+            raise ValueError("cannot decode image data")
+
+    def load(self):
+        """
+        Allocates storage for the image and loads the pixel data.  In
+        normal cases, you don't need to call this method, since the
+        Image class automatically loads an opened image when it is
+        accessed for the first time.
+
+        If the file associated with the image was opened by Pillow, then this
+        method will close it. The exception to this is if the image has
+        multiple frames, in which case the file will be left open for seek
+        operations. See :ref:`file-handling` for more information.
+
+        :returns: An image access object.
+        :rtype: :ref:`PixelAccess` or :py:class:`PIL.PyAccess`
+        """
+        if self.im and self.palette and self.palette.dirty:
+            # realize palette
+            mode, arr = self.palette.getdata()
+            if mode == "RGBA":
+                mode = "RGB"
+                self.info["transparency"] = arr[3::4]
+                arr = bytes(
+                    value for (index, value) in enumerate(arr) if index % 4 != 3
+                )
+            palette_length = self.im.putpalette(mode, arr)
+            self.palette.dirty = 0
+            self.palette.rawmode = None
+            if "transparency" in self.info and mode in ("LA", "PA"):
+                if isinstance(self.info["transparency"], int):
+                    self.im.putpalettealpha(self.info["transparency"], 0)
+                else:
+                    self.im.putpalettealphas(self.info["transparency"])
+                self.palette.mode = "RGBA"
+            else:
+                self.palette.mode = "RGB"
+                self.palette.palette = self.im.getpalette()[: palette_length * 3]
+
+        if self.im:
+            if cffi and USE_CFFI_ACCESS:
+                if self.pyaccess:
+                    return self.pyaccess
+                from . import PyAccess
+
+                self.pyaccess = PyAccess.new(self, self.readonly)
+                if self.pyaccess:
+                    return self.pyaccess
+            return self.im.pixel_access(self.readonly)
+
+    def verify(self):
+        """
+        Verifies the contents of a file. For data read from a file, this
+        method attempts to determine if the file is broken, without
+        actually decoding the image data.  If this method finds any
+        problems, it raises suitable exceptions.  If you need to load
+        the image after using this method, you must reopen the image
+        file.
+        """
+        pass
+
+    def convert(self, mode=None, matrix=None, dither=None, palette=WEB, colors=256):
+        """
+        Returns a converted copy of this image. For the "P" mode, this
+        method translates pixels through the palette.  If mode is
+        omitted, a mode is chosen so that all information in the image
+        and the palette can be represented without a palette.
+
+        The current version supports all possible conversions between
+        "L", "RGB" and "CMYK." The ``matrix`` argument only supports "L"
+        and "RGB".
+
+        When translating a color image to greyscale (mode "L"),
+        the library uses the ITU-R 601-2 luma transform::
+
+            L = R * 299/1000 + G * 587/1000 + B * 114/1000
+
+        The default method of converting a greyscale ("L") or "RGB"
+        image into a bilevel (mode "1") image uses Floyd-Steinberg
+        dither to approximate the original image luminosity levels. If
+        dither is :data:`NONE`, all values larger than 127 are set to 255 (white),
+        all other values to 0 (black). To use other thresholds, use the
+        :py:meth:`~PIL.Image.Image.point` method.
+
+        When converting from "RGBA" to "P" without a ``matrix`` argument,
+        this passes the operation to :py:meth:`~PIL.Image.Image.quantize`,
+        and ``dither`` and ``palette`` are ignored.
+
+        :param mode: The requested mode. See: :ref:`concept-modes`.
+        :param matrix: An optional conversion matrix.  If given, this
+           should be 4- or 12-tuple containing floating point values.
+        :param dither: Dithering method, used when converting from
+           mode "RGB" to "P" or from "RGB" or "L" to "1".
+           Available methods are :data:`NONE` or :data:`FLOYDSTEINBERG` (default).
+           Note that this is not used when ``matrix`` is supplied.
+        :param palette: Palette to use when converting from mode "RGB"
+           to "P".  Available palettes are :data:`WEB` or :data:`ADAPTIVE`.
+        :param colors: Number of colors to use for the :data:`ADAPTIVE` palette.
+           Defaults to 256.
+        :rtype: :py:class:`~PIL.Image.Image`
+        :returns: An :py:class:`~PIL.Image.Image` object.
+        """
+
+        self.load()
+
+        has_transparency = self.info.get("transparency") is not None
+        if not mode and self.mode == "P":
+            # determine default mode
+            if self.palette:
+                mode = self.palette.mode
+            else:
+                mode = "RGB"
+            if mode == "RGB" and has_transparency:
+                mode = "RGBA"
+        if not mode or (mode == self.mode and not matrix):
+            return self.copy()
+
+        if matrix:
+            # matrix conversion
+            if mode not in ("L", "RGB"):
+                raise ValueError("illegal conversion")
+            im = self.im.convert_matrix(mode, matrix)
+            new = self._new(im)
+            if has_transparency and self.im.bands == 3:
+                transparency = new.info["transparency"]
+
+                def convert_transparency(m, v):
+                    v = m[0] * v[0] + m[1] * v[1] + m[2] * v[2] + m[3] * 0.5
+                    return max(0, min(255, int(v)))
+
+                if mode == "L":
+                    transparency = convert_transparency(matrix, transparency)
+                elif len(mode) == 3:
+                    transparency = tuple(
+                        convert_transparency(matrix[i * 4 : i * 4 + 4], transparency)
+                        for i in range(0, len(transparency))
+                    )
+                new.info["transparency"] = transparency
+            return new
+
+        if mode == "P" and self.mode == "RGBA":
+            return self.quantize(colors)
+
+        trns = None
+        delete_trns = False
+        # transparency handling
+        if has_transparency:
+            if self.mode in ("1", "L", "I", "RGB") and mode == "RGBA":
+                # Use transparent conversion to promote from transparent
+                # color to an alpha channel.
+                new_im = self._new(
+                    self.im.convert_transparent(mode, self.info["transparency"])
+                )
+                del new_im.info["transparency"]
+                return new_im
+            elif self.mode in ("L", "RGB", "P") and mode in ("L", "RGB", "P"):
+                t = self.info["transparency"]
+                if isinstance(t, bytes):
+                    # Dragons. This can't be represented by a single color
+                    warnings.warn(
+                        "Palette images with Transparency expressed in bytes should be "
+                        "converted to RGBA images"
+                    )
+                    delete_trns = True
+                else:
+                    # get the new transparency color.
+                    # use existing conversions
+                    trns_im = Image()._new(core.new(self.mode, (1, 1)))
+                    if self.mode == "P":
+                        trns_im.putpalette(self.palette)
+                        if isinstance(t, tuple):
+                            err = "Couldn't allocate a palette color for transparency"
+                            try:
+                                t = trns_im.palette.getcolor(t, self)
+                            except ValueError as e:
+                                if str(e) == "cannot allocate more than 256 colors":
+                                    # If all 256 colors are in use,
+                                    # then there is no need for transparency
+                                    t = None
+                                else:
+                                    raise ValueError(err) from e
+                    if t is None:
+                        trns = None
+                    else:
+                        trns_im.putpixel((0, 0), t)
+
+                        if mode in ("L", "RGB"):
+                            trns_im = trns_im.convert(mode)
+                        else:
+                            # can't just retrieve the palette number, got to do it
+                            # after quantization.
+                            trns_im = trns_im.convert("RGB")
+                        trns = trns_im.getpixel((0, 0))
+
+            elif self.mode == "P" and mode in ("LA", "PA", "RGBA"):
+                t = self.info["transparency"]
+                delete_trns = True
+
+                if isinstance(t, bytes):
+                    self.im.putpalettealphas(t)
+                elif isinstance(t, int):
+                    self.im.putpalettealpha(t, 0)
+                else:
+                    raise ValueError("Transparency for P mode should be bytes or int")
+
+        if mode == "P" and palette == ADAPTIVE:
+            im = self.im.quantize(colors)
+            new = self._new(im)
+            from . import ImagePalette
+
+            new.palette = ImagePalette.ImagePalette("RGB", new.im.getpalette("RGB"))
+            if delete_trns:
+                # This could possibly happen if we requantize to fewer colors.
+                # The transparency would be totally off in that case.
+                del new.info["transparency"]
+            if trns is not None:
+                try:
+                    new.info["transparency"] = new.palette.getcolor(trns, new)
+                except Exception:
+                    # if we can't make a transparent color, don't leave the old
+                    # transparency hanging around to mess us up.
+                    del new.info["transparency"]
+                    warnings.warn("Couldn't allocate palette entry for transparency")
+            return new
+
+        # colorspace conversion
+        if dither is None:
+            dither = FLOYDSTEINBERG
+
+        try:
+            im = self.im.convert(mode, dither)
+        except ValueError:
+            try:
+                # normalize source image and try again
+                im = self.im.convert(getmodebase(self.mode))
+                im = im.convert(mode, dither)
+            except KeyError as e:
+                raise ValueError("illegal conversion") from e
+
+        new_im = self._new(im)
+        if mode == "P" and palette != ADAPTIVE:
+            from . import ImagePalette
+
+            new_im.palette = ImagePalette.ImagePalette("RGB", list(range(256)) * 3)
+        if delete_trns:
+            # crash fail if we leave a bytes transparency in an rgb/l mode.
+            del new_im.info["transparency"]
+        if trns is not None:
+            if new_im.mode == "P":
+                try:
+                    new_im.info["transparency"] = new_im.palette.getcolor(trns, new_im)
+                except ValueError as e:
+                    del new_im.info["transparency"]
+                    if str(e) != "cannot allocate more than 256 colors":
+                        # If all 256 colors are in use,
+                        # then there is no need for transparency
+                        warnings.warn(
+                            "Couldn't allocate palette entry for transparency"
+                        )
+            else:
+                new_im.info["transparency"] = trns
+        return new_im
+
+    def quantize(self, colors=256, method=None, kmeans=0, palette=None, dither=1):
+        """
+        Convert the image to 'P' mode with the specified number
+        of colors.
+
+        :param colors: The desired number of colors, <= 256
+        :param method: :data:`MEDIANCUT` (median cut),
+                       :data:`MAXCOVERAGE` (maximum coverage),
+                       :data:`FASTOCTREE` (fast octree),
+                       :data:`LIBIMAGEQUANT` (libimagequant; check support using
+                       :py:func:`PIL.features.check_feature`
+                       with ``feature="libimagequant"``).
+
+                       By default, :data:`MEDIANCUT` will be used.
+
+                       The exception to this is RGBA images. :data:`MEDIANCUT` and
+                       :data:`MAXCOVERAGE` do not support RGBA images, so
+                       :data:`FASTOCTREE` is used by default instead.
+        :param kmeans: Integer
+        :param palette: Quantize to the palette of given
+                        :py:class:`PIL.Image.Image`.
+        :param dither: Dithering method, used when converting from
+           mode "RGB" to "P" or from "RGB" or "L" to "1".
+           Available methods are :data:`NONE` or :data:`FLOYDSTEINBERG` (default).
+           Default: 1 (legacy setting)
+        :returns: A new image
+
+        """
+
+        self.load()
+
+        if method is None:
+            # defaults:
+            method = MEDIANCUT
+            if self.mode == "RGBA":
+                method = FASTOCTREE
+
+        if self.mode == "RGBA" and method not in (FASTOCTREE, LIBIMAGEQUANT):
+            # Caller specified an invalid mode.
+            raise ValueError(
+                "Fast Octree (method == 2) and libimagequant (method == 3) "
+                "are the only valid methods for quantizing RGBA images"
+            )
+
+        if palette:
+            # use palette from reference image
+            palette.load()
+            if palette.mode != "P":
+                raise ValueError("bad mode for palette image")
+            if self.mode != "RGB" and self.mode != "L":
+                raise ValueError(
+                    "only RGB or L mode images can be quantized to a palette"
+                )
+            im = self.im.convert("P", dither, palette.im)
+            new_im = self._new(im)
+            new_im.palette = palette.palette.copy()
+            return new_im
+
+        im = self._new(self.im.quantize(colors, method, kmeans))
+
+        from . import ImagePalette
+
+        mode = im.im.getpalettemode()
+        palette = im.im.getpalette(mode, mode)[: colors * len(mode)]
+        im.palette = ImagePalette.ImagePalette(mode, palette)
+
+        return im
+
+    def copy(self):
+        """
+        Copies this image. Use this method if you wish to paste things
+        into an image, but still retain the original.
+
+        :rtype: :py:class:`~PIL.Image.Image`
+        :returns: An :py:class:`~PIL.Image.Image` object.
+        """
+        self.load()
+        return self._new(self.im.copy())
+
+    __copy__ = copy
+
+    def crop(self, box=None):
+        """
+        Returns a rectangular region from this image. The box is a
+        4-tuple defining the left, upper, right, and lower pixel
+        coordinate. See :ref:`coordinate-system`.
+
+        Note: Prior to Pillow 3.4.0, this was a lazy operation.
+
+        :param box: The crop rectangle, as a (left, upper, right, lower)-tuple.
+        :rtype: :py:class:`~PIL.Image.Image`
+        :returns: An :py:class:`~PIL.Image.Image` object.
+        """
+
+        if box is None:
+            return self.copy()
+
+        self.load()
+        return self._new(self._crop(self.im, box))
+
+    def _crop(self, im, box):
+        """
+        Returns a rectangular region from the core image object im.
+
+        This is equivalent to calling im.crop((x0, y0, x1, y1)), but
+        includes additional sanity checks.
+
+        :param im: a core image object
+        :param box: The crop rectangle, as a (left, upper, right, lower)-tuple.
+        :returns: A core image object.
+        """
+
+        x0, y0, x1, y1 = map(int, map(round, box))
+
+        absolute_values = (abs(x1 - x0), abs(y1 - y0))
+
+        _decompression_bomb_check(absolute_values)
+
+        return im.crop((x0, y0, x1, y1))
+
+    def draft(self, mode, size):
+        """
+        Configures the image file loader so it returns a version of the
+        image that as closely as possible matches the given mode and
+        size. For example, you can use this method to convert a color
+        JPEG to greyscale while loading it.
+
+        If any changes are made, returns a tuple with the chosen ``mode`` and
+        ``box`` with coordinates of the original image within the altered one.
+
+        Note that this method modifies the :py:class:`~PIL.Image.Image` object
+        in place. If the image has already been loaded, this method has no
+        effect.
+
+        Note: This method is not implemented for most images. It is
+        currently implemented only for JPEG and MPO images.
+
+        :param mode: The requested mode.
+        :param size: The requested size.
+        """
+        pass
+
+    def _expand(self, xmargin, ymargin=None):
+        if ymargin is None:
+            ymargin = xmargin
+        self.load()
+        return self._new(self.im.expand(xmargin, ymargin, 0))
+
+    def filter(self, filter):
+        """
+        Filters this image using the given filter.  For a list of
+        available filters, see the :py:mod:`~PIL.ImageFilter` module.
+
+        :param filter: Filter kernel.
+        :returns: An :py:class:`~PIL.Image.Image` object."""
+
+        from . import ImageFilter
+
+        self.load()
+
+        if isinstance(filter, Callable):
+            filter = filter()
+        if not hasattr(filter, "filter"):
+            raise TypeError(
+                "filter argument should be ImageFilter.Filter instance or class"
+            )
+
+        multiband = isinstance(filter, ImageFilter.MultibandFilter)
+        if self.im.bands == 1 or multiband:
+            return self._new(filter.filter(self.im))
+
+        ims = []
+        for c in range(self.im.bands):
+            ims.append(self._new(filter.filter(self.im.getband(c))))
+        return merge(self.mode, ims)
+
+    def getbands(self):
+        """
+        Returns a tuple containing the name of each band in this image.
+        For example, ``getbands`` on an RGB image returns ("R", "G", "B").
+
+        :returns: A tuple containing band names.
+        :rtype: tuple
+        """
+        return ImageMode.getmode(self.mode).bands
+
+    def getbbox(self):
+        """
+        Calculates the bounding box of the non-zero regions in the
+        image.
+
+        :returns: The bounding box is returned as a 4-tuple defining the
+           left, upper, right, and lower pixel coordinate. See
+           :ref:`coordinate-system`. If the image is completely empty, this
+           method returns None.
+
+        """
+
+        self.load()
+        return self.im.getbbox()
+
+    def getcolors(self, maxcolors=256):
+        """
+        Returns a list of colors used in this image.
+
+        The colors will be in the image's mode. For example, an RGB image will
+        return a tuple of (red, green, blue) color values, and a P image will
+        return the index of the color in the palette.
+
+        :param maxcolors: Maximum number of colors.  If this number is
+           exceeded, this method returns None.  The default limit is
+           256 colors.
+        :returns: An unsorted list of (count, pixel) values.
+        """
+
+        self.load()
+        if self.mode in ("1", "L", "P"):
+            h = self.im.histogram()
+            out = []
+            for i in range(256):
+                if h[i]:
+                    out.append((h[i], i))
+            if len(out) > maxcolors:
+                return None
+            return out
+        return self.im.getcolors(maxcolors)
+
+    def getdata(self, band=None):
+        """
+        Returns the contents of this image as a sequence object
+        containing pixel values.  The sequence object is flattened, so
+        that values for line one follow directly after the values of
+        line zero, and so on.
+
+        Note that the sequence object returned by this method is an
+        internal PIL data type, which only supports certain sequence
+        operations.  To convert it to an ordinary sequence (e.g. for
+        printing), use ``list(im.getdata())``.
+
+        :param band: What band to return.  The default is to return
+           all bands.  To return a single band, pass in the index
+           value (e.g. 0 to get the "R" band from an "RGB" image).
+        :returns: A sequence-like object.
+        """
+
+        self.load()
+        if band is not None:
+            return self.im.getband(band)
+        return self.im  # could be abused
+
+    def getextrema(self):
+        """
+        Gets the the minimum and maximum pixel values for each band in
+        the image.
+
+        :returns: For a single-band image, a 2-tuple containing the
+           minimum and maximum pixel value.  For a multi-band image,
+           a tuple containing one 2-tuple for each band.
+        """
+
+        self.load()
+        if self.im.bands > 1:
+            extrema = []
+            for i in range(self.im.bands):
+                extrema.append(self.im.getband(i).getextrema())
+            return tuple(extrema)
+        return self.im.getextrema()
+
+    def _getxmp(self, xmp_tags):
+        def get_name(tag):
+            return tag.split("}")[1]
+
+        def get_value(element):
+            value = {get_name(k): v for k, v in element.attrib.items()}
+            children = list(element)
+            if children:
+                for child in children:
+                    name = get_name(child.tag)
+                    child_value = get_value(child)
+                    if name in value:
+                        if not isinstance(value[name], list):
+                            value[name] = [value[name]]
+                        value[name].append(child_value)
+                    else:
+                        value[name] = child_value
+            elif value:
+                if element.text:
+                    value["text"] = element.text
+            else:
+                return element.text
+            return value
+
+        if ElementTree is None:
+            warnings.warn("XMP data cannot be read without defusedxml dependency")
+            return {}
+        else:
+            root = ElementTree.fromstring(xmp_tags)
+            return {get_name(root.tag): get_value(root)}
+
+    def getexif(self):
+        if self._exif is None:
+            self._exif = Exif()
+
+        exif_info = self.info.get("exif")
+        if exif_info is None:
+            if "Raw profile type exif" in self.info:
+                exif_info = bytes.fromhex(
+                    "".join(self.info["Raw profile type exif"].split("\n")[3:])
+                )
+            elif hasattr(self, "tag_v2"):
+                self._exif.endian = self.tag_v2._endian
+                self._exif.load_from_fp(self.fp, self.tag_v2._offset)
+        if exif_info is not None:
+            self._exif.load(exif_info)
+
+        # XMP tags
+        if 0x0112 not in self._exif:
+            xmp_tags = self.info.get("XML:com.adobe.xmp")
+            if xmp_tags:
+                match = re.search(r'tiff:Orientation="([0-9])"', xmp_tags)
+                if match:
+                    self._exif[0x0112] = int(match[1])
+
+        return self._exif
+
+    def getim(self):
+        """
+        Returns a capsule that points to the internal image memory.
+
+        :returns: A capsule object.
+        """
+
+        self.load()
+        return self.im.ptr
+
+    def getpalette(self):
+        """
+        Returns the image palette as a list.
+
+        :returns: A list of color values [r, g, b, ...], or None if the
+           image has no palette.
+        """
+
+        self.load()
+        try:
+            return list(self.im.getpalette())
+        except ValueError:
+            return None  # no palette
+
+    def getpixel(self, xy):
+        """
+        Returns the pixel value at a given position.
+
+        :param xy: The coordinate, given as (x, y). See
+           :ref:`coordinate-system`.
+        :returns: The pixel value.  If the image is a multi-layer image,
+           this method returns a tuple.
+        """
+
+        self.load()
+        if self.pyaccess:
+            return self.pyaccess.getpixel(xy)
+        return self.im.getpixel(xy)
+
+    def getprojection(self):
+        """
+        Get projection to x and y axes
+
+        :returns: Two sequences, indicating where there are non-zero
+            pixels along the X-axis and the Y-axis, respectively.
+        """
+
+        self.load()
+        x, y = self.im.getprojection()
+        return list(x), list(y)
+
+    def histogram(self, mask=None, extrema=None):
+        """
+        Returns a histogram for the image. The histogram is returned as
+        a list of pixel counts, one for each pixel value in the source
+        image. If the image has more than one band, the histograms for
+        all bands are concatenated (for example, the histogram for an
+        "RGB" image contains 768 values).
+
+        A bilevel image (mode "1") is treated as a greyscale ("L") image
+        by this method.
+
+        If a mask is provided, the method returns a histogram for those
+        parts of the image where the mask image is non-zero. The mask
+        image must have the same size as the image, and be either a
+        bi-level image (mode "1") or a greyscale image ("L").
+
+        :param mask: An optional mask.
+        :param extrema: An optional tuple of manually-specified extrema.
+        :returns: A list containing pixel counts.
+        """
+        self.load()
+        if mask:
+            mask.load()
+            return self.im.histogram((0, 0), mask.im)
+        if self.mode in ("I", "F"):
+            if extrema is None:
+                extrema = self.getextrema()
+            return self.im.histogram(extrema)
+        return self.im.histogram()
+
+    def entropy(self, mask=None, extrema=None):
+        """
+        Calculates and returns the entropy for the image.
+
+        A bilevel image (mode "1") is treated as a greyscale ("L")
+        image by this method.
+
+        If a mask is provided, the method employs the histogram for
+        those parts of the image where the mask image is non-zero.
+        The mask image must have the same size as the image, and be
+        either a bi-level image (mode "1") or a greyscale image ("L").
+
+        :param mask: An optional mask.
+        :param extrema: An optional tuple of manually-specified extrema.
+        :returns: A float value representing the image entropy
+        """
+        self.load()
+        if mask:
+            mask.load()
+            return self.im.entropy((0, 0), mask.im)
+        if self.mode in ("I", "F"):
+            if extrema is None:
+                extrema = self.getextrema()
+            return self.im.entropy(extrema)
+        return self.im.entropy()
+
+    def paste(self, im, box=None, mask=None):
+        """
+        Pastes another image into this image. The box argument is either
+        a 2-tuple giving the upper left corner, a 4-tuple defining the
+        left, upper, right, and lower pixel coordinate, or None (same as
+        (0, 0)). See :ref:`coordinate-system`. If a 4-tuple is given, the size
+        of the pasted image must match the size of the region.
+
+        If the modes don't match, the pasted image is converted to the mode of
+        this image (see the :py:meth:`~PIL.Image.Image.convert` method for
+        details).
+
+        Instead of an image, the source can be a integer or tuple
+        containing pixel values.  The method then fills the region
+        with the given color.  When creating RGB images, you can
+        also use color strings as supported by the ImageColor module.
+
+        If a mask is given, this method updates only the regions
+        indicated by the mask.  You can use either "1", "L" or "RGBA"
+        images (in the latter case, the alpha band is used as mask).
+        Where the mask is 255, the given image is copied as is.  Where
+        the mask is 0, the current value is preserved.  Intermediate
+        values will mix the two images together, including their alpha
+        channels if they have them.
+
+        See :py:meth:`~PIL.Image.Image.alpha_composite` if you want to
+        combine images with respect to their alpha channels.
+
+        :param im: Source image or pixel value (integer or tuple).
+        :param box: An optional 4-tuple giving the region to paste into.
+           If a 2-tuple is used instead, it's treated as the upper left
+           corner.  If omitted or None, the source is pasted into the
+           upper left corner.
+
+           If an image is given as the second argument and there is no
+           third, the box defaults to (0, 0), and the second argument
+           is interpreted as a mask image.
+        :param mask: An optional mask image.
+        """
+
+        if isImageType(box) and mask is None:
+            # abbreviated paste(im, mask) syntax
+            mask = box
+            box = None
+
+        if box is None:
+            box = (0, 0)
+
+        if len(box) == 2:
+            # upper left corner given; get size from image or mask
+            if isImageType(im):
+                size = im.size
+            elif isImageType(mask):
+                size = mask.size
+            else:
+                # FIXME: use self.size here?
+                raise ValueError("cannot determine region size; use 4-item box")
+            box += (box[0] + size[0], box[1] + size[1])
+
+        if isinstance(im, str):
+            from . import ImageColor
+
+            im = ImageColor.getcolor(im, self.mode)
+
+        elif isImageType(im):
+            im.load()
+            if self.mode != im.mode:
+                if self.mode != "RGB" or im.mode not in ("RGBA", "RGBa"):
+                    # should use an adapter for this!
+                    im = im.convert(self.mode)
+            im = im.im
+
+        self._ensure_mutable()
+
+        if mask:
+            mask.load()
+            self.im.paste(im, box, mask.im)
+        else:
+            self.im.paste(im, box)
+
+    def alpha_composite(self, im, dest=(0, 0), source=(0, 0)):
+        """'In-place' analog of Image.alpha_composite. Composites an image
+        onto this image.
+
+        :param im: image to composite over this one
+        :param dest: Optional 2 tuple (left, top) specifying the upper
+          left corner in this (destination) image.
+        :param source: Optional 2 (left, top) tuple for the upper left
+          corner in the overlay source image, or 4 tuple (left, top, right,
+          bottom) for the bounds of the source rectangle
+
+        Performance Note: Not currently implemented in-place in the core layer.
+        """
+
+        if not isinstance(source, (list, tuple)):
+            raise ValueError("Source must be a tuple")
+        if not isinstance(dest, (list, tuple)):
+            raise ValueError("Destination must be a tuple")
+        if not len(source) in (2, 4):
+            raise ValueError("Source must be a 2 or 4-tuple")
+        if not len(dest) == 2:
+            raise ValueError("Destination must be a 2-tuple")
+        if min(source) < 0:
+            raise ValueError("Source must be non-negative")
+
+        if len(source) == 2:
+            source = source + im.size
+
+        # over image, crop if it's not the whole thing.
+        if source == (0, 0) + im.size:
+            overlay = im
+        else:
+            overlay = im.crop(source)
+
+        # target for the paste
+        box = dest + (dest[0] + overlay.width, dest[1] + overlay.height)
+
+        # destination image. don't copy if we're using the whole image.
+        if box == (0, 0) + self.size:
+            background = self
+        else:
+            background = self.crop(box)
+
+        result = alpha_composite(background, overlay)
+        self.paste(result, box)
+
+    def point(self, lut, mode=None):
+        """
+        Maps this image through a lookup table or function.
+
+        :param lut: A lookup table, containing 256 (or 65536 if
+           self.mode=="I" and mode == "L") values per band in the
+           image.  A function can be used instead, it should take a
+           single argument. The function is called once for each
+           possible pixel value, and the resulting table is applied to
+           all bands of the image.
+
+           It may also be an :py:class:`~PIL.Image.ImagePointHandler`
+           object::
+
+               class Example(Image.ImagePointHandler):
+                 def point(self, data):
+                   # Return result
+        :param mode: Output mode (default is same as input).  In the
+           current version, this can only be used if the source image
+           has mode "L" or "P", and the output has mode "1" or the
+           source image mode is "I" and the output mode is "L".
+        :returns: An :py:class:`~PIL.Image.Image` object.
+        """
+
+        self.load()
+
+        if isinstance(lut, ImagePointHandler):
+            return lut.point(self)
+
+        if callable(lut):
+            # if it isn't a list, it should be a function
+            if self.mode in ("I", "I;16", "F"):
+                # check if the function can be used with point_transform
+                # UNDONE wiredfool -- I think this prevents us from ever doing
+                # a gamma function point transform on > 8bit images.
+                scale, offset = _getscaleoffset(lut)
+                return self._new(self.im.point_transform(scale, offset))
+            # for other modes, convert the function to a table
+            lut = [lut(i) for i in range(256)] * self.im.bands
+
+        if self.mode == "F":
+            # FIXME: _imaging returns a confusing error message for this case
+            raise ValueError("point operation not supported for this mode")
+
+        return self._new(self.im.point(lut, mode))
+
+    def putalpha(self, alpha):
+        """
+        Adds or replaces the alpha layer in this image.  If the image
+        does not have an alpha layer, it's converted to "LA" or "RGBA".
+        The new layer must be either "L" or "1".
+
+        :param alpha: The new alpha layer.  This can either be an "L" or "1"
+           image having the same size as this image, or an integer or
+           other color value.
+        """
+
+        self._ensure_mutable()
+
+        if self.mode not in ("LA", "PA", "RGBA"):
+            # attempt to promote self to a matching alpha mode
+            try:
+                mode = getmodebase(self.mode) + "A"
+                try:
+                    self.im.setmode(mode)
+                except (AttributeError, ValueError) as e:
+                    # do things the hard way
+                    im = self.im.convert(mode)
+                    if im.mode not in ("LA", "PA", "RGBA"):
+                        raise ValueError from e  # sanity check
+                    self.im = im
+                self.pyaccess = None
+                self.mode = self.im.mode
+            except KeyError as e:
+                raise ValueError("illegal image mode") from e
+
+        if self.mode in ("LA", "PA"):
+            band = 1
+        else:
+            band = 3
+
+        if isImageType(alpha):
+            # alpha layer
+            if alpha.mode not in ("1", "L"):
+                raise ValueError("illegal image mode")
+            alpha.load()
+            if alpha.mode == "1":
+                alpha = alpha.convert("L")
+        else:
+            # constant alpha
+            try:
+                self.im.fillband(band, alpha)
+            except (AttributeError, ValueError):
+                # do things the hard way
+                alpha = new("L", self.size, alpha)
+            else:
+                return
+
+        self.im.putband(alpha.im, band)
+
+    def putdata(self, data, scale=1.0, offset=0.0):
+        """
+        Copies pixel data from a flattened sequence object into the image. The
+        values should start at the upper left corner (0, 0), continue to the
+        end of the line, followed directly by the first value of the second
+        line, and so on. Data will be read until either the image or the
+        sequence ends. The scale and offset values are used to adjust the
+        sequence values: **pixel = value*scale + offset**.
+
+        :param data: A flattened sequence object.
+        :param scale: An optional scale value.  The default is 1.0.
+        :param offset: An optional offset value.  The default is 0.0.
+        """
+
+        self._ensure_mutable()
+
+        self.im.putdata(data, scale, offset)
+
+    def putpalette(self, data, rawmode="RGB"):
+        """
+        Attaches a palette to this image.  The image must be a "P", "PA", "L"
+        or "LA" image.
+
+        The palette sequence must contain at most 256 colors, made up of one
+        integer value for each channel in the raw mode.
+        For example, if the raw mode is "RGB", then it can contain at most 768
+        values, made up of red, green and blue values for the corresponding pixel
+        index in the 256 colors.
+        If the raw mode is "RGBA", then it can contain at most 1024 values,
+        containing red, green, blue and alpha values.
+
+        Alternatively, an 8-bit string may be used instead of an integer sequence.
+
+        :param data: A palette sequence (either a list or a string).
+        :param rawmode: The raw mode of the palette. Either "RGB", "RGBA", or a
+           mode that can be transformed to "RGB" (e.g. "R", "BGR;15", "RGBA;L").
+        """
+        from . import ImagePalette
+
+        if self.mode not in ("L", "LA", "P", "PA"):
+            raise ValueError("illegal image mode")
+        if isinstance(data, ImagePalette.ImagePalette):
+            palette = ImagePalette.raw(data.rawmode, data.palette)
+        else:
+            if not isinstance(data, bytes):
+                data = bytes(data)
+            palette = ImagePalette.raw(rawmode, data)
+        self.mode = "PA" if "A" in self.mode else "P"
+        self.palette = palette
+        self.palette.mode = "RGB"
+        self.load()  # install new palette
+
+    def putpixel(self, xy, value):
+        """
+        Modifies the pixel at the given position. The color is given as
+        a single numerical value for single-band images, and a tuple for
+        multi-band images. In addition to this, RGB and RGBA tuples are
+        accepted for P images.
+
+        Note that this method is relatively slow.  For more extensive changes,
+        use :py:meth:`~PIL.Image.Image.paste` or the :py:mod:`~PIL.ImageDraw`
+        module instead.
+
+        See:
+
+        * :py:meth:`~PIL.Image.Image.paste`
+        * :py:meth:`~PIL.Image.Image.putdata`
+        * :py:mod:`~PIL.ImageDraw`
+
+        :param xy: The pixel coordinate, given as (x, y). See
+           :ref:`coordinate-system`.
+        :param value: The pixel value.
+        """
+
+        if self.readonly:
+            self._copy()
+        self.load()
+
+        if self.pyaccess:
+            return self.pyaccess.putpixel(xy, value)
+
+        if (
+            self.mode == "P"
+            and isinstance(value, (list, tuple))
+            and len(value) in [3, 4]
+        ):
+            # RGB or RGBA value for a P image
+            value = self.palette.getcolor(value, self)
+        return self.im.putpixel(xy, value)
+
+    def remap_palette(self, dest_map, source_palette=None):
+        """
+        Rewrites the image to reorder the palette.
+
+        :param dest_map: A list of indexes into the original palette.
+           e.g. ``[1,0]`` would swap a two item palette, and ``list(range(256))``
+           is the identity transform.
+        :param source_palette: Bytes or None.
+        :returns:  An :py:class:`~PIL.Image.Image` object.
+
+        """
+        from . import ImagePalette
+
+        if self.mode not in ("L", "P"):
+            raise ValueError("illegal image mode")
+
+        if source_palette is None:
+            if self.mode == "P":
+                self.load()
+                source_palette = self.im.getpalette("RGB")[:768]
+            else:  # L-mode
+                source_palette = bytearray(i // 3 for i in range(768))
+
+        palette_bytes = b""
+        new_positions = [0] * 256
+
+        # pick only the used colors from the palette
+        for i, oldPosition in enumerate(dest_map):
+            palette_bytes += source_palette[oldPosition * 3 : oldPosition * 3 + 3]
+            new_positions[oldPosition] = i
+
+        # replace the palette color id of all pixel with the new id
+
+        # Palette images are [0..255], mapped through a 1 or 3
+        # byte/color map.  We need to remap the whole image
+        # from palette 1 to palette 2. New_positions is
+        # an array of indexes into palette 1.  Palette 2 is
+        # palette 1 with any holes removed.
+
+        # We're going to leverage the convert mechanism to use the
+        # C code to remap the image from palette 1 to palette 2,
+        # by forcing the source image into 'L' mode and adding a
+        # mapping 'L' mode palette, then converting back to 'L'
+        # sans palette thus converting the image bytes, then
+        # assigning the optimized RGB palette.
+
+        # perf reference, 9500x4000 gif, w/~135 colors
+        # 14 sec prepatch, 1 sec postpatch with optimization forced.
+
+        mapping_palette = bytearray(new_positions)
+
+        m_im = self.copy()
+        m_im.mode = "P"
+
+        m_im.palette = ImagePalette.ImagePalette("RGB", palette=mapping_palette * 3)
+        # possibly set palette dirty, then
+        # m_im.putpalette(mapping_palette, 'L')  # converts to 'P'
+        # or just force it.
+        # UNDONE -- this is part of the general issue with palettes
+        m_im.im.putpalette("RGB;L", m_im.palette.tobytes())
+
+        m_im = m_im.convert("L")
+
+        # Internally, we require 768 bytes for a palette.
+        new_palette_bytes = palette_bytes + (768 - len(palette_bytes)) * b"\x00"
+        m_im.putpalette(new_palette_bytes)
+        m_im.palette = ImagePalette.ImagePalette("RGB", palette=palette_bytes)
+
+        return m_im
+
+    def _get_safe_box(self, size, resample, box):
+        """Expands the box so it includes adjacent pixels
+        that may be used by resampling with the given resampling filter.
+        """
+        filter_support = _filters_support[resample] - 0.5
+        scale_x = (box[2] - box[0]) / size[0]
+        scale_y = (box[3] - box[1]) / size[1]
+        support_x = filter_support * scale_x
+        support_y = filter_support * scale_y
+
+        return (
+            max(0, int(box[0] - support_x)),
+            max(0, int(box[1] - support_y)),
+            min(self.size[0], math.ceil(box[2] + support_x)),
+            min(self.size[1], math.ceil(box[3] + support_y)),
+        )
+
+    def resize(self, size, resample=None, box=None, reducing_gap=None):
+        """
+        Returns a resized copy of this image.
+
+        :param size: The requested size in pixels, as a 2-tuple:
+           (width, height).
+        :param resample: An optional resampling filter.  This can be
+           one of :py:data:`PIL.Image.NEAREST`, :py:data:`PIL.Image.BOX`,
+           :py:data:`PIL.Image.BILINEAR`, :py:data:`PIL.Image.HAMMING`,
+           :py:data:`PIL.Image.BICUBIC` or :py:data:`PIL.Image.LANCZOS`.
+           If the image has mode "1" or "P", it is always set to
+           :py:data:`PIL.Image.NEAREST`.
+           If the image mode specifies a number of bits, such as "I;16", then the
+           default filter is :py:data:`PIL.Image.NEAREST`.
+           Otherwise, the default filter is :py:data:`PIL.Image.BICUBIC`.
+           See: :ref:`concept-filters`.
+        :param box: An optional 4-tuple of floats providing
+           the source image region to be scaled.
+           The values must be within (0, 0, width, height) rectangle.
+           If omitted or None, the entire source is used.
+        :param reducing_gap: Apply optimization by resizing the image
+           in two steps. First, reducing the image by integer times
+           using :py:meth:`~PIL.Image.Image.reduce`.
+           Second, resizing using regular resampling. The last step
+           changes size no less than by ``reducing_gap`` times.
+           ``reducing_gap`` may be None (no first step is performed)
+           or should be greater than 1.0. The bigger ``reducing_gap``,
+           the closer the result to the fair resampling.
+           The smaller ``reducing_gap``, the faster resizing.
+           With ``reducing_gap`` greater or equal to 3.0, the result is
+           indistinguishable from fair resampling in most cases.
+           The default value is None (no optimization).
+        :returns: An :py:class:`~PIL.Image.Image` object.
+        """
+
+        if resample is None:
+            type_special = ";" in self.mode
+            resample = NEAREST if type_special else BICUBIC
+        elif resample not in (NEAREST, BILINEAR, BICUBIC, LANCZOS, BOX, HAMMING):
+            message = f"Unknown resampling filter ({resample})."
+
+            filters = [
+                f"{filter[1]} ({filter[0]})"
+                for filter in (
+                    (NEAREST, "Image.NEAREST"),
+                    (LANCZOS, "Image.LANCZOS"),
+                    (BILINEAR, "Image.BILINEAR"),
+                    (BICUBIC, "Image.BICUBIC"),
+                    (BOX, "Image.BOX"),
+                    (HAMMING, "Image.HAMMING"),
+                )
+            ]
+            raise ValueError(
+                message + " Use " + ", ".join(filters[:-1]) + " or " + filters[-1]
+            )
+
+        if reducing_gap is not None and reducing_gap < 1.0:
+            raise ValueError("reducing_gap must be 1.0 or greater")
+
+        size = tuple(size)
+
+        if box is None:
+            box = (0, 0) + self.size
+        else:
+            box = tuple(box)
+
+        if self.size == size and box == (0, 0) + self.size:
+            return self.copy()
+
+        if self.mode in ("1", "P"):
+            resample = NEAREST
+
+        if self.mode in ["LA", "RGBA"] and resample != NEAREST:
+            im = self.convert({"LA": "La", "RGBA": "RGBa"}[self.mode])
+            im = im.resize(size, resample, box)
+            return im.convert(self.mode)
+
+        self.load()
+
+        if reducing_gap is not None and resample != NEAREST:
+            factor_x = int((box[2] - box[0]) / size[0] / reducing_gap) or 1
+            factor_y = int((box[3] - box[1]) / size[1] / reducing_gap) or 1
+            if factor_x > 1 or factor_y > 1:
+                reduce_box = self._get_safe_box(size, resample, box)
+                factor = (factor_x, factor_y)
+                if callable(self.reduce):
+                    self = self.reduce(factor, box=reduce_box)
+                else:
+                    self = Image.reduce(self, factor, box=reduce_box)
+                box = (
+                    (box[0] - reduce_box[0]) / factor_x,
+                    (box[1] - reduce_box[1]) / factor_y,
+                    (box[2] - reduce_box[0]) / factor_x,
+                    (box[3] - reduce_box[1]) / factor_y,
+                )
+
+        return self._new(self.im.resize(size, resample, box))
+
+    def reduce(self, factor, box=None):
+        """
+        Returns a copy of the image reduced ``factor`` times.
+        If the size of the image is not dividable by ``factor``,
+        the resulting size will be rounded up.
+
+        :param factor: A greater than 0 integer or tuple of two integers
+           for width and height separately.
+        :param box: An optional 4-tuple of ints providing
+           the source image region to be reduced.
+           The values must be within ``(0, 0, width, height)`` rectangle.
+           If omitted or ``None``, the entire source is used.
+        """
+        if not isinstance(factor, (list, tuple)):
+            factor = (factor, factor)
+
+        if box is None:
+            box = (0, 0) + self.size
+        else:
+            box = tuple(box)
+
+        if factor == (1, 1) and box == (0, 0) + self.size:
+            return self.copy()
+
+        if self.mode in ["LA", "RGBA"]:
+            im = self.convert({"LA": "La", "RGBA": "RGBa"}[self.mode])
+            im = im.reduce(factor, box)
+            return im.convert(self.mode)
+
+        self.load()
+
+        return self._new(self.im.reduce(factor, box))
+
+    def rotate(
+        self,
+        angle,
+        resample=NEAREST,
+        expand=0,
+        center=None,
+        translate=None,
+        fillcolor=None,
+    ):
+        """
+        Returns a rotated copy of this image.  This method returns a
+        copy of this image, rotated the given number of degrees counter
+        clockwise around its centre.
+
+        :param angle: In degrees counter clockwise.
+        :param resample: An optional resampling filter.  This can be
+           one of :py:data:`PIL.Image.NEAREST` (use nearest neighbour),
+           :py:data:`PIL.Image.BILINEAR` (linear interpolation in a 2x2
+           environment), or :py:data:`PIL.Image.BICUBIC`
+           (cubic spline interpolation in a 4x4 environment).
+           If omitted, or if the image has mode "1" or "P", it is
+           set to :py:data:`PIL.Image.NEAREST`. See :ref:`concept-filters`.
+        :param expand: Optional expansion flag.  If true, expands the output
+           image to make it large enough to hold the entire rotated image.
+           If false or omitted, make the output image the same size as the
+           input image.  Note that the expand flag assumes rotation around
+           the center and no translation.
+        :param center: Optional center of rotation (a 2-tuple).  Origin is
+           the upper left corner.  Default is the center of the image.
+        :param translate: An optional post-rotate translation (a 2-tuple).
+        :param fillcolor: An optional color for area outside the rotated image.
+        :returns: An :py:class:`~PIL.Image.Image` object.
+        """
+
+        angle = angle % 360.0
+
+        # Fast paths regardless of filter, as long as we're not
+        # translating or changing the center.
+        if not (center or translate):
+            if angle == 0:
+                return self.copy()
+            if angle == 180:
+                return self.transpose(ROTATE_180)
+            if angle in (90, 270) and (expand or self.width == self.height):
+                return self.transpose(ROTATE_90 if angle == 90 else ROTATE_270)
+
+        # Calculate the affine matrix.  Note that this is the reverse
+        # transformation (from destination image to source) because we
+        # want to interpolate the (discrete) destination pixel from
+        # the local area around the (floating) source pixel.
+
+        # The matrix we actually want (note that it operates from the right):
+        # (1, 0, tx)   (1, 0, cx)   ( cos a, sin a, 0)   (1, 0, -cx)
+        # (0, 1, ty) * (0, 1, cy) * (-sin a, cos a, 0) * (0, 1, -cy)
+        # (0, 0,  1)   (0, 0,  1)   (     0,     0, 1)   (0, 0,   1)
+
+        # The reverse matrix is thus:
+        # (1, 0, cx)   ( cos -a, sin -a, 0)   (1, 0, -cx)   (1, 0, -tx)
+        # (0, 1, cy) * (-sin -a, cos -a, 0) * (0, 1, -cy) * (0, 1, -ty)
+        # (0, 0,  1)   (      0,      0, 1)   (0, 0,   1)   (0, 0,   1)
+
+        # In any case, the final translation may be updated at the end to
+        # compensate for the expand flag.
+
+        w, h = self.size
+
+        if translate is None:
+            post_trans = (0, 0)
+        else:
+            post_trans = translate
+        if center is None:
+            # FIXME These should be rounded to ints?
+            rotn_center = (w / 2.0, h / 2.0)
+        else:
+            rotn_center = center
+
+        angle = -math.radians(angle)
+        matrix = [
+            round(math.cos(angle), 15),
+            round(math.sin(angle), 15),
+            0.0,
+            round(-math.sin(angle), 15),
+            round(math.cos(angle), 15),
+            0.0,
+        ]
+
+        def transform(x, y, matrix):
+            (a, b, c, d, e, f) = matrix
+            return a * x + b * y + c, d * x + e * y + f
+
+        matrix[2], matrix[5] = transform(
+            -rotn_center[0] - post_trans[0], -rotn_center[1] - post_trans[1], matrix
+        )
+        matrix[2] += rotn_center[0]
+        matrix[5] += rotn_center[1]
+
+        if expand:
+            # calculate output size
+            xx = []
+            yy = []
+            for x, y in ((0, 0), (w, 0), (w, h), (0, h)):
+                x, y = transform(x, y, matrix)
+                xx.append(x)
+                yy.append(y)
+            nw = math.ceil(max(xx)) - math.floor(min(xx))
+            nh = math.ceil(max(yy)) - math.floor(min(yy))
+
+            # We multiply a translation matrix from the right.  Because of its
+            # special form, this is the same as taking the image of the
+            # translation vector as new translation vector.
+            matrix[2], matrix[5] = transform(-(nw - w) / 2.0, -(nh - h) / 2.0, matrix)
+            w, h = nw, nh
+
+        return self.transform((w, h), AFFINE, matrix, resample, fillcolor=fillcolor)
+
+    def save(self, fp, format=None, **params):
+        """
+        Saves this image under the given filename.  If no format is
+        specified, the format to use is determined from the filename
+        extension, if possible.
+
+        Keyword options can be used to provide additional instructions
+        to the writer. If a writer doesn't recognise an option, it is
+        silently ignored. The available options are described in the
+        :doc:`image format documentation
+        <../handbook/image-file-formats>` for each writer.
+
+        You can use a file object instead of a filename. In this case,
+        you must always specify the format. The file object must
+        implement the ``seek``, ``tell``, and ``write``
+        methods, and be opened in binary mode.
+
+        :param fp: A filename (string), pathlib.Path object or file object.
+        :param format: Optional format override.  If omitted, the
+           format to use is determined from the filename extension.
+           If a file object was used instead of a filename, this
+           parameter should always be used.
+        :param params: Extra parameters to the image writer.
+        :returns: None
+        :exception ValueError: If the output format could not be determined
+           from the file name.  Use the format option to solve this.
+        :exception OSError: If the file could not be written.  The file
+           may have been created, and may contain partial data.
+        """
+
+        filename = ""
+        open_fp = False
+        if isinstance(fp, Path):
+            filename = str(fp)
+            open_fp = True
+        elif isPath(fp):
+            filename = fp
+            open_fp = True
+        elif fp == sys.stdout:
+            try:
+                fp = sys.stdout.buffer
+            except AttributeError:
+                pass
+        if not filename and hasattr(fp, "name") and isPath(fp.name):
+            # only set the name for metadata purposes
+            filename = fp.name
+
+        # may mutate self!
+        self._ensure_mutable()
+
+        save_all = params.pop("save_all", False)
+        self.encoderinfo = params
+        self.encoderconfig = ()
+
+        preinit()
+
+        ext = os.path.splitext(filename)[1].lower()
+
+        if not format:
+            if ext not in EXTENSION:
+                init()
+            try:
+                format = EXTENSION[ext]
+            except KeyError as e:
+                raise ValueError(f"unknown file extension: {ext}") from e
+
+        if format.upper() not in SAVE:
+            init()
+        if save_all:
+            save_handler = SAVE_ALL[format.upper()]
+        else:
+            save_handler = SAVE[format.upper()]
+
+        if open_fp:
+            if params.get("append", False):
+                # Open also for reading ("+"), because TIFF save_all
+                # writer needs to go back and edit the written data.
+                fp = builtins.open(filename, "r+b")
+            else:
+                fp = builtins.open(filename, "w+b")
+
+        try:
+            save_handler(self, fp, filename)
+        finally:
+            # do what we can to clean up
+            if open_fp:
+                fp.close()
+
+    def seek(self, frame):
+        """
+        Seeks to the given frame in this sequence file. If you seek
+        beyond the end of the sequence, the method raises an
+        ``EOFError`` exception. When a sequence file is opened, the
+        library automatically seeks to frame 0.
+
+        See :py:meth:`~PIL.Image.Image.tell`.
+
+        If defined, :attr:`~PIL.Image.Image.n_frames` refers to the
+        number of available frames.
+
+        :param frame: Frame number, starting at 0.
+        :exception EOFError: If the call attempts to seek beyond the end
+            of the sequence.
+        """
+
+        # overridden by file handlers
+        if frame != 0:
+            raise EOFError
+
+    def show(self, title=None):
+        """
+        Displays this image. This method is mainly intended for debugging purposes.
+
+        This method calls :py:func:`PIL.ImageShow.show` internally. You can use
+        :py:func:`PIL.ImageShow.register` to override its default behaviour.
+
+        The image is first saved to a temporary file. By default, it will be in
+        PNG format.
+
+        On Unix, the image is then opened using the **display**, **eog** or
+        **xv** utility, depending on which one can be found.
+
+        On macOS, the image is opened with the native Preview application.
+
+        On Windows, the image is opened with the standard PNG display utility.
+
+        :param title: Optional title to use for the image window, where possible.
+        """
+
+        _show(self, title=title)
+
+    def split(self):
+        """
+        Split this image into individual bands. This method returns a
+        tuple of individual image bands from an image. For example,
+        splitting an "RGB" image creates three new images each
+        containing a copy of one of the original bands (red, green,
+        blue).
+
+        If you need only one band, :py:meth:`~PIL.Image.Image.getchannel`
+        method can be more convenient and faster.
+
+        :returns: A tuple containing bands.
+        """
+
+        self.load()
+        if self.im.bands == 1:
+            ims = [self.copy()]
+        else:
+            ims = map(self._new, self.im.split())
+        return tuple(ims)
+
+    def getchannel(self, channel):
+        """
+        Returns an image containing a single channel of the source image.
+
+        :param channel: What channel to return. Could be index
+          (0 for "R" channel of "RGB") or channel name
+          ("A" for alpha channel of "RGBA").
+        :returns: An image in "L" mode.
+
+        .. versionadded:: 4.3.0
+        """
+        self.load()
+
+        if isinstance(channel, str):
+            try:
+                channel = self.getbands().index(channel)
+            except ValueError as e:
+                raise ValueError(f'The image has no channel "{channel}"') from e
+
+        return self._new(self.im.getband(channel))
+
+    def tell(self):
+        """
+        Returns the current frame number. See :py:meth:`~PIL.Image.Image.seek`.
+
+        If defined, :attr:`~PIL.Image.Image.n_frames` refers to the
+        number of available frames.
+
+        :returns: Frame number, starting with 0.
+        """
+        return 0
+
+    def thumbnail(self, size, resample=BICUBIC, reducing_gap=2.0):
+        """
+        Make this image into a thumbnail.  This method modifies the
+        image to contain a thumbnail version of itself, no larger than
+        the given size.  This method calculates an appropriate thumbnail
+        size to preserve the aspect of the image, calls the
+        :py:meth:`~PIL.Image.Image.draft` method to configure the file reader
+        (where applicable), and finally resizes the image.
+
+        Note that this function modifies the :py:class:`~PIL.Image.Image`
+        object in place.  If you need to use the full resolution image as well,
+        apply this method to a :py:meth:`~PIL.Image.Image.copy` of the original
+        image.
+
+        :param size: Requested size.
+        :param resample: Optional resampling filter.  This can be one
+           of :py:data:`PIL.Image.NEAREST`, :py:data:`PIL.Image.BOX`,
+           :py:data:`PIL.Image.BILINEAR`, :py:data:`PIL.Image.HAMMING`,
+           :py:data:`PIL.Image.BICUBIC` or :py:data:`PIL.Image.LANCZOS`.
+           If omitted, it defaults to :py:data:`PIL.Image.BICUBIC`.
+           (was :py:data:`PIL.Image.NEAREST` prior to version 2.5.0).
+           See: :ref:`concept-filters`.
+        :param reducing_gap: Apply optimization by resizing the image
+           in two steps. First, reducing the image by integer times
+           using :py:meth:`~PIL.Image.Image.reduce` or
+           :py:meth:`~PIL.Image.Image.draft` for JPEG images.
+           Second, resizing using regular resampling. The last step
+           changes size no less than by ``reducing_gap`` times.
+           ``reducing_gap`` may be None (no first step is performed)
+           or should be greater than 1.0. The bigger ``reducing_gap``,
+           the closer the result to the fair resampling.
+           The smaller ``reducing_gap``, the faster resizing.
+           With ``reducing_gap`` greater or equal to 3.0, the result is
+           indistinguishable from fair resampling in most cases.
+           The default value is 2.0 (very close to fair resampling
+           while still being faster in many cases).
+        :returns: None
+        """
+
+        x, y = map(math.floor, size)
+        if x >= self.width and y >= self.height:
+            return
+
+        def round_aspect(number, key):
+            return max(min(math.floor(number), math.ceil(number), key=key), 1)
+
+        # preserve aspect ratio
+        aspect = self.width / self.height
+        if x / y >= aspect:
+            x = round_aspect(y * aspect, key=lambda n: abs(aspect - n / y))
+        else:
+            y = round_aspect(
+                x / aspect, key=lambda n: 0 if n == 0 else abs(aspect - x / n)
+            )
+        size = (x, y)
+
+        box = None
+        if reducing_gap is not None:
+            res = self.draft(None, (size[0] * reducing_gap, size[1] * reducing_gap))
+            if res is not None:
+                box = res[1]
+
+        if self.size != size:
+            im = self.resize(size, resample, box=box, reducing_gap=reducing_gap)
+
+            self.im = im.im
+            self._size = size
+            self.mode = self.im.mode
+
+        self.readonly = 0
+        self.pyaccess = None
+
+    # FIXME: the different transform methods need further explanation
+    # instead of bloating the method docs, add a separate chapter.
+    def transform(
+        self, size, method, data=None, resample=NEAREST, fill=1, fillcolor=None
+    ):
+        """
+        Transforms this image.  This method creates a new image with the
+        given size, and the same mode as the original, and copies data
+        to the new image using the given transform.
+
+        :param size: The output size.
+        :param method: The transformation method.  This is one of
+          :py:data:`PIL.Image.EXTENT` (cut out a rectangular subregion),
+          :py:data:`PIL.Image.AFFINE` (affine transform),
+          :py:data:`PIL.Image.PERSPECTIVE` (perspective transform),
+          :py:data:`PIL.Image.QUAD` (map a quadrilateral to a rectangle), or
+          :py:data:`PIL.Image.MESH` (map a number of source quadrilaterals
+          in one operation).
+
+          It may also be an :py:class:`~PIL.Image.ImageTransformHandler`
+          object::
+
+            class Example(Image.ImageTransformHandler):
+                def transform(self, size, data, resample, fill=1):
+                    # Return result
+
+          It may also be an object with a ``method.getdata`` method
+          that returns a tuple supplying new ``method`` and ``data`` values::
+
+            class Example:
+                def getdata(self):
+                    method = Image.EXTENT
+                    data = (0, 0, 100, 100)
+                    return method, data
+        :param data: Extra data to the transformation method.
+        :param resample: Optional resampling filter.  It can be one of
+           :py:data:`PIL.Image.NEAREST` (use nearest neighbour),
+           :py:data:`PIL.Image.BILINEAR` (linear interpolation in a 2x2
+           environment), or :py:data:`PIL.Image.BICUBIC` (cubic spline
+           interpolation in a 4x4 environment). If omitted, or if the image
+           has mode "1" or "P", it is set to :py:data:`PIL.Image.NEAREST`.
+           See: :ref:`concept-filters`.
+        :param fill: If ``method`` is an
+          :py:class:`~PIL.Image.ImageTransformHandler` object, this is one of
+          the arguments passed to it. Otherwise, it is unused.
+        :param fillcolor: Optional fill color for the area outside the
+           transform in the output image.
+        :returns: An :py:class:`~PIL.Image.Image` object.
+        """
+
+        if self.mode in ("LA", "RGBA") and resample != NEAREST:
+            return (
+                self.convert({"LA": "La", "RGBA": "RGBa"}[self.mode])
+                .transform(size, method, data, resample, fill, fillcolor)
+                .convert(self.mode)
+            )
+
+        if isinstance(method, ImageTransformHandler):
+            return method.transform(size, self, resample=resample, fill=fill)
+
+        if hasattr(method, "getdata"):
+            # compatibility w. old-style transform objects
+            method, data = method.getdata()
+
+        if data is None:
+            raise ValueError("missing method data")
+
+        im = new(self.mode, size, fillcolor)
+        if self.mode == "P" and self.palette:
+            im.palette = self.palette.copy()
+        im.info = self.info.copy()
+        if method == MESH:
+            # list of quads
+            for box, quad in data:
+                im.__transformer(box, self, QUAD, quad, resample, fillcolor is None)
+        else:
+            im.__transformer(
+                (0, 0) + size, self, method, data, resample, fillcolor is None
+            )
+
+        return im
+
+    def __transformer(self, box, image, method, data, resample=NEAREST, fill=1):
+        w = box[2] - box[0]
+        h = box[3] - box[1]
+
+        if method == AFFINE:
+            data = data[0:6]
+
+        elif method == EXTENT:
+            # convert extent to an affine transform
+            x0, y0, x1, y1 = data
+            xs = (x1 - x0) / w
+            ys = (y1 - y0) / h
+            method = AFFINE
+            data = (xs, 0, x0, 0, ys, y0)
+
+        elif method == PERSPECTIVE:
+            data = data[0:8]
+
+        elif method == QUAD:
+            # quadrilateral warp.  data specifies the four corners
+            # given as NW, SW, SE, and NE.
+            nw = data[0:2]
+            sw = data[2:4]
+            se = data[4:6]
+            ne = data[6:8]
+            x0, y0 = nw
+            As = 1.0 / w
+            At = 1.0 / h
+            data = (
+                x0,
+                (ne[0] - x0) * As,
+                (sw[0] - x0) * At,
+                (se[0] - sw[0] - ne[0] + x0) * As * At,
+                y0,
+                (ne[1] - y0) * As,
+                (sw[1] - y0) * At,
+                (se[1] - sw[1] - ne[1] + y0) * As * At,
+            )
+
+        else:
+            raise ValueError("unknown transformation method")
+
+        if resample not in (NEAREST, BILINEAR, BICUBIC):
+            if resample in (BOX, HAMMING, LANCZOS):
+                message = {
+                    BOX: "Image.BOX",
+                    HAMMING: "Image.HAMMING",
+                    LANCZOS: "Image.LANCZOS/Image.ANTIALIAS",
+                }[resample] + f" ({resample}) cannot be used."
+            else:
+                message = f"Unknown resampling filter ({resample})."
+
+            filters = [
+                f"{filter[1]} ({filter[0]})"
+                for filter in (
+                    (NEAREST, "Image.NEAREST"),
+                    (BILINEAR, "Image.BILINEAR"),
+                    (BICUBIC, "Image.BICUBIC"),
+                )
+            ]
+            raise ValueError(
+                message + " Use " + ", ".join(filters[:-1]) + " or " + filters[-1]
+            )
+
+        image.load()
+
+        self.load()
+
+        if image.mode in ("1", "P"):
+            resample = NEAREST
+
+        self.im.transform2(box, image.im, method, data, resample, fill)
+
+    def transpose(self, method):
+        """
+        Transpose image (flip or rotate in 90 degree steps)
+
+        :param method: One of :py:data:`PIL.Image.FLIP_LEFT_RIGHT`,
+          :py:data:`PIL.Image.FLIP_TOP_BOTTOM`, :py:data:`PIL.Image.ROTATE_90`,
+          :py:data:`PIL.Image.ROTATE_180`, :py:data:`PIL.Image.ROTATE_270`,
+          :py:data:`PIL.Image.TRANSPOSE` or :py:data:`PIL.Image.TRANSVERSE`.
+        :returns: Returns a flipped or rotated copy of this image.
+        """
+
+        self.load()
+        return self._new(self.im.transpose(method))
+
+    def effect_spread(self, distance):
+        """
+        Randomly spread pixels in an image.
+
+        :param distance: Distance to spread pixels.
+        """
+        self.load()
+        return self._new(self.im.effect_spread(distance))
+
+    def toqimage(self):
+        """Returns a QImage copy of this image"""
+        from . import ImageQt
+
+        if not ImageQt.qt_is_installed:
+            raise ImportError("Qt bindings are not installed")
+        return ImageQt.toqimage(self)
+
+    def toqpixmap(self):
+        """Returns a QPixmap copy of this image"""
+        from . import ImageQt
+
+        if not ImageQt.qt_is_installed:
+            raise ImportError("Qt bindings are not installed")
+        return ImageQt.toqpixmap(self)
+
+
+# --------------------------------------------------------------------
+# Abstract handlers.
+
+
+class ImagePointHandler:
+    """
+    Used as a mixin by point transforms
+    (for use with :py:meth:`~PIL.Image.Image.point`)
+    """
+
+    pass
+
+
+class ImageTransformHandler:
+    """
+    Used as a mixin by geometry transforms
+    (for use with :py:meth:`~PIL.Image.Image.transform`)
+    """
+
+    pass
+
+
+# --------------------------------------------------------------------
+# Factories
+
+#
+# Debugging
+
+
+def _wedge():
+    """Create greyscale wedge (for debugging only)"""
+
+    return Image()._new(core.wedge("L"))
+
+
+def _check_size(size):
+    """
+    Common check to enforce type and sanity check on size tuples
+
+    :param size: Should be a 2 tuple of (width, height)
+    :returns: True, or raises a ValueError
+    """
+
+    if not isinstance(size, (list, tuple)):
+        raise ValueError("Size must be a tuple")
+    if len(size) != 2:
+        raise ValueError("Size must be a tuple of length 2")
+    if size[0] < 0 or size[1] < 0:
+        raise ValueError("Width and height must be >= 0")
+
+    return True
+
+
+def new(mode, size, color=0):
+    """
+    Creates a new image with the given mode and size.
+
+    :param mode: The mode to use for the new image. See:
+       :ref:`concept-modes`.
+    :param size: A 2-tuple, containing (width, height) in pixels.
+    :param color: What color to use for the image.  Default is black.
+       If given, this should be a single integer or floating point value
+       for single-band modes, and a tuple for multi-band modes (one value
+       per band).  When creating RGB images, you can also use color
+       strings as supported by the ImageColor module.  If the color is
+       None, the image is not initialised.
+    :returns: An :py:class:`~PIL.Image.Image` object.
+    """
+
+    _check_size(size)
+
+    if color is None:
+        # don't initialize
+        return Image()._new(core.new(mode, size))
+
+    if isinstance(color, str):
+        # css3-style specifier
+
+        from . import ImageColor
+
+        color = ImageColor.getcolor(color, mode)
+
+    im = Image()
+    if mode == "P" and isinstance(color, (list, tuple)) and len(color) in [3, 4]:
+        # RGB or RGBA value for a P image
+        from . import ImagePalette
+
+        im.palette = ImagePalette.ImagePalette()
+        color = im.palette.getcolor(color)
+    return im._new(core.fill(mode, size, color))
+
+
+def frombytes(mode, size, data, decoder_name="raw", *args):
+    """
+    Creates a copy of an image memory from pixel data in a buffer.
+
+    In its simplest form, this function takes three arguments
+    (mode, size, and unpacked pixel data).
+
+    You can also use any pixel decoder supported by PIL.  For more
+    information on available decoders, see the section
+    :ref:`Writing Your Own File Decoder <file-decoders>`.
+
+    Note that this function decodes pixel data only, not entire images.
+    If you have an entire image in a string, wrap it in a
+    :py:class:`~io.BytesIO` object, and use :py:func:`~PIL.Image.open` to load
+    it.
+
+    :param mode: The image mode. See: :ref:`concept-modes`.
+    :param size: The image size.
+    :param data: A byte buffer containing raw data for the given mode.
+    :param decoder_name: What decoder to use.
+    :param args: Additional parameters for the given decoder.
+    :returns: An :py:class:`~PIL.Image.Image` object.
+    """
+
+    _check_size(size)
+
+    # may pass tuple instead of argument list
+    if len(args) == 1 and isinstance(args[0], tuple):
+        args = args[0]
+
+    if decoder_name == "raw" and args == ():
+        args = mode
+
+    im = new(mode, size)
+    im.frombytes(data, decoder_name, args)
+    return im
+
+
+def frombuffer(mode, size, data, decoder_name="raw", *args):
+    """
+    Creates an image memory referencing pixel data in a byte buffer.
+
+    This function is similar to :py:func:`~PIL.Image.frombytes`, but uses data
+    in the byte buffer, where possible.  This means that changes to the
+    original buffer object are reflected in this image).  Not all modes can
+    share memory; supported modes include "L", "RGBX", "RGBA", and "CMYK".
+
+    Note that this function decodes pixel data only, not entire images.
+    If you have an entire image file in a string, wrap it in a
+    :py:class:`~io.BytesIO` object, and use :py:func:`~PIL.Image.open` to load it.
+
+    In the current version, the default parameters used for the "raw" decoder
+    differs from that used for :py:func:`~PIL.Image.frombytes`.  This is a
+    bug, and will probably be fixed in a future release.  The current release
+    issues a warning if you do this; to disable the warning, you should provide
+    the full set of parameters.  See below for details.
+
+    :param mode: The image mode. See: :ref:`concept-modes`.
+    :param size: The image size.
+    :param data: A bytes or other buffer object containing raw
+        data for the given mode.
+    :param decoder_name: What decoder to use.
+    :param args: Additional parameters for the given decoder.  For the
+        default encoder ("raw"), it's recommended that you provide the
+        full set of parameters::
+
+            frombuffer(mode, size, data, "raw", mode, 0, 1)
+
+    :returns: An :py:class:`~PIL.Image.Image` object.
+
+    .. versionadded:: 1.1.4
+    """
+
+    _check_size(size)
+
+    # may pass tuple instead of argument list
+    if len(args) == 1 and isinstance(args[0], tuple):
+        args = args[0]
+
+    if decoder_name == "raw":
+        if args == ():
+            args = mode, 0, 1
+        if args[0] in _MAPMODES:
+            im = new(mode, (1, 1))
+            im = im._new(core.map_buffer(data, size, decoder_name, 0, args))
+            im.readonly = 1
+            return im
+
+    return frombytes(mode, size, data, decoder_name, args)
+
+
+def fromarray(obj, mode=None):
+    """
+    Creates an image memory from an object exporting the array interface
+    (using the buffer protocol).
+
+    If ``obj`` is not contiguous, then the ``tobytes`` method is called
+    and :py:func:`~PIL.Image.frombuffer` is used.
+
+    If you have an image in NumPy::
+
+      from PIL import Image
+      import numpy as np
+      im = Image.open("hopper.jpg")
+      a = np.asarray(im)
+
+    Then this can be used to convert it to a Pillow image::
+
+      im = Image.fromarray(a)
+
+    :param obj: Object with array interface
+    :param mode: Optional mode to use when reading ``obj``. Will be determined from
+      type if ``None``.
+
+      This will not be used to convert the data after reading, but will be used to
+      change how the data is read::
+
+        from PIL import Image
+        import numpy as np
+        a = np.full((1, 1), 300)
+        im = Image.fromarray(a, mode="L")
+        im.getpixel((0, 0))  # 44
+        im = Image.fromarray(a, mode="RGB")
+        im.getpixel((0, 0))  # (44, 1, 0)
+
+      See: :ref:`concept-modes` for general information about modes.
+    :returns: An image object.
+
+    .. versionadded:: 1.1.6
+    """
+    arr = obj.__array_interface__
+    shape = arr["shape"]
+    ndim = len(shape)
+    strides = arr.get("strides", None)
+    if mode is None:
+        try:
+            typekey = (1, 1) + shape[2:], arr["typestr"]
+        except KeyError as e:
+            raise TypeError("Cannot handle this data type") from e
+        try:
+            mode, rawmode = _fromarray_typemap[typekey]
+        except KeyError as e:
+            raise TypeError("Cannot handle this data type: %s, %s" % typekey) from e
+    else:
+        rawmode = mode
+    if mode in ["1", "L", "I", "P", "F"]:
+        ndmax = 2
+    elif mode == "RGB":
+        ndmax = 3
+    else:
+        ndmax = 4
+    if ndim > ndmax:
+        raise ValueError(f"Too many dimensions: {ndim} > {ndmax}.")
+
+    size = 1 if ndim == 1 else shape[1], shape[0]
+    if strides is not None:
+        if hasattr(obj, "tobytes"):
+            obj = obj.tobytes()
+        else:
+            obj = obj.tostring()
+
+    return frombuffer(mode, size, obj, "raw", rawmode, 0, 1)
+
+
+def fromqimage(im):
+    """Creates an image instance from a QImage image"""
+    from . import ImageQt
+
+    if not ImageQt.qt_is_installed:
+        raise ImportError("Qt bindings are not installed")
+    return ImageQt.fromqimage(im)
+
+
+def fromqpixmap(im):
+    """Creates an image instance from a QPixmap image"""
+    from . import ImageQt
+
+    if not ImageQt.qt_is_installed:
+        raise ImportError("Qt bindings are not installed")
+    return ImageQt.fromqpixmap(im)
+
+
+_fromarray_typemap = {
+    # (shape, typestr) => mode, rawmode
+    # first two members of shape are set to one
+    ((1, 1), "|b1"): ("1", "1;8"),
+    ((1, 1), "|u1"): ("L", "L"),
+    ((1, 1), "|i1"): ("I", "I;8"),
+    ((1, 1), "<u2"): ("I", "I;16"),
+    ((1, 1), ">u2"): ("I", "I;16B"),
+    ((1, 1), "<i2"): ("I", "I;16S"),
+    ((1, 1), ">i2"): ("I", "I;16BS"),
+    ((1, 1), "<u4"): ("I", "I;32"),
+    ((1, 1), ">u4"): ("I", "I;32B"),
+    ((1, 1), "<i4"): ("I", "I;32S"),
+    ((1, 1), ">i4"): ("I", "I;32BS"),
+    ((1, 1), "<f4"): ("F", "F;32F"),
+    ((1, 1), ">f4"): ("F", "F;32BF"),
+    ((1, 1), "<f8"): ("F", "F;64F"),
+    ((1, 1), ">f8"): ("F", "F;64BF"),
+    ((1, 1, 2), "|u1"): ("LA", "LA"),
+    ((1, 1, 3), "|u1"): ("RGB", "RGB"),
+    ((1, 1, 4), "|u1"): ("RGBA", "RGBA"),
+}
+
+# shortcuts
+_fromarray_typemap[((1, 1), _ENDIAN + "i4")] = ("I", "I")
+_fromarray_typemap[((1, 1), _ENDIAN + "f4")] = ("F", "F")
+
+
+def _decompression_bomb_check(size):
+    if MAX_IMAGE_PIXELS is None:
+        return
+
+    pixels = size[0] * size[1]
+
+    if pixels > 2 * MAX_IMAGE_PIXELS:
+        raise DecompressionBombError(
+            f"Image size ({pixels} pixels) exceeds limit of {2 * MAX_IMAGE_PIXELS} "
+            "pixels, could be decompression bomb DOS attack."
+        )
+
+    if pixels > MAX_IMAGE_PIXELS:
+        warnings.warn(
+            f"Image size ({pixels} pixels) exceeds limit of {MAX_IMAGE_PIXELS} pixels, "
+            "could be decompression bomb DOS attack.",
+            DecompressionBombWarning,
+        )
+
+
+def open(fp, mode="r", formats=None):
+    """
+    Opens and identifies the given image file.
+
+    This is a lazy operation; this function identifies the file, but
+    the file remains open and the actual image data is not read from
+    the file until you try to process the data (or call the
+    :py:meth:`~PIL.Image.Image.load` method).  See
+    :py:func:`~PIL.Image.new`. See :ref:`file-handling`.
+
+    :param fp: A filename (string), pathlib.Path object or a file object.
+       The file object must implement ``file.read``,
+       ``file.seek``, and ``file.tell`` methods,
+       and be opened in binary mode.
+    :param mode: The mode.  If given, this argument must be "r".
+    :param formats: A list or tuple of formats to attempt to load the file in.
+       This can be used to restrict the set of formats checked.
+       Pass ``None`` to try all supported formats. You can print the set of
+       available formats by running ``python3 -m PIL`` or using
+       the :py:func:`PIL.features.pilinfo` function.
+    :returns: An :py:class:`~PIL.Image.Image` object.
+    :exception FileNotFoundError: If the file cannot be found.
+    :exception PIL.UnidentifiedImageError: If the image cannot be opened and
+       identified.
+    :exception ValueError: If the ``mode`` is not "r", or if a ``StringIO``
+       instance is used for ``fp``.
+    :exception TypeError: If ``formats`` is not ``None``, a list or a tuple.
+    """
+
+    if mode != "r":
+        raise ValueError(f"bad mode {repr(mode)}")
+    elif isinstance(fp, io.StringIO):
+        raise ValueError(
+            "StringIO cannot be used to open an image. "
+            "Binary data must be used instead."
+        )
+
+    if formats is None:
+        formats = ID
+    elif not isinstance(formats, (list, tuple)):
+        raise TypeError("formats must be a list or tuple")
+
+    exclusive_fp = False
+    filename = ""
+    if isinstance(fp, Path):
+        filename = str(fp.resolve())
+    elif isPath(fp):
+        filename = fp
+
+    if filename:
+        fp = builtins.open(filename, "rb")
+        exclusive_fp = True
+
+    try:
+        fp.seek(0)
+    except (AttributeError, io.UnsupportedOperation):
+        fp = io.BytesIO(fp.read())
+        exclusive_fp = True
+
+    prefix = fp.read(16)
+
+    preinit()
+
+    accept_warnings = []
+
+    def _open_core(fp, filename, prefix, formats):
+        for i in formats:
+            i = i.upper()
+            if i not in OPEN:
+                init()
+            try:
+                factory, accept = OPEN[i]
+                result = not accept or accept(prefix)
+                if type(result) in [str, bytes]:
+                    accept_warnings.append(result)
+                elif result:
+                    fp.seek(0)
+                    im = factory(fp, filename)
+                    _decompression_bomb_check(im.size)
+                    return im
+            except (SyntaxError, IndexError, TypeError, struct.error):
+                # Leave disabled by default, spams the logs with image
+                # opening failures that are entirely expected.
+                # logger.debug("", exc_info=True)
+                continue
+            except BaseException:
+                if exclusive_fp:
+                    fp.close()
+                raise
+        return None
+
+    im = _open_core(fp, filename, prefix, formats)
+
+    if im is None:
+        if init():
+            im = _open_core(fp, filename, prefix, formats)
+
+    if im:
+        im._exclusive_fp = exclusive_fp
+        return im
+
+    if exclusive_fp:
+        fp.close()
+    for message in accept_warnings:
+        warnings.warn(message)
+    raise UnidentifiedImageError(
+        "cannot identify image file %r" % (filename if filename else fp)
+    )
+
+
+#
+# Image processing.
+
+
+def alpha_composite(im1, im2):
+    """
+    Alpha composite im2 over im1.
+
+    :param im1: The first image. Must have mode RGBA.
+    :param im2: The second image.  Must have mode RGBA, and the same size as
+       the first image.
+    :returns: An :py:class:`~PIL.Image.Image` object.
+    """
+
+    im1.load()
+    im2.load()
+    return im1._new(core.alpha_composite(im1.im, im2.im))
+
+
+def blend(im1, im2, alpha):
+    """
+    Creates a new image by interpolating between two input images, using
+    a constant alpha.::
+
+        out = image1 * (1.0 - alpha) + image2 * alpha
+
+    :param im1: The first image.
+    :param im2: The second image.  Must have the same mode and size as
+       the first image.
+    :param alpha: The interpolation alpha factor.  If alpha is 0.0, a
+       copy of the first image is returned. If alpha is 1.0, a copy of
+       the second image is returned. There are no restrictions on the
+       alpha value. If necessary, the result is clipped to fit into
+       the allowed output range.
+    :returns: An :py:class:`~PIL.Image.Image` object.
+    """
+
+    im1.load()
+    im2.load()
+    return im1._new(core.blend(im1.im, im2.im, alpha))
+
+
+def composite(image1, image2, mask):
+    """
+    Create composite image by blending images using a transparency mask.
+
+    :param image1: The first image.
+    :param image2: The second image.  Must have the same mode and
+       size as the first image.
+    :param mask: A mask image.  This image can have mode
+       "1", "L", or "RGBA", and must have the same size as the
+       other two images.
+    """
+
+    image = image2.copy()
+    image.paste(image1, None, mask)
+    return image
+
+
+def eval(image, *args):
+    """
+    Applies the function (which should take one argument) to each pixel
+    in the given image. If the image has more than one band, the same
+    function is applied to each band. Note that the function is
+    evaluated once for each possible pixel value, so you cannot use
+    random components or other generators.
+
+    :param image: The input image.
+    :param function: A function object, taking one integer argument.
+    :returns: An :py:class:`~PIL.Image.Image` object.
+    """
+
+    return image.point(args[0])
+
+
+def merge(mode, bands):
+    """
+    Merge a set of single band images into a new multiband image.
+
+    :param mode: The mode to use for the output image. See:
+        :ref:`concept-modes`.
+    :param bands: A sequence containing one single-band image for
+        each band in the output image.  All bands must have the
+        same size.
+    :returns: An :py:class:`~PIL.Image.Image` object.
+    """
+
+    if getmodebands(mode) != len(bands) or "*" in mode:
+        raise ValueError("wrong number of bands")
+    for band in bands[1:]:
+        if band.mode != getmodetype(mode):
+            raise ValueError("mode mismatch")
+        if band.size != bands[0].size:
+            raise ValueError("size mismatch")
+    for band in bands:
+        band.load()
+    return bands[0]._new(core.merge(mode, *[b.im for b in bands]))
+
+
+# --------------------------------------------------------------------
+# Plugin registry
+
+
+def register_open(id, factory, accept=None):
+    """
+    Register an image file plugin.  This function should not be used
+    in application code.
+
+    :param id: An image format identifier.
+    :param factory: An image file factory method.
+    :param accept: An optional function that can be used to quickly
+       reject images having another format.
+    """
+    id = id.upper()
+    ID.append(id)
+    OPEN[id] = factory, accept
+
+
+def register_mime(id, mimetype):
+    """
+    Registers an image MIME type.  This function should not be used
+    in application code.
+
+    :param id: An image format identifier.
+    :param mimetype: The image MIME type for this format.
+    """
+    MIME[id.upper()] = mimetype
+
+
+def register_save(id, driver):
+    """
+    Registers an image save function.  This function should not be
+    used in application code.
+
+    :param id: An image format identifier.
+    :param driver: A function to save images in this format.
+    """
+    SAVE[id.upper()] = driver
+
+
+def register_save_all(id, driver):
+    """
+    Registers an image function to save all the frames
+    of a multiframe format.  This function should not be
+    used in application code.
+
+    :param id: An image format identifier.
+    :param driver: A function to save images in this format.
+    """
+    SAVE_ALL[id.upper()] = driver
+
+
+def register_extension(id, extension):
+    """
+    Registers an image extension.  This function should not be
+    used in application code.
+
+    :param id: An image format identifier.
+    :param extension: An extension used for this format.
+    """
+    EXTENSION[extension.lower()] = id.upper()
+
+
+def register_extensions(id, extensions):
+    """
+    Registers image extensions.  This function should not be
+    used in application code.
+
+    :param id: An image format identifier.
+    :param extensions: A list of extensions used for this format.
+    """
+    for extension in extensions:
+        register_extension(id, extension)
+
+
+def registered_extensions():
+    """
+    Returns a dictionary containing all file extensions belonging
+    to registered plugins
+    """
+    if not EXTENSION:
+        init()
+    return EXTENSION
+
+
+def register_decoder(name, decoder):
+    """
+    Registers an image decoder.  This function should not be
+    used in application code.
+
+    :param name: The name of the decoder
+    :param decoder: A callable(mode, args) that returns an
+                    ImageFile.PyDecoder object
+
+    .. versionadded:: 4.1.0
+    """
+    DECODERS[name] = decoder
+
+
+def register_encoder(name, encoder):
+    """
+    Registers an image encoder.  This function should not be
+    used in application code.
+
+    :param name: The name of the encoder
+    :param encoder: A callable(mode, args) that returns an
+                    ImageFile.PyEncoder object
+
+    .. versionadded:: 4.1.0
+    """
+    ENCODERS[name] = encoder
+
+
+# --------------------------------------------------------------------
+# Simple display support.
+
+
+def _show(image, **options):
+    from . import ImageShow
+
+    ImageShow.show(image, **options)
+
+
+# --------------------------------------------------------------------
+# Effects
+
+
+def effect_mandelbrot(size, extent, quality):
+    """
+    Generate a Mandelbrot set covering the given extent.
+
+    :param size: The requested size in pixels, as a 2-tuple:
+       (width, height).
+    :param extent: The extent to cover, as a 4-tuple:
+       (x0, y0, x1, y2).
+    :param quality: Quality.
+    """
+    return Image()._new(core.effect_mandelbrot(size, extent, quality))
+
+
+def effect_noise(size, sigma):
+    """
+    Generate Gaussian noise centered around 128.
+
+    :param size: The requested size in pixels, as a 2-tuple:
+       (width, height).
+    :param sigma: Standard deviation of noise.
+    """
+    return Image()._new(core.effect_noise(size, sigma))
+
+
+def linear_gradient(mode):
+    """
+    Generate 256x256 linear gradient from black to white, top to bottom.
+
+    :param mode: Input mode.
+    """
+    return Image()._new(core.linear_gradient(mode))
+
+
+def radial_gradient(mode):
+    """
+    Generate 256x256 radial gradient from black to white, centre to edge.
+
+    :param mode: Input mode.
+    """
+    return Image()._new(core.radial_gradient(mode))
+
+
+# --------------------------------------------------------------------
+# Resources
+
+
+def _apply_env_variables(env=None):
+    if env is None:
+        env = os.environ
+
+    for var_name, setter in [
+        ("PILLOW_ALIGNMENT", core.set_alignment),
+        ("PILLOW_BLOCK_SIZE", core.set_block_size),
+        ("PILLOW_BLOCKS_MAX", core.set_blocks_max),
+    ]:
+        if var_name not in env:
+            continue
+
+        var = env[var_name].lower()
+
+        units = 1
+        for postfix, mul in [("k", 1024), ("m", 1024 * 1024)]:
+            if var.endswith(postfix):
+                units = mul
+                var = var[: -len(postfix)]
+
+        try:
+            var = int(var) * units
+        except ValueError:
+            warnings.warn(f"{var_name} is not int")
+            continue
+
+        try:
+            setter(var)
+        except ValueError as e:
+            warnings.warn(f"{var_name}: {e}")
+
+
+_apply_env_variables()
+atexit.register(core.clear_cache)
+
+
+class Exif(MutableMapping):
+    endian = None
+
+    def __init__(self):
+        self._data = {}
+        self._ifds = {}
+        self._info = None
+        self._loaded_exif = None
+
+    def _fixup(self, value):
+        try:
+            if len(value) == 1 and isinstance(value, tuple):
+                return value[0]
+        except Exception:
+            pass
+        return value
+
+    def _fixup_dict(self, src_dict):
+        # Helper function
+        # returns a dict with any single item tuples/lists as individual values
+        return {k: self._fixup(v) for k, v in src_dict.items()}
+
+    def _get_ifd_dict(self, offset):
+        try:
+            # an offset pointer to the location of the nested embedded IFD.
+            # It should be a long, but may be corrupted.
+            self.fp.seek(offset)
+        except (KeyError, TypeError):
+            pass
+        else:
+            from . import TiffImagePlugin
+
+            info = TiffImagePlugin.ImageFileDirectory_v2(self.head)
+            info.load(self.fp)
+            return self._fixup_dict(info)
+
+    def _get_head(self):
+        if self.endian == "<":
+            return b"II\x2A\x00\x08\x00\x00\x00"
+        else:
+            return b"MM\x00\x2A\x00\x00\x00\x08"
+
+    def load(self, data):
+        # Extract EXIF information.  This is highly experimental,
+        # and is likely to be replaced with something better in a future
+        # version.
+
+        # The EXIF record consists of a TIFF file embedded in a JPEG
+        # application marker (!).
+        if data == self._loaded_exif:
+            return
+        self._loaded_exif = data
+        self._data.clear()
+        self._ifds.clear()
+        if not data:
+            self._info = None
+            return
+
+        if data.startswith(b"Exif\x00\x00"):
+            data = data[6:]
+        self.fp = io.BytesIO(data)
+        self.head = self.fp.read(8)
+        # process dictionary
+        from . import TiffImagePlugin
+
+        self._info = TiffImagePlugin.ImageFileDirectory_v2(self.head)
+        self.endian = self._info._endian
+        self.fp.seek(self._info.next)
+        self._info.load(self.fp)
+
+    def load_from_fp(self, fp, offset=None):
+        self._loaded_exif = None
+        self._data.clear()
+        self._ifds.clear()
+
+        # process dictionary
+        from . import TiffImagePlugin
+
+        self.fp = fp
+        if offset is not None:
+            self.head = self._get_head()
+        else:
+            self.head = self.fp.read(8)
+        self._info = TiffImagePlugin.ImageFileDirectory_v2(self.head)
+        if self.endian is None:
+            self.endian = self._info._endian
+        if offset is None:
+            offset = self._info.next
+        self.fp.seek(offset)
+        self._info.load(self.fp)
+
+    def _get_merged_dict(self):
+        merged_dict = dict(self)
+
+        # get EXIF extension
+        if 0x8769 in self:
+            ifd = self._get_ifd_dict(self[0x8769])
+            if ifd:
+                merged_dict.update(ifd)
+
+        # GPS
+        if 0x8825 in self:
+            merged_dict[0x8825] = self._get_ifd_dict(self[0x8825])
+
+        return merged_dict
+
+    def tobytes(self, offset=8):
+        from . import TiffImagePlugin
+
+        head = self._get_head()
+        ifd = TiffImagePlugin.ImageFileDirectory_v2(ifh=head)
+        for tag, value in self.items():
+            if tag in [0x8769, 0x8225, 0x8825] and not isinstance(value, dict):
+                value = self.get_ifd(tag)
+                if (
+                    tag == 0x8769
+                    and 0xA005 in value
+                    and not isinstance(value[0xA005], dict)
+                ):
+                    value = value.copy()
+                    value[0xA005] = self.get_ifd(0xA005)
+            ifd[tag] = value
+        return b"Exif\x00\x00" + head + ifd.tobytes(offset)
+
+    def get_ifd(self, tag):
+        if tag not in self._ifds:
+            if tag in [0x8769, 0x8825]:
+                # exif, gpsinfo
+                if tag in self:
+                    self._ifds[tag] = self._get_ifd_dict(self[tag])
+            elif tag in [0xA005, 0x927C]:
+                # interop, makernote
+                if 0x8769 not in self._ifds:
+                    self.get_ifd(0x8769)
+                tag_data = self._ifds[0x8769][tag]
+                if tag == 0x927C:
+                    # makernote
+                    from .TiffImagePlugin import ImageFileDirectory_v2
+
+                    if tag_data[:8] == b"FUJIFILM":
+                        ifd_offset = i32le(tag_data, 8)
+                        ifd_data = tag_data[ifd_offset:]
+
+                        makernote = {}
+                        for i in range(0, struct.unpack("<H", ifd_data[:2])[0]):
+                            ifd_tag, typ, count, data = struct.unpack(
+                                "<HHL4s", ifd_data[i * 12 + 2 : (i + 1) * 12 + 2]
+                            )
+                            try:
+                                (
+                                    unit_size,
+                                    handler,
+                                ) = ImageFileDirectory_v2._load_dispatch[typ]
+                            except KeyError:
+                                continue
+                            size = count * unit_size
+                            if size > 4:
+                                (offset,) = struct.unpack("<L", data)
+                                data = ifd_data[offset - 12 : offset + size - 12]
+                            else:
+                                data = data[:size]
+
+                            if len(data) != size:
+                                warnings.warn(
+                                    "Possibly corrupt EXIF MakerNote data.  "
+                                    f"Expecting to read {size} bytes but only got "
+                                    f"{len(data)}. Skipping tag {ifd_tag}"
+                                )
+                                continue
+
+                            if not data:
+                                continue
+
+                            makernote[ifd_tag] = handler(
+                                ImageFileDirectory_v2(), data, False
+                            )
+                        self._ifds[tag] = dict(self._fixup_dict(makernote))
+                    elif self.get(0x010F) == "Nintendo":
+                        makernote = {}
+                        for i in range(0, struct.unpack(">H", tag_data[:2])[0]):
+                            ifd_tag, typ, count, data = struct.unpack(
+                                ">HHL4s", tag_data[i * 12 + 2 : (i + 1) * 12 + 2]
+                            )
+                            if ifd_tag == 0x1101:
+                                # CameraInfo
+                                (offset,) = struct.unpack(">L", data)
+                                self.fp.seek(offset)
+
+                                camerainfo = {"ModelID": self.fp.read(4)}
+
+                                self.fp.read(4)
+                                # Seconds since 2000
+                                camerainfo["TimeStamp"] = i32le(self.fp.read(12))
+
+                                self.fp.read(4)
+                                camerainfo["InternalSerialNumber"] = self.fp.read(4)
+
+                                self.fp.read(12)
+                                parallax = self.fp.read(4)
+                                handler = ImageFileDirectory_v2._load_dispatch[
+                                    TiffTags.FLOAT
+                                ][1]
+                                camerainfo["Parallax"] = handler(
+                                    ImageFileDirectory_v2(), parallax, False
+                                )
+
+                                self.fp.read(4)
+                                camerainfo["Category"] = self.fp.read(2)
+
+                                makernote = {0x1101: dict(self._fixup_dict(camerainfo))}
+                        self._ifds[tag] = makernote
+                else:
+                    # interop
+                    self._ifds[tag] = self._get_ifd_dict(tag_data)
+        return self._ifds.get(tag, {})
+
+    def __str__(self):
+        if self._info is not None:
+            # Load all keys into self._data
+            for tag in self._info.keys():
+                self[tag]
+
+        return str(self._data)
+
+    def __len__(self):
+        keys = set(self._data)
+        if self._info is not None:
+            keys.update(self._info)
+        return len(keys)
+
+    def __getitem__(self, tag):
+        if self._info is not None and tag not in self._data and tag in self._info:
+            self._data[tag] = self._fixup(self._info[tag])
+            del self._info[tag]
+        return self._data[tag]
+
+    def __contains__(self, tag):
+        return tag in self._data or (self._info is not None and tag in self._info)
+
+    def __setitem__(self, tag, value):
+        if self._info is not None and tag in self._info:
+            del self._info[tag]
+        self._data[tag] = value
+
+    def __delitem__(self, tag):
+        if self._info is not None and tag in self._info:
+            del self._info[tag]
+        else:
+            del self._data[tag]
+
+    def __iter__(self):
+        keys = set(self._data)
+        if self._info is not None:
+            keys.update(self._info)
+        return iter(keys)
diff --git a/.venv/lib/python3.7/site-packages/PIL/ImageChops.py b/.venv/lib/python3.7/site-packages/PIL/ImageChops.py
new file mode 100644
index 0000000..61d3a29
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ImageChops.py
@@ -0,0 +1,328 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# standard channel operations
+#
+# History:
+# 1996-03-24 fl   Created
+# 1996-08-13 fl   Added logical operations (for "1" images)
+# 2000-10-12 fl   Added offset method (from Image.py)
+#
+# Copyright (c) 1997-2000 by Secret Labs AB
+# Copyright (c) 1996-2000 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+from . import Image
+
+
+def constant(image, value):
+    """Fill a channel with a given grey level.
+
+    :rtype: :py:class:`~PIL.Image.Image`
+    """
+
+    return Image.new("L", image.size, value)
+
+
+def duplicate(image):
+    """Copy a channel. Alias for :py:meth:`PIL.Image.Image.copy`.
+
+    :rtype: :py:class:`~PIL.Image.Image`
+    """
+
+    return image.copy()
+
+
+def invert(image):
+    """
+    Invert an image (channel).
+
+    .. code-block:: python
+
+        out = MAX - image
+
+    :rtype: :py:class:`~PIL.Image.Image`
+    """
+
+    image.load()
+    return image._new(image.im.chop_invert())
+
+
+def lighter(image1, image2):
+    """
+    Compares the two images, pixel by pixel, and returns a new image containing
+    the lighter values.
+
+    .. code-block:: python
+
+        out = max(image1, image2)
+
+    :rtype: :py:class:`~PIL.Image.Image`
+    """
+
+    image1.load()
+    image2.load()
+    return image1._new(image1.im.chop_lighter(image2.im))
+
+
+def darker(image1, image2):
+    """
+    Compares the two images, pixel by pixel, and returns a new image containing
+    the darker values.
+
+    .. code-block:: python
+
+        out = min(image1, image2)
+
+    :rtype: :py:class:`~PIL.Image.Image`
+    """
+
+    image1.load()
+    image2.load()
+    return image1._new(image1.im.chop_darker(image2.im))
+
+
+def difference(image1, image2):
+    """
+    Returns the absolute value of the pixel-by-pixel difference between the two
+    images.
+
+    .. code-block:: python
+
+        out = abs(image1 - image2)
+
+    :rtype: :py:class:`~PIL.Image.Image`
+    """
+
+    image1.load()
+    image2.load()
+    return image1._new(image1.im.chop_difference(image2.im))
+
+
+def multiply(image1, image2):
+    """
+    Superimposes two images on top of each other.
+
+    If you multiply an image with a solid black image, the result is black. If
+    you multiply with a solid white image, the image is unaffected.
+
+    .. code-block:: python
+
+        out = image1 * image2 / MAX
+
+    :rtype: :py:class:`~PIL.Image.Image`
+    """
+
+    image1.load()
+    image2.load()
+    return image1._new(image1.im.chop_multiply(image2.im))
+
+
+def screen(image1, image2):
+    """
+    Superimposes two inverted images on top of each other.
+
+    .. code-block:: python
+
+        out = MAX - ((MAX - image1) * (MAX - image2) / MAX)
+
+    :rtype: :py:class:`~PIL.Image.Image`
+    """
+
+    image1.load()
+    image2.load()
+    return image1._new(image1.im.chop_screen(image2.im))
+
+
+def soft_light(image1, image2):
+    """
+    Superimposes two images on top of each other using the Soft Light algorithm
+
+    :rtype: :py:class:`~PIL.Image.Image`
+    """
+
+    image1.load()
+    image2.load()
+    return image1._new(image1.im.chop_soft_light(image2.im))
+
+
+def hard_light(image1, image2):
+    """
+    Superimposes two images on top of each other using the Hard Light algorithm
+
+    :rtype: :py:class:`~PIL.Image.Image`
+    """
+
+    image1.load()
+    image2.load()
+    return image1._new(image1.im.chop_hard_light(image2.im))
+
+
+def overlay(image1, image2):
+    """
+    Superimposes two images on top of each other using the Overlay algorithm
+
+    :rtype: :py:class:`~PIL.Image.Image`
+    """
+
+    image1.load()
+    image2.load()
+    return image1._new(image1.im.chop_overlay(image2.im))
+
+
+def add(image1, image2, scale=1.0, offset=0):
+    """
+    Adds two images, dividing the result by scale and adding the
+    offset. If omitted, scale defaults to 1.0, and offset to 0.0.
+
+    .. code-block:: python
+
+        out = ((image1 + image2) / scale + offset)
+
+    :rtype: :py:class:`~PIL.Image.Image`
+    """
+
+    image1.load()
+    image2.load()
+    return image1._new(image1.im.chop_add(image2.im, scale, offset))
+
+
+def subtract(image1, image2, scale=1.0, offset=0):
+    """
+    Subtracts two images, dividing the result by scale and adding the offset.
+    If omitted, scale defaults to 1.0, and offset to 0.0.
+
+    .. code-block:: python
+
+        out = ((image1 - image2) / scale + offset)
+
+    :rtype: :py:class:`~PIL.Image.Image`
+    """
+
+    image1.load()
+    image2.load()
+    return image1._new(image1.im.chop_subtract(image2.im, scale, offset))
+
+
+def add_modulo(image1, image2):
+    """Add two images, without clipping the result.
+
+    .. code-block:: python
+
+        out = ((image1 + image2) % MAX)
+
+    :rtype: :py:class:`~PIL.Image.Image`
+    """
+
+    image1.load()
+    image2.load()
+    return image1._new(image1.im.chop_add_modulo(image2.im))
+
+
+def subtract_modulo(image1, image2):
+    """Subtract two images, without clipping the result.
+
+    .. code-block:: python
+
+        out = ((image1 - image2) % MAX)
+
+    :rtype: :py:class:`~PIL.Image.Image`
+    """
+
+    image1.load()
+    image2.load()
+    return image1._new(image1.im.chop_subtract_modulo(image2.im))
+
+
+def logical_and(image1, image2):
+    """Logical AND between two images.
+
+    Both of the images must have mode "1". If you would like to perform a
+    logical AND on an image with a mode other than "1", try
+    :py:meth:`~PIL.ImageChops.multiply` instead, using a black-and-white mask
+    as the second image.
+
+    .. code-block:: python
+
+        out = ((image1 and image2) % MAX)
+
+    :rtype: :py:class:`~PIL.Image.Image`
+    """
+
+    image1.load()
+    image2.load()
+    return image1._new(image1.im.chop_and(image2.im))
+
+
+def logical_or(image1, image2):
+    """Logical OR between two images.
+
+    Both of the images must have mode "1".
+
+    .. code-block:: python
+
+        out = ((image1 or image2) % MAX)
+
+    :rtype: :py:class:`~PIL.Image.Image`
+    """
+
+    image1.load()
+    image2.load()
+    return image1._new(image1.im.chop_or(image2.im))
+
+
+def logical_xor(image1, image2):
+    """Logical XOR between two images.
+
+    Both of the images must have mode "1".
+
+    .. code-block:: python
+
+        out = ((bool(image1) != bool(image2)) % MAX)
+
+    :rtype: :py:class:`~PIL.Image.Image`
+    """
+
+    image1.load()
+    image2.load()
+    return image1._new(image1.im.chop_xor(image2.im))
+
+
+def blend(image1, image2, alpha):
+    """Blend images using constant transparency weight. Alias for
+    :py:func:`PIL.Image.blend`.
+
+    :rtype: :py:class:`~PIL.Image.Image`
+    """
+
+    return Image.blend(image1, image2, alpha)
+
+
+def composite(image1, image2, mask):
+    """Create composite using transparency mask. Alias for
+    :py:func:`PIL.Image.composite`.
+
+    :rtype: :py:class:`~PIL.Image.Image`
+    """
+
+    return Image.composite(image1, image2, mask)
+
+
+def offset(image, xoffset, yoffset=None):
+    """Returns a copy of the image where data has been offset by the given
+    distances. Data wraps around the edges. If ``yoffset`` is omitted, it
+    is assumed to be equal to ``xoffset``.
+
+    :param xoffset: The horizontal distance.
+    :param yoffset: The vertical distance.  If omitted, both
+        distances are set to the same value.
+    :rtype: :py:class:`~PIL.Image.Image`
+    """
+
+    if yoffset is None:
+        yoffset = xoffset
+    image.load()
+    return image._new(image.im.offset(xoffset, yoffset))
diff --git a/.venv/lib/python3.7/site-packages/PIL/ImageCms.py b/.venv/lib/python3.7/site-packages/PIL/ImageCms.py
new file mode 100644
index 0000000..60e700f
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ImageCms.py
@@ -0,0 +1,999 @@
+# The Python Imaging Library.
+# $Id$
+
+# Optional color management support, based on Kevin Cazabon's PyCMS
+# library.
+
+# History:
+
+# 2009-03-08 fl   Added to PIL.
+
+# Copyright (C) 2002-2003 Kevin Cazabon
+# Copyright (c) 2009 by Fredrik Lundh
+# Copyright (c) 2013 by Eric Soroos
+
+# See the README file for information on usage and redistribution.  See
+# below for the original description.
+
+import sys
+
+from PIL import Image
+
+try:
+    from PIL import _imagingcms
+except ImportError as ex:
+    # Allow error import for doc purposes, but error out when accessing
+    # anything in core.
+    from ._util import deferred_error
+
+    _imagingcms = deferred_error(ex)
+
+DESCRIPTION = """
+pyCMS
+
+    a Python / PIL interface to the littleCMS ICC Color Management System
+    Copyright (C) 2002-2003 Kevin Cazabon
+    kevin@cazabon.com
+    https://www.cazabon.com
+
+    pyCMS home page:  https://www.cazabon.com/pyCMS
+    littleCMS home page:  https://www.littlecms.com
+    (littleCMS is Copyright (C) 1998-2001 Marti Maria)
+
+    Originally released under LGPL.  Graciously donated to PIL in
+    March 2009, for distribution under the standard PIL license
+
+    The pyCMS.py module provides a "clean" interface between Python/PIL and
+    pyCMSdll, taking care of some of the more complex handling of the direct
+    pyCMSdll functions, as well as error-checking and making sure that all
+    relevant data is kept together.
+
+    While it is possible to call pyCMSdll functions directly, it's not highly
+    recommended.
+
+    Version History:
+
+        1.0.0 pil       Oct 2013 Port to LCMS 2.
+
+        0.1.0 pil mod   March 10, 2009
+
+                        Renamed display profile to proof profile. The proof
+                        profile is the profile of the device that is being
+                        simulated, not the profile of the device which is
+                        actually used to display/print the final simulation
+                        (that'd be the output profile) - also see LCMSAPI.txt
+                        input colorspace -> using 'renderingIntent' -> proof
+                        colorspace -> using 'proofRenderingIntent' -> output
+                        colorspace
+
+                        Added LCMS FLAGS support.
+                        Added FLAGS["SOFTPROOFING"] as default flag for
+                        buildProofTransform (otherwise the proof profile/intent
+                        would be ignored).
+
+        0.1.0 pil       March 2009 - added to PIL, as PIL.ImageCms
+
+        0.0.2 alpha     Jan 6, 2002
+
+                        Added try/except statements around type() checks of
+                        potential CObjects... Python won't let you use type()
+                        on them, and raises a TypeError (stupid, if you ask
+                        me!)
+
+                        Added buildProofTransformFromOpenProfiles() function.
+                        Additional fixes in DLL, see DLL code for details.
+
+        0.0.1 alpha     first public release, Dec. 26, 2002
+
+    Known to-do list with current version (of Python interface, not pyCMSdll):
+
+        none
+
+"""
+
+VERSION = "1.0.0 pil"
+
+# --------------------------------------------------------------------.
+
+core = _imagingcms
+
+#
+# intent/direction values
+
+INTENT_PERCEPTUAL = 0
+INTENT_RELATIVE_COLORIMETRIC = 1
+INTENT_SATURATION = 2
+INTENT_ABSOLUTE_COLORIMETRIC = 3
+
+DIRECTION_INPUT = 0
+DIRECTION_OUTPUT = 1
+DIRECTION_PROOF = 2
+
+#
+# flags
+
+FLAGS = {
+    "MATRIXINPUT": 1,
+    "MATRIXOUTPUT": 2,
+    "MATRIXONLY": (1 | 2),
+    "NOWHITEONWHITEFIXUP": 4,  # Don't hot fix scum dot
+    # Don't create prelinearization tables on precalculated transforms
+    # (internal use):
+    "NOPRELINEARIZATION": 16,
+    "GUESSDEVICECLASS": 32,  # Guess device class (for transform2devicelink)
+    "NOTCACHE": 64,  # Inhibit 1-pixel cache
+    "NOTPRECALC": 256,
+    "NULLTRANSFORM": 512,  # Don't transform anyway
+    "HIGHRESPRECALC": 1024,  # Use more memory to give better accuracy
+    "LOWRESPRECALC": 2048,  # Use less memory to minimize resources
+    "WHITEBLACKCOMPENSATION": 8192,
+    "BLACKPOINTCOMPENSATION": 8192,
+    "GAMUTCHECK": 4096,  # Out of Gamut alarm
+    "SOFTPROOFING": 16384,  # Do softproofing
+    "PRESERVEBLACK": 32768,  # Black preservation
+    "NODEFAULTRESOURCEDEF": 16777216,  # CRD special
+    "GRIDPOINTS": lambda n: ((n) & 0xFF) << 16,  # Gridpoints
+}
+
+_MAX_FLAG = 0
+for flag in FLAGS.values():
+    if isinstance(flag, int):
+        _MAX_FLAG = _MAX_FLAG | flag
+
+
+# --------------------------------------------------------------------.
+# Experimental PIL-level API
+# --------------------------------------------------------------------.
+
+##
+# Profile.
+
+
+class ImageCmsProfile:
+    def __init__(self, profile):
+        """
+        :param profile: Either a string representing a filename,
+            a file like object containing a profile or a
+            low-level profile object
+
+        """
+
+        if isinstance(profile, str):
+            if sys.platform == "win32":
+                profile_bytes_path = profile.encode()
+                try:
+                    profile_bytes_path.decode("ascii")
+                except UnicodeDecodeError:
+                    with open(profile, "rb") as f:
+                        self._set(core.profile_frombytes(f.read()))
+                    return
+            self._set(core.profile_open(profile), profile)
+        elif hasattr(profile, "read"):
+            self._set(core.profile_frombytes(profile.read()))
+        elif isinstance(profile, _imagingcms.CmsProfile):
+            self._set(profile)
+        else:
+            raise TypeError("Invalid type for Profile")
+
+    def _set(self, profile, filename=None):
+        self.profile = profile
+        self.filename = filename
+        if profile:
+            self.product_name = None  # profile.product_name
+            self.product_info = None  # profile.product_info
+        else:
+            self.product_name = None
+            self.product_info = None
+
+    def tobytes(self):
+        """
+        Returns the profile in a format suitable for embedding in
+        saved images.
+
+        :returns: a bytes object containing the ICC profile.
+        """
+
+        return core.profile_tobytes(self.profile)
+
+
+class ImageCmsTransform(Image.ImagePointHandler):
+
+    """
+    Transform.  This can be used with the procedural API, or with the standard
+    :py:func:`~PIL.Image.Image.point` method.
+
+    Will return the output profile in the ``output.info['icc_profile']``.
+    """
+
+    def __init__(
+        self,
+        input,
+        output,
+        input_mode,
+        output_mode,
+        intent=INTENT_PERCEPTUAL,
+        proof=None,
+        proof_intent=INTENT_ABSOLUTE_COLORIMETRIC,
+        flags=0,
+    ):
+        if proof is None:
+            self.transform = core.buildTransform(
+                input.profile, output.profile, input_mode, output_mode, intent, flags
+            )
+        else:
+            self.transform = core.buildProofTransform(
+                input.profile,
+                output.profile,
+                proof.profile,
+                input_mode,
+                output_mode,
+                intent,
+                proof_intent,
+                flags,
+            )
+        # Note: inputMode and outputMode are for pyCMS compatibility only
+        self.input_mode = self.inputMode = input_mode
+        self.output_mode = self.outputMode = output_mode
+
+        self.output_profile = output
+
+    def point(self, im):
+        return self.apply(im)
+
+    def apply(self, im, imOut=None):
+        im.load()
+        if imOut is None:
+            imOut = Image.new(self.output_mode, im.size, None)
+        self.transform.apply(im.im.id, imOut.im.id)
+        imOut.info["icc_profile"] = self.output_profile.tobytes()
+        return imOut
+
+    def apply_in_place(self, im):
+        im.load()
+        if im.mode != self.output_mode:
+            raise ValueError("mode mismatch")  # wrong output mode
+        self.transform.apply(im.im.id, im.im.id)
+        im.info["icc_profile"] = self.output_profile.tobytes()
+        return im
+
+
+def get_display_profile(handle=None):
+    """
+    (experimental) Fetches the profile for the current display device.
+
+    :returns: ``None`` if the profile is not known.
+    """
+
+    if sys.platform != "win32":
+        return None
+
+    from PIL import ImageWin
+
+    if isinstance(handle, ImageWin.HDC):
+        profile = core.get_display_profile_win32(handle, 1)
+    else:
+        profile = core.get_display_profile_win32(handle or 0)
+    if profile is None:
+        return None
+    return ImageCmsProfile(profile)
+
+
+# --------------------------------------------------------------------.
+# pyCMS compatible layer
+# --------------------------------------------------------------------.
+
+
+class PyCMSError(Exception):
+
+    """(pyCMS) Exception class.
+    This is used for all errors in the pyCMS API."""
+
+    pass
+
+
+def profileToProfile(
+    im,
+    inputProfile,
+    outputProfile,
+    renderingIntent=INTENT_PERCEPTUAL,
+    outputMode=None,
+    inPlace=False,
+    flags=0,
+):
+    """
+    (pyCMS) Applies an ICC transformation to a given image, mapping from
+    ``inputProfile`` to ``outputProfile``.
+
+    If the input or output profiles specified are not valid filenames, a
+    :exc:`PyCMSError` will be raised.  If ``inPlace`` is ``True`` and
+    ``outputMode != im.mode``, a :exc:`PyCMSError` will be raised.
+    If an error occurs during application of the profiles,
+    a :exc:`PyCMSError` will be raised.
+    If ``outputMode`` is not a mode supported by the ``outputProfile`` (or by pyCMS),
+    a :exc:`PyCMSError` will be raised.
+
+    This function applies an ICC transformation to im from ``inputProfile``'s
+    color space to ``outputProfile``'s color space using the specified rendering
+    intent to decide how to handle out-of-gamut colors.
+
+    ``outputMode`` can be used to specify that a color mode conversion is to
+    be done using these profiles, but the specified profiles must be able
+    to handle that mode.  I.e., if converting im from RGB to CMYK using
+    profiles, the input profile must handle RGB data, and the output
+    profile must handle CMYK data.
+
+    :param im: An open :py:class:`~PIL.Image.Image` object (i.e. Image.new(...)
+        or Image.open(...), etc.)
+    :param inputProfile: String, as a valid filename path to the ICC input
+        profile you wish to use for this image, or a profile object
+    :param outputProfile: String, as a valid filename path to the ICC output
+        profile you wish to use for this image, or a profile object
+    :param renderingIntent: Integer (0-3) specifying the rendering intent you
+        wish to use for the transform
+
+            ImageCms.INTENT_PERCEPTUAL            = 0 (DEFAULT)
+            ImageCms.INTENT_RELATIVE_COLORIMETRIC = 1
+            ImageCms.INTENT_SATURATION            = 2
+            ImageCms.INTENT_ABSOLUTE_COLORIMETRIC = 3
+
+        see the pyCMS documentation for details on rendering intents and what
+        they do.
+    :param outputMode: A valid PIL mode for the output image (i.e. "RGB",
+        "CMYK", etc.).  Note: if rendering the image "inPlace", outputMode
+        MUST be the same mode as the input, or omitted completely.  If
+        omitted, the outputMode will be the same as the mode of the input
+        image (im.mode)
+    :param inPlace: Boolean.  If ``True``, the original image is modified in-place,
+        and ``None`` is returned.  If ``False`` (default), a new
+        :py:class:`~PIL.Image.Image` object is returned with the transform applied.
+    :param flags: Integer (0-...) specifying additional flags
+    :returns: Either None or a new :py:class:`~PIL.Image.Image` object, depending on
+        the value of ``inPlace``
+    :exception PyCMSError:
+    """
+
+    if outputMode is None:
+        outputMode = im.mode
+
+    if not isinstance(renderingIntent, int) or not (0 <= renderingIntent <= 3):
+        raise PyCMSError("renderingIntent must be an integer between 0 and 3")
+
+    if not isinstance(flags, int) or not (0 <= flags <= _MAX_FLAG):
+        raise PyCMSError("flags must be an integer between 0 and %s" + _MAX_FLAG)
+
+    try:
+        if not isinstance(inputProfile, ImageCmsProfile):
+            inputProfile = ImageCmsProfile(inputProfile)
+        if not isinstance(outputProfile, ImageCmsProfile):
+            outputProfile = ImageCmsProfile(outputProfile)
+        transform = ImageCmsTransform(
+            inputProfile,
+            outputProfile,
+            im.mode,
+            outputMode,
+            renderingIntent,
+            flags=flags,
+        )
+        if inPlace:
+            transform.apply_in_place(im)
+            imOut = None
+        else:
+            imOut = transform.apply(im)
+    except (OSError, TypeError, ValueError) as v:
+        raise PyCMSError(v) from v
+
+    return imOut
+
+
+def getOpenProfile(profileFilename):
+    """
+    (pyCMS) Opens an ICC profile file.
+
+    The PyCMSProfile object can be passed back into pyCMS for use in creating
+    transforms and such (as in ImageCms.buildTransformFromOpenProfiles()).
+
+    If ``profileFilename`` is not a valid filename for an ICC profile,
+    a :exc:`PyCMSError` will be raised.
+
+    :param profileFilename: String, as a valid filename path to the ICC profile
+        you wish to open, or a file-like object.
+    :returns: A CmsProfile class object.
+    :exception PyCMSError:
+    """
+
+    try:
+        return ImageCmsProfile(profileFilename)
+    except (OSError, TypeError, ValueError) as v:
+        raise PyCMSError(v) from v
+
+
+def buildTransform(
+    inputProfile,
+    outputProfile,
+    inMode,
+    outMode,
+    renderingIntent=INTENT_PERCEPTUAL,
+    flags=0,
+):
+    """
+    (pyCMS) Builds an ICC transform mapping from the ``inputProfile`` to the
+    ``outputProfile``. Use applyTransform to apply the transform to a given
+    image.
+
+    If the input or output profiles specified are not valid filenames, a
+    :exc:`PyCMSError` will be raised. If an error occurs during creation
+    of the transform, a :exc:`PyCMSError` will be raised.
+
+    If ``inMode`` or ``outMode`` are not a mode supported by the ``outputProfile``
+    (or by pyCMS), a :exc:`PyCMSError` will be raised.
+
+    This function builds and returns an ICC transform from the ``inputProfile``
+    to the ``outputProfile`` using the ``renderingIntent`` to determine what to do
+    with out-of-gamut colors.  It will ONLY work for converting images that
+    are in ``inMode`` to images that are in ``outMode`` color format (PIL mode,
+    i.e. "RGB", "RGBA", "CMYK", etc.).
+
+    Building the transform is a fair part of the overhead in
+    ImageCms.profileToProfile(), so if you're planning on converting multiple
+    images using the same input/output settings, this can save you time.
+    Once you have a transform object, it can be used with
+    ImageCms.applyProfile() to convert images without the need to re-compute
+    the lookup table for the transform.
+
+    The reason pyCMS returns a class object rather than a handle directly
+    to the transform is that it needs to keep track of the PIL input/output
+    modes that the transform is meant for.  These attributes are stored in
+    the ``inMode`` and ``outMode`` attributes of the object (which can be
+    manually overridden if you really want to, but I don't know of any
+    time that would be of use, or would even work).
+
+    :param inputProfile: String, as a valid filename path to the ICC input
+        profile you wish to use for this transform, or a profile object
+    :param outputProfile: String, as a valid filename path to the ICC output
+        profile you wish to use for this transform, or a profile object
+    :param inMode: String, as a valid PIL mode that the appropriate profile
+        also supports (i.e. "RGB", "RGBA", "CMYK", etc.)
+    :param outMode: String, as a valid PIL mode that the appropriate profile
+        also supports (i.e. "RGB", "RGBA", "CMYK", etc.)
+    :param renderingIntent: Integer (0-3) specifying the rendering intent you
+        wish to use for the transform
+
+            ImageCms.INTENT_PERCEPTUAL            = 0 (DEFAULT)
+            ImageCms.INTENT_RELATIVE_COLORIMETRIC = 1
+            ImageCms.INTENT_SATURATION            = 2
+            ImageCms.INTENT_ABSOLUTE_COLORIMETRIC = 3
+
+        see the pyCMS documentation for details on rendering intents and what
+        they do.
+    :param flags: Integer (0-...) specifying additional flags
+    :returns: A CmsTransform class object.
+    :exception PyCMSError:
+    """
+
+    if not isinstance(renderingIntent, int) or not (0 <= renderingIntent <= 3):
+        raise PyCMSError("renderingIntent must be an integer between 0 and 3")
+
+    if not isinstance(flags, int) or not (0 <= flags <= _MAX_FLAG):
+        raise PyCMSError("flags must be an integer between 0 and %s" + _MAX_FLAG)
+
+    try:
+        if not isinstance(inputProfile, ImageCmsProfile):
+            inputProfile = ImageCmsProfile(inputProfile)
+        if not isinstance(outputProfile, ImageCmsProfile):
+            outputProfile = ImageCmsProfile(outputProfile)
+        return ImageCmsTransform(
+            inputProfile, outputProfile, inMode, outMode, renderingIntent, flags=flags
+        )
+    except (OSError, TypeError, ValueError) as v:
+        raise PyCMSError(v) from v
+
+
+def buildProofTransform(
+    inputProfile,
+    outputProfile,
+    proofProfile,
+    inMode,
+    outMode,
+    renderingIntent=INTENT_PERCEPTUAL,
+    proofRenderingIntent=INTENT_ABSOLUTE_COLORIMETRIC,
+    flags=FLAGS["SOFTPROOFING"],
+):
+    """
+    (pyCMS) Builds an ICC transform mapping from the ``inputProfile`` to the
+    ``outputProfile``, but tries to simulate the result that would be
+    obtained on the ``proofProfile`` device.
+
+    If the input, output, or proof profiles specified are not valid
+    filenames, a :exc:`PyCMSError` will be raised.
+
+    If an error occurs during creation of the transform,
+    a :exc:`PyCMSError` will be raised.
+
+    If ``inMode`` or ``outMode`` are not a mode supported by the ``outputProfile``
+    (or by pyCMS), a :exc:`PyCMSError` will be raised.
+
+    This function builds and returns an ICC transform from the ``inputProfile``
+    to the ``outputProfile``, but tries to simulate the result that would be
+    obtained on the ``proofProfile`` device using ``renderingIntent`` and
+    ``proofRenderingIntent`` to determine what to do with out-of-gamut
+    colors.  This is known as "soft-proofing".  It will ONLY work for
+    converting images that are in ``inMode`` to images that are in outMode
+    color format (PIL mode, i.e. "RGB", "RGBA", "CMYK", etc.).
+
+    Usage of the resulting transform object is exactly the same as with
+    ImageCms.buildTransform().
+
+    Proof profiling is generally used when using an output device to get a
+    good idea of what the final printed/displayed image would look like on
+    the ``proofProfile`` device when it's quicker and easier to use the
+    output device for judging color.  Generally, this means that the
+    output device is a monitor, or a dye-sub printer (etc.), and the simulated
+    device is something more expensive, complicated, or time consuming
+    (making it difficult to make a real print for color judgement purposes).
+
+    Soft-proofing basically functions by adjusting the colors on the
+    output device to match the colors of the device being simulated. However,
+    when the simulated device has a much wider gamut than the output
+    device, you may obtain marginal results.
+
+    :param inputProfile: String, as a valid filename path to the ICC input
+        profile you wish to use for this transform, or a profile object
+    :param outputProfile: String, as a valid filename path to the ICC output
+        (monitor, usually) profile you wish to use for this transform, or a
+        profile object
+    :param proofProfile: String, as a valid filename path to the ICC proof
+        profile you wish to use for this transform, or a profile object
+    :param inMode: String, as a valid PIL mode that the appropriate profile
+        also supports (i.e. "RGB", "RGBA", "CMYK", etc.)
+    :param outMode: String, as a valid PIL mode that the appropriate profile
+        also supports (i.e. "RGB", "RGBA", "CMYK", etc.)
+    :param renderingIntent: Integer (0-3) specifying the rendering intent you
+        wish to use for the input->proof (simulated) transform
+
+            ImageCms.INTENT_PERCEPTUAL            = 0 (DEFAULT)
+            ImageCms.INTENT_RELATIVE_COLORIMETRIC = 1
+            ImageCms.INTENT_SATURATION            = 2
+            ImageCms.INTENT_ABSOLUTE_COLORIMETRIC = 3
+
+        see the pyCMS documentation for details on rendering intents and what
+        they do.
+    :param proofRenderingIntent: Integer (0-3) specifying the rendering intent
+        you wish to use for proof->output transform
+
+            ImageCms.INTENT_PERCEPTUAL            = 0 (DEFAULT)
+            ImageCms.INTENT_RELATIVE_COLORIMETRIC = 1
+            ImageCms.INTENT_SATURATION            = 2
+            ImageCms.INTENT_ABSOLUTE_COLORIMETRIC = 3
+
+        see the pyCMS documentation for details on rendering intents and what
+        they do.
+    :param flags: Integer (0-...) specifying additional flags
+    :returns: A CmsTransform class object.
+    :exception PyCMSError:
+    """
+
+    if not isinstance(renderingIntent, int) or not (0 <= renderingIntent <= 3):
+        raise PyCMSError("renderingIntent must be an integer between 0 and 3")
+
+    if not isinstance(flags, int) or not (0 <= flags <= _MAX_FLAG):
+        raise PyCMSError("flags must be an integer between 0 and %s" + _MAX_FLAG)
+
+    try:
+        if not isinstance(inputProfile, ImageCmsProfile):
+            inputProfile = ImageCmsProfile(inputProfile)
+        if not isinstance(outputProfile, ImageCmsProfile):
+            outputProfile = ImageCmsProfile(outputProfile)
+        if not isinstance(proofProfile, ImageCmsProfile):
+            proofProfile = ImageCmsProfile(proofProfile)
+        return ImageCmsTransform(
+            inputProfile,
+            outputProfile,
+            inMode,
+            outMode,
+            renderingIntent,
+            proofProfile,
+            proofRenderingIntent,
+            flags,
+        )
+    except (OSError, TypeError, ValueError) as v:
+        raise PyCMSError(v) from v
+
+
+buildTransformFromOpenProfiles = buildTransform
+buildProofTransformFromOpenProfiles = buildProofTransform
+
+
+def applyTransform(im, transform, inPlace=False):
+    """
+    (pyCMS) Applies a transform to a given image.
+
+    If ``im.mode != transform.inMode``, a :exc:`PyCMSError` is raised.
+
+    If ``inPlace`` is ``True`` and ``transform.inMode != transform.outMode``, a
+    :exc:`PyCMSError` is raised.
+
+    If ``im.mode``, ``transform.inMode`` or ``transform.outMode`` is not
+    supported by pyCMSdll or the profiles you used for the transform, a
+    :exc:`PyCMSError` is raised.
+
+    If an error occurs while the transform is being applied,
+    a :exc:`PyCMSError` is raised.
+
+    This function applies a pre-calculated transform (from
+    ImageCms.buildTransform() or ImageCms.buildTransformFromOpenProfiles())
+    to an image. The transform can be used for multiple images, saving
+    considerable calculation time if doing the same conversion multiple times.
+
+    If you want to modify im in-place instead of receiving a new image as
+    the return value, set ``inPlace`` to ``True``.  This can only be done if
+    ``transform.inMode`` and ``transform.outMode`` are the same, because we can't
+    change the mode in-place (the buffer sizes for some modes are
+    different).  The default behavior is to return a new :py:class:`~PIL.Image.Image`
+    object of the same dimensions in mode ``transform.outMode``.
+
+    :param im: An :py:class:`~PIL.Image.Image` object, and im.mode must be the same
+        as the ``inMode`` supported by the transform.
+    :param transform: A valid CmsTransform class object
+    :param inPlace: Bool.  If ``True``, ``im`` is modified in place and ``None`` is
+        returned, if ``False``, a new :py:class:`~PIL.Image.Image` object with the
+        transform applied is returned (and ``im`` is not changed). The default is
+        ``False``.
+    :returns: Either ``None``, or a new :py:class:`~PIL.Image.Image` object,
+        depending on the value of ``inPlace``. The profile will be returned in
+        the image's ``info['icc_profile']``.
+    :exception PyCMSError:
+    """
+
+    try:
+        if inPlace:
+            transform.apply_in_place(im)
+            imOut = None
+        else:
+            imOut = transform.apply(im)
+    except (TypeError, ValueError) as v:
+        raise PyCMSError(v) from v
+
+    return imOut
+
+
+def createProfile(colorSpace, colorTemp=-1):
+    """
+    (pyCMS) Creates a profile.
+
+    If colorSpace not in ``["LAB", "XYZ", "sRGB"]``,
+    a :exc:`PyCMSError` is raised.
+
+    If using LAB and ``colorTemp`` is not a positive integer,
+    a :exc:`PyCMSError` is raised.
+
+    If an error occurs while creating the profile,
+    a :exc:`PyCMSError` is raised.
+
+    Use this function to create common profiles on-the-fly instead of
+    having to supply a profile on disk and knowing the path to it.  It
+    returns a normal CmsProfile object that can be passed to
+    ImageCms.buildTransformFromOpenProfiles() to create a transform to apply
+    to images.
+
+    :param colorSpace: String, the color space of the profile you wish to
+        create.
+        Currently only "LAB", "XYZ", and "sRGB" are supported.
+    :param colorTemp: Positive integer for the white point for the profile, in
+        degrees Kelvin (i.e. 5000, 6500, 9600, etc.).  The default is for D50
+        illuminant if omitted (5000k).  colorTemp is ONLY applied to LAB
+        profiles, and is ignored for XYZ and sRGB.
+    :returns: A CmsProfile class object
+    :exception PyCMSError:
+    """
+
+    if colorSpace not in ["LAB", "XYZ", "sRGB"]:
+        raise PyCMSError(
+            f"Color space not supported for on-the-fly profile creation ({colorSpace})"
+        )
+
+    if colorSpace == "LAB":
+        try:
+            colorTemp = float(colorTemp)
+        except (TypeError, ValueError) as e:
+            raise PyCMSError(
+                f'Color temperature must be numeric, "{colorTemp}" not valid'
+            ) from e
+
+    try:
+        return core.createProfile(colorSpace, colorTemp)
+    except (TypeError, ValueError) as v:
+        raise PyCMSError(v) from v
+
+
+def getProfileName(profile):
+    """
+
+    (pyCMS) Gets the internal product name for the given profile.
+
+    If ``profile`` isn't a valid CmsProfile object or filename to a profile,
+    a :exc:`PyCMSError` is raised If an error occurs while trying
+    to obtain the name tag, a :exc:`PyCMSError` is raised.
+
+    Use this function to obtain the INTERNAL name of the profile (stored
+    in an ICC tag in the profile itself), usually the one used when the
+    profile was originally created.  Sometimes this tag also contains
+    additional information supplied by the creator.
+
+    :param profile: EITHER a valid CmsProfile object, OR a string of the
+        filename of an ICC profile.
+    :returns: A string containing the internal name of the profile as stored
+        in an ICC tag.
+    :exception PyCMSError:
+    """
+
+    try:
+        # add an extra newline to preserve pyCMS compatibility
+        if not isinstance(profile, ImageCmsProfile):
+            profile = ImageCmsProfile(profile)
+        # do it in python, not c.
+        #    // name was "%s - %s" (model, manufacturer) || Description ,
+        #    // but if the Model and Manufacturer were the same or the model
+        #    // was long, Just the model,  in 1.x
+        model = profile.profile.model
+        manufacturer = profile.profile.manufacturer
+
+        if not (model or manufacturer):
+            return (profile.profile.profile_description or "") + "\n"
+        if not manufacturer or len(model) > 30:
+            return model + "\n"
+        return f"{model} - {manufacturer}\n"
+
+    except (AttributeError, OSError, TypeError, ValueError) as v:
+        raise PyCMSError(v) from v
+
+
+def getProfileInfo(profile):
+    """
+    (pyCMS) Gets the internal product information for the given profile.
+
+    If ``profile`` isn't a valid CmsProfile object or filename to a profile,
+    a :exc:`PyCMSError` is raised.
+
+    If an error occurs while trying to obtain the info tag,
+    a :exc:`PyCMSError` is raised.
+
+    Use this function to obtain the information stored in the profile's
+    info tag.  This often contains details about the profile, and how it
+    was created, as supplied by the creator.
+
+    :param profile: EITHER a valid CmsProfile object, OR a string of the
+        filename of an ICC profile.
+    :returns: A string containing the internal profile information stored in
+        an ICC tag.
+    :exception PyCMSError:
+    """
+
+    try:
+        if not isinstance(profile, ImageCmsProfile):
+            profile = ImageCmsProfile(profile)
+        # add an extra newline to preserve pyCMS compatibility
+        # Python, not C. the white point bits weren't working well,
+        # so skipping.
+        # info was description \r\n\r\n copyright \r\n\r\n K007 tag \r\n\r\n whitepoint
+        description = profile.profile.profile_description
+        cpright = profile.profile.copyright
+        arr = []
+        for elt in (description, cpright):
+            if elt:
+                arr.append(elt)
+        return "\r\n\r\n".join(arr) + "\r\n\r\n"
+
+    except (AttributeError, OSError, TypeError, ValueError) as v:
+        raise PyCMSError(v) from v
+
+
+def getProfileCopyright(profile):
+    """
+    (pyCMS) Gets the copyright for the given profile.
+
+    If ``profile`` isn't a valid CmsProfile object or filename to a profile, a
+    :exc:`PyCMSError` is raised.
+
+    If an error occurs while trying to obtain the copyright tag,
+    a :exc:`PyCMSError` is raised.
+
+    Use this function to obtain the information stored in the profile's
+    copyright tag.
+
+    :param profile: EITHER a valid CmsProfile object, OR a string of the
+        filename of an ICC profile.
+    :returns: A string containing the internal profile information stored in
+        an ICC tag.
+    :exception PyCMSError:
+    """
+    try:
+        # add an extra newline to preserve pyCMS compatibility
+        if not isinstance(profile, ImageCmsProfile):
+            profile = ImageCmsProfile(profile)
+        return (profile.profile.copyright or "") + "\n"
+    except (AttributeError, OSError, TypeError, ValueError) as v:
+        raise PyCMSError(v) from v
+
+
+def getProfileManufacturer(profile):
+    """
+    (pyCMS) Gets the manufacturer for the given profile.
+
+    If ``profile`` isn't a valid CmsProfile object or filename to a profile, a
+    :exc:`PyCMSError` is raised.
+
+    If an error occurs while trying to obtain the manufacturer tag, a
+    :exc:`PyCMSError` is raised.
+
+    Use this function to obtain the information stored in the profile's
+    manufacturer tag.
+
+    :param profile: EITHER a valid CmsProfile object, OR a string of the
+        filename of an ICC profile.
+    :returns: A string containing the internal profile information stored in
+        an ICC tag.
+    :exception PyCMSError:
+    """
+    try:
+        # add an extra newline to preserve pyCMS compatibility
+        if not isinstance(profile, ImageCmsProfile):
+            profile = ImageCmsProfile(profile)
+        return (profile.profile.manufacturer or "") + "\n"
+    except (AttributeError, OSError, TypeError, ValueError) as v:
+        raise PyCMSError(v) from v
+
+
+def getProfileModel(profile):
+    """
+    (pyCMS) Gets the model for the given profile.
+
+    If ``profile`` isn't a valid CmsProfile object or filename to a profile, a
+    :exc:`PyCMSError` is raised.
+
+    If an error occurs while trying to obtain the model tag,
+    a :exc:`PyCMSError` is raised.
+
+    Use this function to obtain the information stored in the profile's
+    model tag.
+
+    :param profile: EITHER a valid CmsProfile object, OR a string of the
+        filename of an ICC profile.
+    :returns: A string containing the internal profile information stored in
+        an ICC tag.
+    :exception PyCMSError:
+    """
+
+    try:
+        # add an extra newline to preserve pyCMS compatibility
+        if not isinstance(profile, ImageCmsProfile):
+            profile = ImageCmsProfile(profile)
+        return (profile.profile.model or "") + "\n"
+    except (AttributeError, OSError, TypeError, ValueError) as v:
+        raise PyCMSError(v) from v
+
+
+def getProfileDescription(profile):
+    """
+    (pyCMS) Gets the description for the given profile.
+
+    If ``profile`` isn't a valid CmsProfile object or filename to a profile, a
+    :exc:`PyCMSError` is raised.
+
+    If an error occurs while trying to obtain the description tag,
+    a :exc:`PyCMSError` is raised.
+
+    Use this function to obtain the information stored in the profile's
+    description tag.
+
+    :param profile: EITHER a valid CmsProfile object, OR a string of the
+        filename of an ICC profile.
+    :returns: A string containing the internal profile information stored in an
+        ICC tag.
+    :exception PyCMSError:
+    """
+
+    try:
+        # add an extra newline to preserve pyCMS compatibility
+        if not isinstance(profile, ImageCmsProfile):
+            profile = ImageCmsProfile(profile)
+        return (profile.profile.profile_description or "") + "\n"
+    except (AttributeError, OSError, TypeError, ValueError) as v:
+        raise PyCMSError(v) from v
+
+
+def getDefaultIntent(profile):
+    """
+    (pyCMS) Gets the default intent name for the given profile.
+
+    If ``profile`` isn't a valid CmsProfile object or filename to a profile, a
+    :exc:`PyCMSError` is raised.
+
+    If an error occurs while trying to obtain the default intent, a
+    :exc:`PyCMSError` is raised.
+
+    Use this function to determine the default (and usually best optimized)
+    rendering intent for this profile.  Most profiles support multiple
+    rendering intents, but are intended mostly for one type of conversion.
+    If you wish to use a different intent than returned, use
+    ImageCms.isIntentSupported() to verify it will work first.
+
+    :param profile: EITHER a valid CmsProfile object, OR a string of the
+        filename of an ICC profile.
+    :returns: Integer 0-3 specifying the default rendering intent for this
+        profile.
+
+            ImageCms.INTENT_PERCEPTUAL            = 0 (DEFAULT)
+            ImageCms.INTENT_RELATIVE_COLORIMETRIC = 1
+            ImageCms.INTENT_SATURATION            = 2
+            ImageCms.INTENT_ABSOLUTE_COLORIMETRIC = 3
+
+        see the pyCMS documentation for details on rendering intents and what
+            they do.
+    :exception PyCMSError:
+    """
+
+    try:
+        if not isinstance(profile, ImageCmsProfile):
+            profile = ImageCmsProfile(profile)
+        return profile.profile.rendering_intent
+    except (AttributeError, OSError, TypeError, ValueError) as v:
+        raise PyCMSError(v) from v
+
+
+def isIntentSupported(profile, intent, direction):
+    """
+    (pyCMS) Checks if a given intent is supported.
+
+    Use this function to verify that you can use your desired
+    ``intent`` with ``profile``, and that ``profile`` can be used for the
+    input/output/proof profile as you desire.
+
+    Some profiles are created specifically for one "direction", can cannot
+    be used for others. Some profiles can only be used for certain
+    rendering intents, so it's best to either verify this before trying
+    to create a transform with them (using this function), or catch the
+    potential :exc:`PyCMSError` that will occur if they don't
+    support the modes you select.
+
+    :param profile: EITHER a valid CmsProfile object, OR a string of the
+        filename of an ICC profile.
+    :param intent: Integer (0-3) specifying the rendering intent you wish to
+        use with this profile
+
+            ImageCms.INTENT_PERCEPTUAL            = 0 (DEFAULT)
+            ImageCms.INTENT_RELATIVE_COLORIMETRIC = 1
+            ImageCms.INTENT_SATURATION            = 2
+            ImageCms.INTENT_ABSOLUTE_COLORIMETRIC = 3
+
+        see the pyCMS documentation for details on rendering intents and what
+            they do.
+    :param direction: Integer specifying if the profile is to be used for
+        input, output, or proof
+
+            INPUT  = 0 (or use ImageCms.DIRECTION_INPUT)
+            OUTPUT = 1 (or use ImageCms.DIRECTION_OUTPUT)
+            PROOF  = 2 (or use ImageCms.DIRECTION_PROOF)
+
+    :returns: 1 if the intent/direction are supported, -1 if they are not.
+    :exception PyCMSError:
+    """
+
+    try:
+        if not isinstance(profile, ImageCmsProfile):
+            profile = ImageCmsProfile(profile)
+        # FIXME: I get different results for the same data w. different
+        # compilers.  Bug in LittleCMS or in the binding?
+        if profile.profile.is_intent_supported(intent, direction):
+            return 1
+        else:
+            return -1
+    except (AttributeError, OSError, TypeError, ValueError) as v:
+        raise PyCMSError(v) from v
+
+
+def versions():
+    """
+    (pyCMS) Fetches versions.
+    """
+
+    return (VERSION, core.littlecms_version, sys.version.split()[0], Image.__version__)
diff --git a/.venv/lib/python3.7/site-packages/PIL/ImageColor.py b/.venv/lib/python3.7/site-packages/PIL/ImageColor.py
new file mode 100644
index 0000000..25f92f2
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ImageColor.py
@@ -0,0 +1,302 @@
+#
+# The Python Imaging Library
+# $Id$
+#
+# map CSS3-style colour description strings to RGB
+#
+# History:
+# 2002-10-24 fl   Added support for CSS-style color strings
+# 2002-12-15 fl   Added RGBA support
+# 2004-03-27 fl   Fixed remaining int() problems for Python 1.5.2
+# 2004-07-19 fl   Fixed gray/grey spelling issues
+# 2009-03-05 fl   Fixed rounding error in grayscale calculation
+#
+# Copyright (c) 2002-2004 by Secret Labs AB
+# Copyright (c) 2002-2004 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+import re
+
+from . import Image
+
+
+def getrgb(color):
+    """
+     Convert a color string to an RGB or RGBA tuple. If the string cannot be
+     parsed, this function raises a :py:exc:`ValueError` exception.
+
+    .. versionadded:: 1.1.4
+
+    :param color: A color string
+    :return: ``(red, green, blue[, alpha])``
+    """
+    if len(color) > 100:
+        raise ValueError("color specifier is too long")
+    color = color.lower()
+
+    rgb = colormap.get(color, None)
+    if rgb:
+        if isinstance(rgb, tuple):
+            return rgb
+        colormap[color] = rgb = getrgb(rgb)
+        return rgb
+
+    # check for known string formats
+    if re.match("#[a-f0-9]{3}$", color):
+        return (int(color[1] * 2, 16), int(color[2] * 2, 16), int(color[3] * 2, 16))
+
+    if re.match("#[a-f0-9]{4}$", color):
+        return (
+            int(color[1] * 2, 16),
+            int(color[2] * 2, 16),
+            int(color[3] * 2, 16),
+            int(color[4] * 2, 16),
+        )
+
+    if re.match("#[a-f0-9]{6}$", color):
+        return (int(color[1:3], 16), int(color[3:5], 16), int(color[5:7], 16))
+
+    if re.match("#[a-f0-9]{8}$", color):
+        return (
+            int(color[1:3], 16),
+            int(color[3:5], 16),
+            int(color[5:7], 16),
+            int(color[7:9], 16),
+        )
+
+    m = re.match(r"rgb\(\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*\)$", color)
+    if m:
+        return (int(m.group(1)), int(m.group(2)), int(m.group(3)))
+
+    m = re.match(r"rgb\(\s*(\d+)%\s*,\s*(\d+)%\s*,\s*(\d+)%\s*\)$", color)
+    if m:
+        return (
+            int((int(m.group(1)) * 255) / 100.0 + 0.5),
+            int((int(m.group(2)) * 255) / 100.0 + 0.5),
+            int((int(m.group(3)) * 255) / 100.0 + 0.5),
+        )
+
+    m = re.match(
+        r"hsl\(\s*(\d+\.?\d*)\s*,\s*(\d+\.?\d*)%\s*,\s*(\d+\.?\d*)%\s*\)$", color
+    )
+    if m:
+        from colorsys import hls_to_rgb
+
+        rgb = hls_to_rgb(
+            float(m.group(1)) / 360.0,
+            float(m.group(3)) / 100.0,
+            float(m.group(2)) / 100.0,
+        )
+        return (
+            int(rgb[0] * 255 + 0.5),
+            int(rgb[1] * 255 + 0.5),
+            int(rgb[2] * 255 + 0.5),
+        )
+
+    m = re.match(
+        r"hs[bv]\(\s*(\d+\.?\d*)\s*,\s*(\d+\.?\d*)%\s*,\s*(\d+\.?\d*)%\s*\)$", color
+    )
+    if m:
+        from colorsys import hsv_to_rgb
+
+        rgb = hsv_to_rgb(
+            float(m.group(1)) / 360.0,
+            float(m.group(2)) / 100.0,
+            float(m.group(3)) / 100.0,
+        )
+        return (
+            int(rgb[0] * 255 + 0.5),
+            int(rgb[1] * 255 + 0.5),
+            int(rgb[2] * 255 + 0.5),
+        )
+
+    m = re.match(r"rgba\(\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*\)$", color)
+    if m:
+        return (int(m.group(1)), int(m.group(2)), int(m.group(3)), int(m.group(4)))
+    raise ValueError(f"unknown color specifier: {repr(color)}")
+
+
+def getcolor(color, mode):
+    """
+    Same as :py:func:`~PIL.ImageColor.getrgb`, but converts the RGB value to a
+    greyscale value if the mode is not color or a palette image. If the string
+    cannot be parsed, this function raises a :py:exc:`ValueError` exception.
+
+    .. versionadded:: 1.1.4
+
+    :param color: A color string
+    :return: ``(graylevel [, alpha]) or (red, green, blue[, alpha])``
+    """
+    # same as getrgb, but converts the result to the given mode
+    color, alpha = getrgb(color), 255
+    if len(color) == 4:
+        color, alpha = color[0:3], color[3]
+
+    if Image.getmodebase(mode) == "L":
+        r, g, b = color
+        # ITU-R Recommendation 601-2 for nonlinear RGB
+        # scaled to 24 bits to match the convert's implementation.
+        color = (r * 19595 + g * 38470 + b * 7471 + 0x8000) >> 16
+        if mode[-1] == "A":
+            return (color, alpha)
+    else:
+        if mode[-1] == "A":
+            return color + (alpha,)
+    return color
+
+
+colormap = {
+    # X11 colour table from https://drafts.csswg.org/css-color-4/, with
+    # gray/grey spelling issues fixed.  This is a superset of HTML 4.0
+    # colour names used in CSS 1.
+    "aliceblue": "#f0f8ff",
+    "antiquewhite": "#faebd7",
+    "aqua": "#00ffff",
+    "aquamarine": "#7fffd4",
+    "azure": "#f0ffff",
+    "beige": "#f5f5dc",
+    "bisque": "#ffe4c4",
+    "black": "#000000",
+    "blanchedalmond": "#ffebcd",
+    "blue": "#0000ff",
+    "blueviolet": "#8a2be2",
+    "brown": "#a52a2a",
+    "burlywood": "#deb887",
+    "cadetblue": "#5f9ea0",
+    "chartreuse": "#7fff00",
+    "chocolate": "#d2691e",
+    "coral": "#ff7f50",
+    "cornflowerblue": "#6495ed",
+    "cornsilk": "#fff8dc",
+    "crimson": "#dc143c",
+    "cyan": "#00ffff",
+    "darkblue": "#00008b",
+    "darkcyan": "#008b8b",
+    "darkgoldenrod": "#b8860b",
+    "darkgray": "#a9a9a9",
+    "darkgrey": "#a9a9a9",
+    "darkgreen": "#006400",
+    "darkkhaki": "#bdb76b",
+    "darkmagenta": "#8b008b",
+    "darkolivegreen": "#556b2f",
+    "darkorange": "#ff8c00",
+    "darkorchid": "#9932cc",
+    "darkred": "#8b0000",
+    "darksalmon": "#e9967a",
+    "darkseagreen": "#8fbc8f",
+    "darkslateblue": "#483d8b",
+    "darkslategray": "#2f4f4f",
+    "darkslategrey": "#2f4f4f",
+    "darkturquoise": "#00ced1",
+    "darkviolet": "#9400d3",
+    "deeppink": "#ff1493",
+    "deepskyblue": "#00bfff",
+    "dimgray": "#696969",
+    "dimgrey": "#696969",
+    "dodgerblue": "#1e90ff",
+    "firebrick": "#b22222",
+    "floralwhite": "#fffaf0",
+    "forestgreen": "#228b22",
+    "fuchsia": "#ff00ff",
+    "gainsboro": "#dcdcdc",
+    "ghostwhite": "#f8f8ff",
+    "gold": "#ffd700",
+    "goldenrod": "#daa520",
+    "gray": "#808080",
+    "grey": "#808080",
+    "green": "#008000",
+    "greenyellow": "#adff2f",
+    "honeydew": "#f0fff0",
+    "hotpink": "#ff69b4",
+    "indianred": "#cd5c5c",
+    "indigo": "#4b0082",
+    "ivory": "#fffff0",
+    "khaki": "#f0e68c",
+    "lavender": "#e6e6fa",
+    "lavenderblush": "#fff0f5",
+    "lawngreen": "#7cfc00",
+    "lemonchiffon": "#fffacd",
+    "lightblue": "#add8e6",
+    "lightcoral": "#f08080",
+    "lightcyan": "#e0ffff",
+    "lightgoldenrodyellow": "#fafad2",
+    "lightgreen": "#90ee90",
+    "lightgray": "#d3d3d3",
+    "lightgrey": "#d3d3d3",
+    "lightpink": "#ffb6c1",
+    "lightsalmon": "#ffa07a",
+    "lightseagreen": "#20b2aa",
+    "lightskyblue": "#87cefa",
+    "lightslategray": "#778899",
+    "lightslategrey": "#778899",
+    "lightsteelblue": "#b0c4de",
+    "lightyellow": "#ffffe0",
+    "lime": "#00ff00",
+    "limegreen": "#32cd32",
+    "linen": "#faf0e6",
+    "magenta": "#ff00ff",
+    "maroon": "#800000",
+    "mediumaquamarine": "#66cdaa",
+    "mediumblue": "#0000cd",
+    "mediumorchid": "#ba55d3",
+    "mediumpurple": "#9370db",
+    "mediumseagreen": "#3cb371",
+    "mediumslateblue": "#7b68ee",
+    "mediumspringgreen": "#00fa9a",
+    "mediumturquoise": "#48d1cc",
+    "mediumvioletred": "#c71585",
+    "midnightblue": "#191970",
+    "mintcream": "#f5fffa",
+    "mistyrose": "#ffe4e1",
+    "moccasin": "#ffe4b5",
+    "navajowhite": "#ffdead",
+    "navy": "#000080",
+    "oldlace": "#fdf5e6",
+    "olive": "#808000",
+    "olivedrab": "#6b8e23",
+    "orange": "#ffa500",
+    "orangered": "#ff4500",
+    "orchid": "#da70d6",
+    "palegoldenrod": "#eee8aa",
+    "palegreen": "#98fb98",
+    "paleturquoise": "#afeeee",
+    "palevioletred": "#db7093",
+    "papayawhip": "#ffefd5",
+    "peachpuff": "#ffdab9",
+    "peru": "#cd853f",
+    "pink": "#ffc0cb",
+    "plum": "#dda0dd",
+    "powderblue": "#b0e0e6",
+    "purple": "#800080",
+    "rebeccapurple": "#663399",
+    "red": "#ff0000",
+    "rosybrown": "#bc8f8f",
+    "royalblue": "#4169e1",
+    "saddlebrown": "#8b4513",
+    "salmon": "#fa8072",
+    "sandybrown": "#f4a460",
+    "seagreen": "#2e8b57",
+    "seashell": "#fff5ee",
+    "sienna": "#a0522d",
+    "silver": "#c0c0c0",
+    "skyblue": "#87ceeb",
+    "slateblue": "#6a5acd",
+    "slategray": "#708090",
+    "slategrey": "#708090",
+    "snow": "#fffafa",
+    "springgreen": "#00ff7f",
+    "steelblue": "#4682b4",
+    "tan": "#d2b48c",
+    "teal": "#008080",
+    "thistle": "#d8bfd8",
+    "tomato": "#ff6347",
+    "turquoise": "#40e0d0",
+    "violet": "#ee82ee",
+    "wheat": "#f5deb3",
+    "white": "#ffffff",
+    "whitesmoke": "#f5f5f5",
+    "yellow": "#ffff00",
+    "yellowgreen": "#9acd32",
+}
diff --git a/.venv/lib/python3.7/site-packages/PIL/ImageDraw.py b/.venv/lib/python3.7/site-packages/PIL/ImageDraw.py
new file mode 100644
index 0000000..610ccd4
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ImageDraw.py
@@ -0,0 +1,1004 @@
+#
+# The Python Imaging Library
+# $Id$
+#
+# drawing interface operations
+#
+# History:
+# 1996-04-13 fl   Created (experimental)
+# 1996-08-07 fl   Filled polygons, ellipses.
+# 1996-08-13 fl   Added text support
+# 1998-06-28 fl   Handle I and F images
+# 1998-12-29 fl   Added arc; use arc primitive to draw ellipses
+# 1999-01-10 fl   Added shape stuff (experimental)
+# 1999-02-06 fl   Added bitmap support
+# 1999-02-11 fl   Changed all primitives to take options
+# 1999-02-20 fl   Fixed backwards compatibility
+# 2000-10-12 fl   Copy on write, when necessary
+# 2001-02-18 fl   Use default ink for bitmap/text also in fill mode
+# 2002-10-24 fl   Added support for CSS-style color strings
+# 2002-12-10 fl   Added experimental support for RGBA-on-RGB drawing
+# 2002-12-11 fl   Refactored low-level drawing API (work in progress)
+# 2004-08-26 fl   Made Draw() a factory function, added getdraw() support
+# 2004-09-04 fl   Added width support to line primitive
+# 2004-09-10 fl   Added font mode handling
+# 2006-06-19 fl   Added font bearing support (getmask2)
+#
+# Copyright (c) 1997-2006 by Secret Labs AB
+# Copyright (c) 1996-2006 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+import math
+import numbers
+
+from . import Image, ImageColor, ImageFont
+
+"""
+A simple 2D drawing interface for PIL images.
+<p>
+Application code should use the <b>Draw</b> factory, instead of
+directly.
+"""
+
+
+class ImageDraw:
+    def __init__(self, im, mode=None):
+        """
+        Create a drawing instance.
+
+        :param im: The image to draw in.
+        :param mode: Optional mode to use for color values.  For RGB
+           images, this argument can be RGB or RGBA (to blend the
+           drawing into the image).  For all other modes, this argument
+           must be the same as the image mode.  If omitted, the mode
+           defaults to the mode of the image.
+        """
+        im.load()
+        if im.readonly:
+            im._copy()  # make it writeable
+        blend = 0
+        if mode is None:
+            mode = im.mode
+        if mode != im.mode:
+            if mode == "RGBA" and im.mode == "RGB":
+                blend = 1
+            else:
+                raise ValueError("mode mismatch")
+        if mode == "P":
+            self.palette = im.palette
+        else:
+            self.palette = None
+        self._image = im
+        self.im = im.im
+        self.draw = Image.core.draw(self.im, blend)
+        self.mode = mode
+        if mode in ("I", "F"):
+            self.ink = self.draw.draw_ink(1)
+        else:
+            self.ink = self.draw.draw_ink(-1)
+        if mode in ("1", "P", "I", "F"):
+            # FIXME: fix Fill2 to properly support matte for I+F images
+            self.fontmode = "1"
+        else:
+            self.fontmode = "L"  # aliasing is okay for other modes
+        self.fill = 0
+        self.font = None
+
+    def getfont(self):
+        """
+        Get the current default font.
+
+        :returns: An image font."""
+        if not self.font:
+            # FIXME: should add a font repository
+            from . import ImageFont
+
+            self.font = ImageFont.load_default()
+        return self.font
+
+    def _getink(self, ink, fill=None):
+        if ink is None and fill is None:
+            if self.fill:
+                fill = self.ink
+            else:
+                ink = self.ink
+        else:
+            if ink is not None:
+                if isinstance(ink, str):
+                    ink = ImageColor.getcolor(ink, self.mode)
+                if self.palette and not isinstance(ink, numbers.Number):
+                    ink = self.palette.getcolor(ink, self._image)
+                ink = self.draw.draw_ink(ink)
+            if fill is not None:
+                if isinstance(fill, str):
+                    fill = ImageColor.getcolor(fill, self.mode)
+                if self.palette and not isinstance(fill, numbers.Number):
+                    fill = self.palette.getcolor(fill, self._image)
+                fill = self.draw.draw_ink(fill)
+        return ink, fill
+
+    def arc(self, xy, start, end, fill=None, width=1):
+        """Draw an arc."""
+        ink, fill = self._getink(fill)
+        if ink is not None:
+            self.draw.draw_arc(xy, start, end, ink, width)
+
+    def bitmap(self, xy, bitmap, fill=None):
+        """Draw a bitmap."""
+        bitmap.load()
+        ink, fill = self._getink(fill)
+        if ink is None:
+            ink = fill
+        if ink is not None:
+            self.draw.draw_bitmap(xy, bitmap.im, ink)
+
+    def chord(self, xy, start, end, fill=None, outline=None, width=1):
+        """Draw a chord."""
+        ink, fill = self._getink(outline, fill)
+        if fill is not None:
+            self.draw.draw_chord(xy, start, end, fill, 1)
+        if ink is not None and ink != fill and width != 0:
+            self.draw.draw_chord(xy, start, end, ink, 0, width)
+
+    def ellipse(self, xy, fill=None, outline=None, width=1):
+        """Draw an ellipse."""
+        ink, fill = self._getink(outline, fill)
+        if fill is not None:
+            self.draw.draw_ellipse(xy, fill, 1)
+        if ink is not None and ink != fill and width != 0:
+            self.draw.draw_ellipse(xy, ink, 0, width)
+
+    def line(self, xy, fill=None, width=0, joint=None):
+        """Draw a line, or a connected sequence of line segments."""
+        ink = self._getink(fill)[0]
+        if ink is not None:
+            self.draw.draw_lines(xy, ink, width)
+            if joint == "curve" and width > 4:
+                if not isinstance(xy[0], (list, tuple)):
+                    xy = [tuple(xy[i : i + 2]) for i in range(0, len(xy), 2)]
+                for i in range(1, len(xy) - 1):
+                    point = xy[i]
+                    angles = [
+                        math.degrees(math.atan2(end[0] - start[0], start[1] - end[1]))
+                        % 360
+                        for start, end in ((xy[i - 1], point), (point, xy[i + 1]))
+                    ]
+                    if angles[0] == angles[1]:
+                        # This is a straight line, so no joint is required
+                        continue
+
+                    def coord_at_angle(coord, angle):
+                        x, y = coord
+                        angle -= 90
+                        distance = width / 2 - 1
+                        return tuple(
+                            p + (math.floor(p_d) if p_d > 0 else math.ceil(p_d))
+                            for p, p_d in (
+                                (x, distance * math.cos(math.radians(angle))),
+                                (y, distance * math.sin(math.radians(angle))),
+                            )
+                        )
+
+                    flipped = (
+                        angles[1] > angles[0] and angles[1] - 180 > angles[0]
+                    ) or (angles[1] < angles[0] and angles[1] + 180 > angles[0])
+                    coords = [
+                        (point[0] - width / 2 + 1, point[1] - width / 2 + 1),
+                        (point[0] + width / 2 - 1, point[1] + width / 2 - 1),
+                    ]
+                    if flipped:
+                        start, end = (angles[1] + 90, angles[0] + 90)
+                    else:
+                        start, end = (angles[0] - 90, angles[1] - 90)
+                    self.pieslice(coords, start - 90, end - 90, fill)
+
+                    if width > 8:
+                        # Cover potential gaps between the line and the joint
+                        if flipped:
+                            gapCoords = [
+                                coord_at_angle(point, angles[0] + 90),
+                                point,
+                                coord_at_angle(point, angles[1] + 90),
+                            ]
+                        else:
+                            gapCoords = [
+                                coord_at_angle(point, angles[0] - 90),
+                                point,
+                                coord_at_angle(point, angles[1] - 90),
+                            ]
+                        self.line(gapCoords, fill, width=3)
+
+    def shape(self, shape, fill=None, outline=None):
+        """(Experimental) Draw a shape."""
+        shape.close()
+        ink, fill = self._getink(outline, fill)
+        if fill is not None:
+            self.draw.draw_outline(shape, fill, 1)
+        if ink is not None and ink != fill:
+            self.draw.draw_outline(shape, ink, 0)
+
+    def pieslice(self, xy, start, end, fill=None, outline=None, width=1):
+        """Draw a pieslice."""
+        ink, fill = self._getink(outline, fill)
+        if fill is not None:
+            self.draw.draw_pieslice(xy, start, end, fill, 1)
+        if ink is not None and ink != fill and width != 0:
+            self.draw.draw_pieslice(xy, start, end, ink, 0, width)
+
+    def point(self, xy, fill=None):
+        """Draw one or more individual pixels."""
+        ink, fill = self._getink(fill)
+        if ink is not None:
+            self.draw.draw_points(xy, ink)
+
+    def polygon(self, xy, fill=None, outline=None, width=1):
+        """Draw a polygon."""
+        ink, fill = self._getink(outline, fill)
+        if fill is not None:
+            self.draw.draw_polygon(xy, fill, 1)
+        if ink is not None and ink != fill and width != 0:
+            if width == 1:
+                self.draw.draw_polygon(xy, ink, 0, width)
+            else:
+                # To avoid expanding the polygon outwards,
+                # use the fill as a mask
+                mask = Image.new("1", self.im.size)
+                mask_ink = self._getink(1)[0]
+
+                fill_im = mask.copy()
+                draw = Draw(fill_im)
+                draw.draw.draw_polygon(xy, mask_ink, 1)
+
+                ink_im = mask.copy()
+                draw = Draw(ink_im)
+                width = width * 2 - 1
+                draw.draw.draw_polygon(xy, mask_ink, 0, width)
+
+                mask.paste(ink_im, mask=fill_im)
+
+                im = Image.new(self.mode, self.im.size)
+                draw = Draw(im)
+                draw.draw.draw_polygon(xy, ink, 0, width)
+                self.im.paste(im.im, (0, 0) + im.size, mask.im)
+
+    def regular_polygon(
+        self, bounding_circle, n_sides, rotation=0, fill=None, outline=None
+    ):
+        """Draw a regular polygon."""
+        xy = _compute_regular_polygon_vertices(bounding_circle, n_sides, rotation)
+        self.polygon(xy, fill, outline)
+
+    def rectangle(self, xy, fill=None, outline=None, width=1):
+        """Draw a rectangle."""
+        ink, fill = self._getink(outline, fill)
+        if fill is not None:
+            self.draw.draw_rectangle(xy, fill, 1)
+        if ink is not None and ink != fill and width != 0:
+            self.draw.draw_rectangle(xy, ink, 0, width)
+
+    def rounded_rectangle(self, xy, radius=0, fill=None, outline=None, width=1):
+        """Draw a rounded rectangle."""
+        if isinstance(xy[0], (list, tuple)):
+            (x0, y0), (x1, y1) = xy
+        else:
+            x0, y0, x1, y1 = xy
+
+        d = radius * 2
+
+        full_x = d >= x1 - x0
+        if full_x:
+            # The two left and two right corners are joined
+            d = x1 - x0
+        full_y = d >= y1 - y0
+        if full_y:
+            # The two top and two bottom corners are joined
+            d = y1 - y0
+        if full_x and full_y:
+            # If all corners are joined, that is a circle
+            return self.ellipse(xy, fill, outline, width)
+
+        if d == 0:
+            # If the corners have no curve, that is a rectangle
+            return self.rectangle(xy, fill, outline, width)
+
+        r = d // 2
+        ink, fill = self._getink(outline, fill)
+
+        def draw_corners(pieslice):
+            if full_x:
+                # Draw top and bottom halves
+                parts = (
+                    ((x0, y0, x0 + d, y0 + d), 180, 360),
+                    ((x0, y1 - d, x0 + d, y1), 0, 180),
+                )
+            elif full_y:
+                # Draw left and right halves
+                parts = (
+                    ((x0, y0, x0 + d, y0 + d), 90, 270),
+                    ((x1 - d, y0, x1, y0 + d), 270, 90),
+                )
+            else:
+                # Draw four separate corners
+                parts = (
+                    ((x1 - d, y0, x1, y0 + d), 270, 360),
+                    ((x1 - d, y1 - d, x1, y1), 0, 90),
+                    ((x0, y1 - d, x0 + d, y1), 90, 180),
+                    ((x0, y0, x0 + d, y0 + d), 180, 270),
+                )
+            for part in parts:
+                if pieslice:
+                    self.draw.draw_pieslice(*(part + (fill, 1)))
+                else:
+                    self.draw.draw_arc(*(part + (ink, width)))
+
+        if fill is not None:
+            draw_corners(True)
+
+            if full_x:
+                self.draw.draw_rectangle((x0, y0 + r + 1, x1, y1 - r - 1), fill, 1)
+            else:
+                self.draw.draw_rectangle((x0 + r + 1, y0, x1 - r - 1, y1), fill, 1)
+            if not full_x and not full_y:
+                self.draw.draw_rectangle((x0, y0 + r + 1, x0 + r, y1 - r - 1), fill, 1)
+                self.draw.draw_rectangle((x1 - r, y0 + r + 1, x1, y1 - r - 1), fill, 1)
+        if ink is not None and ink != fill and width != 0:
+            draw_corners(False)
+
+            if not full_x:
+                self.draw.draw_rectangle(
+                    (x0 + r + 1, y0, x1 - r - 1, y0 + width - 1), ink, 1
+                )
+                self.draw.draw_rectangle(
+                    (x0 + r + 1, y1 - width + 1, x1 - r - 1, y1), ink, 1
+                )
+            if not full_y:
+                self.draw.draw_rectangle(
+                    (x0, y0 + r + 1, x0 + width - 1, y1 - r - 1), ink, 1
+                )
+                self.draw.draw_rectangle(
+                    (x1 - width + 1, y0 + r + 1, x1, y1 - r - 1), ink, 1
+                )
+
+    def _multiline_check(self, text):
+        """Draw text."""
+        split_character = "\n" if isinstance(text, str) else b"\n"
+
+        return split_character in text
+
+    def _multiline_split(self, text):
+        split_character = "\n" if isinstance(text, str) else b"\n"
+
+        return text.split(split_character)
+
+    def text(
+        self,
+        xy,
+        text,
+        fill=None,
+        font=None,
+        anchor=None,
+        spacing=4,
+        align="left",
+        direction=None,
+        features=None,
+        language=None,
+        stroke_width=0,
+        stroke_fill=None,
+        embedded_color=False,
+        *args,
+        **kwargs,
+    ):
+        if self._multiline_check(text):
+            return self.multiline_text(
+                xy,
+                text,
+                fill,
+                font,
+                anchor,
+                spacing,
+                align,
+                direction,
+                features,
+                language,
+                stroke_width,
+                stroke_fill,
+                embedded_color,
+            )
+
+        if embedded_color and self.mode not in ("RGB", "RGBA"):
+            raise ValueError("Embedded color supported only in RGB and RGBA modes")
+
+        if font is None:
+            font = self.getfont()
+
+        def getink(fill):
+            ink, fill = self._getink(fill)
+            if ink is None:
+                return fill
+            return ink
+
+        def draw_text(ink, stroke_width=0, stroke_offset=None):
+            mode = self.fontmode
+            if stroke_width == 0 and embedded_color:
+                mode = "RGBA"
+            coord = xy
+            try:
+                mask, offset = font.getmask2(
+                    text,
+                    mode,
+                    direction=direction,
+                    features=features,
+                    language=language,
+                    stroke_width=stroke_width,
+                    anchor=anchor,
+                    ink=ink,
+                    *args,
+                    **kwargs,
+                )
+                coord = coord[0] + offset[0], coord[1] + offset[1]
+            except AttributeError:
+                try:
+                    mask = font.getmask(
+                        text,
+                        mode,
+                        direction,
+                        features,
+                        language,
+                        stroke_width,
+                        anchor,
+                        ink,
+                        *args,
+                        **kwargs,
+                    )
+                except TypeError:
+                    mask = font.getmask(text)
+            if stroke_offset:
+                coord = coord[0] + stroke_offset[0], coord[1] + stroke_offset[1]
+            if mode == "RGBA":
+                # font.getmask2(mode="RGBA") returns color in RGB bands and mask in A
+                # extract mask and set text alpha
+                color, mask = mask, mask.getband(3)
+                color.fillband(3, (ink >> 24) & 0xFF)
+                coord2 = coord[0] + mask.size[0], coord[1] + mask.size[1]
+                self.im.paste(color, coord + coord2, mask)
+            else:
+                self.draw.draw_bitmap(coord, mask, ink)
+
+        ink = getink(fill)
+        if ink is not None:
+            stroke_ink = None
+            if stroke_width:
+                stroke_ink = getink(stroke_fill) if stroke_fill is not None else ink
+
+            if stroke_ink is not None:
+                # Draw stroked text
+                draw_text(stroke_ink, stroke_width)
+
+                # Draw normal text
+                draw_text(ink, 0)
+            else:
+                # Only draw normal text
+                draw_text(ink)
+
+    def multiline_text(
+        self,
+        xy,
+        text,
+        fill=None,
+        font=None,
+        anchor=None,
+        spacing=4,
+        align="left",
+        direction=None,
+        features=None,
+        language=None,
+        stroke_width=0,
+        stroke_fill=None,
+        embedded_color=False,
+    ):
+        if direction == "ttb":
+            raise ValueError("ttb direction is unsupported for multiline text")
+
+        if anchor is None:
+            anchor = "la"
+        elif len(anchor) != 2:
+            raise ValueError("anchor must be a 2 character string")
+        elif anchor[1] in "tb":
+            raise ValueError("anchor not supported for multiline text")
+
+        widths = []
+        max_width = 0
+        lines = self._multiline_split(text)
+        line_spacing = (
+            self.textsize("A", font=font, stroke_width=stroke_width)[1] + spacing
+        )
+        for line in lines:
+            line_width = self.textlength(
+                line, font, direction=direction, features=features, language=language
+            )
+            widths.append(line_width)
+            max_width = max(max_width, line_width)
+
+        top = xy[1]
+        if anchor[1] == "m":
+            top -= (len(lines) - 1) * line_spacing / 2.0
+        elif anchor[1] == "d":
+            top -= (len(lines) - 1) * line_spacing
+
+        for idx, line in enumerate(lines):
+            left = xy[0]
+            width_difference = max_width - widths[idx]
+
+            # first align left by anchor
+            if anchor[0] == "m":
+                left -= width_difference / 2.0
+            elif anchor[0] == "r":
+                left -= width_difference
+
+            # then align by align parameter
+            if align == "left":
+                pass
+            elif align == "center":
+                left += width_difference / 2.0
+            elif align == "right":
+                left += width_difference
+            else:
+                raise ValueError('align must be "left", "center" or "right"')
+
+            self.text(
+                (left, top),
+                line,
+                fill,
+                font,
+                anchor,
+                direction=direction,
+                features=features,
+                language=language,
+                stroke_width=stroke_width,
+                stroke_fill=stroke_fill,
+                embedded_color=embedded_color,
+            )
+            top += line_spacing
+
+    def textsize(
+        self,
+        text,
+        font=None,
+        spacing=4,
+        direction=None,
+        features=None,
+        language=None,
+        stroke_width=0,
+    ):
+        """Get the size of a given string, in pixels."""
+        if self._multiline_check(text):
+            return self.multiline_textsize(
+                text, font, spacing, direction, features, language, stroke_width
+            )
+
+        if font is None:
+            font = self.getfont()
+        return font.getsize(text, direction, features, language, stroke_width)
+
+    def multiline_textsize(
+        self,
+        text,
+        font=None,
+        spacing=4,
+        direction=None,
+        features=None,
+        language=None,
+        stroke_width=0,
+    ):
+        max_width = 0
+        lines = self._multiline_split(text)
+        line_spacing = (
+            self.textsize("A", font=font, stroke_width=stroke_width)[1] + spacing
+        )
+        for line in lines:
+            line_width, line_height = self.textsize(
+                line, font, spacing, direction, features, language, stroke_width
+            )
+            max_width = max(max_width, line_width)
+        return max_width, len(lines) * line_spacing - spacing
+
+    def textlength(
+        self,
+        text,
+        font=None,
+        direction=None,
+        features=None,
+        language=None,
+        embedded_color=False,
+    ):
+        """Get the length of a given string, in pixels with 1/64 precision."""
+        if self._multiline_check(text):
+            raise ValueError("can't measure length of multiline text")
+        if embedded_color and self.mode not in ("RGB", "RGBA"):
+            raise ValueError("Embedded color supported only in RGB and RGBA modes")
+
+        if font is None:
+            font = self.getfont()
+        mode = "RGBA" if embedded_color else self.fontmode
+        try:
+            return font.getlength(text, mode, direction, features, language)
+        except AttributeError:
+            size = self.textsize(
+                text, font, direction=direction, features=features, language=language
+            )
+            if direction == "ttb":
+                return size[1]
+            return size[0]
+
+    def textbbox(
+        self,
+        xy,
+        text,
+        font=None,
+        anchor=None,
+        spacing=4,
+        align="left",
+        direction=None,
+        features=None,
+        language=None,
+        stroke_width=0,
+        embedded_color=False,
+    ):
+        """Get the bounding box of a given string, in pixels."""
+        if embedded_color and self.mode not in ("RGB", "RGBA"):
+            raise ValueError("Embedded color supported only in RGB and RGBA modes")
+
+        if self._multiline_check(text):
+            return self.multiline_textbbox(
+                xy,
+                text,
+                font,
+                anchor,
+                spacing,
+                align,
+                direction,
+                features,
+                language,
+                stroke_width,
+                embedded_color,
+            )
+
+        if font is None:
+            font = self.getfont()
+        if not isinstance(font, ImageFont.FreeTypeFont):
+            raise ValueError("Only supported for TrueType fonts")
+        mode = "RGBA" if embedded_color else self.fontmode
+        bbox = font.getbbox(
+            text, mode, direction, features, language, stroke_width, anchor
+        )
+        return bbox[0] + xy[0], bbox[1] + xy[1], bbox[2] + xy[0], bbox[3] + xy[1]
+
+    def multiline_textbbox(
+        self,
+        xy,
+        text,
+        font=None,
+        anchor=None,
+        spacing=4,
+        align="left",
+        direction=None,
+        features=None,
+        language=None,
+        stroke_width=0,
+        embedded_color=False,
+    ):
+        if direction == "ttb":
+            raise ValueError("ttb direction is unsupported for multiline text")
+
+        if anchor is None:
+            anchor = "la"
+        elif len(anchor) != 2:
+            raise ValueError("anchor must be a 2 character string")
+        elif anchor[1] in "tb":
+            raise ValueError("anchor not supported for multiline text")
+
+        widths = []
+        max_width = 0
+        lines = self._multiline_split(text)
+        line_spacing = (
+            self.textsize("A", font=font, stroke_width=stroke_width)[1] + spacing
+        )
+        for line in lines:
+            line_width = self.textlength(
+                line,
+                font,
+                direction=direction,
+                features=features,
+                language=language,
+                embedded_color=embedded_color,
+            )
+            widths.append(line_width)
+            max_width = max(max_width, line_width)
+
+        top = xy[1]
+        if anchor[1] == "m":
+            top -= (len(lines) - 1) * line_spacing / 2.0
+        elif anchor[1] == "d":
+            top -= (len(lines) - 1) * line_spacing
+
+        bbox = None
+
+        for idx, line in enumerate(lines):
+            left = xy[0]
+            width_difference = max_width - widths[idx]
+
+            # first align left by anchor
+            if anchor[0] == "m":
+                left -= width_difference / 2.0
+            elif anchor[0] == "r":
+                left -= width_difference
+
+            # then align by align parameter
+            if align == "left":
+                pass
+            elif align == "center":
+                left += width_difference / 2.0
+            elif align == "right":
+                left += width_difference
+            else:
+                raise ValueError('align must be "left", "center" or "right"')
+
+            bbox_line = self.textbbox(
+                (left, top),
+                line,
+                font,
+                anchor,
+                direction=direction,
+                features=features,
+                language=language,
+                stroke_width=stroke_width,
+                embedded_color=embedded_color,
+            )
+            if bbox is None:
+                bbox = bbox_line
+            else:
+                bbox = (
+                    min(bbox[0], bbox_line[0]),
+                    min(bbox[1], bbox_line[1]),
+                    max(bbox[2], bbox_line[2]),
+                    max(bbox[3], bbox_line[3]),
+                )
+
+            top += line_spacing
+
+        if bbox is None:
+            return xy[0], xy[1], xy[0], xy[1]
+        return bbox
+
+
+def Draw(im, mode=None):
+    """
+    A simple 2D drawing interface for PIL images.
+
+    :param im: The image to draw in.
+    :param mode: Optional mode to use for color values.  For RGB
+       images, this argument can be RGB or RGBA (to blend the
+       drawing into the image).  For all other modes, this argument
+       must be the same as the image mode.  If omitted, the mode
+       defaults to the mode of the image.
+    """
+    try:
+        return im.getdraw(mode)
+    except AttributeError:
+        return ImageDraw(im, mode)
+
+
+# experimental access to the outline API
+try:
+    Outline = Image.core.outline
+except AttributeError:
+    Outline = None
+
+
+def getdraw(im=None, hints=None):
+    """
+    (Experimental) A more advanced 2D drawing interface for PIL images,
+    based on the WCK interface.
+
+    :param im: The image to draw in.
+    :param hints: An optional list of hints.
+    :returns: A (drawing context, drawing resource factory) tuple.
+    """
+    # FIXME: this needs more work!
+    # FIXME: come up with a better 'hints' scheme.
+    handler = None
+    if not hints or "nicest" in hints:
+        try:
+            from . import _imagingagg as handler
+        except ImportError:
+            pass
+    if handler is None:
+        from . import ImageDraw2 as handler
+    if im:
+        im = handler.Draw(im)
+    return im, handler
+
+
+def floodfill(image, xy, value, border=None, thresh=0):
+    """
+    (experimental) Fills a bounded region with a given color.
+
+    :param image: Target image.
+    :param xy: Seed position (a 2-item coordinate tuple). See
+        :ref:`coordinate-system`.
+    :param value: Fill color.
+    :param border: Optional border value.  If given, the region consists of
+        pixels with a color different from the border color.  If not given,
+        the region consists of pixels having the same color as the seed
+        pixel.
+    :param thresh: Optional threshold value which specifies a maximum
+        tolerable difference of a pixel value from the 'background' in
+        order for it to be replaced. Useful for filling regions of
+        non-homogeneous, but similar, colors.
+    """
+    # based on an implementation by Eric S. Raymond
+    # amended by yo1995 @20180806
+    pixel = image.load()
+    x, y = xy
+    try:
+        background = pixel[x, y]
+        if _color_diff(value, background) <= thresh:
+            return  # seed point already has fill color
+        pixel[x, y] = value
+    except (ValueError, IndexError):
+        return  # seed point outside image
+    edge = {(x, y)}
+    # use a set to keep record of current and previous edge pixels
+    # to reduce memory consumption
+    full_edge = set()
+    while edge:
+        new_edge = set()
+        for (x, y) in edge:  # 4 adjacent method
+            for (s, t) in ((x + 1, y), (x - 1, y), (x, y + 1), (x, y - 1)):
+                # If already processed, or if a coordinate is negative, skip
+                if (s, t) in full_edge or s < 0 or t < 0:
+                    continue
+                try:
+                    p = pixel[s, t]
+                except (ValueError, IndexError):
+                    pass
+                else:
+                    full_edge.add((s, t))
+                    if border is None:
+                        fill = _color_diff(p, background) <= thresh
+                    else:
+                        fill = p != value and p != border
+                    if fill:
+                        pixel[s, t] = value
+                        new_edge.add((s, t))
+        full_edge = edge  # discard pixels processed
+        edge = new_edge
+
+
+def _compute_regular_polygon_vertices(bounding_circle, n_sides, rotation):
+    """
+    Generate a list of vertices for a 2D regular polygon.
+
+    :param bounding_circle: The bounding circle is a tuple defined
+        by a point and radius. The polygon is inscribed in this circle.
+        (e.g. ``bounding_circle=(x, y, r)`` or ``((x, y), r)``)
+    :param n_sides: Number of sides
+        (e.g. ``n_sides=3`` for a triangle, ``6`` for a hexagon)
+    :param rotation: Apply an arbitrary rotation to the polygon
+        (e.g. ``rotation=90``, applies a 90 degree rotation)
+    :return: List of regular polygon vertices
+        (e.g. ``[(25, 50), (50, 50), (50, 25), (25, 25)]``)
+
+    How are the vertices computed?
+    1. Compute the following variables
+        - theta: Angle between the apothem & the nearest polygon vertex
+        - side_length: Length of each polygon edge
+        - centroid: Center of bounding circle (1st, 2nd elements of bounding_circle)
+        - polygon_radius: Polygon radius (last element of bounding_circle)
+        - angles: Location of each polygon vertex in polar grid
+            (e.g. A square with 0 degree rotation => [225.0, 315.0, 45.0, 135.0])
+
+    2. For each angle in angles, get the polygon vertex at that angle
+        The vertex is computed using the equation below.
+            X= xcos(φ) + ysin(φ)
+            Y= −xsin(φ) + ycos(φ)
+
+        Note:
+            φ = angle in degrees
+            x = 0
+            y = polygon_radius
+
+        The formula above assumes rotation around the origin.
+        In our case, we are rotating around the centroid.
+        To account for this, we use the formula below
+            X = xcos(φ) + ysin(φ) + centroid_x
+            Y = −xsin(φ) + ycos(φ) + centroid_y
+    """
+    # 1. Error Handling
+    # 1.1 Check `n_sides` has an appropriate value
+    if not isinstance(n_sides, int):
+        raise TypeError("n_sides should be an int")
+    if n_sides < 3:
+        raise ValueError("n_sides should be an int > 2")
+
+    # 1.2 Check `bounding_circle` has an appropriate value
+    if not isinstance(bounding_circle, (list, tuple)):
+        raise TypeError("bounding_circle should be a tuple")
+
+    if len(bounding_circle) == 3:
+        *centroid, polygon_radius = bounding_circle
+    elif len(bounding_circle) == 2:
+        centroid, polygon_radius = bounding_circle
+    else:
+        raise ValueError(
+            "bounding_circle should contain 2D coordinates "
+            "and a radius (e.g. (x, y, r) or ((x, y), r) )"
+        )
+
+    if not all(isinstance(i, (int, float)) for i in (*centroid, polygon_radius)):
+        raise ValueError("bounding_circle should only contain numeric data")
+
+    if not len(centroid) == 2:
+        raise ValueError(
+            "bounding_circle centre should contain 2D coordinates (e.g. (x, y))"
+        )
+
+    if polygon_radius <= 0:
+        raise ValueError("bounding_circle radius should be > 0")
+
+    # 1.3 Check `rotation` has an appropriate value
+    if not isinstance(rotation, (int, float)):
+        raise ValueError("rotation should be an int or float")
+
+    # 2. Define Helper Functions
+    def _apply_rotation(point, degrees, centroid):
+        return (
+            round(
+                point[0] * math.cos(math.radians(360 - degrees))
+                - point[1] * math.sin(math.radians(360 - degrees))
+                + centroid[0],
+                2,
+            ),
+            round(
+                point[1] * math.cos(math.radians(360 - degrees))
+                + point[0] * math.sin(math.radians(360 - degrees))
+                + centroid[1],
+                2,
+            ),
+        )
+
+    def _compute_polygon_vertex(centroid, polygon_radius, angle):
+        start_point = [polygon_radius, 0]
+        return _apply_rotation(start_point, angle, centroid)
+
+    def _get_angles(n_sides, rotation):
+        angles = []
+        degrees = 360 / n_sides
+        # Start with the bottom left polygon vertex
+        current_angle = (270 - 0.5 * degrees) + rotation
+        for _ in range(0, n_sides):
+            angles.append(current_angle)
+            current_angle += degrees
+            if current_angle > 360:
+                current_angle -= 360
+        return angles
+
+    # 3. Variable Declarations
+    angles = _get_angles(n_sides, rotation)
+
+    # 4. Compute Vertices
+    return [
+        _compute_polygon_vertex(centroid, polygon_radius, angle) for angle in angles
+    ]
+
+
+def _color_diff(color1, color2):
+    """
+    Uses 1-norm distance to calculate difference between two values.
+    """
+    if isinstance(color2, tuple):
+        return sum(abs(color1[i] - color2[i]) for i in range(0, len(color2)))
+    else:
+        return abs(color1 - color2)
diff --git a/.venv/lib/python3.7/site-packages/PIL/ImageDraw2.py b/.venv/lib/python3.7/site-packages/PIL/ImageDraw2.py
new file mode 100644
index 0000000..1f63110
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ImageDraw2.py
@@ -0,0 +1,179 @@
+#
+# The Python Imaging Library
+# $Id$
+#
+# WCK-style drawing interface operations
+#
+# History:
+# 2003-12-07 fl   created
+# 2005-05-15 fl   updated; added to PIL as ImageDraw2
+# 2005-05-15 fl   added text support
+# 2005-05-20 fl   added arc/chord/pieslice support
+#
+# Copyright (c) 2003-2005 by Secret Labs AB
+# Copyright (c) 2003-2005 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+
+"""
+(Experimental) WCK-style drawing interface operations
+
+.. seealso:: :py:mod:`PIL.ImageDraw`
+"""
+
+
+from . import Image, ImageColor, ImageDraw, ImageFont, ImagePath
+
+
+class Pen:
+    """Stores an outline color and width."""
+
+    def __init__(self, color, width=1, opacity=255):
+        self.color = ImageColor.getrgb(color)
+        self.width = width
+
+
+class Brush:
+    """Stores a fill color"""
+
+    def __init__(self, color, opacity=255):
+        self.color = ImageColor.getrgb(color)
+
+
+class Font:
+    """Stores a TrueType font and color"""
+
+    def __init__(self, color, file, size=12):
+        # FIXME: add support for bitmap fonts
+        self.color = ImageColor.getrgb(color)
+        self.font = ImageFont.truetype(file, size)
+
+
+class Draw:
+    """
+    (Experimental) WCK-style drawing interface
+    """
+
+    def __init__(self, image, size=None, color=None):
+        if not hasattr(image, "im"):
+            image = Image.new(image, size, color)
+        self.draw = ImageDraw.Draw(image)
+        self.image = image
+        self.transform = None
+
+    def flush(self):
+        return self.image
+
+    def render(self, op, xy, pen, brush=None):
+        # handle color arguments
+        outline = fill = None
+        width = 1
+        if isinstance(pen, Pen):
+            outline = pen.color
+            width = pen.width
+        elif isinstance(brush, Pen):
+            outline = brush.color
+            width = brush.width
+        if isinstance(brush, Brush):
+            fill = brush.color
+        elif isinstance(pen, Brush):
+            fill = pen.color
+        # handle transformation
+        if self.transform:
+            xy = ImagePath.Path(xy)
+            xy.transform(self.transform)
+        # render the item
+        if op == "line":
+            self.draw.line(xy, fill=outline, width=width)
+        else:
+            getattr(self.draw, op)(xy, fill=fill, outline=outline)
+
+    def settransform(self, offset):
+        """Sets a transformation offset."""
+        (xoffset, yoffset) = offset
+        self.transform = (1, 0, xoffset, 0, 1, yoffset)
+
+    def arc(self, xy, start, end, *options):
+        """
+        Draws an arc (a portion of a circle outline) between the start and end
+        angles, inside the given bounding box.
+
+        .. seealso:: :py:meth:`PIL.ImageDraw.ImageDraw.arc`
+        """
+        self.render("arc", xy, start, end, *options)
+
+    def chord(self, xy, start, end, *options):
+        """
+        Same as :py:meth:`~PIL.ImageDraw2.Draw.arc`, but connects the end points
+        with a straight line.
+
+        .. seealso:: :py:meth:`PIL.ImageDraw.ImageDraw.chord`
+        """
+        self.render("chord", xy, start, end, *options)
+
+    def ellipse(self, xy, *options):
+        """
+        Draws an ellipse inside the given bounding box.
+
+        .. seealso:: :py:meth:`PIL.ImageDraw.ImageDraw.ellipse`
+        """
+        self.render("ellipse", xy, *options)
+
+    def line(self, xy, *options):
+        """
+        Draws a line between the coordinates in the ``xy`` list.
+
+        .. seealso:: :py:meth:`PIL.ImageDraw.ImageDraw.line`
+        """
+        self.render("line", xy, *options)
+
+    def pieslice(self, xy, start, end, *options):
+        """
+        Same as arc, but also draws straight lines between the end points and the
+        center of the bounding box.
+
+        .. seealso:: :py:meth:`PIL.ImageDraw.ImageDraw.pieslice`
+        """
+        self.render("pieslice", xy, start, end, *options)
+
+    def polygon(self, xy, *options):
+        """
+        Draws a polygon.
+
+        The polygon outline consists of straight lines between the given
+        coordinates, plus a straight line between the last and the first
+        coordinate.
+
+
+        .. seealso:: :py:meth:`PIL.ImageDraw.ImageDraw.polygon`
+        """
+        self.render("polygon", xy, *options)
+
+    def rectangle(self, xy, *options):
+        """
+        Draws a rectangle.
+
+        .. seealso:: :py:meth:`PIL.ImageDraw.ImageDraw.rectangle`
+        """
+        self.render("rectangle", xy, *options)
+
+    def text(self, xy, text, font):
+        """
+        Draws the string at the given position.
+
+        .. seealso:: :py:meth:`PIL.ImageDraw.ImageDraw.text`
+        """
+        if self.transform:
+            xy = ImagePath.Path(xy)
+            xy.transform(self.transform)
+        self.draw.text(xy, text, font=font.font, fill=font.color)
+
+    def textsize(self, text, font):
+        """
+        Return the size of the given string, in pixels.
+
+        .. seealso:: :py:meth:`PIL.ImageDraw.ImageDraw.textsize`
+        """
+        return self.draw.textsize(text, font=font.font)
diff --git a/.venv/lib/python3.7/site-packages/PIL/ImageEnhance.py b/.venv/lib/python3.7/site-packages/PIL/ImageEnhance.py
new file mode 100644
index 0000000..3b79d5c
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ImageEnhance.py
@@ -0,0 +1,103 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# image enhancement classes
+#
+# For a background, see "Image Processing By Interpolation and
+# Extrapolation", Paul Haeberli and Douglas Voorhies.  Available
+# at http://www.graficaobscura.com/interp/index.html
+#
+# History:
+# 1996-03-23 fl  Created
+# 2009-06-16 fl  Fixed mean calculation
+#
+# Copyright (c) Secret Labs AB 1997.
+# Copyright (c) Fredrik Lundh 1996.
+#
+# See the README file for information on usage and redistribution.
+#
+
+from . import Image, ImageFilter, ImageStat
+
+
+class _Enhance:
+    def enhance(self, factor):
+        """
+        Returns an enhanced image.
+
+        :param factor: A floating point value controlling the enhancement.
+                       Factor 1.0 always returns a copy of the original image,
+                       lower factors mean less color (brightness, contrast,
+                       etc), and higher values more. There are no restrictions
+                       on this value.
+        :rtype: :py:class:`~PIL.Image.Image`
+        """
+        return Image.blend(self.degenerate, self.image, factor)
+
+
+class Color(_Enhance):
+    """Adjust image color balance.
+
+    This class can be used to adjust the colour balance of an image, in
+    a manner similar to the controls on a colour TV set. An enhancement
+    factor of 0.0 gives a black and white image. A factor of 1.0 gives
+    the original image.
+    """
+
+    def __init__(self, image):
+        self.image = image
+        self.intermediate_mode = "L"
+        if "A" in image.getbands():
+            self.intermediate_mode = "LA"
+
+        self.degenerate = image.convert(self.intermediate_mode).convert(image.mode)
+
+
+class Contrast(_Enhance):
+    """Adjust image contrast.
+
+    This class can be used to control the contrast of an image, similar
+    to the contrast control on a TV set. An enhancement factor of 0.0
+    gives a solid grey image. A factor of 1.0 gives the original image.
+    """
+
+    def __init__(self, image):
+        self.image = image
+        mean = int(ImageStat.Stat(image.convert("L")).mean[0] + 0.5)
+        self.degenerate = Image.new("L", image.size, mean).convert(image.mode)
+
+        if "A" in image.getbands():
+            self.degenerate.putalpha(image.getchannel("A"))
+
+
+class Brightness(_Enhance):
+    """Adjust image brightness.
+
+    This class can be used to control the brightness of an image.  An
+    enhancement factor of 0.0 gives a black image. A factor of 1.0 gives the
+    original image.
+    """
+
+    def __init__(self, image):
+        self.image = image
+        self.degenerate = Image.new(image.mode, image.size, 0)
+
+        if "A" in image.getbands():
+            self.degenerate.putalpha(image.getchannel("A"))
+
+
+class Sharpness(_Enhance):
+    """Adjust image sharpness.
+
+    This class can be used to adjust the sharpness of an image. An
+    enhancement factor of 0.0 gives a blurred image, a factor of 1.0 gives the
+    original image, and a factor of 2.0 gives a sharpened image.
+    """
+
+    def __init__(self, image):
+        self.image = image
+        self.degenerate = image.filter(ImageFilter.SMOOTH)
+
+        if "A" in image.getbands():
+            self.degenerate.putalpha(image.getchannel("A"))
diff --git a/.venv/lib/python3.7/site-packages/PIL/ImageFile.py b/.venv/lib/python3.7/site-packages/PIL/ImageFile.py
new file mode 100644
index 0000000..3374a5b
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ImageFile.py
@@ -0,0 +1,691 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# base class for image file handlers
+#
+# history:
+# 1995-09-09 fl   Created
+# 1996-03-11 fl   Fixed load mechanism.
+# 1996-04-15 fl   Added pcx/xbm decoders.
+# 1996-04-30 fl   Added encoders.
+# 1996-12-14 fl   Added load helpers
+# 1997-01-11 fl   Use encode_to_file where possible
+# 1997-08-27 fl   Flush output in _save
+# 1998-03-05 fl   Use memory mapping for some modes
+# 1999-02-04 fl   Use memory mapping also for "I;16" and "I;16B"
+# 1999-05-31 fl   Added image parser
+# 2000-10-12 fl   Set readonly flag on memory-mapped images
+# 2002-03-20 fl   Use better messages for common decoder errors
+# 2003-04-21 fl   Fall back on mmap/map_buffer if map is not available
+# 2003-10-30 fl   Added StubImageFile class
+# 2004-02-25 fl   Made incremental parser more robust
+#
+# Copyright (c) 1997-2004 by Secret Labs AB
+# Copyright (c) 1995-2004 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+import io
+import itertools
+import struct
+import sys
+
+from . import Image
+from ._util import isPath
+
+MAXBLOCK = 65536
+
+SAFEBLOCK = 1024 * 1024
+
+LOAD_TRUNCATED_IMAGES = False
+"""Whether or not to load truncated image files. User code may change this."""
+
+ERRORS = {
+    -1: "image buffer overrun error",
+    -2: "decoding error",
+    -3: "unknown error",
+    -8: "bad configuration",
+    -9: "out of memory error",
+}
+"""Dict of known error codes returned from :meth:`.PyDecoder.decode`."""
+
+
+#
+# --------------------------------------------------------------------
+# Helpers
+
+
+def raise_oserror(error):
+    try:
+        message = Image.core.getcodecstatus(error)
+    except AttributeError:
+        message = ERRORS.get(error)
+    if not message:
+        message = f"decoder error {error}"
+    raise OSError(message + " when reading image file")
+
+
+def _tilesort(t):
+    # sort on offset
+    return t[2]
+
+
+#
+# --------------------------------------------------------------------
+# ImageFile base class
+
+
+class ImageFile(Image.Image):
+    """Base class for image file format handlers."""
+
+    def __init__(self, fp=None, filename=None):
+        super().__init__()
+
+        self._min_frame = 0
+
+        self.custom_mimetype = None
+
+        self.tile = None
+        """ A list of tile descriptors, or ``None`` """
+
+        self.readonly = 1  # until we know better
+
+        self.decoderconfig = ()
+        self.decodermaxblock = MAXBLOCK
+
+        if isPath(fp):
+            # filename
+            self.fp = open(fp, "rb")
+            self.filename = fp
+            self._exclusive_fp = True
+        else:
+            # stream
+            self.fp = fp
+            self.filename = filename
+            # can be overridden
+            self._exclusive_fp = None
+
+        try:
+            try:
+                self._open()
+            except (
+                IndexError,  # end of data
+                TypeError,  # end of data (ord)
+                KeyError,  # unsupported mode
+                EOFError,  # got header but not the first frame
+                struct.error,
+            ) as v:
+                raise SyntaxError(v) from v
+
+            if not self.mode or self.size[0] <= 0:
+                raise SyntaxError("not identified by this driver")
+        except BaseException:
+            # close the file only if we have opened it this constructor
+            if self._exclusive_fp:
+                self.fp.close()
+            raise
+
+    def get_format_mimetype(self):
+        if self.custom_mimetype:
+            return self.custom_mimetype
+        if self.format is not None:
+            return Image.MIME.get(self.format.upper())
+
+    def verify(self):
+        """Check file integrity"""
+
+        # raise exception if something's wrong.  must be called
+        # directly after open, and closes file when finished.
+        if self._exclusive_fp:
+            self.fp.close()
+        self.fp = None
+
+    def load(self):
+        """Load image data based on tile list"""
+
+        if self.tile is None:
+            raise OSError("cannot load this image")
+
+        pixel = Image.Image.load(self)
+        if not self.tile:
+            return pixel
+
+        self.map = None
+        use_mmap = self.filename and len(self.tile) == 1
+        # As of pypy 2.1.0, memory mapping was failing here.
+        use_mmap = use_mmap and not hasattr(sys, "pypy_version_info")
+
+        readonly = 0
+
+        # look for read/seek overrides
+        try:
+            read = self.load_read
+            # don't use mmap if there are custom read/seek functions
+            use_mmap = False
+        except AttributeError:
+            read = self.fp.read
+
+        try:
+            seek = self.load_seek
+            use_mmap = False
+        except AttributeError:
+            seek = self.fp.seek
+
+        if use_mmap:
+            # try memory mapping
+            decoder_name, extents, offset, args = self.tile[0]
+            if (
+                decoder_name == "raw"
+                and len(args) >= 3
+                and args[0] == self.mode
+                and args[0] in Image._MAPMODES
+            ):
+                try:
+                    # use mmap, if possible
+                    import mmap
+
+                    with open(self.filename) as fp:
+                        self.map = mmap.mmap(fp.fileno(), 0, access=mmap.ACCESS_READ)
+                    self.im = Image.core.map_buffer(
+                        self.map, self.size, decoder_name, offset, args
+                    )
+                    readonly = 1
+                    # After trashing self.im,
+                    # we might need to reload the palette data.
+                    if self.palette:
+                        self.palette.dirty = 1
+                except (AttributeError, OSError, ImportError):
+                    self.map = None
+
+        self.load_prepare()
+        err_code = -3  # initialize to unknown error
+        if not self.map:
+            # sort tiles in file order
+            self.tile.sort(key=_tilesort)
+
+            try:
+                # FIXME: This is a hack to handle TIFF's JpegTables tag.
+                prefix = self.tile_prefix
+            except AttributeError:
+                prefix = b""
+
+            # Remove consecutive duplicates that only differ by their offset
+            self.tile = [
+                list(tiles)[-1]
+                for _, tiles in itertools.groupby(
+                    self.tile, lambda tile: (tile[0], tile[1], tile[3])
+                )
+            ]
+            for decoder_name, extents, offset, args in self.tile:
+                decoder = Image._getdecoder(
+                    self.mode, decoder_name, args, self.decoderconfig
+                )
+                try:
+                    seek(offset)
+                    decoder.setimage(self.im, extents)
+                    if decoder.pulls_fd:
+                        decoder.setfd(self.fp)
+                        status, err_code = decoder.decode(b"")
+                    else:
+                        b = prefix
+                        while True:
+                            try:
+                                s = read(self.decodermaxblock)
+                            except (IndexError, struct.error) as e:
+                                # truncated png/gif
+                                if LOAD_TRUNCATED_IMAGES:
+                                    break
+                                else:
+                                    raise OSError("image file is truncated") from e
+
+                            if not s:  # truncated jpeg
+                                if LOAD_TRUNCATED_IMAGES:
+                                    break
+                                else:
+                                    raise OSError(
+                                        "image file is truncated "
+                                        f"({len(b)} bytes not processed)"
+                                    )
+
+                            b = b + s
+                            n, err_code = decoder.decode(b)
+                            if n < 0:
+                                break
+                            b = b[n:]
+                finally:
+                    # Need to cleanup here to prevent leaks
+                    decoder.cleanup()
+
+        self.tile = []
+        self.readonly = readonly
+
+        self.load_end()
+
+        if self._exclusive_fp and self._close_exclusive_fp_after_loading:
+            self.fp.close()
+        self.fp = None
+
+        if not self.map and not LOAD_TRUNCATED_IMAGES and err_code < 0:
+            # still raised if decoder fails to return anything
+            raise_oserror(err_code)
+
+        return Image.Image.load(self)
+
+    def load_prepare(self):
+        # create image memory if necessary
+        if not self.im or self.im.mode != self.mode or self.im.size != self.size:
+            self.im = Image.core.new(self.mode, self.size)
+        # create palette (optional)
+        if self.mode == "P":
+            Image.Image.load(self)
+
+    def load_end(self):
+        # may be overridden
+        pass
+
+    # may be defined for contained formats
+    # def load_seek(self, pos):
+    #     pass
+
+    # may be defined for blocked formats (e.g. PNG)
+    # def load_read(self, bytes):
+    #     pass
+
+    def _seek_check(self, frame):
+        if (
+            frame < self._min_frame
+            # Only check upper limit on frames if additional seek operations
+            # are not required to do so
+            or (
+                not (hasattr(self, "_n_frames") and self._n_frames is None)
+                and frame >= self.n_frames + self._min_frame
+            )
+        ):
+            raise EOFError("attempt to seek outside sequence")
+
+        return self.tell() != frame
+
+
+class StubImageFile(ImageFile):
+    """
+    Base class for stub image loaders.
+
+    A stub loader is an image loader that can identify files of a
+    certain format, but relies on external code to load the file.
+    """
+
+    def _open(self):
+        raise NotImplementedError("StubImageFile subclass must implement _open")
+
+    def load(self):
+        loader = self._load()
+        if loader is None:
+            raise OSError(f"cannot find loader for this {self.format} file")
+        image = loader.load(self)
+        assert image is not None
+        # become the other object (!)
+        self.__class__ = image.__class__
+        self.__dict__ = image.__dict__
+
+    def _load(self):
+        """(Hook) Find actual image loader."""
+        raise NotImplementedError("StubImageFile subclass must implement _load")
+
+
+class Parser:
+    """
+    Incremental image parser.  This class implements the standard
+    feed/close consumer interface.
+    """
+
+    incremental = None
+    image = None
+    data = None
+    decoder = None
+    offset = 0
+    finished = 0
+
+    def reset(self):
+        """
+        (Consumer) Reset the parser.  Note that you can only call this
+        method immediately after you've created a parser; parser
+        instances cannot be reused.
+        """
+        assert self.data is None, "cannot reuse parsers"
+
+    def feed(self, data):
+        """
+        (Consumer) Feed data to the parser.
+
+        :param data: A string buffer.
+        :exception OSError: If the parser failed to parse the image file.
+        """
+        # collect data
+
+        if self.finished:
+            return
+
+        if self.data is None:
+            self.data = data
+        else:
+            self.data = self.data + data
+
+        # parse what we have
+        if self.decoder:
+
+            if self.offset > 0:
+                # skip header
+                skip = min(len(self.data), self.offset)
+                self.data = self.data[skip:]
+                self.offset = self.offset - skip
+                if self.offset > 0 or not self.data:
+                    return
+
+            n, e = self.decoder.decode(self.data)
+
+            if n < 0:
+                # end of stream
+                self.data = None
+                self.finished = 1
+                if e < 0:
+                    # decoding error
+                    self.image = None
+                    raise_oserror(e)
+                else:
+                    # end of image
+                    return
+            self.data = self.data[n:]
+
+        elif self.image:
+
+            # if we end up here with no decoder, this file cannot
+            # be incrementally parsed.  wait until we've gotten all
+            # available data
+            pass
+
+        else:
+
+            # attempt to open this file
+            try:
+                with io.BytesIO(self.data) as fp:
+                    im = Image.open(fp)
+            except OSError:
+                # traceback.print_exc()
+                pass  # not enough data
+            else:
+                flag = hasattr(im, "load_seek") or hasattr(im, "load_read")
+                if flag or len(im.tile) != 1:
+                    # custom load code, or multiple tiles
+                    self.decode = None
+                else:
+                    # initialize decoder
+                    im.load_prepare()
+                    d, e, o, a = im.tile[0]
+                    im.tile = []
+                    self.decoder = Image._getdecoder(im.mode, d, a, im.decoderconfig)
+                    self.decoder.setimage(im.im, e)
+
+                    # calculate decoder offset
+                    self.offset = o
+                    if self.offset <= len(self.data):
+                        self.data = self.data[self.offset :]
+                        self.offset = 0
+
+                self.image = im
+
+    def __enter__(self):
+        return self
+
+    def __exit__(self, *args):
+        self.close()
+
+    def close(self):
+        """
+        (Consumer) Close the stream.
+
+        :returns: An image object.
+        :exception OSError: If the parser failed to parse the image file either
+                            because it cannot be identified or cannot be
+                            decoded.
+        """
+        # finish decoding
+        if self.decoder:
+            # get rid of what's left in the buffers
+            self.feed(b"")
+            self.data = self.decoder = None
+            if not self.finished:
+                raise OSError("image was incomplete")
+        if not self.image:
+            raise OSError("cannot parse this image")
+        if self.data:
+            # incremental parsing not possible; reopen the file
+            # not that we have all data
+            with io.BytesIO(self.data) as fp:
+                try:
+                    self.image = Image.open(fp)
+                finally:
+                    self.image.load()
+        return self.image
+
+
+# --------------------------------------------------------------------
+
+
+def _save(im, fp, tile, bufsize=0):
+    """Helper to save image based on tile list
+
+    :param im: Image object.
+    :param fp: File object.
+    :param tile: Tile list.
+    :param bufsize: Optional buffer size
+    """
+
+    im.load()
+    if not hasattr(im, "encoderconfig"):
+        im.encoderconfig = ()
+    tile.sort(key=_tilesort)
+    # FIXME: make MAXBLOCK a configuration parameter
+    # It would be great if we could have the encoder specify what it needs
+    # But, it would need at least the image size in most cases. RawEncode is
+    # a tricky case.
+    bufsize = max(MAXBLOCK, bufsize, im.size[0] * 4)  # see RawEncode.c
+    try:
+        fh = fp.fileno()
+        fp.flush()
+    except (AttributeError, io.UnsupportedOperation) as exc:
+        # compress to Python file-compatible object
+        for e, b, o, a in tile:
+            e = Image._getencoder(im.mode, e, a, im.encoderconfig)
+            if o > 0:
+                fp.seek(o)
+            e.setimage(im.im, b)
+            if e.pushes_fd:
+                e.setfd(fp)
+                l, s = e.encode_to_pyfd()
+            else:
+                while True:
+                    l, s, d = e.encode(bufsize)
+                    fp.write(d)
+                    if s:
+                        break
+            if s < 0:
+                raise OSError(f"encoder error {s} when writing image file") from exc
+            e.cleanup()
+    else:
+        # slight speedup: compress to real file object
+        for e, b, o, a in tile:
+            e = Image._getencoder(im.mode, e, a, im.encoderconfig)
+            if o > 0:
+                fp.seek(o)
+            e.setimage(im.im, b)
+            if e.pushes_fd:
+                e.setfd(fp)
+                l, s = e.encode_to_pyfd()
+            else:
+                s = e.encode_to_file(fh, bufsize)
+            if s < 0:
+                raise OSError(f"encoder error {s} when writing image file")
+            e.cleanup()
+    if hasattr(fp, "flush"):
+        fp.flush()
+
+
+def _safe_read(fp, size):
+    """
+    Reads large blocks in a safe way.  Unlike fp.read(n), this function
+    doesn't trust the user.  If the requested size is larger than
+    SAFEBLOCK, the file is read block by block.
+
+    :param fp: File handle.  Must implement a <b>read</b> method.
+    :param size: Number of bytes to read.
+    :returns: A string containing <i>size</i> bytes of data.
+
+    Raises an OSError if the file is truncated and the read cannot be completed
+
+    """
+    if size <= 0:
+        return b""
+    if size <= SAFEBLOCK:
+        data = fp.read(size)
+        if len(data) < size:
+            raise OSError("Truncated File Read")
+        return data
+    data = []
+    remaining_size = size
+    while remaining_size > 0:
+        block = fp.read(min(remaining_size, SAFEBLOCK))
+        if not block:
+            break
+        data.append(block)
+        remaining_size -= len(block)
+    if sum(len(d) for d in data) < size:
+        raise OSError("Truncated File Read")
+    return b"".join(data)
+
+
+class PyCodecState:
+    def __init__(self):
+        self.xsize = 0
+        self.ysize = 0
+        self.xoff = 0
+        self.yoff = 0
+
+    def extents(self):
+        return (self.xoff, self.yoff, self.xoff + self.xsize, self.yoff + self.ysize)
+
+
+class PyDecoder:
+    """
+    Python implementation of a format decoder. Override this class and
+    add the decoding logic in the :meth:`decode` method.
+
+    See :ref:`Writing Your Own File Decoder in Python<file-decoders-py>`
+    """
+
+    _pulls_fd = False
+
+    def __init__(self, mode, *args):
+        self.im = None
+        self.state = PyCodecState()
+        self.fd = None
+        self.mode = mode
+        self.init(args)
+
+    def init(self, args):
+        """
+        Override to perform decoder specific initialization
+
+        :param args: Array of args items from the tile entry
+        :returns: None
+        """
+        self.args = args
+
+    @property
+    def pulls_fd(self):
+        return self._pulls_fd
+
+    def decode(self, buffer):
+        """
+        Override to perform the decoding process.
+
+        :param buffer: A bytes object with the data to be decoded.
+        :returns: A tuple of ``(bytes consumed, errcode)``.
+            If finished with decoding return <0 for the bytes consumed.
+            Err codes are from :data:`.ImageFile.ERRORS`.
+        """
+        raise NotImplementedError()
+
+    def cleanup(self):
+        """
+        Override to perform decoder specific cleanup
+
+        :returns: None
+        """
+        pass
+
+    def setfd(self, fd):
+        """
+        Called from ImageFile to set the python file-like object
+
+        :param fd: A python file-like object
+        :returns: None
+        """
+        self.fd = fd
+
+    def setimage(self, im, extents=None):
+        """
+        Called from ImageFile to set the core output image for the decoder
+
+        :param im: A core image object
+        :param extents: a 4 tuple of (x0, y0, x1, y1) defining the rectangle
+            for this tile
+        :returns: None
+        """
+
+        # following c code
+        self.im = im
+
+        if extents:
+            (x0, y0, x1, y1) = extents
+        else:
+            (x0, y0, x1, y1) = (0, 0, 0, 0)
+
+        if x0 == 0 and x1 == 0:
+            self.state.xsize, self.state.ysize = self.im.size
+        else:
+            self.state.xoff = x0
+            self.state.yoff = y0
+            self.state.xsize = x1 - x0
+            self.state.ysize = y1 - y0
+
+        if self.state.xsize <= 0 or self.state.ysize <= 0:
+            raise ValueError("Size cannot be negative")
+
+        if (
+            self.state.xsize + self.state.xoff > self.im.size[0]
+            or self.state.ysize + self.state.yoff > self.im.size[1]
+        ):
+            raise ValueError("Tile cannot extend outside image")
+
+    def set_as_raw(self, data, rawmode=None):
+        """
+        Convenience method to set the internal image from a stream of raw data
+
+        :param data: Bytes to be set
+        :param rawmode: The rawmode to be used for the decoder.
+            If not specified, it will default to the mode of the image
+        :returns: None
+        """
+
+        if not rawmode:
+            rawmode = self.mode
+        d = Image._getdecoder(self.mode, "raw", (rawmode))
+        d.setimage(self.im, self.state.extents())
+        s = d.decode(data)
+
+        if s[0] >= 0:
+            raise ValueError("not enough image data")
+        if s[1] != 0:
+            raise ValueError("cannot decode image data")
diff --git a/.venv/lib/python3.7/site-packages/PIL/ImageFilter.py b/.venv/lib/python3.7/site-packages/PIL/ImageFilter.py
new file mode 100644
index 0000000..d2ece37
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ImageFilter.py
@@ -0,0 +1,538 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# standard filters
+#
+# History:
+# 1995-11-27 fl   Created
+# 2002-06-08 fl   Added rank and mode filters
+# 2003-09-15 fl   Fixed rank calculation in rank filter; added expand call
+#
+# Copyright (c) 1997-2003 by Secret Labs AB.
+# Copyright (c) 1995-2002 by Fredrik Lundh.
+#
+# See the README file for information on usage and redistribution.
+#
+import functools
+
+
+class Filter:
+    pass
+
+
+class MultibandFilter(Filter):
+    pass
+
+
+class BuiltinFilter(MultibandFilter):
+    def filter(self, image):
+        if image.mode == "P":
+            raise ValueError("cannot filter palette images")
+        return image.filter(*self.filterargs)
+
+
+class Kernel(BuiltinFilter):
+    """
+    Create a convolution kernel.  The current version only
+    supports 3x3 and 5x5 integer and floating point kernels.
+
+    In the current version, kernels can only be applied to
+    "L" and "RGB" images.
+
+    :param size: Kernel size, given as (width, height). In the current
+                    version, this must be (3,3) or (5,5).
+    :param kernel: A sequence containing kernel weights.
+    :param scale: Scale factor. If given, the result for each pixel is
+                    divided by this value.  The default is the sum of the
+                    kernel weights.
+    :param offset: Offset. If given, this value is added to the result,
+                    after it has been divided by the scale factor.
+    """
+
+    name = "Kernel"
+
+    def __init__(self, size, kernel, scale=None, offset=0):
+        if scale is None:
+            # default scale is sum of kernel
+            scale = functools.reduce(lambda a, b: a + b, kernel)
+        if size[0] * size[1] != len(kernel):
+            raise ValueError("not enough coefficients in kernel")
+        self.filterargs = size, scale, offset, kernel
+
+
+class RankFilter(Filter):
+    """
+    Create a rank filter.  The rank filter sorts all pixels in
+    a window of the given size, and returns the ``rank``'th value.
+
+    :param size: The kernel size, in pixels.
+    :param rank: What pixel value to pick.  Use 0 for a min filter,
+                 ``size * size / 2`` for a median filter, ``size * size - 1``
+                 for a max filter, etc.
+    """
+
+    name = "Rank"
+
+    def __init__(self, size, rank):
+        self.size = size
+        self.rank = rank
+
+    def filter(self, image):
+        if image.mode == "P":
+            raise ValueError("cannot filter palette images")
+        image = image.expand(self.size // 2, self.size // 2)
+        return image.rankfilter(self.size, self.rank)
+
+
+class MedianFilter(RankFilter):
+    """
+    Create a median filter. Picks the median pixel value in a window with the
+    given size.
+
+    :param size: The kernel size, in pixels.
+    """
+
+    name = "Median"
+
+    def __init__(self, size=3):
+        self.size = size
+        self.rank = size * size // 2
+
+
+class MinFilter(RankFilter):
+    """
+    Create a min filter.  Picks the lowest pixel value in a window with the
+    given size.
+
+    :param size: The kernel size, in pixels.
+    """
+
+    name = "Min"
+
+    def __init__(self, size=3):
+        self.size = size
+        self.rank = 0
+
+
+class MaxFilter(RankFilter):
+    """
+    Create a max filter.  Picks the largest pixel value in a window with the
+    given size.
+
+    :param size: The kernel size, in pixels.
+    """
+
+    name = "Max"
+
+    def __init__(self, size=3):
+        self.size = size
+        self.rank = size * size - 1
+
+
+class ModeFilter(Filter):
+    """
+    Create a mode filter. Picks the most frequent pixel value in a box with the
+    given size.  Pixel values that occur only once or twice are ignored; if no
+    pixel value occurs more than twice, the original pixel value is preserved.
+
+    :param size: The kernel size, in pixels.
+    """
+
+    name = "Mode"
+
+    def __init__(self, size=3):
+        self.size = size
+
+    def filter(self, image):
+        return image.modefilter(self.size)
+
+
+class GaussianBlur(MultibandFilter):
+    """Blurs the image with a sequence of extended box filters, which
+    approximates a Gaussian kernel. For details on accuracy see
+    <https://www.mia.uni-saarland.de/Publications/gwosdek-ssvm11.pdf>
+
+    :param radius: Standard deviation of the Gaussian kernel.
+    """
+
+    name = "GaussianBlur"
+
+    def __init__(self, radius=2):
+        self.radius = radius
+
+    def filter(self, image):
+        return image.gaussian_blur(self.radius)
+
+
+class BoxBlur(MultibandFilter):
+    """Blurs the image by setting each pixel to the average value of the pixels
+    in a square box extending radius pixels in each direction.
+    Supports float radius of arbitrary size. Uses an optimized implementation
+    which runs in linear time relative to the size of the image
+    for any radius value.
+
+    :param radius: Size of the box in one direction. Radius 0 does not blur,
+                   returns an identical image. Radius 1 takes 1 pixel
+                   in each direction, i.e. 9 pixels in total.
+    """
+
+    name = "BoxBlur"
+
+    def __init__(self, radius):
+        self.radius = radius
+
+    def filter(self, image):
+        return image.box_blur(self.radius)
+
+
+class UnsharpMask(MultibandFilter):
+    """Unsharp mask filter.
+
+    See Wikipedia's entry on `digital unsharp masking`_ for an explanation of
+    the parameters.
+
+    :param radius: Blur Radius
+    :param percent: Unsharp strength, in percent
+    :param threshold: Threshold controls the minimum brightness change that
+      will be sharpened
+
+    .. _digital unsharp masking: https://en.wikipedia.org/wiki/Unsharp_masking#Digital_unsharp_masking
+
+    """  # noqa: E501
+
+    name = "UnsharpMask"
+
+    def __init__(self, radius=2, percent=150, threshold=3):
+        self.radius = radius
+        self.percent = percent
+        self.threshold = threshold
+
+    def filter(self, image):
+        return image.unsharp_mask(self.radius, self.percent, self.threshold)
+
+
+class BLUR(BuiltinFilter):
+    name = "Blur"
+    # fmt: off
+    filterargs = (5, 5), 16, 0, (
+        1, 1, 1, 1, 1,
+        1, 0, 0, 0, 1,
+        1, 0, 0, 0, 1,
+        1, 0, 0, 0, 1,
+        1, 1, 1, 1, 1,
+    )
+    # fmt: on
+
+
+class CONTOUR(BuiltinFilter):
+    name = "Contour"
+    # fmt: off
+    filterargs = (3, 3), 1, 255, (
+        -1, -1, -1,
+        -1,  8, -1,
+        -1, -1, -1,
+    )
+    # fmt: on
+
+
+class DETAIL(BuiltinFilter):
+    name = "Detail"
+    # fmt: off
+    filterargs = (3, 3), 6, 0, (
+        0,  -1,  0,
+        -1, 10, -1,
+        0,  -1,  0,
+    )
+    # fmt: on
+
+
+class EDGE_ENHANCE(BuiltinFilter):
+    name = "Edge-enhance"
+    # fmt: off
+    filterargs = (3, 3), 2, 0, (
+        -1, -1, -1,
+        -1, 10, -1,
+        -1, -1, -1,
+    )
+    # fmt: on
+
+
+class EDGE_ENHANCE_MORE(BuiltinFilter):
+    name = "Edge-enhance More"
+    # fmt: off
+    filterargs = (3, 3), 1, 0, (
+        -1, -1, -1,
+        -1,  9, -1,
+        -1, -1, -1,
+    )
+    # fmt: on
+
+
+class EMBOSS(BuiltinFilter):
+    name = "Emboss"
+    # fmt: off
+    filterargs = (3, 3), 1, 128, (
+        -1, 0, 0,
+        0,  1, 0,
+        0,  0, 0,
+    )
+    # fmt: on
+
+
+class FIND_EDGES(BuiltinFilter):
+    name = "Find Edges"
+    # fmt: off
+    filterargs = (3, 3), 1, 0, (
+        -1, -1, -1,
+        -1,  8, -1,
+        -1, -1, -1,
+    )
+    # fmt: on
+
+
+class SHARPEN(BuiltinFilter):
+    name = "Sharpen"
+    # fmt: off
+    filterargs = (3, 3), 16, 0, (
+        -2, -2, -2,
+        -2, 32, -2,
+        -2, -2, -2,
+    )
+    # fmt: on
+
+
+class SMOOTH(BuiltinFilter):
+    name = "Smooth"
+    # fmt: off
+    filterargs = (3, 3), 13, 0, (
+        1, 1, 1,
+        1, 5, 1,
+        1, 1, 1,
+    )
+    # fmt: on
+
+
+class SMOOTH_MORE(BuiltinFilter):
+    name = "Smooth More"
+    # fmt: off
+    filterargs = (5, 5), 100, 0, (
+        1, 1,  1, 1, 1,
+        1, 5,  5, 5, 1,
+        1, 5, 44, 5, 1,
+        1, 5,  5, 5, 1,
+        1, 1,  1, 1, 1,
+    )
+    # fmt: on
+
+
+class Color3DLUT(MultibandFilter):
+    """Three-dimensional color lookup table.
+
+    Transforms 3-channel pixels using the values of the channels as coordinates
+    in the 3D lookup table and interpolating the nearest elements.
+
+    This method allows you to apply almost any color transformation
+    in constant time by using pre-calculated decimated tables.
+
+    .. versionadded:: 5.2.0
+
+    :param size: Size of the table. One int or tuple of (int, int, int).
+                 Minimal size in any dimension is 2, maximum is 65.
+    :param table: Flat lookup table. A list of ``channels * size**3``
+                  float elements or a list of ``size**3`` channels-sized
+                  tuples with floats. Channels are changed first,
+                  then first dimension, then second, then third.
+                  Value 0.0 corresponds lowest value of output, 1.0 highest.
+    :param channels: Number of channels in the table. Could be 3 or 4.
+                     Default is 3.
+    :param target_mode: A mode for the result image. Should have not less
+                        than ``channels`` channels. Default is ``None``,
+                        which means that mode wouldn't be changed.
+    """
+
+    name = "Color 3D LUT"
+
+    def __init__(self, size, table, channels=3, target_mode=None, **kwargs):
+        if channels not in (3, 4):
+            raise ValueError("Only 3 or 4 output channels are supported")
+        self.size = size = self._check_size(size)
+        self.channels = channels
+        self.mode = target_mode
+
+        # Hidden flag `_copy_table=False` could be used to avoid extra copying
+        # of the table if the table is specially made for the constructor.
+        copy_table = kwargs.get("_copy_table", True)
+        items = size[0] * size[1] * size[2]
+        wrong_size = False
+
+        numpy = None
+        if hasattr(table, "shape"):
+            try:
+                import numpy
+            except ImportError:  # pragma: no cover
+                pass
+
+        if numpy and isinstance(table, numpy.ndarray):
+            if copy_table:
+                table = table.copy()
+
+            if table.shape in [
+                (items * channels,),
+                (items, channels),
+                (size[2], size[1], size[0], channels),
+            ]:
+                table = table.reshape(items * channels)
+            else:
+                wrong_size = True
+
+        else:
+            if copy_table:
+                table = list(table)
+
+            # Convert to a flat list
+            if table and isinstance(table[0], (list, tuple)):
+                table, raw_table = [], table
+                for pixel in raw_table:
+                    if len(pixel) != channels:
+                        raise ValueError(
+                            "The elements of the table should "
+                            "have a length of {}.".format(channels)
+                        )
+                    table.extend(pixel)
+
+        if wrong_size or len(table) != items * channels:
+            raise ValueError(
+                "The table should have either channels * size**3 float items "
+                "or size**3 items of channels-sized tuples with floats. "
+                f"Table should be: {channels}x{size[0]}x{size[1]}x{size[2]}. "
+                f"Actual length: {len(table)}"
+            )
+        self.table = table
+
+    @staticmethod
+    def _check_size(size):
+        try:
+            _, _, _ = size
+        except ValueError as e:
+            raise ValueError(
+                "Size should be either an integer or a tuple of three integers."
+            ) from e
+        except TypeError:
+            size = (size, size, size)
+        size = [int(x) for x in size]
+        for size1D in size:
+            if not 2 <= size1D <= 65:
+                raise ValueError("Size should be in [2, 65] range.")
+        return size
+
+    @classmethod
+    def generate(cls, size, callback, channels=3, target_mode=None):
+        """Generates new LUT using provided callback.
+
+        :param size: Size of the table. Passed to the constructor.
+        :param callback: Function with three parameters which correspond
+                         three color channels. Will be called ``size**3``
+                         times with values from 0.0 to 1.0 and should return
+                         a tuple with ``channels`` elements.
+        :param channels: The number of channels which should return callback.
+        :param target_mode: Passed to the constructor of the resulting
+                            lookup table.
+        """
+        size1D, size2D, size3D = cls._check_size(size)
+        if channels not in (3, 4):
+            raise ValueError("Only 3 or 4 output channels are supported")
+
+        table = [0] * (size1D * size2D * size3D * channels)
+        idx_out = 0
+        for b in range(size3D):
+            for g in range(size2D):
+                for r in range(size1D):
+                    table[idx_out : idx_out + channels] = callback(
+                        r / (size1D - 1), g / (size2D - 1), b / (size3D - 1)
+                    )
+                    idx_out += channels
+
+        return cls(
+            (size1D, size2D, size3D),
+            table,
+            channels=channels,
+            target_mode=target_mode,
+            _copy_table=False,
+        )
+
+    def transform(self, callback, with_normals=False, channels=None, target_mode=None):
+        """Transforms the table values using provided callback and returns
+        a new LUT with altered values.
+
+        :param callback: A function which takes old lookup table values
+                         and returns a new set of values. The number
+                         of arguments which function should take is
+                         ``self.channels`` or ``3 + self.channels``
+                         if ``with_normals`` flag is set.
+                         Should return a tuple of ``self.channels`` or
+                         ``channels`` elements if it is set.
+        :param with_normals: If true, ``callback`` will be called with
+                             coordinates in the color cube as the first
+                             three arguments. Otherwise, ``callback``
+                             will be called only with actual color values.
+        :param channels: The number of channels in the resulting lookup table.
+        :param target_mode: Passed to the constructor of the resulting
+                            lookup table.
+        """
+        if channels not in (None, 3, 4):
+            raise ValueError("Only 3 or 4 output channels are supported")
+        ch_in = self.channels
+        ch_out = channels or ch_in
+        size1D, size2D, size3D = self.size
+
+        table = [0] * (size1D * size2D * size3D * ch_out)
+        idx_in = 0
+        idx_out = 0
+        for b in range(size3D):
+            for g in range(size2D):
+                for r in range(size1D):
+                    values = self.table[idx_in : idx_in + ch_in]
+                    if with_normals:
+                        values = callback(
+                            r / (size1D - 1),
+                            g / (size2D - 1),
+                            b / (size3D - 1),
+                            *values,
+                        )
+                    else:
+                        values = callback(*values)
+                    table[idx_out : idx_out + ch_out] = values
+                    idx_in += ch_in
+                    idx_out += ch_out
+
+        return type(self)(
+            self.size,
+            table,
+            channels=ch_out,
+            target_mode=target_mode or self.mode,
+            _copy_table=False,
+        )
+
+    def __repr__(self):
+        r = [
+            f"{self.__class__.__name__} from {self.table.__class__.__name__}",
+            "size={:d}x{:d}x{:d}".format(*self.size),
+            f"channels={self.channels:d}",
+        ]
+        if self.mode:
+            r.append(f"target_mode={self.mode}")
+        return "<{}>".format(" ".join(r))
+
+    def filter(self, image):
+        from . import Image
+
+        return image.color_lut_3d(
+            self.mode or image.mode,
+            Image.LINEAR,
+            self.channels,
+            self.size[0],
+            self.size[1],
+            self.size[2],
+            self.table,
+        )
diff --git a/.venv/lib/python3.7/site-packages/PIL/ImageFont.py b/.venv/lib/python3.7/site-packages/PIL/ImageFont.py
new file mode 100644
index 0000000..805c8ff
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ImageFont.py
@@ -0,0 +1,1049 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# PIL raster font management
+#
+# History:
+# 1996-08-07 fl   created (experimental)
+# 1997-08-25 fl   minor adjustments to handle fonts from pilfont 0.3
+# 1999-02-06 fl   rewrote most font management stuff in C
+# 1999-03-17 fl   take pth files into account in load_path (from Richard Jones)
+# 2001-02-17 fl   added freetype support
+# 2001-05-09 fl   added TransposedFont wrapper class
+# 2002-03-04 fl   make sure we have a "L" or "1" font
+# 2002-12-04 fl   skip non-directory entries in the system path
+# 2003-04-29 fl   add embedded default font
+# 2003-09-27 fl   added support for truetype charmap encodings
+#
+# Todo:
+# Adapt to PILFONT2 format (16-bit fonts, compressed, single file)
+#
+# Copyright (c) 1997-2003 by Secret Labs AB
+# Copyright (c) 1996-2003 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+import base64
+import os
+import sys
+from io import BytesIO
+
+from . import Image
+from ._util import isDirectory, isPath
+
+LAYOUT_BASIC = 0
+LAYOUT_RAQM = 1
+
+
+class _imagingft_not_installed:
+    # module placeholder
+    def __getattr__(self, id):
+        raise ImportError("The _imagingft C module is not installed")
+
+
+try:
+    from . import _imagingft as core
+except ImportError:
+    core = _imagingft_not_installed()
+
+
+# FIXME: add support for pilfont2 format (see FontFile.py)
+
+# --------------------------------------------------------------------
+# Font metrics format:
+#       "PILfont" LF
+#       fontdescriptor LF
+#       (optional) key=value... LF
+#       "DATA" LF
+#       binary data: 256*10*2 bytes (dx, dy, dstbox, srcbox)
+#
+# To place a character, cut out srcbox and paste at dstbox,
+# relative to the character position.  Then move the character
+# position according to dx, dy.
+# --------------------------------------------------------------------
+
+
+class ImageFont:
+    "PIL font wrapper"
+
+    def _load_pilfont(self, filename):
+
+        with open(filename, "rb") as fp:
+            image = None
+            for ext in (".png", ".gif", ".pbm"):
+                if image:
+                    image.close()
+                try:
+                    fullname = os.path.splitext(filename)[0] + ext
+                    image = Image.open(fullname)
+                except Exception:
+                    pass
+                else:
+                    if image and image.mode in ("1", "L"):
+                        break
+            else:
+                if image:
+                    image.close()
+                raise OSError("cannot find glyph data file")
+
+            self.file = fullname
+
+            self._load_pilfont_data(fp, image)
+            image.close()
+
+    def _load_pilfont_data(self, file, image):
+
+        # read PILfont header
+        if file.readline() != b"PILfont\n":
+            raise SyntaxError("Not a PILfont file")
+        file.readline().split(b";")
+        self.info = []  # FIXME: should be a dictionary
+        while True:
+            s = file.readline()
+            if not s or s == b"DATA\n":
+                break
+            self.info.append(s)
+
+        # read PILfont metrics
+        data = file.read(256 * 20)
+
+        # check image
+        if image.mode not in ("1", "L"):
+            raise TypeError("invalid font image mode")
+
+        image.load()
+
+        self.font = Image.core.font(image.im, data)
+
+    def getsize(self, text, *args, **kwargs):
+        """
+        Returns width and height (in pixels) of given text.
+
+        :param text: Text to measure.
+
+        :return: (width, height)
+        """
+        return self.font.getsize(text)
+
+    def getmask(self, text, mode="", *args, **kwargs):
+        """
+        Create a bitmap for the text.
+
+        If the font uses antialiasing, the bitmap should have mode ``L`` and use a
+        maximum value of 255. Otherwise, it should have mode ``1``.
+
+        :param text: Text to render.
+        :param mode: Used by some graphics drivers to indicate what mode the
+                     driver prefers; if empty, the renderer may return either
+                     mode. Note that the mode is always a string, to simplify
+                     C-level implementations.
+
+                     .. versionadded:: 1.1.5
+
+        :return: An internal PIL storage memory instance as defined by the
+                 :py:mod:`PIL.Image.core` interface module.
+        """
+        return self.font.getmask(text, mode)
+
+
+##
+# Wrapper for FreeType fonts.  Application code should use the
+# <b>truetype</b> factory function to create font objects.
+
+
+class FreeTypeFont:
+    "FreeType font wrapper (requires _imagingft service)"
+
+    def __init__(self, font=None, size=10, index=0, encoding="", layout_engine=None):
+        # FIXME: use service provider instead
+
+        self.path = font
+        self.size = size
+        self.index = index
+        self.encoding = encoding
+
+        if layout_engine not in (LAYOUT_BASIC, LAYOUT_RAQM):
+            layout_engine = LAYOUT_BASIC
+            if core.HAVE_RAQM:
+                layout_engine = LAYOUT_RAQM
+        elif layout_engine == LAYOUT_RAQM and not core.HAVE_RAQM:
+            layout_engine = LAYOUT_BASIC
+
+        self.layout_engine = layout_engine
+
+        def load_from_bytes(f):
+            self.font_bytes = f.read()
+            self.font = core.getfont(
+                "", size, index, encoding, self.font_bytes, layout_engine
+            )
+
+        if isPath(font):
+            if sys.platform == "win32":
+                font_bytes_path = font if isinstance(font, bytes) else font.encode()
+                try:
+                    font_bytes_path.decode("ascii")
+                except UnicodeDecodeError:
+                    # FreeType cannot load fonts with non-ASCII characters on Windows
+                    # So load it into memory first
+                    with open(font, "rb") as f:
+                        load_from_bytes(f)
+                    return
+            self.font = core.getfont(
+                font, size, index, encoding, layout_engine=layout_engine
+            )
+        else:
+            load_from_bytes(font)
+
+    def __getstate__(self):
+        return [self.path, self.size, self.index, self.encoding, self.layout_engine]
+
+    def __setstate__(self, state):
+        path, size, index, encoding, layout_engine = state
+        self.__init__(path, size, index, encoding, layout_engine)
+
+    def _multiline_split(self, text):
+        split_character = "\n" if isinstance(text, str) else b"\n"
+        return text.split(split_character)
+
+    def getname(self):
+        """
+        :return: A tuple of the font family (e.g. Helvetica) and the font style
+            (e.g. Bold)
+        """
+        return self.font.family, self.font.style
+
+    def getmetrics(self):
+        """
+        :return: A tuple of the font ascent (the distance from the baseline to
+            the highest outline point) and descent (the distance from the
+            baseline to the lowest outline point, a negative value)
+        """
+        return self.font.ascent, self.font.descent
+
+    def getlength(self, text, mode="", direction=None, features=None, language=None):
+        """
+        Returns length (in pixels with 1/64 precision) of given text when rendered
+        in font with provided direction, features, and language.
+
+        This is the amount by which following text should be offset.
+        Text bounding box may extend past the length in some fonts,
+        e.g. when using italics or accents.
+
+        The result is returned as a float; it is a whole number if using basic layout.
+
+        Note that the sum of two lengths may not equal the length of a concatenated
+        string due to kerning. If you need to adjust for kerning, include the following
+        character and subtract its length.
+
+        For example, instead of
+
+        .. code-block:: python
+
+          hello = font.getlength("Hello")
+          world = font.getlength("World")
+          hello_world = hello + world  # not adjusted for kerning
+          assert hello_world == font.getlength("HelloWorld")  # may fail
+
+        use
+
+        .. code-block:: python
+
+          hello = font.getlength("HelloW") - font.getlength("W")  # adjusted for kerning
+          world = font.getlength("World")
+          hello_world = hello + world  # adjusted for kerning
+          assert hello_world == font.getlength("HelloWorld")  # True
+
+        or disable kerning with (requires libraqm)
+
+        .. code-block:: python
+
+          hello = draw.textlength("Hello", font, features=["-kern"])
+          world = draw.textlength("World", font, features=["-kern"])
+          hello_world = hello + world  # kerning is disabled, no need to adjust
+          assert hello_world == draw.textlength("HelloWorld", font, features=["-kern"])
+
+        .. versionadded:: 8.0.0
+
+        :param text: Text to measure.
+        :param mode: Used by some graphics drivers to indicate what mode the
+                     driver prefers; if empty, the renderer may return either
+                     mode. Note that the mode is always a string, to simplify
+                     C-level implementations.
+
+        :param direction: Direction of the text. It can be 'rtl' (right to
+                          left), 'ltr' (left to right) or 'ttb' (top to bottom).
+                          Requires libraqm.
+
+        :param features: A list of OpenType font features to be used during text
+                         layout. This is usually used to turn on optional
+                         font features that are not enabled by default,
+                         for example 'dlig' or 'ss01', but can be also
+                         used to turn off default font features for
+                         example '-liga' to disable ligatures or '-kern'
+                         to disable kerning.  To get all supported
+                         features, see
+                         https://docs.microsoft.com/en-us/typography/opentype/spec/featurelist
+                         Requires libraqm.
+
+        :param language: Language of the text. Different languages may use
+                         different glyph shapes or ligatures. This parameter tells
+                         the font which language the text is in, and to apply the
+                         correct substitutions as appropriate, if available.
+                         It should be a `BCP 47 language code
+                         <https://www.w3.org/International/articles/language-tags/>`_
+                         Requires libraqm.
+
+        :return: Width for horizontal, height for vertical text.
+        """
+        return self.font.getlength(text, mode, direction, features, language) / 64
+
+    def getbbox(
+        self,
+        text,
+        mode="",
+        direction=None,
+        features=None,
+        language=None,
+        stroke_width=0,
+        anchor=None,
+    ):
+        """
+        Returns bounding box (in pixels) of given text relative to given anchor
+        when rendered in font with provided direction, features, and language.
+
+        Use :py:meth:`getlength()` to get the offset of following text with
+        1/64 pixel precision. The bounding box includes extra margins for
+        some fonts, e.g. italics or accents.
+
+        .. versionadded:: 8.0.0
+
+        :param text: Text to render.
+        :param mode: Used by some graphics drivers to indicate what mode the
+                     driver prefers; if empty, the renderer may return either
+                     mode. Note that the mode is always a string, to simplify
+                     C-level implementations.
+
+        :param direction: Direction of the text. It can be 'rtl' (right to
+                          left), 'ltr' (left to right) or 'ttb' (top to bottom).
+                          Requires libraqm.
+
+        :param features: A list of OpenType font features to be used during text
+                         layout. This is usually used to turn on optional
+                         font features that are not enabled by default,
+                         for example 'dlig' or 'ss01', but can be also
+                         used to turn off default font features for
+                         example '-liga' to disable ligatures or '-kern'
+                         to disable kerning.  To get all supported
+                         features, see
+                         https://docs.microsoft.com/en-us/typography/opentype/spec/featurelist
+                         Requires libraqm.
+
+        :param language: Language of the text. Different languages may use
+                         different glyph shapes or ligatures. This parameter tells
+                         the font which language the text is in, and to apply the
+                         correct substitutions as appropriate, if available.
+                         It should be a `BCP 47 language code
+                         <https://www.w3.org/International/articles/language-tags/>`_
+                         Requires libraqm.
+
+        :param stroke_width: The width of the text stroke.
+
+        :param anchor:  The text anchor alignment. Determines the relative location of
+                        the anchor to the text. The default alignment is top left.
+                        See :ref:`text-anchors` for valid values.
+
+        :return: ``(left, top, right, bottom)`` bounding box
+        """
+        size, offset = self.font.getsize(
+            text, mode, direction, features, language, anchor
+        )
+        left, top = offset[0] - stroke_width, offset[1] - stroke_width
+        width, height = size[0] + 2 * stroke_width, size[1] + 2 * stroke_width
+        return left, top, left + width, top + height
+
+    def getsize(
+        self, text, direction=None, features=None, language=None, stroke_width=0
+    ):
+        """
+        Returns width and height (in pixels) of given text if rendered in font with
+        provided direction, features, and language.
+
+        Use :py:meth:`getlength()` to measure the offset of following text with
+        1/64 pixel precision.
+        Use :py:meth:`getbbox()` to get the exact bounding box based on an anchor.
+
+        .. note:: For historical reasons this function measures text height from
+            the ascender line instead of the top, see :ref:`text-anchors`.
+            If you wish to measure text height from the top, it is recommended
+            to use the bottom value of :meth:`getbbox` with ``anchor='lt'`` instead.
+
+        :param text: Text to measure.
+
+        :param direction: Direction of the text. It can be 'rtl' (right to
+                          left), 'ltr' (left to right) or 'ttb' (top to bottom).
+                          Requires libraqm.
+
+                          .. versionadded:: 4.2.0
+
+        :param features: A list of OpenType font features to be used during text
+                         layout. This is usually used to turn on optional
+                         font features that are not enabled by default,
+                         for example 'dlig' or 'ss01', but can be also
+                         used to turn off default font features for
+                         example '-liga' to disable ligatures or '-kern'
+                         to disable kerning.  To get all supported
+                         features, see
+                         https://docs.microsoft.com/en-us/typography/opentype/spec/featurelist
+                         Requires libraqm.
+
+                         .. versionadded:: 4.2.0
+
+        :param language: Language of the text. Different languages may use
+                         different glyph shapes or ligatures. This parameter tells
+                         the font which language the text is in, and to apply the
+                         correct substitutions as appropriate, if available.
+                         It should be a `BCP 47 language code
+                         <https://www.w3.org/International/articles/language-tags/>`_
+                         Requires libraqm.
+
+                         .. versionadded:: 6.0.0
+
+        :param stroke_width: The width of the text stroke.
+
+                         .. versionadded:: 6.2.0
+
+        :return: (width, height)
+        """
+        # vertical offset is added for historical reasons
+        # see https://github.com/python-pillow/Pillow/pull/4910#discussion_r486682929
+        size, offset = self.font.getsize(text, "L", direction, features, language)
+        return (
+            size[0] + stroke_width * 2,
+            size[1] + stroke_width * 2 + offset[1],
+        )
+
+    def getsize_multiline(
+        self,
+        text,
+        direction=None,
+        spacing=4,
+        features=None,
+        language=None,
+        stroke_width=0,
+    ):
+        """
+        Returns width and height (in pixels) of given text if rendered in font
+        with provided direction, features, and language, while respecting
+        newline characters.
+
+        :param text: Text to measure.
+
+        :param direction: Direction of the text. It can be 'rtl' (right to
+                          left), 'ltr' (left to right) or 'ttb' (top to bottom).
+                          Requires libraqm.
+
+        :param spacing: The vertical gap between lines, defaulting to 4 pixels.
+
+        :param features: A list of OpenType font features to be used during text
+                         layout. This is usually used to turn on optional
+                         font features that are not enabled by default,
+                         for example 'dlig' or 'ss01', but can be also
+                         used to turn off default font features for
+                         example '-liga' to disable ligatures or '-kern'
+                         to disable kerning.  To get all supported
+                         features, see
+                         https://docs.microsoft.com/en-us/typography/opentype/spec/featurelist
+                         Requires libraqm.
+
+        :param language: Language of the text. Different languages may use
+                         different glyph shapes or ligatures. This parameter tells
+                         the font which language the text is in, and to apply the
+                         correct substitutions as appropriate, if available.
+                         It should be a `BCP 47 language code
+                         <https://www.w3.org/International/articles/language-tags/>`_
+                         Requires libraqm.
+
+                         .. versionadded:: 6.0.0
+
+        :param stroke_width: The width of the text stroke.
+
+                         .. versionadded:: 6.2.0
+
+        :return: (width, height)
+        """
+        max_width = 0
+        lines = self._multiline_split(text)
+        line_spacing = self.getsize("A", stroke_width=stroke_width)[1] + spacing
+        for line in lines:
+            line_width, line_height = self.getsize(
+                line, direction, features, language, stroke_width
+            )
+            max_width = max(max_width, line_width)
+
+        return max_width, len(lines) * line_spacing - spacing
+
+    def getoffset(self, text):
+        """
+        Returns the offset of given text. This is the gap between the
+        starting coordinate and the first marking. Note that this gap is
+        included in the result of :py:func:`~PIL.ImageFont.FreeTypeFont.getsize`.
+
+        :param text: Text to measure.
+
+        :return: A tuple of the x and y offset
+        """
+        return self.font.getsize(text)[1]
+
+    def getmask(
+        self,
+        text,
+        mode="",
+        direction=None,
+        features=None,
+        language=None,
+        stroke_width=0,
+        anchor=None,
+        ink=0,
+    ):
+        """
+        Create a bitmap for the text.
+
+        If the font uses antialiasing, the bitmap should have mode ``L`` and use a
+        maximum value of 255. If the font has embedded color data, the bitmap
+        should have mode ``RGBA``. Otherwise, it should have mode ``1``.
+
+        :param text: Text to render.
+        :param mode: Used by some graphics drivers to indicate what mode the
+                     driver prefers; if empty, the renderer may return either
+                     mode. Note that the mode is always a string, to simplify
+                     C-level implementations.
+
+                     .. versionadded:: 1.1.5
+
+        :param direction: Direction of the text. It can be 'rtl' (right to
+                          left), 'ltr' (left to right) or 'ttb' (top to bottom).
+                          Requires libraqm.
+
+                          .. versionadded:: 4.2.0
+
+        :param features: A list of OpenType font features to be used during text
+                         layout. This is usually used to turn on optional
+                         font features that are not enabled by default,
+                         for example 'dlig' or 'ss01', but can be also
+                         used to turn off default font features for
+                         example '-liga' to disable ligatures or '-kern'
+                         to disable kerning.  To get all supported
+                         features, see
+                         https://docs.microsoft.com/en-us/typography/opentype/spec/featurelist
+                         Requires libraqm.
+
+                         .. versionadded:: 4.2.0
+
+        :param language: Language of the text. Different languages may use
+                         different glyph shapes or ligatures. This parameter tells
+                         the font which language the text is in, and to apply the
+                         correct substitutions as appropriate, if available.
+                         It should be a `BCP 47 language code
+                         <https://www.w3.org/International/articles/language-tags/>`_
+                         Requires libraqm.
+
+                         .. versionadded:: 6.0.0
+
+        :param stroke_width: The width of the text stroke.
+
+                         .. versionadded:: 6.2.0
+
+        :param anchor:  The text anchor alignment. Determines the relative location of
+                        the anchor to the text. The default alignment is top left.
+                        See :ref:`text-anchors` for valid values.
+
+                         .. versionadded:: 8.0.0
+
+        :param ink: Foreground ink for rendering in RGBA mode.
+
+                         .. versionadded:: 8.0.0
+
+        :return: An internal PIL storage memory instance as defined by the
+                 :py:mod:`PIL.Image.core` interface module.
+        """
+        return self.getmask2(
+            text,
+            mode,
+            direction=direction,
+            features=features,
+            language=language,
+            stroke_width=stroke_width,
+            anchor=anchor,
+            ink=ink,
+        )[0]
+
+    def getmask2(
+        self,
+        text,
+        mode="",
+        fill=Image.core.fill,
+        direction=None,
+        features=None,
+        language=None,
+        stroke_width=0,
+        anchor=None,
+        ink=0,
+        *args,
+        **kwargs,
+    ):
+        """
+        Create a bitmap for the text.
+
+        If the font uses antialiasing, the bitmap should have mode ``L`` and use a
+        maximum value of 255. If the font has embedded color data, the bitmap
+        should have mode ``RGBA``. Otherwise, it should have mode ``1``.
+
+        :param text: Text to render.
+        :param mode: Used by some graphics drivers to indicate what mode the
+                     driver prefers; if empty, the renderer may return either
+                     mode. Note that the mode is always a string, to simplify
+                     C-level implementations.
+
+                     .. versionadded:: 1.1.5
+
+        :param direction: Direction of the text. It can be 'rtl' (right to
+                          left), 'ltr' (left to right) or 'ttb' (top to bottom).
+                          Requires libraqm.
+
+                          .. versionadded:: 4.2.0
+
+        :param features: A list of OpenType font features to be used during text
+                         layout. This is usually used to turn on optional
+                         font features that are not enabled by default,
+                         for example 'dlig' or 'ss01', but can be also
+                         used to turn off default font features for
+                         example '-liga' to disable ligatures or '-kern'
+                         to disable kerning.  To get all supported
+                         features, see
+                         https://docs.microsoft.com/en-us/typography/opentype/spec/featurelist
+                         Requires libraqm.
+
+                         .. versionadded:: 4.2.0
+
+        :param language: Language of the text. Different languages may use
+                         different glyph shapes or ligatures. This parameter tells
+                         the font which language the text is in, and to apply the
+                         correct substitutions as appropriate, if available.
+                         It should be a `BCP 47 language code
+                         <https://www.w3.org/International/articles/language-tags/>`_
+                         Requires libraqm.
+
+                         .. versionadded:: 6.0.0
+
+        :param stroke_width: The width of the text stroke.
+
+                         .. versionadded:: 6.2.0
+
+        :param anchor:  The text anchor alignment. Determines the relative location of
+                        the anchor to the text. The default alignment is top left.
+                        See :ref:`text-anchors` for valid values.
+
+                         .. versionadded:: 8.0.0
+
+        :param ink: Foreground ink for rendering in RGBA mode.
+
+                         .. versionadded:: 8.0.0
+
+        :return: A tuple of an internal PIL storage memory instance as defined by the
+                 :py:mod:`PIL.Image.core` interface module, and the text offset, the
+                 gap between the starting coordinate and the first marking
+        """
+        size, offset = self.font.getsize(
+            text, mode, direction, features, language, anchor
+        )
+        size = size[0] + stroke_width * 2, size[1] + stroke_width * 2
+        offset = offset[0] - stroke_width, offset[1] - stroke_width
+        Image._decompression_bomb_check(size)
+        im = fill("RGBA" if mode == "RGBA" else "L", size, 0)
+        self.font.render(
+            text, im.id, mode, direction, features, language, stroke_width, ink
+        )
+        return im, offset
+
+    def font_variant(
+        self, font=None, size=None, index=None, encoding=None, layout_engine=None
+    ):
+        """
+        Create a copy of this FreeTypeFont object,
+        using any specified arguments to override the settings.
+
+        Parameters are identical to the parameters used to initialize this
+        object.
+
+        :return: A FreeTypeFont object.
+        """
+        return FreeTypeFont(
+            font=self.path if font is None else font,
+            size=self.size if size is None else size,
+            index=self.index if index is None else index,
+            encoding=self.encoding if encoding is None else encoding,
+            layout_engine=layout_engine or self.layout_engine,
+        )
+
+    def get_variation_names(self):
+        """
+        :returns: A list of the named styles in a variation font.
+        :exception OSError: If the font is not a variation font.
+        """
+        try:
+            names = self.font.getvarnames()
+        except AttributeError as e:
+            raise NotImplementedError("FreeType 2.9.1 or greater is required") from e
+        return [name.replace(b"\x00", b"") for name in names]
+
+    def set_variation_by_name(self, name):
+        """
+        :param name: The name of the style.
+        :exception OSError: If the font is not a variation font.
+        """
+        names = self.get_variation_names()
+        if not isinstance(name, bytes):
+            name = name.encode()
+        index = names.index(name)
+
+        if index == getattr(self, "_last_variation_index", None):
+            # When the same name is set twice in a row,
+            # there is an 'unknown freetype error'
+            # https://savannah.nongnu.org/bugs/?56186
+            return
+        self._last_variation_index = index
+
+        self.font.setvarname(index)
+
+    def get_variation_axes(self):
+        """
+        :returns: A list of the axes in a variation font.
+        :exception OSError: If the font is not a variation font.
+        """
+        try:
+            axes = self.font.getvaraxes()
+        except AttributeError as e:
+            raise NotImplementedError("FreeType 2.9.1 or greater is required") from e
+        for axis in axes:
+            axis["name"] = axis["name"].replace(b"\x00", b"")
+        return axes
+
+    def set_variation_by_axes(self, axes):
+        """
+        :param axes: A list of values for each axis.
+        :exception OSError: If the font is not a variation font.
+        """
+        try:
+            self.font.setvaraxes(axes)
+        except AttributeError as e:
+            raise NotImplementedError("FreeType 2.9.1 or greater is required") from e
+
+
+class TransposedFont:
+    "Wrapper for writing rotated or mirrored text"
+
+    def __init__(self, font, orientation=None):
+        """
+        Wrapper that creates a transposed font from any existing font
+        object.
+
+        :param font: A font object.
+        :param orientation: An optional orientation.  If given, this should
+            be one of Image.FLIP_LEFT_RIGHT, Image.FLIP_TOP_BOTTOM,
+            Image.ROTATE_90, Image.ROTATE_180, or Image.ROTATE_270.
+        """
+        self.font = font
+        self.orientation = orientation  # any 'transpose' argument, or None
+
+    def getsize(self, text, *args, **kwargs):
+        w, h = self.font.getsize(text)
+        if self.orientation in (Image.ROTATE_90, Image.ROTATE_270):
+            return h, w
+        return w, h
+
+    def getmask(self, text, mode="", *args, **kwargs):
+        im = self.font.getmask(text, mode, *args, **kwargs)
+        if self.orientation is not None:
+            return im.transpose(self.orientation)
+        return im
+
+
+def load(filename):
+    """
+    Load a font file.  This function loads a font object from the given
+    bitmap font file, and returns the corresponding font object.
+
+    :param filename: Name of font file.
+    :return: A font object.
+    :exception OSError: If the file could not be read.
+    """
+    f = ImageFont()
+    f._load_pilfont(filename)
+    return f
+
+
+def truetype(font=None, size=10, index=0, encoding="", layout_engine=None):
+    """
+    Load a TrueType or OpenType font from a file or file-like object,
+    and create a font object.
+    This function loads a font object from the given file or file-like
+    object, and creates a font object for a font of the given size.
+
+    Pillow uses FreeType to open font files. If you are opening many fonts
+    simultaneously on Windows, be aware that Windows limits the number of files
+    that can be open in C at once to 512. If you approach that limit, an
+    ``OSError`` may be thrown, reporting that FreeType "cannot open resource".
+
+    This function requires the _imagingft service.
+
+    :param font: A filename or file-like object containing a TrueType font.
+                 If the file is not found in this filename, the loader may also
+                 search in other directories, such as the :file:`fonts/`
+                 directory on Windows or :file:`/Library/Fonts/`,
+                 :file:`/System/Library/Fonts/` and :file:`~/Library/Fonts/` on
+                 macOS.
+
+    :param size: The requested size, in points.
+    :param index: Which font face to load (default is first available face).
+    :param encoding: Which font encoding to use (default is Unicode). Possible
+                     encodings include (see the FreeType documentation for more
+                     information):
+
+                     * "unic" (Unicode)
+                     * "symb" (Microsoft Symbol)
+                     * "ADOB" (Adobe Standard)
+                     * "ADBE" (Adobe Expert)
+                     * "ADBC" (Adobe Custom)
+                     * "armn" (Apple Roman)
+                     * "sjis" (Shift JIS)
+                     * "gb  " (PRC)
+                     * "big5"
+                     * "wans" (Extended Wansung)
+                     * "joha" (Johab)
+                     * "lat1" (Latin-1)
+
+                     This specifies the character set to use. It does not alter the
+                     encoding of any text provided in subsequent operations.
+    :param layout_engine: Which layout engine to use, if available:
+                     :data:`.ImageFont.LAYOUT_BASIC` or :data:`.ImageFont.LAYOUT_RAQM`.
+
+                     You can check support for Raqm layout using
+                     :py:func:`PIL.features.check_feature` with ``feature="raqm"``.
+
+                     .. versionadded:: 4.2.0
+    :return: A font object.
+    :exception OSError: If the file could not be read.
+    """
+
+    def freetype(font):
+        return FreeTypeFont(font, size, index, encoding, layout_engine)
+
+    try:
+        return freetype(font)
+    except OSError:
+        if not isPath(font):
+            raise
+        ttf_filename = os.path.basename(font)
+
+        dirs = []
+        if sys.platform == "win32":
+            # check the windows font repository
+            # NOTE: must use uppercase WINDIR, to work around bugs in
+            # 1.5.2's os.environ.get()
+            windir = os.environ.get("WINDIR")
+            if windir:
+                dirs.append(os.path.join(windir, "fonts"))
+        elif sys.platform in ("linux", "linux2"):
+            lindirs = os.environ.get("XDG_DATA_DIRS", "")
+            if not lindirs:
+                # According to the freedesktop spec, XDG_DATA_DIRS should
+                # default to /usr/share
+                lindirs = "/usr/share"
+            dirs += [os.path.join(lindir, "fonts") for lindir in lindirs.split(":")]
+        elif sys.platform == "darwin":
+            dirs += [
+                "/Library/Fonts",
+                "/System/Library/Fonts",
+                os.path.expanduser("~/Library/Fonts"),
+            ]
+
+        ext = os.path.splitext(ttf_filename)[1]
+        first_font_with_a_different_extension = None
+        for directory in dirs:
+            for walkroot, walkdir, walkfilenames in os.walk(directory):
+                for walkfilename in walkfilenames:
+                    if ext and walkfilename == ttf_filename:
+                        return freetype(os.path.join(walkroot, walkfilename))
+                    elif not ext and os.path.splitext(walkfilename)[0] == ttf_filename:
+                        fontpath = os.path.join(walkroot, walkfilename)
+                        if os.path.splitext(fontpath)[1] == ".ttf":
+                            return freetype(fontpath)
+                        if not ext and first_font_with_a_different_extension is None:
+                            first_font_with_a_different_extension = fontpath
+        if first_font_with_a_different_extension:
+            return freetype(first_font_with_a_different_extension)
+        raise
+
+
+def load_path(filename):
+    """
+    Load font file. Same as :py:func:`~PIL.ImageFont.load`, but searches for a
+    bitmap font along the Python path.
+
+    :param filename: Name of font file.
+    :return: A font object.
+    :exception OSError: If the file could not be read.
+    """
+    for directory in sys.path:
+        if isDirectory(directory):
+            if not isinstance(filename, str):
+                filename = filename.decode("utf-8")
+            try:
+                return load(os.path.join(directory, filename))
+            except OSError:
+                pass
+    raise OSError("cannot find font file")
+
+
+def load_default():
+    """Load a "better than nothing" default font.
+
+    .. versionadded:: 1.1.4
+
+    :return: A font object.
+    """
+    f = ImageFont()
+    f._load_pilfont_data(
+        # courB08
+        BytesIO(
+            base64.b64decode(
+                b"""
+UElMZm9udAo7Ozs7OzsxMDsKREFUQQoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYAAAAA//8AAQAAAAAAAAABAAEA
+BgAAAAH/+gADAAAAAQAAAAMABgAGAAAAAf/6AAT//QADAAAABgADAAYAAAAA//kABQABAAYAAAAL
+AAgABgAAAAD/+AAFAAEACwAAABAACQAGAAAAAP/5AAUAAAAQAAAAFQAHAAYAAP////oABQAAABUA
+AAAbAAYABgAAAAH/+QAE//wAGwAAAB4AAwAGAAAAAf/5AAQAAQAeAAAAIQAIAAYAAAAB//kABAAB
+ACEAAAAkAAgABgAAAAD/+QAE//0AJAAAACgABAAGAAAAAP/6AAX//wAoAAAALQAFAAYAAAAB//8A
+BAACAC0AAAAwAAMABgAAAAD//AAF//0AMAAAADUAAQAGAAAAAf//AAMAAAA1AAAANwABAAYAAAAB
+//kABQABADcAAAA7AAgABgAAAAD/+QAFAAAAOwAAAEAABwAGAAAAAP/5AAYAAABAAAAARgAHAAYA
+AAAA//kABQAAAEYAAABLAAcABgAAAAD/+QAFAAAASwAAAFAABwAGAAAAAP/5AAYAAABQAAAAVgAH
+AAYAAAAA//kABQAAAFYAAABbAAcABgAAAAD/+QAFAAAAWwAAAGAABwAGAAAAAP/5AAUAAABgAAAA
+ZQAHAAYAAAAA//kABQAAAGUAAABqAAcABgAAAAD/+QAFAAAAagAAAG8ABwAGAAAAAf/8AAMAAABv
+AAAAcQAEAAYAAAAA//wAAwACAHEAAAB0AAYABgAAAAD/+gAE//8AdAAAAHgABQAGAAAAAP/7AAT/
+/gB4AAAAfAADAAYAAAAB//oABf//AHwAAACAAAUABgAAAAD/+gAFAAAAgAAAAIUABgAGAAAAAP/5
+AAYAAQCFAAAAiwAIAAYAAP////oABgAAAIsAAACSAAYABgAA////+gAFAAAAkgAAAJgABgAGAAAA
+AP/6AAUAAACYAAAAnQAGAAYAAP////oABQAAAJ0AAACjAAYABgAA////+gAFAAAAowAAAKkABgAG
+AAD////6AAUAAACpAAAArwAGAAYAAAAA//oABQAAAK8AAAC0AAYABgAA////+gAGAAAAtAAAALsA
+BgAGAAAAAP/6AAQAAAC7AAAAvwAGAAYAAP////oABQAAAL8AAADFAAYABgAA////+gAGAAAAxQAA
+AMwABgAGAAD////6AAUAAADMAAAA0gAGAAYAAP////oABQAAANIAAADYAAYABgAA////+gAGAAAA
+2AAAAN8ABgAGAAAAAP/6AAUAAADfAAAA5AAGAAYAAP////oABQAAAOQAAADqAAYABgAAAAD/+gAF
+AAEA6gAAAO8ABwAGAAD////6AAYAAADvAAAA9gAGAAYAAAAA//oABQAAAPYAAAD7AAYABgAA////
++gAFAAAA+wAAAQEABgAGAAD////6AAYAAAEBAAABCAAGAAYAAP////oABgAAAQgAAAEPAAYABgAA
+////+gAGAAABDwAAARYABgAGAAAAAP/6AAYAAAEWAAABHAAGAAYAAP////oABgAAARwAAAEjAAYA
+BgAAAAD/+gAFAAABIwAAASgABgAGAAAAAf/5AAQAAQEoAAABKwAIAAYAAAAA//kABAABASsAAAEv
+AAgABgAAAAH/+QAEAAEBLwAAATIACAAGAAAAAP/5AAX//AEyAAABNwADAAYAAAAAAAEABgACATcA
+AAE9AAEABgAAAAH/+QAE//wBPQAAAUAAAwAGAAAAAP/7AAYAAAFAAAABRgAFAAYAAP////kABQAA
+AUYAAAFMAAcABgAAAAD/+wAFAAABTAAAAVEABQAGAAAAAP/5AAYAAAFRAAABVwAHAAYAAAAA//sA
+BQAAAVcAAAFcAAUABgAAAAD/+QAFAAABXAAAAWEABwAGAAAAAP/7AAYAAgFhAAABZwAHAAYAAP//
+//kABQAAAWcAAAFtAAcABgAAAAD/+QAGAAABbQAAAXMABwAGAAAAAP/5AAQAAgFzAAABdwAJAAYA
+AP////kABgAAAXcAAAF+AAcABgAAAAD/+QAGAAABfgAAAYQABwAGAAD////7AAUAAAGEAAABigAF
+AAYAAP////sABQAAAYoAAAGQAAUABgAAAAD/+wAFAAABkAAAAZUABQAGAAD////7AAUAAgGVAAAB
+mwAHAAYAAAAA//sABgACAZsAAAGhAAcABgAAAAD/+wAGAAABoQAAAacABQAGAAAAAP/7AAYAAAGn
+AAABrQAFAAYAAAAA//kABgAAAa0AAAGzAAcABgAA////+wAGAAABswAAAboABQAGAAD////7AAUA
+AAG6AAABwAAFAAYAAP////sABgAAAcAAAAHHAAUABgAAAAD/+wAGAAABxwAAAc0ABQAGAAD////7
+AAYAAgHNAAAB1AAHAAYAAAAA//sABQAAAdQAAAHZAAUABgAAAAH/+QAFAAEB2QAAAd0ACAAGAAAA
+Av/6AAMAAQHdAAAB3gAHAAYAAAAA//kABAABAd4AAAHiAAgABgAAAAD/+wAF//0B4gAAAecAAgAA
+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYAAAAB
+//sAAwACAecAAAHpAAcABgAAAAD/+QAFAAEB6QAAAe4ACAAGAAAAAP/5AAYAAAHuAAAB9AAHAAYA
+AAAA//oABf//AfQAAAH5AAUABgAAAAD/+QAGAAAB+QAAAf8ABwAGAAAAAv/5AAMAAgH/AAACAAAJ
+AAYAAAAA//kABQABAgAAAAIFAAgABgAAAAH/+gAE//sCBQAAAggAAQAGAAAAAP/5AAYAAAIIAAAC
+DgAHAAYAAAAB//kABf/+Ag4AAAISAAUABgAA////+wAGAAACEgAAAhkABQAGAAAAAP/7AAX//gIZ
+AAACHgADAAYAAAAA//wABf/9Ah4AAAIjAAEABgAAAAD/+QAHAAACIwAAAioABwAGAAAAAP/6AAT/
++wIqAAACLgABAAYAAAAA//kABP/8Ai4AAAIyAAMABgAAAAD/+gAFAAACMgAAAjcABgAGAAAAAf/5
+AAT//QI3AAACOgAEAAYAAAAB//kABP/9AjoAAAI9AAQABgAAAAL/+QAE//sCPQAAAj8AAgAGAAD/
+///7AAYAAgI/AAACRgAHAAYAAAAA//kABgABAkYAAAJMAAgABgAAAAH//AAD//0CTAAAAk4AAQAG
+AAAAAf//AAQAAgJOAAACUQADAAYAAAAB//kABP/9AlEAAAJUAAQABgAAAAH/+QAF//4CVAAAAlgA
+BQAGAAD////7AAYAAAJYAAACXwAFAAYAAP////kABgAAAl8AAAJmAAcABgAA////+QAGAAACZgAA
+Am0ABwAGAAD////5AAYAAAJtAAACdAAHAAYAAAAA//sABQACAnQAAAJ5AAcABgAA////9wAGAAAC
+eQAAAoAACQAGAAD////3AAYAAAKAAAAChwAJAAYAAP////cABgAAAocAAAKOAAkABgAA////9wAG
+AAACjgAAApUACQAGAAD////4AAYAAAKVAAACnAAIAAYAAP////cABgAAApwAAAKjAAkABgAA////
++gAGAAACowAAAqoABgAGAAAAAP/6AAUAAgKqAAACrwAIAAYAAP////cABQAAAq8AAAK1AAkABgAA
+////9wAFAAACtQAAArsACQAGAAD////3AAUAAAK7AAACwQAJAAYAAP////gABQAAAsEAAALHAAgA
+BgAAAAD/9wAEAAACxwAAAssACQAGAAAAAP/3AAQAAALLAAACzwAJAAYAAAAA//cABAAAAs8AAALT
+AAkABgAAAAD/+AAEAAAC0wAAAtcACAAGAAD////6AAUAAALXAAAC3QAGAAYAAP////cABgAAAt0A
+AALkAAkABgAAAAD/9wAFAAAC5AAAAukACQAGAAAAAP/3AAUAAALpAAAC7gAJAAYAAAAA//cABQAA
+Au4AAALzAAkABgAAAAD/9wAFAAAC8wAAAvgACQAGAAAAAP/4AAUAAAL4AAAC/QAIAAYAAAAA//oA
+Bf//Av0AAAMCAAUABgAA////+gAGAAADAgAAAwkABgAGAAD////3AAYAAAMJAAADEAAJAAYAAP//
+//cABgAAAxAAAAMXAAkABgAA////9wAGAAADFwAAAx4ACQAGAAD////4AAYAAAAAAAoABwASAAYA
+AP////cABgAAAAcACgAOABMABgAA////+gAFAAAADgAKABQAEAAGAAD////6AAYAAAAUAAoAGwAQ
+AAYAAAAA//gABgAAABsACgAhABIABgAAAAD/+AAGAAAAIQAKACcAEgAGAAAAAP/4AAYAAAAnAAoA
+LQASAAYAAAAA//gABgAAAC0ACgAzABIABgAAAAD/+QAGAAAAMwAKADkAEQAGAAAAAP/3AAYAAAA5
+AAoAPwATAAYAAP////sABQAAAD8ACgBFAA8ABgAAAAD/+wAFAAIARQAKAEoAEQAGAAAAAP/4AAUA
+AABKAAoATwASAAYAAAAA//gABQAAAE8ACgBUABIABgAAAAD/+AAFAAAAVAAKAFkAEgAGAAAAAP/5
+AAUAAABZAAoAXgARAAYAAAAA//gABgAAAF4ACgBkABIABgAAAAD/+AAGAAAAZAAKAGoAEgAGAAAA
+AP/4AAYAAABqAAoAcAASAAYAAAAA//kABgAAAHAACgB2ABEABgAAAAD/+AAFAAAAdgAKAHsAEgAG
+AAD////4AAYAAAB7AAoAggASAAYAAAAA//gABQAAAIIACgCHABIABgAAAAD/+AAFAAAAhwAKAIwA
+EgAGAAAAAP/4AAUAAACMAAoAkQASAAYAAAAA//gABQAAAJEACgCWABIABgAAAAD/+QAFAAAAlgAK
+AJsAEQAGAAAAAP/6AAX//wCbAAoAoAAPAAYAAAAA//oABQABAKAACgClABEABgAA////+AAGAAAA
+pQAKAKwAEgAGAAD////4AAYAAACsAAoAswASAAYAAP////gABgAAALMACgC6ABIABgAA////+QAG
+AAAAugAKAMEAEQAGAAD////4AAYAAgDBAAoAyAAUAAYAAP////kABQACAMgACgDOABMABgAA////
++QAGAAIAzgAKANUAEw==
+"""
+            )
+        ),
+        Image.open(
+            BytesIO(
+                base64.b64decode(
+                    b"""
+iVBORw0KGgoAAAANSUhEUgAAAx4AAAAUAQAAAAArMtZoAAAEwElEQVR4nABlAJr/AHVE4czCI/4u
+Mc4b7vuds/xzjz5/3/7u/n9vMe7vnfH/9++vPn/xyf5zhxzjt8GHw8+2d83u8x27199/nxuQ6Od9
+M43/5z2I+9n9ZtmDBwMQECDRQw/eQIQohJXxpBCNVE6QCCAAAAD//wBlAJr/AgALyj1t/wINwq0g
+LeNZUworuN1cjTPIzrTX6ofHWeo3v336qPzfEwRmBnHTtf95/fglZK5N0PDgfRTslpGBvz7LFc4F
+IUXBWQGjQ5MGCx34EDFPwXiY4YbYxavpnhHFrk14CDAAAAD//wBlAJr/AgKqRooH2gAgPeggvUAA
+Bu2WfgPoAwzRAABAAAAAAACQgLz/3Uv4Gv+gX7BJgDeeGP6AAAD1NMDzKHD7ANWr3loYbxsAD791
+NAADfcoIDyP44K/jv4Y63/Z+t98Ovt+ub4T48LAAAAD//wBlAJr/AuplMlADJAAAAGuAphWpqhMx
+in0A/fRvAYBABPgBwBUgABBQ/sYAyv9g0bCHgOLoGAAAAAAAREAAwI7nr0ArYpow7aX8//9LaP/9
+SjdavWA8ePHeBIKB//81/83ndznOaXx379wAAAD//wBlAJr/AqDxW+D3AABAAbUh/QMnbQag/gAY
+AYDAAACgtgD/gOqAAAB5IA/8AAAk+n9w0AAA8AAAmFRJuPo27ciC0cD5oeW4E7KA/wD3ECMAn2tt
+y8PgwH8AfAxFzC0JzeAMtratAsC/ffwAAAD//wBlAJr/BGKAyCAA4AAAAvgeYTAwHd1kmQF5chkG
+ABoMIHcL5xVpTfQbUqzlAAAErwAQBgAAEOClA5D9il08AEh/tUzdCBsXkbgACED+woQg8Si9VeqY
+lODCn7lmF6NhnAEYgAAA/NMIAAAAAAD//2JgjLZgVGBg5Pv/Tvpc8hwGBjYGJADjHDrAwPzAjv/H
+/Wf3PzCwtzcwHmBgYGcwbZz8wHaCAQMDOwMDQ8MCBgYOC3W7mp+f0w+wHOYxO3OG+e376hsMZjk3
+AAAAAP//YmCMY2A4wMAIN5e5gQETPD6AZisDAwMDgzSDAAPjByiHcQMDAwMDg1nOze1lByRu5/47
+c4859311AYNZzg0AAAAA//9iYGDBYihOIIMuwIjGL39/fwffA8b//xv/P2BPtzzHwCBjUQAAAAD/
+/yLFBrIBAAAA//9i1HhcwdhizX7u8NZNzyLbvT97bfrMf/QHI8evOwcSqGUJAAAA//9iYBB81iSw
+pEE170Qrg5MIYydHqwdDQRMrAwcVrQAAAAD//2J4x7j9AAMDn8Q/BgYLBoaiAwwMjPdvMDBYM1Tv
+oJodAAAAAP//Yqo/83+dxePWlxl3npsel9lvLfPcqlE9725C+acfVLMEAAAA//9i+s9gwCoaaGMR
+evta/58PTEWzr21hufPjA8N+qlnBwAAAAAD//2JiWLci5v1+HmFXDqcnULE/MxgYGBj+f6CaJQAA
+AAD//2Ji2FrkY3iYpYC5qDeGgeEMAwPDvwQBBoYvcTwOVLMEAAAA//9isDBgkP///0EOg9z35v//
+Gc/eeW7BwPj5+QGZhANUswMAAAD//2JgqGBgYGBgqEMXlvhMPUsAAAAA//8iYDd1AAAAAP//AwDR
+w7IkEbzhVQAAAABJRU5ErkJggg==
+"""
+                )
+            )
+        ),
+    )
+    return f
diff --git a/.venv/lib/python3.7/site-packages/PIL/ImageGrab.py b/.venv/lib/python3.7/site-packages/PIL/ImageGrab.py
new file mode 100644
index 0000000..b93ec3f
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ImageGrab.py
@@ -0,0 +1,120 @@
+#
+# The Python Imaging Library
+# $Id$
+#
+# screen grabber
+#
+# History:
+# 2001-04-26 fl  created
+# 2001-09-17 fl  use builtin driver, if present
+# 2002-11-19 fl  added grabclipboard support
+#
+# Copyright (c) 2001-2002 by Secret Labs AB
+# Copyright (c) 2001-2002 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+import sys
+
+from . import Image
+
+if sys.platform == "darwin":
+    import os
+    import subprocess
+    import tempfile
+
+
+def grab(bbox=None, include_layered_windows=False, all_screens=False, xdisplay=None):
+    if xdisplay is None:
+        if sys.platform == "darwin":
+            fh, filepath = tempfile.mkstemp(".png")
+            os.close(fh)
+            subprocess.call(["screencapture", "-x", filepath])
+            im = Image.open(filepath)
+            im.load()
+            os.unlink(filepath)
+            if bbox:
+                im_cropped = im.crop(bbox)
+                im.close()
+                return im_cropped
+            return im
+        elif sys.platform == "win32":
+            offset, size, data = Image.core.grabscreen_win32(
+                include_layered_windows, all_screens
+            )
+            im = Image.frombytes(
+                "RGB",
+                size,
+                data,
+                # RGB, 32-bit line padding, origin lower left corner
+                "raw",
+                "BGR",
+                (size[0] * 3 + 3) & -4,
+                -1,
+            )
+            if bbox:
+                x0, y0 = offset
+                left, top, right, bottom = bbox
+                im = im.crop((left - x0, top - y0, right - x0, bottom - y0))
+            return im
+    # use xdisplay=None for default display on non-win32/macOS systems
+    if not Image.core.HAVE_XCB:
+        raise OSError("Pillow was built without XCB support")
+    size, data = Image.core.grabscreen_x11(xdisplay)
+    im = Image.frombytes("RGB", size, data, "raw", "BGRX", size[0] * 4, 1)
+    if bbox:
+        im = im.crop(bbox)
+    return im
+
+
+def grabclipboard():
+    if sys.platform == "darwin":
+        fh, filepath = tempfile.mkstemp(".jpg")
+        os.close(fh)
+        commands = [
+            'set theFile to (open for access POSIX file "'
+            + filepath
+            + '" with write permission)',
+            "try",
+            "    write (the clipboard as JPEG picture) to theFile",
+            "end try",
+            "close access theFile",
+        ]
+        script = ["osascript"]
+        for command in commands:
+            script += ["-e", command]
+        subprocess.call(script)
+
+        im = None
+        if os.stat(filepath).st_size != 0:
+            im = Image.open(filepath)
+            im.load()
+        os.unlink(filepath)
+        return im
+    elif sys.platform == "win32":
+        fmt, data = Image.core.grabclipboard_win32()
+        if fmt == "file":  # CF_HDROP
+            import struct
+
+            o = struct.unpack_from("I", data)[0]
+            if data[16] != 0:
+                files = data[o:].decode("utf-16le").split("\0")
+            else:
+                files = data[o:].decode("mbcs").split("\0")
+            return files[: files.index("")]
+        if isinstance(data, bytes):
+            import io
+
+            data = io.BytesIO(data)
+            if fmt == "png":
+                from . import PngImagePlugin
+
+                return PngImagePlugin.PngImageFile(data)
+            elif fmt == "DIB":
+                from . import BmpImagePlugin
+
+                return BmpImagePlugin.DibImageFile(data)
+        return None
+    else:
+        raise NotImplementedError("ImageGrab.grabclipboard() is macOS and Windows only")
diff --git a/.venv/lib/python3.7/site-packages/PIL/ImageMath.py b/.venv/lib/python3.7/site-packages/PIL/ImageMath.py
new file mode 100644
index 0000000..47ad3c9
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ImageMath.py
@@ -0,0 +1,265 @@
+#
+# The Python Imaging Library
+# $Id$
+#
+# a simple math add-on for the Python Imaging Library
+#
+# History:
+# 1999-02-15 fl   Original PIL Plus release
+# 2005-05-05 fl   Simplified and cleaned up for PIL 1.1.6
+# 2005-09-12 fl   Fixed int() and float() for Python 2.4.1
+#
+# Copyright (c) 1999-2005 by Secret Labs AB
+# Copyright (c) 2005 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+import builtins
+
+from . import Image, _imagingmath
+
+VERBOSE = 0
+
+
+def _isconstant(v):
+    return isinstance(v, (int, float))
+
+
+class _Operand:
+    """Wraps an image operand, providing standard operators"""
+
+    def __init__(self, im):
+        self.im = im
+
+    def __fixup(self, im1):
+        # convert image to suitable mode
+        if isinstance(im1, _Operand):
+            # argument was an image.
+            if im1.im.mode in ("1", "L"):
+                return im1.im.convert("I")
+            elif im1.im.mode in ("I", "F"):
+                return im1.im
+            else:
+                raise ValueError(f"unsupported mode: {im1.im.mode}")
+        else:
+            # argument was a constant
+            if _isconstant(im1) and self.im.mode in ("1", "L", "I"):
+                return Image.new("I", self.im.size, im1)
+            else:
+                return Image.new("F", self.im.size, im1)
+
+    def apply(self, op, im1, im2=None, mode=None):
+        im1 = self.__fixup(im1)
+        if im2 is None:
+            # unary operation
+            out = Image.new(mode or im1.mode, im1.size, None)
+            im1.load()
+            try:
+                op = getattr(_imagingmath, op + "_" + im1.mode)
+            except AttributeError as e:
+                raise TypeError(f"bad operand type for '{op}'") from e
+            _imagingmath.unop(op, out.im.id, im1.im.id)
+        else:
+            # binary operation
+            im2 = self.__fixup(im2)
+            if im1.mode != im2.mode:
+                # convert both arguments to floating point
+                if im1.mode != "F":
+                    im1 = im1.convert("F")
+                if im2.mode != "F":
+                    im2 = im2.convert("F")
+                if im1.mode != im2.mode:
+                    raise ValueError("mode mismatch")
+            if im1.size != im2.size:
+                # crop both arguments to a common size
+                size = (min(im1.size[0], im2.size[0]), min(im1.size[1], im2.size[1]))
+                if im1.size != size:
+                    im1 = im1.crop((0, 0) + size)
+                if im2.size != size:
+                    im2 = im2.crop((0, 0) + size)
+                out = Image.new(mode or im1.mode, size, None)
+            else:
+                out = Image.new(mode or im1.mode, im1.size, None)
+            im1.load()
+            im2.load()
+            try:
+                op = getattr(_imagingmath, op + "_" + im1.mode)
+            except AttributeError as e:
+                raise TypeError(f"bad operand type for '{op}'") from e
+            _imagingmath.binop(op, out.im.id, im1.im.id, im2.im.id)
+        return _Operand(out)
+
+    # unary operators
+    def __bool__(self):
+        # an image is "true" if it contains at least one non-zero pixel
+        return self.im.getbbox() is not None
+
+    def __abs__(self):
+        return self.apply("abs", self)
+
+    def __pos__(self):
+        return self
+
+    def __neg__(self):
+        return self.apply("neg", self)
+
+    # binary operators
+    def __add__(self, other):
+        return self.apply("add", self, other)
+
+    def __radd__(self, other):
+        return self.apply("add", other, self)
+
+    def __sub__(self, other):
+        return self.apply("sub", self, other)
+
+    def __rsub__(self, other):
+        return self.apply("sub", other, self)
+
+    def __mul__(self, other):
+        return self.apply("mul", self, other)
+
+    def __rmul__(self, other):
+        return self.apply("mul", other, self)
+
+    def __truediv__(self, other):
+        return self.apply("div", self, other)
+
+    def __rtruediv__(self, other):
+        return self.apply("div", other, self)
+
+    def __mod__(self, other):
+        return self.apply("mod", self, other)
+
+    def __rmod__(self, other):
+        return self.apply("mod", other, self)
+
+    def __pow__(self, other):
+        return self.apply("pow", self, other)
+
+    def __rpow__(self, other):
+        return self.apply("pow", other, self)
+
+    # bitwise
+    def __invert__(self):
+        return self.apply("invert", self)
+
+    def __and__(self, other):
+        return self.apply("and", self, other)
+
+    def __rand__(self, other):
+        return self.apply("and", other, self)
+
+    def __or__(self, other):
+        return self.apply("or", self, other)
+
+    def __ror__(self, other):
+        return self.apply("or", other, self)
+
+    def __xor__(self, other):
+        return self.apply("xor", self, other)
+
+    def __rxor__(self, other):
+        return self.apply("xor", other, self)
+
+    def __lshift__(self, other):
+        return self.apply("lshift", self, other)
+
+    def __rshift__(self, other):
+        return self.apply("rshift", self, other)
+
+    # logical
+    def __eq__(self, other):
+        return self.apply("eq", self, other)
+
+    def __ne__(self, other):
+        return self.apply("ne", self, other)
+
+    def __lt__(self, other):
+        return self.apply("lt", self, other)
+
+    def __le__(self, other):
+        return self.apply("le", self, other)
+
+    def __gt__(self, other):
+        return self.apply("gt", self, other)
+
+    def __ge__(self, other):
+        return self.apply("ge", self, other)
+
+
+# conversions
+def imagemath_int(self):
+    return _Operand(self.im.convert("I"))
+
+
+def imagemath_float(self):
+    return _Operand(self.im.convert("F"))
+
+
+# logical
+def imagemath_equal(self, other):
+    return self.apply("eq", self, other, mode="I")
+
+
+def imagemath_notequal(self, other):
+    return self.apply("ne", self, other, mode="I")
+
+
+def imagemath_min(self, other):
+    return self.apply("min", self, other)
+
+
+def imagemath_max(self, other):
+    return self.apply("max", self, other)
+
+
+def imagemath_convert(self, mode):
+    return _Operand(self.im.convert(mode))
+
+
+ops = {}
+for k, v in list(globals().items()):
+    if k[:10] == "imagemath_":
+        ops[k[10:]] = v
+
+
+def eval(expression, _dict={}, **kw):
+    """
+    Evaluates an image expression.
+
+    :param expression: A string containing a Python-style expression.
+    :param options: Values to add to the evaluation context.  You
+                    can either use a dictionary, or one or more keyword
+                    arguments.
+    :return: The evaluated expression. This is usually an image object, but can
+             also be an integer, a floating point value, or a pixel tuple,
+             depending on the expression.
+    """
+
+    # build execution namespace
+    args = ops.copy()
+    args.update(_dict)
+    args.update(kw)
+    for k, v in list(args.items()):
+        if hasattr(v, "im"):
+            args[k] = _Operand(v)
+
+    compiled_code = compile(expression, "<string>", "eval")
+
+    def scan(code):
+        for const in code.co_consts:
+            if type(const) == type(compiled_code):
+                scan(const)
+
+        for name in code.co_names:
+            if name not in args and name != "abs":
+                raise ValueError(f"'{name}' not allowed")
+
+    scan(compiled_code)
+    out = builtins.eval(expression, {"__builtins": {"abs": abs}}, args)
+    try:
+        return out.im
+    except AttributeError:
+        return out
diff --git a/.venv/lib/python3.7/site-packages/PIL/ImageMode.py b/.venv/lib/python3.7/site-packages/PIL/ImageMode.py
new file mode 100644
index 0000000..0afcf9f
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ImageMode.py
@@ -0,0 +1,74 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# standard mode descriptors
+#
+# History:
+# 2006-03-20 fl   Added
+#
+# Copyright (c) 2006 by Secret Labs AB.
+# Copyright (c) 2006 by Fredrik Lundh.
+#
+# See the README file for information on usage and redistribution.
+#
+
+# mode descriptor cache
+_modes = None
+
+
+class ModeDescriptor:
+    """Wrapper for mode strings."""
+
+    def __init__(self, mode, bands, basemode, basetype):
+        self.mode = mode
+        self.bands = bands
+        self.basemode = basemode
+        self.basetype = basetype
+
+    def __str__(self):
+        return self.mode
+
+
+def getmode(mode):
+    """Gets a mode descriptor for the given mode."""
+    global _modes
+    if not _modes:
+        # initialize mode cache
+        modes = {}
+        for m, (basemode, basetype, bands) in {
+            # core modes
+            "1": ("L", "L", ("1",)),
+            "L": ("L", "L", ("L",)),
+            "I": ("L", "I", ("I",)),
+            "F": ("L", "F", ("F",)),
+            "P": ("P", "L", ("P",)),
+            "RGB": ("RGB", "L", ("R", "G", "B")),
+            "RGBX": ("RGB", "L", ("R", "G", "B", "X")),
+            "RGBA": ("RGB", "L", ("R", "G", "B", "A")),
+            "CMYK": ("RGB", "L", ("C", "M", "Y", "K")),
+            "YCbCr": ("RGB", "L", ("Y", "Cb", "Cr")),
+            "LAB": ("RGB", "L", ("L", "A", "B")),
+            "HSV": ("RGB", "L", ("H", "S", "V")),
+            # extra experimental modes
+            "RGBa": ("RGB", "L", ("R", "G", "B", "a")),
+            "LA": ("L", "L", ("L", "A")),
+            "La": ("L", "L", ("L", "a")),
+            "PA": ("RGB", "L", ("P", "A")),
+        }.items():
+            modes[m] = ModeDescriptor(m, bands, basemode, basetype)
+        # mapping modes
+        for i16mode in (
+            "I;16",
+            "I;16S",
+            "I;16L",
+            "I;16LS",
+            "I;16B",
+            "I;16BS",
+            "I;16N",
+            "I;16NS",
+        ):
+            modes[i16mode] = ModeDescriptor(i16mode, ("I",), "L", "L")
+        # set global mode cache atomically
+        _modes = modes
+    return _modes[mode]
diff --git a/.venv/lib/python3.7/site-packages/PIL/ImageMorph.py b/.venv/lib/python3.7/site-packages/PIL/ImageMorph.py
new file mode 100644
index 0000000..fe00837
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ImageMorph.py
@@ -0,0 +1,245 @@
+# A binary morphology add-on for the Python Imaging Library
+#
+# History:
+#   2014-06-04 Initial version.
+#
+# Copyright (c) 2014 Dov Grobgeld <dov.grobgeld@gmail.com>
+
+import re
+
+from . import Image, _imagingmorph
+
+LUT_SIZE = 1 << 9
+
+# fmt: off
+ROTATION_MATRIX = [
+    6, 3, 0,
+    7, 4, 1,
+    8, 5, 2,
+]
+MIRROR_MATRIX = [
+    2, 1, 0,
+    5, 4, 3,
+    8, 7, 6,
+]
+# fmt: on
+
+
+class LutBuilder:
+    """A class for building a MorphLut from a descriptive language
+
+    The input patterns is a list of a strings sequences like these::
+
+        4:(...
+           .1.
+           111)->1
+
+    (whitespaces including linebreaks are ignored). The option 4
+    describes a series of symmetry operations (in this case a
+    4-rotation), the pattern is described by:
+
+    - . or X - Ignore
+    - 1 - Pixel is on
+    - 0 - Pixel is off
+
+    The result of the operation is described after "->" string.
+
+    The default is to return the current pixel value, which is
+    returned if no other match is found.
+
+    Operations:
+
+    - 4 - 4 way rotation
+    - N - Negate
+    - 1 - Dummy op for no other operation (an op must always be given)
+    - M - Mirroring
+
+    Example::
+
+        lb = LutBuilder(patterns = ["4:(... .1. 111)->1"])
+        lut = lb.build_lut()
+
+    """
+
+    def __init__(self, patterns=None, op_name=None):
+        if patterns is not None:
+            self.patterns = patterns
+        else:
+            self.patterns = []
+        self.lut = None
+        if op_name is not None:
+            known_patterns = {
+                "corner": ["1:(... ... ...)->0", "4:(00. 01. ...)->1"],
+                "dilation4": ["4:(... .0. .1.)->1"],
+                "dilation8": ["4:(... .0. .1.)->1", "4:(... .0. ..1)->1"],
+                "erosion4": ["4:(... .1. .0.)->0"],
+                "erosion8": ["4:(... .1. .0.)->0", "4:(... .1. ..0)->0"],
+                "edge": [
+                    "1:(... ... ...)->0",
+                    "4:(.0. .1. ...)->1",
+                    "4:(01. .1. ...)->1",
+                ],
+            }
+            if op_name not in known_patterns:
+                raise Exception("Unknown pattern " + op_name + "!")
+
+            self.patterns = known_patterns[op_name]
+
+    def add_patterns(self, patterns):
+        self.patterns += patterns
+
+    def build_default_lut(self):
+        symbols = [0, 1]
+        m = 1 << 4  # pos of current pixel
+        self.lut = bytearray(symbols[(i & m) > 0] for i in range(LUT_SIZE))
+
+    def get_lut(self):
+        return self.lut
+
+    def _string_permute(self, pattern, permutation):
+        """string_permute takes a pattern and a permutation and returns the
+        string permuted according to the permutation list.
+        """
+        assert len(permutation) == 9
+        return "".join(pattern[p] for p in permutation)
+
+    def _pattern_permute(self, basic_pattern, options, basic_result):
+        """pattern_permute takes a basic pattern and its result and clones
+        the pattern according to the modifications described in the $options
+        parameter. It returns a list of all cloned patterns."""
+        patterns = [(basic_pattern, basic_result)]
+
+        # rotations
+        if "4" in options:
+            res = patterns[-1][1]
+            for i in range(4):
+                patterns.append(
+                    (self._string_permute(patterns[-1][0], ROTATION_MATRIX), res)
+                )
+        # mirror
+        if "M" in options:
+            n = len(patterns)
+            for pattern, res in patterns[0:n]:
+                patterns.append((self._string_permute(pattern, MIRROR_MATRIX), res))
+
+        # negate
+        if "N" in options:
+            n = len(patterns)
+            for pattern, res in patterns[0:n]:
+                # Swap 0 and 1
+                pattern = pattern.replace("0", "Z").replace("1", "0").replace("Z", "1")
+                res = 1 - int(res)
+                patterns.append((pattern, res))
+
+        return patterns
+
+    def build_lut(self):
+        """Compile all patterns into a morphology lut.
+
+        TBD :Build based on (file) morphlut:modify_lut
+        """
+        self.build_default_lut()
+        patterns = []
+
+        # Parse and create symmetries of the patterns strings
+        for p in self.patterns:
+            m = re.search(r"(\w*):?\s*\((.+?)\)\s*->\s*(\d)", p.replace("\n", ""))
+            if not m:
+                raise Exception('Syntax error in pattern "' + p + '"')
+            options = m.group(1)
+            pattern = m.group(2)
+            result = int(m.group(3))
+
+            # Get rid of spaces
+            pattern = pattern.replace(" ", "").replace("\n", "")
+
+            patterns += self._pattern_permute(pattern, options, result)
+
+        # compile the patterns into regular expressions for speed
+        for i, pattern in enumerate(patterns):
+            p = pattern[0].replace(".", "X").replace("X", "[01]")
+            p = re.compile(p)
+            patterns[i] = (p, pattern[1])
+
+        # Step through table and find patterns that match.
+        # Note that all the patterns are searched. The last one
+        # caught overrides
+        for i in range(LUT_SIZE):
+            # Build the bit pattern
+            bitpattern = bin(i)[2:]
+            bitpattern = ("0" * (9 - len(bitpattern)) + bitpattern)[::-1]
+
+            for p, r in patterns:
+                if p.match(bitpattern):
+                    self.lut[i] = [0, 1][r]
+
+        return self.lut
+
+
+class MorphOp:
+    """A class for binary morphological operators"""
+
+    def __init__(self, lut=None, op_name=None, patterns=None):
+        """Create a binary morphological operator"""
+        self.lut = lut
+        if op_name is not None:
+            self.lut = LutBuilder(op_name=op_name).build_lut()
+        elif patterns is not None:
+            self.lut = LutBuilder(patterns=patterns).build_lut()
+
+    def apply(self, image):
+        """Run a single morphological operation on an image
+
+        Returns a tuple of the number of changed pixels and the
+        morphed image"""
+        if self.lut is None:
+            raise Exception("No operator loaded")
+
+        if image.mode != "L":
+            raise ValueError("Image mode must be L")
+        outimage = Image.new(image.mode, image.size, None)
+        count = _imagingmorph.apply(bytes(self.lut), image.im.id, outimage.im.id)
+        return count, outimage
+
+    def match(self, image):
+        """Get a list of coordinates matching the morphological operation on
+        an image.
+
+        Returns a list of tuples of (x,y) coordinates
+        of all matching pixels. See :ref:`coordinate-system`."""
+        if self.lut is None:
+            raise Exception("No operator loaded")
+
+        if image.mode != "L":
+            raise ValueError("Image mode must be L")
+        return _imagingmorph.match(bytes(self.lut), image.im.id)
+
+    def get_on_pixels(self, image):
+        """Get a list of all turned on pixels in a binary image
+
+        Returns a list of tuples of (x,y) coordinates
+        of all matching pixels. See :ref:`coordinate-system`."""
+
+        if image.mode != "L":
+            raise ValueError("Image mode must be L")
+        return _imagingmorph.get_on_pixels(image.im.id)
+
+    def load_lut(self, filename):
+        """Load an operator from an mrl file"""
+        with open(filename, "rb") as f:
+            self.lut = bytearray(f.read())
+
+        if len(self.lut) != LUT_SIZE:
+            self.lut = None
+            raise Exception("Wrong size operator file!")
+
+    def save_lut(self, filename):
+        """Save an operator to an mrl file"""
+        if self.lut is None:
+            raise Exception("No operator loaded")
+        with open(filename, "wb") as f:
+            f.write(self.lut)
+
+    def set_lut(self, lut):
+        """Set the lut from an external source"""
+        self.lut = lut
diff --git a/.venv/lib/python3.7/site-packages/PIL/ImageOps.py b/.venv/lib/python3.7/site-packages/PIL/ImageOps.py
new file mode 100644
index 0000000..b170e9d
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ImageOps.py
@@ -0,0 +1,608 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# standard image operations
+#
+# History:
+# 2001-10-20 fl   Created
+# 2001-10-23 fl   Added autocontrast operator
+# 2001-12-18 fl   Added Kevin's fit operator
+# 2004-03-14 fl   Fixed potential division by zero in equalize
+# 2005-05-05 fl   Fixed equalize for low number of values
+#
+# Copyright (c) 2001-2004 by Secret Labs AB
+# Copyright (c) 2001-2004 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+import functools
+import operator
+import re
+
+from . import Image
+
+#
+# helpers
+
+
+def _border(border):
+    if isinstance(border, tuple):
+        if len(border) == 2:
+            left, top = right, bottom = border
+        elif len(border) == 4:
+            left, top, right, bottom = border
+    else:
+        left = top = right = bottom = border
+    return left, top, right, bottom
+
+
+def _color(color, mode):
+    if isinstance(color, str):
+        from . import ImageColor
+
+        color = ImageColor.getcolor(color, mode)
+    return color
+
+
+def _lut(image, lut):
+    if image.mode == "P":
+        # FIXME: apply to lookup table, not image data
+        raise NotImplementedError("mode P support coming soon")
+    elif image.mode in ("L", "RGB"):
+        if image.mode == "RGB" and len(lut) == 256:
+            lut = lut + lut + lut
+        return image.point(lut)
+    else:
+        raise OSError("not supported for this image mode")
+
+
+#
+# actions
+
+
+def autocontrast(image, cutoff=0, ignore=None, mask=None, preserve_tone=False):
+    """
+    Maximize (normalize) image contrast. This function calculates a
+    histogram of the input image (or mask region), removes ``cutoff`` percent of the
+    lightest and darkest pixels from the histogram, and remaps the image
+    so that the darkest pixel becomes black (0), and the lightest
+    becomes white (255).
+
+    :param image: The image to process.
+    :param cutoff: The percent to cut off from the histogram on the low and
+                   high ends. Either a tuple of (low, high), or a single
+                   number for both.
+    :param ignore: The background pixel value (use None for no background).
+    :param mask: Histogram used in contrast operation is computed using pixels
+                 within the mask. If no mask is given the entire image is used
+                 for histogram computation.
+    :param preserve_tone: Preserve image tone in Photoshop-like style autocontrast.
+
+                          .. versionadded:: 8.2.0
+
+    :return: An image.
+    """
+    if preserve_tone:
+        histogram = image.convert("L").histogram(mask)
+    else:
+        histogram = image.histogram(mask)
+
+    lut = []
+    for layer in range(0, len(histogram), 256):
+        h = histogram[layer : layer + 256]
+        if ignore is not None:
+            # get rid of outliers
+            try:
+                h[ignore] = 0
+            except TypeError:
+                # assume sequence
+                for ix in ignore:
+                    h[ix] = 0
+        if cutoff:
+            # cut off pixels from both ends of the histogram
+            if not isinstance(cutoff, tuple):
+                cutoff = (cutoff, cutoff)
+            # get number of pixels
+            n = 0
+            for ix in range(256):
+                n = n + h[ix]
+            # remove cutoff% pixels from the low end
+            cut = n * cutoff[0] // 100
+            for lo in range(256):
+                if cut > h[lo]:
+                    cut = cut - h[lo]
+                    h[lo] = 0
+                else:
+                    h[lo] -= cut
+                    cut = 0
+                if cut <= 0:
+                    break
+            # remove cutoff% samples from the high end
+            cut = n * cutoff[1] // 100
+            for hi in range(255, -1, -1):
+                if cut > h[hi]:
+                    cut = cut - h[hi]
+                    h[hi] = 0
+                else:
+                    h[hi] -= cut
+                    cut = 0
+                if cut <= 0:
+                    break
+        # find lowest/highest samples after preprocessing
+        for lo in range(256):
+            if h[lo]:
+                break
+        for hi in range(255, -1, -1):
+            if h[hi]:
+                break
+        if hi <= lo:
+            # don't bother
+            lut.extend(list(range(256)))
+        else:
+            scale = 255.0 / (hi - lo)
+            offset = -lo * scale
+            for ix in range(256):
+                ix = int(ix * scale + offset)
+                if ix < 0:
+                    ix = 0
+                elif ix > 255:
+                    ix = 255
+                lut.append(ix)
+    return _lut(image, lut)
+
+
+def colorize(image, black, white, mid=None, blackpoint=0, whitepoint=255, midpoint=127):
+    """
+    Colorize grayscale image.
+    This function calculates a color wedge which maps all black pixels in
+    the source image to the first color and all white pixels to the
+    second color. If ``mid`` is specified, it uses three-color mapping.
+    The ``black`` and ``white`` arguments should be RGB tuples or color names;
+    optionally you can use three-color mapping by also specifying ``mid``.
+    Mapping positions for any of the colors can be specified
+    (e.g. ``blackpoint``), where these parameters are the integer
+    value corresponding to where the corresponding color should be mapped.
+    These parameters must have logical order, such that
+    ``blackpoint <= midpoint <= whitepoint`` (if ``mid`` is specified).
+
+    :param image: The image to colorize.
+    :param black: The color to use for black input pixels.
+    :param white: The color to use for white input pixels.
+    :param mid: The color to use for midtone input pixels.
+    :param blackpoint: an int value [0, 255] for the black mapping.
+    :param whitepoint: an int value [0, 255] for the white mapping.
+    :param midpoint: an int value [0, 255] for the midtone mapping.
+    :return: An image.
+    """
+
+    # Initial asserts
+    assert image.mode == "L"
+    if mid is None:
+        assert 0 <= blackpoint <= whitepoint <= 255
+    else:
+        assert 0 <= blackpoint <= midpoint <= whitepoint <= 255
+
+    # Define colors from arguments
+    black = _color(black, "RGB")
+    white = _color(white, "RGB")
+    if mid is not None:
+        mid = _color(mid, "RGB")
+
+    # Empty lists for the mapping
+    red = []
+    green = []
+    blue = []
+
+    # Create the low-end values
+    for i in range(0, blackpoint):
+        red.append(black[0])
+        green.append(black[1])
+        blue.append(black[2])
+
+    # Create the mapping (2-color)
+    if mid is None:
+
+        range_map = range(0, whitepoint - blackpoint)
+
+        for i in range_map:
+            red.append(black[0] + i * (white[0] - black[0]) // len(range_map))
+            green.append(black[1] + i * (white[1] - black[1]) // len(range_map))
+            blue.append(black[2] + i * (white[2] - black[2]) // len(range_map))
+
+    # Create the mapping (3-color)
+    else:
+
+        range_map1 = range(0, midpoint - blackpoint)
+        range_map2 = range(0, whitepoint - midpoint)
+
+        for i in range_map1:
+            red.append(black[0] + i * (mid[0] - black[0]) // len(range_map1))
+            green.append(black[1] + i * (mid[1] - black[1]) // len(range_map1))
+            blue.append(black[2] + i * (mid[2] - black[2]) // len(range_map1))
+        for i in range_map2:
+            red.append(mid[0] + i * (white[0] - mid[0]) // len(range_map2))
+            green.append(mid[1] + i * (white[1] - mid[1]) // len(range_map2))
+            blue.append(mid[2] + i * (white[2] - mid[2]) // len(range_map2))
+
+    # Create the high-end values
+    for i in range(0, 256 - whitepoint):
+        red.append(white[0])
+        green.append(white[1])
+        blue.append(white[2])
+
+    # Return converted image
+    image = image.convert("RGB")
+    return _lut(image, red + green + blue)
+
+
+def contain(image, size, method=Image.BICUBIC):
+    """
+    Returns a resized version of the image, set to the maximum width and height
+    within the requested size, while maintaining the original aspect ratio.
+
+    :param image: The image to resize and crop.
+    :param size: The requested output size in pixels, given as a
+                 (width, height) tuple.
+    :param method: Resampling method to use. Default is
+                   :py:attr:`PIL.Image.BICUBIC`. See :ref:`concept-filters`.
+    :return: An image.
+    """
+
+    im_ratio = image.width / image.height
+    dest_ratio = size[0] / size[1]
+
+    if im_ratio != dest_ratio:
+        if im_ratio > dest_ratio:
+            new_height = int(image.height / image.width * size[0])
+            if new_height != size[1]:
+                size = (size[0], new_height)
+        else:
+            new_width = int(image.width / image.height * size[1])
+            if new_width != size[0]:
+                size = (new_width, size[1])
+    return image.resize(size, resample=method)
+
+
+def pad(image, size, method=Image.BICUBIC, color=None, centering=(0.5, 0.5)):
+    """
+    Returns a resized and padded version of the image, expanded to fill the
+    requested aspect ratio and size.
+
+    :param image: The image to resize and crop.
+    :param size: The requested output size in pixels, given as a
+                 (width, height) tuple.
+    :param method: Resampling method to use. Default is
+                   :py:attr:`PIL.Image.BICUBIC`. See :ref:`concept-filters`.
+    :param color: The background color of the padded image.
+    :param centering: Control the position of the original image within the
+                      padded version.
+
+                          (0.5, 0.5) will keep the image centered
+                          (0, 0) will keep the image aligned to the top left
+                          (1, 1) will keep the image aligned to the bottom
+                          right
+    :return: An image.
+    """
+
+    resized = contain(image, size, method)
+    if resized.size == size:
+        out = resized
+    else:
+        out = Image.new(image.mode, size, color)
+        if resized.width != size[0]:
+            x = int((size[0] - resized.width) * max(0, min(centering[0], 1)))
+            out.paste(resized, (x, 0))
+        else:
+            y = int((size[1] - resized.height) * max(0, min(centering[1], 1)))
+            out.paste(resized, (0, y))
+    return out
+
+
+def crop(image, border=0):
+    """
+    Remove border from image.  The same amount of pixels are removed
+    from all four sides.  This function works on all image modes.
+
+    .. seealso:: :py:meth:`~PIL.Image.Image.crop`
+
+    :param image: The image to crop.
+    :param border: The number of pixels to remove.
+    :return: An image.
+    """
+    left, top, right, bottom = _border(border)
+    return image.crop((left, top, image.size[0] - right, image.size[1] - bottom))
+
+
+def scale(image, factor, resample=Image.BICUBIC):
+    """
+    Returns a rescaled image by a specific factor given in parameter.
+    A factor greater than 1 expands the image, between 0 and 1 contracts the
+    image.
+
+    :param image: The image to rescale.
+    :param factor: The expansion factor, as a float.
+    :param resample: Resampling method to use. Default is
+                     :py:attr:`PIL.Image.BICUBIC`. See :ref:`concept-filters`.
+    :returns: An :py:class:`~PIL.Image.Image` object.
+    """
+    if factor == 1:
+        return image.copy()
+    elif factor <= 0:
+        raise ValueError("the factor must be greater than 0")
+    else:
+        size = (round(factor * image.width), round(factor * image.height))
+        return image.resize(size, resample)
+
+
+def deform(image, deformer, resample=Image.BILINEAR):
+    """
+    Deform the image.
+
+    :param image: The image to deform.
+    :param deformer: A deformer object.  Any object that implements a
+                    ``getmesh`` method can be used.
+    :param resample: An optional resampling filter. Same values possible as
+       in the PIL.Image.transform function.
+    :return: An image.
+    """
+    return image.transform(image.size, Image.MESH, deformer.getmesh(image), resample)
+
+
+def equalize(image, mask=None):
+    """
+    Equalize the image histogram. This function applies a non-linear
+    mapping to the input image, in order to create a uniform
+    distribution of grayscale values in the output image.
+
+    :param image: The image to equalize.
+    :param mask: An optional mask.  If given, only the pixels selected by
+                 the mask are included in the analysis.
+    :return: An image.
+    """
+    if image.mode == "P":
+        image = image.convert("RGB")
+    h = image.histogram(mask)
+    lut = []
+    for b in range(0, len(h), 256):
+        histo = [_f for _f in h[b : b + 256] if _f]
+        if len(histo) <= 1:
+            lut.extend(list(range(256)))
+        else:
+            step = (functools.reduce(operator.add, histo) - histo[-1]) // 255
+            if not step:
+                lut.extend(list(range(256)))
+            else:
+                n = step // 2
+                for i in range(256):
+                    lut.append(n // step)
+                    n = n + h[i + b]
+    return _lut(image, lut)
+
+
+def expand(image, border=0, fill=0):
+    """
+    Add border to the image
+
+    :param image: The image to expand.
+    :param border: Border width, in pixels.
+    :param fill: Pixel fill value (a color value).  Default is 0 (black).
+    :return: An image.
+    """
+    left, top, right, bottom = _border(border)
+    width = left + image.size[0] + right
+    height = top + image.size[1] + bottom
+    color = _color(fill, image.mode)
+    if image.mode == "P" and image.palette:
+        image.load()
+        palette = image.palette.copy()
+        if isinstance(color, tuple):
+            color = palette.getcolor(color)
+    else:
+        palette = None
+    out = Image.new(image.mode, (width, height), color)
+    if palette:
+        out.putpalette(palette.palette)
+    out.paste(image, (left, top))
+    return out
+
+
+def fit(image, size, method=Image.BICUBIC, bleed=0.0, centering=(0.5, 0.5)):
+    """
+    Returns a resized and cropped version of the image, cropped to the
+    requested aspect ratio and size.
+
+    This function was contributed by Kevin Cazabon.
+
+    :param image: The image to resize and crop.
+    :param size: The requested output size in pixels, given as a
+                 (width, height) tuple.
+    :param method: Resampling method to use. Default is
+                   :py:attr:`PIL.Image.BICUBIC`. See :ref:`concept-filters`.
+    :param bleed: Remove a border around the outside of the image from all
+                  four edges. The value is a decimal percentage (use 0.01 for
+                  one percent). The default value is 0 (no border).
+                  Cannot be greater than or equal to 0.5.
+    :param centering: Control the cropping position.  Use (0.5, 0.5) for
+                      center cropping (e.g. if cropping the width, take 50% off
+                      of the left side, and therefore 50% off the right side).
+                      (0.0, 0.0) will crop from the top left corner (i.e. if
+                      cropping the width, take all of the crop off of the right
+                      side, and if cropping the height, take all of it off the
+                      bottom).  (1.0, 0.0) will crop from the bottom left
+                      corner, etc. (i.e. if cropping the width, take all of the
+                      crop off the left side, and if cropping the height take
+                      none from the top, and therefore all off the bottom).
+    :return: An image.
+    """
+
+    # by Kevin Cazabon, Feb 17/2000
+    # kevin@cazabon.com
+    # https://www.cazabon.com
+
+    # ensure centering is mutable
+    centering = list(centering)
+
+    if not 0.0 <= centering[0] <= 1.0:
+        centering[0] = 0.5
+    if not 0.0 <= centering[1] <= 1.0:
+        centering[1] = 0.5
+
+    if not 0.0 <= bleed < 0.5:
+        bleed = 0.0
+
+    # calculate the area to use for resizing and cropping, subtracting
+    # the 'bleed' around the edges
+
+    # number of pixels to trim off on Top and Bottom, Left and Right
+    bleed_pixels = (bleed * image.size[0], bleed * image.size[1])
+
+    live_size = (
+        image.size[0] - bleed_pixels[0] * 2,
+        image.size[1] - bleed_pixels[1] * 2,
+    )
+
+    # calculate the aspect ratio of the live_size
+    live_size_ratio = live_size[0] / live_size[1]
+
+    # calculate the aspect ratio of the output image
+    output_ratio = size[0] / size[1]
+
+    # figure out if the sides or top/bottom will be cropped off
+    if live_size_ratio == output_ratio:
+        # live_size is already the needed ratio
+        crop_width = live_size[0]
+        crop_height = live_size[1]
+    elif live_size_ratio >= output_ratio:
+        # live_size is wider than what's needed, crop the sides
+        crop_width = output_ratio * live_size[1]
+        crop_height = live_size[1]
+    else:
+        # live_size is taller than what's needed, crop the top and bottom
+        crop_width = live_size[0]
+        crop_height = live_size[0] / output_ratio
+
+    # make the crop
+    crop_left = bleed_pixels[0] + (live_size[0] - crop_width) * centering[0]
+    crop_top = bleed_pixels[1] + (live_size[1] - crop_height) * centering[1]
+
+    crop = (crop_left, crop_top, crop_left + crop_width, crop_top + crop_height)
+
+    # resize the image and return it
+    return image.resize(size, method, box=crop)
+
+
+def flip(image):
+    """
+    Flip the image vertically (top to bottom).
+
+    :param image: The image to flip.
+    :return: An image.
+    """
+    return image.transpose(Image.FLIP_TOP_BOTTOM)
+
+
+def grayscale(image):
+    """
+    Convert the image to grayscale.
+
+    :param image: The image to convert.
+    :return: An image.
+    """
+    return image.convert("L")
+
+
+def invert(image):
+    """
+    Invert (negate) the image.
+
+    :param image: The image to invert.
+    :return: An image.
+    """
+    lut = []
+    for i in range(256):
+        lut.append(255 - i)
+    return _lut(image, lut)
+
+
+def mirror(image):
+    """
+    Flip image horizontally (left to right).
+
+    :param image: The image to mirror.
+    :return: An image.
+    """
+    return image.transpose(Image.FLIP_LEFT_RIGHT)
+
+
+def posterize(image, bits):
+    """
+    Reduce the number of bits for each color channel.
+
+    :param image: The image to posterize.
+    :param bits: The number of bits to keep for each channel (1-8).
+    :return: An image.
+    """
+    lut = []
+    mask = ~(2 ** (8 - bits) - 1)
+    for i in range(256):
+        lut.append(i & mask)
+    return _lut(image, lut)
+
+
+def solarize(image, threshold=128):
+    """
+    Invert all pixel values above a threshold.
+
+    :param image: The image to solarize.
+    :param threshold: All pixels above this greyscale level are inverted.
+    :return: An image.
+    """
+    lut = []
+    for i in range(256):
+        if i < threshold:
+            lut.append(i)
+        else:
+            lut.append(255 - i)
+    return _lut(image, lut)
+
+
+def exif_transpose(image):
+    """
+    If an image has an EXIF Orientation tag, return a new image that is
+    transposed accordingly. Otherwise, return a copy of the image.
+
+    :param image: The image to transpose.
+    :return: An image.
+    """
+    exif = image.getexif()
+    orientation = exif.get(0x0112)
+    method = {
+        2: Image.FLIP_LEFT_RIGHT,
+        3: Image.ROTATE_180,
+        4: Image.FLIP_TOP_BOTTOM,
+        5: Image.TRANSPOSE,
+        6: Image.ROTATE_270,
+        7: Image.TRANSVERSE,
+        8: Image.ROTATE_90,
+    }.get(orientation)
+    if method is not None:
+        transposed_image = image.transpose(method)
+        transposed_exif = transposed_image.getexif()
+        if 0x0112 in transposed_exif:
+            del transposed_exif[0x0112]
+            if "exif" in transposed_image.info:
+                transposed_image.info["exif"] = transposed_exif.tobytes()
+            elif "Raw profile type exif" in transposed_image.info:
+                transposed_image.info[
+                    "Raw profile type exif"
+                ] = transposed_exif.tobytes().hex()
+            elif "XML:com.adobe.xmp" in transposed_image.info:
+                transposed_image.info["XML:com.adobe.xmp"] = re.sub(
+                    r'tiff:Orientation="([0-9])"',
+                    "",
+                    transposed_image.info["XML:com.adobe.xmp"],
+                )
+        return transposed_image
+    return image.copy()
diff --git a/.venv/lib/python3.7/site-packages/PIL/ImagePalette.py b/.venv/lib/python3.7/site-packages/PIL/ImagePalette.py
new file mode 100644
index 0000000..1e0d36b
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ImagePalette.py
@@ -0,0 +1,261 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# image palette object
+#
+# History:
+# 1996-03-11 fl   Rewritten.
+# 1997-01-03 fl   Up and running.
+# 1997-08-23 fl   Added load hack
+# 2001-04-16 fl   Fixed randint shadow bug in random()
+#
+# Copyright (c) 1997-2001 by Secret Labs AB
+# Copyright (c) 1996-1997 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+import array
+import warnings
+
+from . import GimpGradientFile, GimpPaletteFile, ImageColor, PaletteFile
+
+
+class ImagePalette:
+    """
+    Color palette for palette mapped images
+
+    :param mode: The mode to use for the palette. See:
+        :ref:`concept-modes`. Defaults to "RGB"
+    :param palette: An optional palette. If given, it must be a bytearray,
+        an array or a list of ints between 0-255. The list must consist of
+        all channels for one color followed by the next color (e.g. RGBRGBRGB).
+        Defaults to an empty palette.
+    :param size: An optional palette size. If given, an error is raised
+        if ``palette`` is not of equal length.
+    """
+
+    def __init__(self, mode="RGB", palette=None, size=0):
+        self.mode = mode
+        self.rawmode = None  # if set, palette contains raw data
+        self.palette = palette or bytearray()
+        self.dirty = None
+        if size != 0:
+            warnings.warn(
+                "The size parameter is deprecated and will be removed in Pillow 10 "
+                "(2023-07-01).",
+                DeprecationWarning,
+            )
+            if size != len(self.palette):
+                raise ValueError("wrong palette size")
+
+    @property
+    def palette(self):
+        return self._palette
+
+    @palette.setter
+    def palette(self, palette):
+        self._palette = palette
+
+        mode_len = len(self.mode)
+        self.colors = {}
+        for i in range(0, len(self.palette), mode_len):
+            color = tuple(self.palette[i : i + mode_len])
+            if color in self.colors:
+                continue
+            self.colors[color] = i // mode_len
+
+    def copy(self):
+        new = ImagePalette()
+
+        new.mode = self.mode
+        new.rawmode = self.rawmode
+        if self.palette is not None:
+            new.palette = self.palette[:]
+        new.dirty = self.dirty
+
+        return new
+
+    def getdata(self):
+        """
+        Get palette contents in format suitable for the low-level
+        ``im.putpalette`` primitive.
+
+        .. warning:: This method is experimental.
+        """
+        if self.rawmode:
+            return self.rawmode, self.palette
+        return self.mode, self.tobytes()
+
+    def tobytes(self):
+        """Convert palette to bytes.
+
+        .. warning:: This method is experimental.
+        """
+        if self.rawmode:
+            raise ValueError("palette contains raw palette data")
+        if isinstance(self.palette, bytes):
+            return self.palette
+        arr = array.array("B", self.palette)
+        return arr.tobytes()
+
+    # Declare tostring as an alias for tobytes
+    tostring = tobytes
+
+    def getcolor(self, color, image=None):
+        """Given an rgb tuple, allocate palette entry.
+
+        .. warning:: This method is experimental.
+        """
+        if self.rawmode:
+            raise ValueError("palette contains raw palette data")
+        if isinstance(color, tuple):
+            if self.mode == "RGB":
+                if len(color) == 4 and color[3] == 255:
+                    color = color[:3]
+            elif self.mode == "RGBA":
+                if len(color) == 3:
+                    color += (255,)
+            try:
+                return self.colors[color]
+            except KeyError as e:
+                # allocate new color slot
+                if not isinstance(self.palette, bytearray):
+                    self._palette = bytearray(self.palette)
+                index = len(self.palette) // 3
+                special_colors = ()
+                if image:
+                    special_colors = (
+                        image.info.get("background"),
+                        image.info.get("transparency"),
+                    )
+                while index in special_colors:
+                    index += 1
+                if index >= 256:
+                    if image:
+                        # Search for an unused index
+                        for i, count in reversed(list(enumerate(image.histogram()))):
+                            if count == 0 and i not in special_colors:
+                                index = i
+                                break
+                    if index >= 256:
+                        raise ValueError("cannot allocate more than 256 colors") from e
+                self.colors[color] = index
+                if index * 3 < len(self.palette):
+                    self._palette = (
+                        self.palette[: index * 3]
+                        + bytes(color)
+                        + self.palette[index * 3 + 3 :]
+                    )
+                else:
+                    self._palette += bytes(color)
+                self.dirty = 1
+                return index
+        else:
+            raise ValueError(f"unknown color specifier: {repr(color)}")
+
+    def save(self, fp):
+        """Save palette to text file.
+
+        .. warning:: This method is experimental.
+        """
+        if self.rawmode:
+            raise ValueError("palette contains raw palette data")
+        if isinstance(fp, str):
+            fp = open(fp, "w")
+        fp.write("# Palette\n")
+        fp.write(f"# Mode: {self.mode}\n")
+        for i in range(256):
+            fp.write(f"{i}")
+            for j in range(i * len(self.mode), (i + 1) * len(self.mode)):
+                try:
+                    fp.write(f" {self.palette[j]}")
+                except IndexError:
+                    fp.write(" 0")
+            fp.write("\n")
+        fp.close()
+
+
+# --------------------------------------------------------------------
+# Internal
+
+
+def raw(rawmode, data):
+    palette = ImagePalette()
+    palette.rawmode = rawmode
+    palette.palette = data
+    palette.dirty = 1
+    return palette
+
+
+# --------------------------------------------------------------------
+# Factories
+
+
+def make_linear_lut(black, white):
+    lut = []
+    if black == 0:
+        for i in range(256):
+            lut.append(white * i // 255)
+    else:
+        raise NotImplementedError  # FIXME
+    return lut
+
+
+def make_gamma_lut(exp):
+    lut = []
+    for i in range(256):
+        lut.append(int(((i / 255.0) ** exp) * 255.0 + 0.5))
+    return lut
+
+
+def negative(mode="RGB"):
+    palette = list(range(256 * len(mode)))
+    palette.reverse()
+    return ImagePalette(mode, [i // len(mode) for i in palette])
+
+
+def random(mode="RGB"):
+    from random import randint
+
+    palette = []
+    for i in range(256 * len(mode)):
+        palette.append(randint(0, 255))
+    return ImagePalette(mode, palette)
+
+
+def sepia(white="#fff0c0"):
+    bands = [make_linear_lut(0, band) for band in ImageColor.getrgb(white)]
+    return ImagePalette("RGB", [bands[i % 3][i // 3] for i in range(256 * 3)])
+
+
+def wedge(mode="RGB"):
+    palette = list(range(256 * len(mode)))
+    return ImagePalette(mode, [i // len(mode) for i in palette])
+
+
+def load(filename):
+
+    # FIXME: supports GIMP gradients only
+
+    with open(filename, "rb") as fp:
+
+        for paletteHandler in [
+            GimpPaletteFile.GimpPaletteFile,
+            GimpGradientFile.GimpGradientFile,
+            PaletteFile.PaletteFile,
+        ]:
+            try:
+                fp.seek(0)
+                lut = paletteHandler(fp).getpalette()
+                if lut:
+                    break
+            except (SyntaxError, ValueError):
+                # import traceback
+                # traceback.print_exc()
+                pass
+        else:
+            raise OSError("cannot load palette")
+
+    return lut  # data, rawmode
diff --git a/.venv/lib/python3.7/site-packages/PIL/ImagePath.py b/.venv/lib/python3.7/site-packages/PIL/ImagePath.py
new file mode 100644
index 0000000..3d3538c
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ImagePath.py
@@ -0,0 +1,19 @@
+#
+# The Python Imaging Library
+# $Id$
+#
+# path interface
+#
+# History:
+# 1996-11-04 fl   Created
+# 2002-04-14 fl   Added documentation stub class
+#
+# Copyright (c) Secret Labs AB 1997.
+# Copyright (c) Fredrik Lundh 1996.
+#
+# See the README file for information on usage and redistribution.
+#
+
+from . import Image
+
+Path = Image.core.path
diff --git a/.venv/lib/python3.7/site-packages/PIL/ImageQt.py b/.venv/lib/python3.7/site-packages/PIL/ImageQt.py
new file mode 100644
index 0000000..db8fa0f
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ImageQt.py
@@ -0,0 +1,223 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# a simple Qt image interface.
+#
+# history:
+# 2006-06-03 fl: created
+# 2006-06-04 fl: inherit from QImage instead of wrapping it
+# 2006-06-05 fl: removed toimage helper; move string support to ImageQt
+# 2013-11-13 fl: add support for Qt5 (aurelien.ballier@cyclonit.com)
+#
+# Copyright (c) 2006 by Secret Labs AB
+# Copyright (c) 2006 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+import sys
+from io import BytesIO
+
+from . import Image
+from ._util import isPath
+
+qt_versions = [
+    ["6", "PyQt6"],
+    ["side6", "PySide6"],
+    ["5", "PyQt5"],
+    ["side2", "PySide2"],
+]
+
+# If a version has already been imported, attempt it first
+qt_versions.sort(key=lambda qt_version: qt_version[1] in sys.modules, reverse=True)
+for qt_version, qt_module in qt_versions:
+    try:
+        if qt_module == "PyQt6":
+            from PyQt6.QtCore import QBuffer, QIODevice
+            from PyQt6.QtGui import QImage, QPixmap, qRgba
+        elif qt_module == "PySide6":
+            from PySide6.QtCore import QBuffer, QIODevice
+            from PySide6.QtGui import QImage, QPixmap, qRgba
+        elif qt_module == "PyQt5":
+            from PyQt5.QtCore import QBuffer, QIODevice
+            from PyQt5.QtGui import QImage, QPixmap, qRgba
+        elif qt_module == "PySide2":
+            from PySide2.QtCore import QBuffer, QIODevice
+            from PySide2.QtGui import QImage, QPixmap, qRgba
+    except (ImportError, RuntimeError):
+        continue
+    qt_is_installed = True
+    break
+else:
+    qt_is_installed = False
+    qt_version = None
+
+
+def rgb(r, g, b, a=255):
+    """(Internal) Turns an RGB color into a Qt compatible color integer."""
+    # use qRgb to pack the colors, and then turn the resulting long
+    # into a negative integer with the same bitpattern.
+    return qRgba(r, g, b, a) & 0xFFFFFFFF
+
+
+def fromqimage(im):
+    """
+    :param im: QImage or PIL ImageQt object
+    """
+    buffer = QBuffer()
+    if qt_version == "6":
+        try:
+            qt_openmode = QIODevice.OpenModeFlag
+        except AttributeError:
+            qt_openmode = QIODevice.OpenMode
+    else:
+        qt_openmode = QIODevice
+    buffer.open(qt_openmode.ReadWrite)
+    # preserve alpha channel with png
+    # otherwise ppm is more friendly with Image.open
+    if im.hasAlphaChannel():
+        im.save(buffer, "png")
+    else:
+        im.save(buffer, "ppm")
+
+    b = BytesIO()
+    b.write(buffer.data())
+    buffer.close()
+    b.seek(0)
+
+    return Image.open(b)
+
+
+def fromqpixmap(im):
+    return fromqimage(im)
+    # buffer = QBuffer()
+    # buffer.open(QIODevice.ReadWrite)
+    # # im.save(buffer)
+    # # What if png doesn't support some image features like animation?
+    # im.save(buffer, 'ppm')
+    # bytes_io = BytesIO()
+    # bytes_io.write(buffer.data())
+    # buffer.close()
+    # bytes_io.seek(0)
+    # return Image.open(bytes_io)
+
+
+def align8to32(bytes, width, mode):
+    """
+    converts each scanline of data from 8 bit to 32 bit aligned
+    """
+
+    bits_per_pixel = {"1": 1, "L": 8, "P": 8, "I;16": 16}[mode]
+
+    # calculate bytes per line and the extra padding if needed
+    bits_per_line = bits_per_pixel * width
+    full_bytes_per_line, remaining_bits_per_line = divmod(bits_per_line, 8)
+    bytes_per_line = full_bytes_per_line + (1 if remaining_bits_per_line else 0)
+
+    extra_padding = -bytes_per_line % 4
+
+    # already 32 bit aligned by luck
+    if not extra_padding:
+        return bytes
+
+    new_data = []
+    for i in range(len(bytes) // bytes_per_line):
+        new_data.append(
+            bytes[i * bytes_per_line : (i + 1) * bytes_per_line]
+            + b"\x00" * extra_padding
+        )
+
+    return b"".join(new_data)
+
+
+def _toqclass_helper(im):
+    data = None
+    colortable = None
+    exclusive_fp = False
+
+    # handle filename, if given instead of image name
+    if hasattr(im, "toUtf8"):
+        # FIXME - is this really the best way to do this?
+        im = str(im.toUtf8(), "utf-8")
+    if isPath(im):
+        im = Image.open(im)
+        exclusive_fp = True
+
+    qt_format = QImage.Format if qt_version == "6" else QImage
+    if im.mode == "1":
+        format = qt_format.Format_Mono
+    elif im.mode == "L":
+        format = qt_format.Format_Indexed8
+        colortable = []
+        for i in range(256):
+            colortable.append(rgb(i, i, i))
+    elif im.mode == "P":
+        format = qt_format.Format_Indexed8
+        colortable = []
+        palette = im.getpalette()
+        for i in range(0, len(palette), 3):
+            colortable.append(rgb(*palette[i : i + 3]))
+    elif im.mode == "RGB":
+        # Populate the 4th channel with 255
+        im = im.convert("RGBA")
+
+        data = im.tobytes("raw", "BGRA")
+        format = qt_format.Format_RGB32
+    elif im.mode == "RGBA":
+        data = im.tobytes("raw", "BGRA")
+        format = qt_format.Format_ARGB32
+    elif im.mode == "I;16" and hasattr(qt_format, "Format_Grayscale16"):  # Qt 5.13+
+        im = im.point(lambda i: i * 256)
+
+        format = qt_format.Format_Grayscale16
+    else:
+        if exclusive_fp:
+            im.close()
+        raise ValueError(f"unsupported image mode {repr(im.mode)}")
+
+    size = im.size
+    __data = data or align8to32(im.tobytes(), size[0], im.mode)
+    if exclusive_fp:
+        im.close()
+    return {"data": __data, "size": size, "format": format, "colortable": colortable}
+
+
+if qt_is_installed:
+
+    class ImageQt(QImage):
+        def __init__(self, im):
+            """
+            An PIL image wrapper for Qt.  This is a subclass of PyQt's QImage
+            class.
+
+            :param im: A PIL Image object, or a file name (given either as
+                Python string or a PyQt string object).
+            """
+            im_data = _toqclass_helper(im)
+            # must keep a reference, or Qt will crash!
+            # All QImage constructors that take data operate on an existing
+            # buffer, so this buffer has to hang on for the life of the image.
+            # Fixes https://github.com/python-pillow/Pillow/issues/1370
+            self.__data = im_data["data"]
+            super().__init__(
+                self.__data,
+                im_data["size"][0],
+                im_data["size"][1],
+                im_data["format"],
+            )
+            if im_data["colortable"]:
+                self.setColorTable(im_data["colortable"])
+
+
+def toqimage(im):
+    return ImageQt(im)
+
+
+def toqpixmap(im):
+    # # This doesn't work. For now using a dumb approach.
+    # im_data = _toqclass_helper(im)
+    # result = QPixmap(im_data["size"][0], im_data["size"][1])
+    # result.loadFromData(im_data["data"])
+    qimage = toqimage(im)
+    return QPixmap.fromImage(qimage)
diff --git a/.venv/lib/python3.7/site-packages/PIL/ImageSequence.py b/.venv/lib/python3.7/site-packages/PIL/ImageSequence.py
new file mode 100644
index 0000000..9df910a
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ImageSequence.py
@@ -0,0 +1,75 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# sequence support classes
+#
+# history:
+# 1997-02-20 fl     Created
+#
+# Copyright (c) 1997 by Secret Labs AB.
+# Copyright (c) 1997 by Fredrik Lundh.
+#
+# See the README file for information on usage and redistribution.
+#
+
+##
+
+
+class Iterator:
+    """
+    This class implements an iterator object that can be used to loop
+    over an image sequence.
+
+    You can use the ``[]`` operator to access elements by index. This operator
+    will raise an :py:exc:`IndexError` if you try to access a nonexistent
+    frame.
+
+    :param im: An image object.
+    """
+
+    def __init__(self, im):
+        if not hasattr(im, "seek"):
+            raise AttributeError("im must have seek method")
+        self.im = im
+        self.position = getattr(self.im, "_min_frame", 0)
+
+    def __getitem__(self, ix):
+        try:
+            self.im.seek(ix)
+            return self.im
+        except EOFError as e:
+            raise IndexError from e  # end of sequence
+
+    def __iter__(self):
+        return self
+
+    def __next__(self):
+        try:
+            self.im.seek(self.position)
+            self.position += 1
+            return self.im
+        except EOFError as e:
+            raise StopIteration from e
+
+
+def all_frames(im, func=None):
+    """
+    Applies a given function to all frames in an image or a list of images.
+    The frames are returned as a list of separate images.
+
+    :param im: An image, or a list of images.
+    :param func: The function to apply to all of the image frames.
+    :returns: A list of images.
+    """
+    if not isinstance(im, list):
+        im = [im]
+
+    ims = []
+    for imSequence in im:
+        current = imSequence.tell()
+
+        ims += [im_frame.copy() for im_frame in Iterator(imSequence)]
+
+        imSequence.seek(current)
+    return [func(im) for im in ims] if func else ims
diff --git a/.venv/lib/python3.7/site-packages/PIL/ImageShow.py b/.venv/lib/python3.7/site-packages/PIL/ImageShow.py
new file mode 100644
index 0000000..c928fc3
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ImageShow.py
@@ -0,0 +1,309 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# im.show() drivers
+#
+# History:
+# 2008-04-06 fl   Created
+#
+# Copyright (c) Secret Labs AB 2008.
+#
+# See the README file for information on usage and redistribution.
+#
+import os
+import shutil
+import subprocess
+import sys
+from shlex import quote
+
+from PIL import Image
+
+_viewers = []
+
+
+def register(viewer, order=1):
+    """
+    The :py:func:`register` function is used to register additional viewers.
+
+    :param viewer: The viewer to be registered.
+    :param order:
+        Zero or a negative integer to prepend this viewer to the list,
+        a positive integer to append it.
+    """
+    try:
+        if issubclass(viewer, Viewer):
+            viewer = viewer()
+    except TypeError:
+        pass  # raised if viewer wasn't a class
+    if order > 0:
+        _viewers.append(viewer)
+    else:
+        _viewers.insert(0, viewer)
+
+
+def show(image, title=None, **options):
+    r"""
+    Display a given image.
+
+    :param image: An image object.
+    :param title: Optional title. Not all viewers can display the title.
+    :param \**options: Additional viewer options.
+    :returns: ``True`` if a suitable viewer was found, ``False`` otherwise.
+    """
+    for viewer in _viewers:
+        if viewer.show(image, title=title, **options):
+            return 1
+    return 0
+
+
+class Viewer:
+    """Base class for viewers."""
+
+    # main api
+
+    def show(self, image, **options):
+        """
+        The main function for displaying an image.
+        Converts the given image to the target format and displays it.
+        """
+
+        if not (
+            image.mode in ("1", "RGBA")
+            or (self.format == "PNG" and image.mode in ("I;16", "LA"))
+        ):
+            base = Image.getmodebase(image.mode)
+            if image.mode != base:
+                image = image.convert(base)
+
+        return self.show_image(image, **options)
+
+    # hook methods
+
+    format = None
+    """The format to convert the image into."""
+    options = {}
+    """Additional options used to convert the image."""
+
+    def get_format(self, image):
+        """Return format name, or ``None`` to save as PGM/PPM."""
+        return self.format
+
+    def get_command(self, file, **options):
+        """
+        Returns the command used to display the file.
+        Not implemented in the base class.
+        """
+        raise NotImplementedError
+
+    def save_image(self, image):
+        """Save to temporary file and return filename."""
+        return image._dump(format=self.get_format(image), **self.options)
+
+    def show_image(self, image, **options):
+        """Display the given image."""
+        return self.show_file(self.save_image(image), **options)
+
+    def show_file(self, file, **options):
+        """Display given file"""
+        os.system(self.get_command(file, **options))
+        return 1
+
+    def _remove_file_after_delay(self, file):
+        subprocess.Popen(
+            [
+                sys.executable,
+                "-c",
+                "import os, sys, time; time.sleep(20); os.remove(sys.argv[1])",
+                file,
+            ]
+        )
+
+
+# --------------------------------------------------------------------
+
+
+class WindowsViewer(Viewer):
+    """The default viewer on Windows is the default system application for PNG files."""
+
+    format = "PNG"
+    options = {"compress_level": 1}
+
+    def get_command(self, file, **options):
+        return (
+            f'start "Pillow" /WAIT "{file}" '
+            "&& ping -n 2 127.0.0.1 >NUL "
+            f'&& del /f "{file}"'
+        )
+
+
+if sys.platform == "win32":
+    register(WindowsViewer)
+
+
+class MacViewer(Viewer):
+    """The default viewer on macOS using ``Preview.app``."""
+
+    format = "PNG"
+    options = {"compress_level": 1}
+
+    def get_command(self, file, **options):
+        # on darwin open returns immediately resulting in the temp
+        # file removal while app is opening
+        command = "open -a Preview.app"
+        command = f"({command} {quote(file)}; sleep 20; rm -f {quote(file)})&"
+        return command
+
+    def show_file(self, file, **options):
+        """Display given file"""
+        subprocess.call(["open", "-a", "Preview.app", file])
+        self._remove_file_after_delay(file)
+        return 1
+
+
+if sys.platform == "darwin":
+    register(MacViewer)
+
+
+class UnixViewer(Viewer):
+    format = "PNG"
+    options = {"compress_level": 1}
+
+    def get_command(self, file, **options):
+        command = self.get_command_ex(file, **options)[0]
+        return f"({command} {quote(file)}; rm -f {quote(file)})&"
+
+
+class XDGViewer(UnixViewer):
+    """
+    The freedesktop.org ``xdg-open`` command.
+    """
+
+    def get_command_ex(self, file, **options):
+        command = executable = "xdg-open"
+        return command, executable
+
+    def show_file(self, file, **options):
+        """Display given file"""
+        subprocess.Popen(["xdg-open", file])
+        self._remove_file_after_delay(file)
+        return 1
+
+
+class DisplayViewer(UnixViewer):
+    """
+    The ImageMagick ``display`` command.
+    This viewer supports the ``title`` parameter.
+    """
+
+    def get_command_ex(self, file, title=None, **options):
+        command = executable = "display"
+        if title:
+            command += f" -name {quote(title)}"
+        return command, executable
+
+    def show_file(self, file, **options):
+        """Display given file"""
+        args = ["display"]
+        if "title" in options:
+            args += ["-name", options["title"]]
+        args.append(file)
+
+        subprocess.Popen(args)
+        os.remove(file)
+        return 1
+
+
+class GmDisplayViewer(UnixViewer):
+    """The GraphicsMagick ``gm display`` command."""
+
+    def get_command_ex(self, file, **options):
+        executable = "gm"
+        command = "gm display"
+        return command, executable
+
+    def show_file(self, file, **options):
+        """Display given file"""
+        subprocess.Popen(["gm", "display", file])
+        os.remove(file)
+        return 1
+
+
+class EogViewer(UnixViewer):
+    """The GNOME Image Viewer ``eog`` command."""
+
+    def get_command_ex(self, file, **options):
+        executable = "eog"
+        command = "eog -n"
+        return command, executable
+
+    def show_file(self, file, **options):
+        """Display given file"""
+        subprocess.Popen(["eog", "-n", file])
+        os.remove(file)
+        return 1
+
+
+class XVViewer(UnixViewer):
+    """
+    The X Viewer ``xv`` command.
+    This viewer supports the ``title`` parameter.
+    """
+
+    def get_command_ex(self, file, title=None, **options):
+        # note: xv is pretty outdated.  most modern systems have
+        # imagemagick's display command instead.
+        command = executable = "xv"
+        if title:
+            command += f" -name {quote(title)}"
+        return command, executable
+
+    def show_file(self, file, **options):
+        """Display given file"""
+        args = ["xv"]
+        if "title" in options:
+            args += ["-name", options["title"]]
+        args.append(file)
+
+        subprocess.Popen(args)
+        os.remove(file)
+        return 1
+
+
+if sys.platform not in ("win32", "darwin"):  # unixoids
+    if shutil.which("xdg-open"):
+        register(XDGViewer)
+    if shutil.which("display"):
+        register(DisplayViewer)
+    if shutil.which("gm"):
+        register(GmDisplayViewer)
+    if shutil.which("eog"):
+        register(EogViewer)
+    if shutil.which("xv"):
+        register(XVViewer)
+
+
+class IPythonViewer(Viewer):
+    """The viewer for IPython frontends."""
+
+    def show_image(self, image, **options):
+        ipython_display(image)
+        return 1
+
+
+try:
+    from IPython.display import display as ipython_display
+except ImportError:
+    pass
+else:
+    register(IPythonViewer)
+
+
+if __name__ == "__main__":
+
+    if len(sys.argv) < 2:
+        print("Syntax: python3 ImageShow.py imagefile [title]")
+        sys.exit()
+
+    with Image.open(sys.argv[1]) as im:
+        print(show(im, *sys.argv[2:]))
diff --git a/.venv/lib/python3.7/site-packages/PIL/ImageStat.py b/.venv/lib/python3.7/site-packages/PIL/ImageStat.py
new file mode 100644
index 0000000..50bafc9
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ImageStat.py
@@ -0,0 +1,147 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# global image statistics
+#
+# History:
+# 1996-04-05 fl   Created
+# 1997-05-21 fl   Added mask; added rms, var, stddev attributes
+# 1997-08-05 fl   Added median
+# 1998-07-05 hk   Fixed integer overflow error
+#
+# Notes:
+# This class shows how to implement delayed evaluation of attributes.
+# To get a certain value, simply access the corresponding attribute.
+# The __getattr__ dispatcher takes care of the rest.
+#
+# Copyright (c) Secret Labs AB 1997.
+# Copyright (c) Fredrik Lundh 1996-97.
+#
+# See the README file for information on usage and redistribution.
+#
+
+import functools
+import math
+import operator
+
+
+class Stat:
+    def __init__(self, image_or_list, mask=None):
+        try:
+            if mask:
+                self.h = image_or_list.histogram(mask)
+            else:
+                self.h = image_or_list.histogram()
+        except AttributeError:
+            self.h = image_or_list  # assume it to be a histogram list
+        if not isinstance(self.h, list):
+            raise TypeError("first argument must be image or list")
+        self.bands = list(range(len(self.h) // 256))
+
+    def __getattr__(self, id):
+        """Calculate missing attribute"""
+        if id[:4] == "_get":
+            raise AttributeError(id)
+        # calculate missing attribute
+        v = getattr(self, "_get" + id)()
+        setattr(self, id, v)
+        return v
+
+    def _getextrema(self):
+        """Get min/max values for each band in the image"""
+
+        def minmax(histogram):
+            n = 255
+            x = 0
+            for i in range(256):
+                if histogram[i]:
+                    n = min(n, i)
+                    x = max(x, i)
+            return n, x  # returns (255, 0) if there's no data in the histogram
+
+        v = []
+        for i in range(0, len(self.h), 256):
+            v.append(minmax(self.h[i:]))
+        return v
+
+    def _getcount(self):
+        """Get total number of pixels in each layer"""
+
+        v = []
+        for i in range(0, len(self.h), 256):
+            v.append(functools.reduce(operator.add, self.h[i : i + 256]))
+        return v
+
+    def _getsum(self):
+        """Get sum of all pixels in each layer"""
+
+        v = []
+        for i in range(0, len(self.h), 256):
+            layerSum = 0.0
+            for j in range(256):
+                layerSum += j * self.h[i + j]
+            v.append(layerSum)
+        return v
+
+    def _getsum2(self):
+        """Get squared sum of all pixels in each layer"""
+
+        v = []
+        for i in range(0, len(self.h), 256):
+            sum2 = 0.0
+            for j in range(256):
+                sum2 += (j ** 2) * float(self.h[i + j])
+            v.append(sum2)
+        return v
+
+    def _getmean(self):
+        """Get average pixel level for each layer"""
+
+        v = []
+        for i in self.bands:
+            v.append(self.sum[i] / self.count[i])
+        return v
+
+    def _getmedian(self):
+        """Get median pixel level for each layer"""
+
+        v = []
+        for i in self.bands:
+            s = 0
+            half = self.count[i] // 2
+            b = i * 256
+            for j in range(256):
+                s = s + self.h[b + j]
+                if s > half:
+                    break
+            v.append(j)
+        return v
+
+    def _getrms(self):
+        """Get RMS for each layer"""
+
+        v = []
+        for i in self.bands:
+            v.append(math.sqrt(self.sum2[i] / self.count[i]))
+        return v
+
+    def _getvar(self):
+        """Get variance for each layer"""
+
+        v = []
+        for i in self.bands:
+            n = self.count[i]
+            v.append((self.sum2[i] - (self.sum[i] ** 2.0) / n) / n)
+        return v
+
+    def _getstddev(self):
+        """Get standard deviation for each layer"""
+
+        v = []
+        for i in self.bands:
+            v.append(math.sqrt(self.var[i]))
+        return v
+
+
+Global = Stat  # compatibility
diff --git a/.venv/lib/python3.7/site-packages/PIL/ImageTk.py b/.venv/lib/python3.7/site-packages/PIL/ImageTk.py
new file mode 100644
index 0000000..62db7a7
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ImageTk.py
@@ -0,0 +1,300 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# a Tk display interface
+#
+# History:
+# 96-04-08 fl   Created
+# 96-09-06 fl   Added getimage method
+# 96-11-01 fl   Rewritten, removed image attribute and crop method
+# 97-05-09 fl   Use PyImagingPaste method instead of image type
+# 97-05-12 fl   Minor tweaks to match the IFUNC95 interface
+# 97-05-17 fl   Support the "pilbitmap" booster patch
+# 97-06-05 fl   Added file= and data= argument to image constructors
+# 98-03-09 fl   Added width and height methods to Image classes
+# 98-07-02 fl   Use default mode for "P" images without palette attribute
+# 98-07-02 fl   Explicitly destroy Tkinter image objects
+# 99-07-24 fl   Support multiple Tk interpreters (from Greg Couch)
+# 99-07-26 fl   Automatically hook into Tkinter (if possible)
+# 99-08-15 fl   Hook uses _imagingtk instead of _imaging
+#
+# Copyright (c) 1997-1999 by Secret Labs AB
+# Copyright (c) 1996-1997 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+import tkinter
+from io import BytesIO
+
+from . import Image
+
+# --------------------------------------------------------------------
+# Check for Tkinter interface hooks
+
+_pilbitmap_ok = None
+
+
+def _pilbitmap_check():
+    global _pilbitmap_ok
+    if _pilbitmap_ok is None:
+        try:
+            im = Image.new("1", (1, 1))
+            tkinter.BitmapImage(data=f"PIL:{im.im.id}")
+            _pilbitmap_ok = 1
+        except tkinter.TclError:
+            _pilbitmap_ok = 0
+    return _pilbitmap_ok
+
+
+def _get_image_from_kw(kw):
+    source = None
+    if "file" in kw:
+        source = kw.pop("file")
+    elif "data" in kw:
+        source = BytesIO(kw.pop("data"))
+    if source:
+        return Image.open(source)
+
+
+# --------------------------------------------------------------------
+# PhotoImage
+
+
+class PhotoImage:
+    """
+    A Tkinter-compatible photo image.  This can be used
+    everywhere Tkinter expects an image object.  If the image is an RGBA
+    image, pixels having alpha 0 are treated as transparent.
+
+    The constructor takes either a PIL image, or a mode and a size.
+    Alternatively, you can use the ``file`` or ``data`` options to initialize
+    the photo image object.
+
+    :param image: Either a PIL image, or a mode string.  If a mode string is
+                  used, a size must also be given.
+    :param size: If the first argument is a mode string, this defines the size
+                 of the image.
+    :keyword file: A filename to load the image from (using
+                   ``Image.open(file)``).
+    :keyword data: An 8-bit string containing image data (as loaded from an
+                   image file).
+    """
+
+    def __init__(self, image=None, size=None, **kw):
+
+        # Tk compatibility: file or data
+        if image is None:
+            image = _get_image_from_kw(kw)
+
+        if hasattr(image, "mode") and hasattr(image, "size"):
+            # got an image instead of a mode
+            mode = image.mode
+            if mode == "P":
+                # palette mapped data
+                image.load()
+                try:
+                    mode = image.palette.mode
+                except AttributeError:
+                    mode = "RGB"  # default
+            size = image.size
+            kw["width"], kw["height"] = size
+        else:
+            mode = image
+            image = None
+
+        if mode not in ["1", "L", "RGB", "RGBA"]:
+            mode = Image.getmodebase(mode)
+
+        self.__mode = mode
+        self.__size = size
+        self.__photo = tkinter.PhotoImage(**kw)
+        self.tk = self.__photo.tk
+        if image:
+            self.paste(image)
+
+    def __del__(self):
+        name = self.__photo.name
+        self.__photo.name = None
+        try:
+            self.__photo.tk.call("image", "delete", name)
+        except Exception:
+            pass  # ignore internal errors
+
+    def __str__(self):
+        """
+        Get the Tkinter photo image identifier.  This method is automatically
+        called by Tkinter whenever a PhotoImage object is passed to a Tkinter
+        method.
+
+        :return: A Tkinter photo image identifier (a string).
+        """
+        return str(self.__photo)
+
+    def width(self):
+        """
+        Get the width of the image.
+
+        :return: The width, in pixels.
+        """
+        return self.__size[0]
+
+    def height(self):
+        """
+        Get the height of the image.
+
+        :return: The height, in pixels.
+        """
+        return self.__size[1]
+
+    def paste(self, im, box=None):
+        """
+        Paste a PIL image into the photo image.  Note that this can
+        be very slow if the photo image is displayed.
+
+        :param im: A PIL image. The size must match the target region.  If the
+                   mode does not match, the image is converted to the mode of
+                   the bitmap image.
+        :param box: A 4-tuple defining the left, upper, right, and lower pixel
+                    coordinate. See :ref:`coordinate-system`. If None is given
+                    instead of a tuple, all of the image is assumed.
+        """
+
+        # convert to blittable
+        im.load()
+        image = im.im
+        if image.isblock() and im.mode == self.__mode:
+            block = image
+        else:
+            block = image.new_block(self.__mode, im.size)
+            image.convert2(block, image)  # convert directly between buffers
+
+        tk = self.__photo.tk
+
+        try:
+            tk.call("PyImagingPhoto", self.__photo, block.id)
+        except tkinter.TclError:
+            # activate Tkinter hook
+            try:
+                from . import _imagingtk
+
+                try:
+                    if hasattr(tk, "interp"):
+                        # Required for PyPy, which always has CFFI installed
+                        from cffi import FFI
+
+                        ffi = FFI()
+
+                        # PyPy is using an FFI CDATA element
+                        # (Pdb) self.tk.interp
+                        #  <cdata 'Tcl_Interp *' 0x3061b50>
+                        _imagingtk.tkinit(int(ffi.cast("uintptr_t", tk.interp)), 1)
+                    else:
+                        _imagingtk.tkinit(tk.interpaddr(), 1)
+                except AttributeError:
+                    _imagingtk.tkinit(id(tk), 0)
+                tk.call("PyImagingPhoto", self.__photo, block.id)
+            except (ImportError, AttributeError, tkinter.TclError):
+                raise  # configuration problem; cannot attach to Tkinter
+
+
+# --------------------------------------------------------------------
+# BitmapImage
+
+
+class BitmapImage:
+    """
+    A Tkinter-compatible bitmap image.  This can be used everywhere Tkinter
+    expects an image object.
+
+    The given image must have mode "1".  Pixels having value 0 are treated as
+    transparent.  Options, if any, are passed on to Tkinter.  The most commonly
+    used option is ``foreground``, which is used to specify the color for the
+    non-transparent parts.  See the Tkinter documentation for information on
+    how to specify colours.
+
+    :param image: A PIL image.
+    """
+
+    def __init__(self, image=None, **kw):
+
+        # Tk compatibility: file or data
+        if image is None:
+            image = _get_image_from_kw(kw)
+
+        self.__mode = image.mode
+        self.__size = image.size
+
+        if _pilbitmap_check():
+            # fast way (requires the pilbitmap booster patch)
+            image.load()
+            kw["data"] = f"PIL:{image.im.id}"
+            self.__im = image  # must keep a reference
+        else:
+            # slow but safe way
+            kw["data"] = image.tobitmap()
+        self.__photo = tkinter.BitmapImage(**kw)
+
+    def __del__(self):
+        name = self.__photo.name
+        self.__photo.name = None
+        try:
+            self.__photo.tk.call("image", "delete", name)
+        except Exception:
+            pass  # ignore internal errors
+
+    def width(self):
+        """
+        Get the width of the image.
+
+        :return: The width, in pixels.
+        """
+        return self.__size[0]
+
+    def height(self):
+        """
+        Get the height of the image.
+
+        :return: The height, in pixels.
+        """
+        return self.__size[1]
+
+    def __str__(self):
+        """
+        Get the Tkinter bitmap image identifier.  This method is automatically
+        called by Tkinter whenever a BitmapImage object is passed to a Tkinter
+        method.
+
+        :return: A Tkinter bitmap image identifier (a string).
+        """
+        return str(self.__photo)
+
+
+def getimage(photo):
+    """Copies the contents of a PhotoImage to a PIL image memory."""
+    im = Image.new("RGBA", (photo.width(), photo.height()))
+    block = im.im
+
+    photo.tk.call("PyImagingPhotoGet", photo, block.id)
+
+    return im
+
+
+def _show(image, title):
+    """Helper for the Image.show method."""
+
+    class UI(tkinter.Label):
+        def __init__(self, master, im):
+            if im.mode == "1":
+                self.image = BitmapImage(im, foreground="white", master=master)
+            else:
+                self.image = PhotoImage(im, master=master)
+            super().__init__(master, image=self.image, bg="black", bd=0)
+
+    if not tkinter._default_root:
+        raise OSError("tkinter not initialized")
+    top = tkinter.Toplevel()
+    if title:
+        top.title(title)
+    UI(top, image).pack()
diff --git a/.venv/lib/python3.7/site-packages/PIL/ImageTransform.py b/.venv/lib/python3.7/site-packages/PIL/ImageTransform.py
new file mode 100644
index 0000000..77791ab
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ImageTransform.py
@@ -0,0 +1,102 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# transform wrappers
+#
+# History:
+# 2002-04-08 fl   Created
+#
+# Copyright (c) 2002 by Secret Labs AB
+# Copyright (c) 2002 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+from . import Image
+
+
+class Transform(Image.ImageTransformHandler):
+    def __init__(self, data):
+        self.data = data
+
+    def getdata(self):
+        return self.method, self.data
+
+    def transform(self, size, image, **options):
+        # can be overridden
+        method, data = self.getdata()
+        return image.transform(size, method, data, **options)
+
+
+class AffineTransform(Transform):
+    """
+    Define an affine image transform.
+
+    This function takes a 6-tuple (a, b, c, d, e, f) which contain the first
+    two rows from an affine transform matrix. For each pixel (x, y) in the
+    output image, the new value is taken from a position (a x + b y + c,
+    d x + e y + f) in the input image, rounded to nearest pixel.
+
+    This function can be used to scale, translate, rotate, and shear the
+    original image.
+
+    See :py:meth:`~PIL.Image.Image.transform`
+
+    :param matrix: A 6-tuple (a, b, c, d, e, f) containing the first two rows
+        from an affine transform matrix.
+    """
+
+    method = Image.AFFINE
+
+
+class ExtentTransform(Transform):
+    """
+    Define a transform to extract a subregion from an image.
+
+    Maps a rectangle (defined by two corners) from the image to a rectangle of
+    the given size. The resulting image will contain data sampled from between
+    the corners, such that (x0, y0) in the input image will end up at (0,0) in
+    the output image, and (x1, y1) at size.
+
+    This method can be used to crop, stretch, shrink, or mirror an arbitrary
+    rectangle in the current image. It is slightly slower than crop, but about
+    as fast as a corresponding resize operation.
+
+    See :py:meth:`~PIL.Image.Image.transform`
+
+    :param bbox: A 4-tuple (x0, y0, x1, y1) which specifies two points in the
+        input image's coordinate system. See :ref:`coordinate-system`.
+    """
+
+    method = Image.EXTENT
+
+
+class QuadTransform(Transform):
+    """
+    Define a quad image transform.
+
+    Maps a quadrilateral (a region defined by four corners) from the image to a
+    rectangle of the given size.
+
+    See :py:meth:`~PIL.Image.Image.transform`
+
+    :param xy: An 8-tuple (x0, y0, x1, y1, x2, y2, x3, y3) which contain the
+        upper left, lower left, lower right, and upper right corner of the
+        source quadrilateral.
+    """
+
+    method = Image.QUAD
+
+
+class MeshTransform(Transform):
+    """
+    Define a mesh image transform.  A mesh transform consists of one or more
+    individual quad transforms.
+
+    See :py:meth:`~PIL.Image.Image.transform`
+
+    :param data: A list of (bbox, quad) tuples.
+    """
+
+    method = Image.MESH
diff --git a/.venv/lib/python3.7/site-packages/PIL/ImageWin.py b/.venv/lib/python3.7/site-packages/PIL/ImageWin.py
new file mode 100644
index 0000000..ca9b14c
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ImageWin.py
@@ -0,0 +1,230 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# a Windows DIB display interface
+#
+# History:
+# 1996-05-20 fl   Created
+# 1996-09-20 fl   Fixed subregion exposure
+# 1997-09-21 fl   Added draw primitive (for tzPrint)
+# 2003-05-21 fl   Added experimental Window/ImageWindow classes
+# 2003-09-05 fl   Added fromstring/tostring methods
+#
+# Copyright (c) Secret Labs AB 1997-2003.
+# Copyright (c) Fredrik Lundh 1996-2003.
+#
+# See the README file for information on usage and redistribution.
+#
+
+from . import Image
+
+
+class HDC:
+    """
+    Wraps an HDC integer. The resulting object can be passed to the
+    :py:meth:`~PIL.ImageWin.Dib.draw` and :py:meth:`~PIL.ImageWin.Dib.expose`
+    methods.
+    """
+
+    def __init__(self, dc):
+        self.dc = dc
+
+    def __int__(self):
+        return self.dc
+
+
+class HWND:
+    """
+    Wraps an HWND integer. The resulting object can be passed to the
+    :py:meth:`~PIL.ImageWin.Dib.draw` and :py:meth:`~PIL.ImageWin.Dib.expose`
+    methods, instead of a DC.
+    """
+
+    def __init__(self, wnd):
+        self.wnd = wnd
+
+    def __int__(self):
+        return self.wnd
+
+
+class Dib:
+    """
+    A Windows bitmap with the given mode and size.  The mode can be one of "1",
+    "L", "P", or "RGB".
+
+    If the display requires a palette, this constructor creates a suitable
+    palette and associates it with the image. For an "L" image, 128 greylevels
+    are allocated. For an "RGB" image, a 6x6x6 colour cube is used, together
+    with 20 greylevels.
+
+    To make sure that palettes work properly under Windows, you must call the
+    ``palette`` method upon certain events from Windows.
+
+    :param image: Either a PIL image, or a mode string. If a mode string is
+                  used, a size must also be given.  The mode can be one of "1",
+                  "L", "P", or "RGB".
+    :param size: If the first argument is a mode string, this
+                 defines the size of the image.
+    """
+
+    def __init__(self, image, size=None):
+        if hasattr(image, "mode") and hasattr(image, "size"):
+            mode = image.mode
+            size = image.size
+        else:
+            mode = image
+            image = None
+        if mode not in ["1", "L", "P", "RGB"]:
+            mode = Image.getmodebase(mode)
+        self.image = Image.core.display(mode, size)
+        self.mode = mode
+        self.size = size
+        if image:
+            self.paste(image)
+
+    def expose(self, handle):
+        """
+        Copy the bitmap contents to a device context.
+
+        :param handle: Device context (HDC), cast to a Python integer, or an
+                       HDC or HWND instance.  In PythonWin, you can use
+                       ``CDC.GetHandleAttrib()`` to get a suitable handle.
+        """
+        if isinstance(handle, HWND):
+            dc = self.image.getdc(handle)
+            try:
+                result = self.image.expose(dc)
+            finally:
+                self.image.releasedc(handle, dc)
+        else:
+            result = self.image.expose(handle)
+        return result
+
+    def draw(self, handle, dst, src=None):
+        """
+        Same as expose, but allows you to specify where to draw the image, and
+        what part of it to draw.
+
+        The destination and source areas are given as 4-tuple rectangles. If
+        the source is omitted, the entire image is copied. If the source and
+        the destination have different sizes, the image is resized as
+        necessary.
+        """
+        if not src:
+            src = (0, 0) + self.size
+        if isinstance(handle, HWND):
+            dc = self.image.getdc(handle)
+            try:
+                result = self.image.draw(dc, dst, src)
+            finally:
+                self.image.releasedc(handle, dc)
+        else:
+            result = self.image.draw(handle, dst, src)
+        return result
+
+    def query_palette(self, handle):
+        """
+        Installs the palette associated with the image in the given device
+        context.
+
+        This method should be called upon **QUERYNEWPALETTE** and
+        **PALETTECHANGED** events from Windows. If this method returns a
+        non-zero value, one or more display palette entries were changed, and
+        the image should be redrawn.
+
+        :param handle: Device context (HDC), cast to a Python integer, or an
+                       HDC or HWND instance.
+        :return: A true value if one or more entries were changed (this
+                 indicates that the image should be redrawn).
+        """
+        if isinstance(handle, HWND):
+            handle = self.image.getdc(handle)
+            try:
+                result = self.image.query_palette(handle)
+            finally:
+                self.image.releasedc(handle, handle)
+        else:
+            result = self.image.query_palette(handle)
+        return result
+
+    def paste(self, im, box=None):
+        """
+        Paste a PIL image into the bitmap image.
+
+        :param im: A PIL image.  The size must match the target region.
+                   If the mode does not match, the image is converted to the
+                   mode of the bitmap image.
+        :param box: A 4-tuple defining the left, upper, right, and
+                    lower pixel coordinate.  See :ref:`coordinate-system`. If
+                    None is given instead of a tuple, all of the image is
+                    assumed.
+        """
+        im.load()
+        if self.mode != im.mode:
+            im = im.convert(self.mode)
+        if box:
+            self.image.paste(im.im, box)
+        else:
+            self.image.paste(im.im)
+
+    def frombytes(self, buffer):
+        """
+        Load display memory contents from byte data.
+
+        :param buffer: A buffer containing display data (usually
+                       data returned from :py:func:`~PIL.ImageWin.Dib.tobytes`)
+        """
+        return self.image.frombytes(buffer)
+
+    def tobytes(self):
+        """
+        Copy display memory contents to bytes object.
+
+        :return: A bytes object containing display data.
+        """
+        return self.image.tobytes()
+
+
+class Window:
+    """Create a Window with the given title size."""
+
+    def __init__(self, title="PIL", width=None, height=None):
+        self.hwnd = Image.core.createwindow(
+            title, self.__dispatcher, width or 0, height or 0
+        )
+
+    def __dispatcher(self, action, *args):
+        return getattr(self, "ui_handle_" + action)(*args)
+
+    def ui_handle_clear(self, dc, x0, y0, x1, y1):
+        pass
+
+    def ui_handle_damage(self, x0, y0, x1, y1):
+        pass
+
+    def ui_handle_destroy(self):
+        pass
+
+    def ui_handle_repair(self, dc, x0, y0, x1, y1):
+        pass
+
+    def ui_handle_resize(self, width, height):
+        pass
+
+    def mainloop(self):
+        Image.core.eventloop()
+
+
+class ImageWindow(Window):
+    """Create an image window which displays the given image."""
+
+    def __init__(self, image, title="PIL"):
+        if not isinstance(image, Dib):
+            image = Dib(image)
+        self.image = image
+        width, height = image.size
+        super().__init__(title, width=width, height=height)
+
+    def ui_handle_repair(self, dc, x0, y0, x1, y1):
+        self.image.draw(dc, (x0, y0, x1, y1))
diff --git a/.venv/lib/python3.7/site-packages/PIL/ImtImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/ImtImagePlugin.py
new file mode 100644
index 0000000..21ffd74
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/ImtImagePlugin.py
@@ -0,0 +1,93 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# IM Tools support for PIL
+#
+# history:
+# 1996-05-27 fl   Created (read 8-bit images only)
+# 2001-02-17 fl   Use 're' instead of 'regex' (Python 2.1) (0.2)
+#
+# Copyright (c) Secret Labs AB 1997-2001.
+# Copyright (c) Fredrik Lundh 1996-2001.
+#
+# See the README file for information on usage and redistribution.
+#
+
+
+import re
+
+from . import Image, ImageFile
+
+#
+# --------------------------------------------------------------------
+
+field = re.compile(br"([a-z]*) ([^ \r\n]*)")
+
+
+##
+# Image plugin for IM Tools images.
+
+
+class ImtImageFile(ImageFile.ImageFile):
+
+    format = "IMT"
+    format_description = "IM Tools"
+
+    def _open(self):
+
+        # Quick rejection: if there's not a LF among the first
+        # 100 bytes, this is (probably) not a text header.
+
+        if b"\n" not in self.fp.read(100):
+            raise SyntaxError("not an IM file")
+        self.fp.seek(0)
+
+        xsize = ysize = 0
+
+        while True:
+
+            s = self.fp.read(1)
+            if not s:
+                break
+
+            if s == b"\x0C":
+
+                # image data begins
+                self.tile = [
+                    ("raw", (0, 0) + self.size, self.fp.tell(), (self.mode, 0, 1))
+                ]
+
+                break
+
+            else:
+
+                # read key/value pair
+                # FIXME: dangerous, may read whole file
+                s = s + self.fp.readline()
+                if len(s) == 1 or len(s) > 100:
+                    break
+                if s[0] == ord(b"*"):
+                    continue  # comment
+
+                m = field.match(s)
+                if not m:
+                    break
+                k, v = m.group(1, 2)
+                if k == "width":
+                    xsize = int(v)
+                    self._size = xsize, ysize
+                elif k == "height":
+                    ysize = int(v)
+                    self._size = xsize, ysize
+                elif k == "pixel" and v == "n8":
+                    self.mode = "L"
+
+
+#
+# --------------------------------------------------------------------
+
+Image.register_open(ImtImageFile.format, ImtImageFile)
+
+#
+# no extension registered (".im" is simply too common)
diff --git a/.venv/lib/python3.7/site-packages/PIL/IptcImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/IptcImagePlugin.py
new file mode 100644
index 0000000..0bbe506
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/IptcImagePlugin.py
@@ -0,0 +1,230 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# IPTC/NAA file handling
+#
+# history:
+# 1995-10-01 fl   Created
+# 1998-03-09 fl   Cleaned up and added to PIL
+# 2002-06-18 fl   Added getiptcinfo helper
+#
+# Copyright (c) Secret Labs AB 1997-2002.
+# Copyright (c) Fredrik Lundh 1995.
+#
+# See the README file for information on usage and redistribution.
+#
+import os
+import tempfile
+
+from . import Image, ImageFile
+from ._binary import i8
+from ._binary import i16be as i16
+from ._binary import i32be as i32
+from ._binary import o8
+
+COMPRESSION = {1: "raw", 5: "jpeg"}
+
+PAD = o8(0) * 4
+
+
+#
+# Helpers
+
+
+def i(c):
+    return i32((PAD + c)[-4:])
+
+
+def dump(c):
+    for i in c:
+        print("%02x" % i8(i), end=" ")
+    print()
+
+
+##
+# Image plugin for IPTC/NAA datastreams.  To read IPTC/NAA fields
+# from TIFF and JPEG files, use the <b>getiptcinfo</b> function.
+
+
+class IptcImageFile(ImageFile.ImageFile):
+
+    format = "IPTC"
+    format_description = "IPTC/NAA"
+
+    def getint(self, key):
+        return i(self.info[key])
+
+    def field(self):
+        #
+        # get a IPTC field header
+        s = self.fp.read(5)
+        if not len(s):
+            return None, 0
+
+        tag = s[1], s[2]
+
+        # syntax
+        if s[0] != 0x1C or tag[0] < 1 or tag[0] > 9:
+            raise SyntaxError("invalid IPTC/NAA file")
+
+        # field size
+        size = s[3]
+        if size > 132:
+            raise OSError("illegal field length in IPTC/NAA file")
+        elif size == 128:
+            size = 0
+        elif size > 128:
+            size = i(self.fp.read(size - 128))
+        else:
+            size = i16(s, 3)
+
+        return tag, size
+
+    def _open(self):
+
+        # load descriptive fields
+        while True:
+            offset = self.fp.tell()
+            tag, size = self.field()
+            if not tag or tag == (8, 10):
+                break
+            if size:
+                tagdata = self.fp.read(size)
+            else:
+                tagdata = None
+            if tag in self.info:
+                if isinstance(self.info[tag], list):
+                    self.info[tag].append(tagdata)
+                else:
+                    self.info[tag] = [self.info[tag], tagdata]
+            else:
+                self.info[tag] = tagdata
+
+        # mode
+        layers = i8(self.info[(3, 60)][0])
+        component = i8(self.info[(3, 60)][1])
+        if (3, 65) in self.info:
+            id = i8(self.info[(3, 65)][0]) - 1
+        else:
+            id = 0
+        if layers == 1 and not component:
+            self.mode = "L"
+        elif layers == 3 and component:
+            self.mode = "RGB"[id]
+        elif layers == 4 and component:
+            self.mode = "CMYK"[id]
+
+        # size
+        self._size = self.getint((3, 20)), self.getint((3, 30))
+
+        # compression
+        try:
+            compression = COMPRESSION[self.getint((3, 120))]
+        except KeyError as e:
+            raise OSError("Unknown IPTC image compression") from e
+
+        # tile
+        if tag == (8, 10):
+            self.tile = [
+                ("iptc", (compression, offset), (0, 0, self.size[0], self.size[1]))
+            ]
+
+    def load(self):
+
+        if len(self.tile) != 1 or self.tile[0][0] != "iptc":
+            return ImageFile.ImageFile.load(self)
+
+        type, tile, box = self.tile[0]
+
+        encoding, offset = tile
+
+        self.fp.seek(offset)
+
+        # Copy image data to temporary file
+        o_fd, outfile = tempfile.mkstemp(text=False)
+        o = os.fdopen(o_fd)
+        if encoding == "raw":
+            # To simplify access to the extracted file,
+            # prepend a PPM header
+            o.write("P5\n%d %d\n255\n" % self.size)
+        while True:
+            type, size = self.field()
+            if type != (8, 10):
+                break
+            while size > 0:
+                s = self.fp.read(min(size, 8192))
+                if not s:
+                    break
+                o.write(s)
+                size -= len(s)
+        o.close()
+
+        try:
+            with Image.open(outfile) as _im:
+                _im.load()
+                self.im = _im.im
+        finally:
+            try:
+                os.unlink(outfile)
+            except OSError:
+                pass
+
+
+Image.register_open(IptcImageFile.format, IptcImageFile)
+
+Image.register_extension(IptcImageFile.format, ".iim")
+
+
+def getiptcinfo(im):
+    """
+    Get IPTC information from TIFF, JPEG, or IPTC file.
+
+    :param im: An image containing IPTC data.
+    :returns: A dictionary containing IPTC information, or None if
+        no IPTC information block was found.
+    """
+    import io
+
+    from . import JpegImagePlugin, TiffImagePlugin
+
+    data = None
+
+    if isinstance(im, IptcImageFile):
+        # return info dictionary right away
+        return im.info
+
+    elif isinstance(im, JpegImagePlugin.JpegImageFile):
+        # extract the IPTC/NAA resource
+        photoshop = im.info.get("photoshop")
+        if photoshop:
+            data = photoshop.get(0x0404)
+
+    elif isinstance(im, TiffImagePlugin.TiffImageFile):
+        # get raw data from the IPTC/NAA tag (PhotoShop tags the data
+        # as 4-byte integers, so we cannot use the get method...)
+        try:
+            data = im.tag.tagdata[TiffImagePlugin.IPTC_NAA_CHUNK]
+        except (AttributeError, KeyError):
+            pass
+
+    if data is None:
+        return None  # no properties
+
+    # create an IptcImagePlugin object without initializing it
+    class FakeImage:
+        pass
+
+    im = FakeImage()
+    im.__class__ = IptcImageFile
+
+    # parse the IPTC information chunk
+    im.info = {}
+    im.fp = io.BytesIO(data)
+
+    try:
+        im._open()
+    except (IndexError, KeyError):
+        pass  # expected failure
+
+    return im.info
diff --git a/.venv/lib/python3.7/site-packages/PIL/Jpeg2KImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/Jpeg2KImagePlugin.py
new file mode 100644
index 0000000..cc79802
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/Jpeg2KImagePlugin.py
@@ -0,0 +1,360 @@
+#
+# The Python Imaging Library
+# $Id$
+#
+# JPEG2000 file handling
+#
+# History:
+# 2014-03-12 ajh  Created
+# 2021-06-30 rogermb  Extract dpi information from the 'resc' header box
+#
+# Copyright (c) 2014 Coriolis Systems Limited
+# Copyright (c) 2014 Alastair Houghton
+#
+# See the README file for information on usage and redistribution.
+#
+import io
+import os
+import struct
+
+from . import Image, ImageFile
+
+
+class BoxReader:
+    """
+    A small helper class to read fields stored in JPEG2000 header boxes
+    and to easily step into and read sub-boxes.
+    """
+
+    def __init__(self, fp, length=-1):
+        self.fp = fp
+        self.has_length = length >= 0
+        self.length = length
+        self.remaining_in_box = -1
+
+    def _can_read(self, num_bytes):
+        if self.has_length and self.fp.tell() + num_bytes > self.length:
+            # Outside box: ensure we don't read past the known file length
+            return False
+        if self.remaining_in_box >= 0:
+            # Inside box contents: ensure read does not go past box boundaries
+            return num_bytes <= self.remaining_in_box
+        else:
+            return True  # No length known, just read
+
+    def _read_bytes(self, num_bytes):
+        if not self._can_read(num_bytes):
+            raise SyntaxError("Not enough data in header")
+
+        data = self.fp.read(num_bytes)
+        if len(data) < num_bytes:
+            raise OSError(
+                f"Expected to read {num_bytes} bytes but only got {len(data)}."
+            )
+
+        if self.remaining_in_box > 0:
+            self.remaining_in_box -= num_bytes
+        return data
+
+    def read_fields(self, field_format):
+        size = struct.calcsize(field_format)
+        data = self._read_bytes(size)
+        return struct.unpack(field_format, data)
+
+    def read_boxes(self):
+        size = self.remaining_in_box
+        data = self._read_bytes(size)
+        return BoxReader(io.BytesIO(data), size)
+
+    def has_next_box(self):
+        if self.has_length:
+            return self.fp.tell() + self.remaining_in_box < self.length
+        else:
+            return True
+
+    def next_box_type(self):
+        # Skip the rest of the box if it has not been read
+        if self.remaining_in_box > 0:
+            self.fp.seek(self.remaining_in_box, os.SEEK_CUR)
+        self.remaining_in_box = -1
+
+        # Read the length and type of the next box
+        lbox, tbox = self.read_fields(">I4s")
+        if lbox == 1:
+            lbox = self.read_fields(">Q")[0]
+            hlen = 16
+        else:
+            hlen = 8
+
+        if lbox < hlen or not self._can_read(lbox - hlen):
+            raise SyntaxError("Invalid header length")
+
+        self.remaining_in_box = lbox - hlen
+        return tbox
+
+
+def _parse_codestream(fp):
+    """Parse the JPEG 2000 codestream to extract the size and component
+    count from the SIZ marker segment, returning a PIL (size, mode) tuple."""
+
+    hdr = fp.read(2)
+    lsiz = struct.unpack(">H", hdr)[0]
+    siz = hdr + fp.read(lsiz - 2)
+    lsiz, rsiz, xsiz, ysiz, xosiz, yosiz, _, _, _, _, csiz = struct.unpack_from(
+        ">HHIIIIIIIIH", siz
+    )
+    ssiz = [None] * csiz
+    xrsiz = [None] * csiz
+    yrsiz = [None] * csiz
+    for i in range(csiz):
+        ssiz[i], xrsiz[i], yrsiz[i] = struct.unpack_from(">BBB", siz, 36 + 3 * i)
+
+    size = (xsiz - xosiz, ysiz - yosiz)
+    if csiz == 1:
+        if (yrsiz[0] & 0x7F) > 8:
+            mode = "I;16"
+        else:
+            mode = "L"
+    elif csiz == 2:
+        mode = "LA"
+    elif csiz == 3:
+        mode = "RGB"
+    elif csiz == 4:
+        mode = "RGBA"
+    else:
+        mode = None
+
+    return (size, mode)
+
+
+def _res_to_dpi(num, denom, exp):
+    """Convert JPEG2000's (numerator, denominator, exponent-base-10) resolution,
+    calculated as (num / denom) * 10^exp and stored in dots per meter,
+    to floating-point dots per inch."""
+    if denom != 0:
+        return (254 * num * (10 ** exp)) / (10000 * denom)
+
+
+def _parse_jp2_header(fp):
+    """Parse the JP2 header box to extract size, component count,
+    color space information, and optionally DPI information,
+    returning a (size, mode, mimetype, dpi) tuple."""
+
+    # Find the JP2 header box
+    reader = BoxReader(fp)
+    header = None
+    mimetype = None
+    while reader.has_next_box():
+        tbox = reader.next_box_type()
+
+        if tbox == b"jp2h":
+            header = reader.read_boxes()
+            break
+        elif tbox == b"ftyp":
+            if reader.read_fields(">4s")[0] == b"jpx ":
+                mimetype = "image/jpx"
+
+    size = None
+    mode = None
+    bpc = None
+    nc = None
+    dpi = None  # 2-tuple of DPI info, or None
+
+    while header.has_next_box():
+        tbox = header.next_box_type()
+
+        if tbox == b"ihdr":
+            height, width, nc, bpc = header.read_fields(">IIHB")
+            size = (width, height)
+            if nc == 1 and (bpc & 0x7F) > 8:
+                mode = "I;16"
+            elif nc == 1:
+                mode = "L"
+            elif nc == 2:
+                mode = "LA"
+            elif nc == 3:
+                mode = "RGB"
+            elif nc == 4:
+                mode = "RGBA"
+        elif tbox == b"res ":
+            res = header.read_boxes()
+            while res.has_next_box():
+                tres = res.next_box_type()
+                if tres == b"resc":
+                    vrcn, vrcd, hrcn, hrcd, vrce, hrce = res.read_fields(">HHHHBB")
+                    hres = _res_to_dpi(hrcn, hrcd, hrce)
+                    vres = _res_to_dpi(vrcn, vrcd, vrce)
+                    if hres is not None and vres is not None:
+                        dpi = (hres, vres)
+                    break
+
+    if size is None or mode is None:
+        raise SyntaxError("Malformed JP2 header")
+
+    return (size, mode, mimetype, dpi)
+
+
+##
+# Image plugin for JPEG2000 images.
+
+
+class Jpeg2KImageFile(ImageFile.ImageFile):
+    format = "JPEG2000"
+    format_description = "JPEG 2000 (ISO 15444)"
+
+    def _open(self):
+        sig = self.fp.read(4)
+        if sig == b"\xff\x4f\xff\x51":
+            self.codec = "j2k"
+            self._size, self.mode = _parse_codestream(self.fp)
+        else:
+            sig = sig + self.fp.read(8)
+
+            if sig == b"\x00\x00\x00\x0cjP  \x0d\x0a\x87\x0a":
+                self.codec = "jp2"
+                header = _parse_jp2_header(self.fp)
+                self._size, self.mode, self.custom_mimetype, dpi = header
+                if dpi is not None:
+                    self.info["dpi"] = dpi
+            else:
+                raise SyntaxError("not a JPEG 2000 file")
+
+        if self.size is None or self.mode is None:
+            raise SyntaxError("unable to determine size/mode")
+
+        self._reduce = 0
+        self.layers = 0
+
+        fd = -1
+        length = -1
+
+        try:
+            fd = self.fp.fileno()
+            length = os.fstat(fd).st_size
+        except Exception:
+            fd = -1
+            try:
+                pos = self.fp.tell()
+                self.fp.seek(0, io.SEEK_END)
+                length = self.fp.tell()
+                self.fp.seek(pos)
+            except Exception:
+                length = -1
+
+        self.tile = [
+            (
+                "jpeg2k",
+                (0, 0) + self.size,
+                0,
+                (self.codec, self._reduce, self.layers, fd, length),
+            )
+        ]
+
+    @property
+    def reduce(self):
+        # https://github.com/python-pillow/Pillow/issues/4343 found that the
+        # new Image 'reduce' method was shadowed by this plugin's 'reduce'
+        # property. This attempts to allow for both scenarios
+        return self._reduce or super().reduce
+
+    @reduce.setter
+    def reduce(self, value):
+        self._reduce = value
+
+    def load(self):
+        if self.tile and self._reduce:
+            power = 1 << self._reduce
+            adjust = power >> 1
+            self._size = (
+                int((self.size[0] + adjust) / power),
+                int((self.size[1] + adjust) / power),
+            )
+
+            # Update the reduce and layers settings
+            t = self.tile[0]
+            t3 = (t[3][0], self._reduce, self.layers, t[3][3], t[3][4])
+            self.tile = [(t[0], (0, 0) + self.size, t[2], t3)]
+
+        return ImageFile.ImageFile.load(self)
+
+
+def _accept(prefix):
+    return (
+        prefix[:4] == b"\xff\x4f\xff\x51"
+        or prefix[:12] == b"\x00\x00\x00\x0cjP  \x0d\x0a\x87\x0a"
+    )
+
+
+# ------------------------------------------------------------
+# Save support
+
+
+def _save(im, fp, filename):
+    if filename.endswith(".j2k"):
+        kind = "j2k"
+    else:
+        kind = "jp2"
+
+    # Get the keyword arguments
+    info = im.encoderinfo
+
+    offset = info.get("offset", None)
+    tile_offset = info.get("tile_offset", None)
+    tile_size = info.get("tile_size", None)
+    quality_mode = info.get("quality_mode", "rates")
+    quality_layers = info.get("quality_layers", None)
+    if quality_layers is not None and not (
+        isinstance(quality_layers, (list, tuple))
+        and all(
+            [
+                isinstance(quality_layer, (int, float))
+                for quality_layer in quality_layers
+            ]
+        )
+    ):
+        raise ValueError("quality_layers must be a sequence of numbers")
+
+    num_resolutions = info.get("num_resolutions", 0)
+    cblk_size = info.get("codeblock_size", None)
+    precinct_size = info.get("precinct_size", None)
+    irreversible = info.get("irreversible", False)
+    progression = info.get("progression", "LRCP")
+    cinema_mode = info.get("cinema_mode", "no")
+    fd = -1
+
+    if hasattr(fp, "fileno"):
+        try:
+            fd = fp.fileno()
+        except Exception:
+            fd = -1
+
+    im.encoderconfig = (
+        offset,
+        tile_offset,
+        tile_size,
+        quality_mode,
+        quality_layers,
+        num_resolutions,
+        cblk_size,
+        precinct_size,
+        irreversible,
+        progression,
+        cinema_mode,
+        fd,
+    )
+
+    ImageFile._save(im, fp, [("jpeg2k", (0, 0) + im.size, 0, kind)])
+
+
+# ------------------------------------------------------------
+# Registry stuff
+
+
+Image.register_open(Jpeg2KImageFile.format, Jpeg2KImageFile, _accept)
+Image.register_save(Jpeg2KImageFile.format, _save)
+
+Image.register_extensions(
+    Jpeg2KImageFile.format, [".jp2", ".j2k", ".jpc", ".jpf", ".jpx", ".j2c"]
+)
+
+Image.register_mime(Jpeg2KImageFile.format, "image/jp2")
diff --git a/.venv/lib/python3.7/site-packages/PIL/JpegImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/JpegImagePlugin.py
new file mode 100644
index 0000000..ccdcc20
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/JpegImagePlugin.py
@@ -0,0 +1,827 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# JPEG (JFIF) file handling
+#
+# See "Digital Compression and Coding of Continuous-Tone Still Images,
+# Part 1, Requirements and Guidelines" (CCITT T.81 / ISO 10918-1)
+#
+# History:
+# 1995-09-09 fl   Created
+# 1995-09-13 fl   Added full parser
+# 1996-03-25 fl   Added hack to use the IJG command line utilities
+# 1996-05-05 fl   Workaround Photoshop 2.5 CMYK polarity bug
+# 1996-05-28 fl   Added draft support, JFIF version (0.1)
+# 1996-12-30 fl   Added encoder options, added progression property (0.2)
+# 1997-08-27 fl   Save mode 1 images as BW (0.3)
+# 1998-07-12 fl   Added YCbCr to draft and save methods (0.4)
+# 1998-10-19 fl   Don't hang on files using 16-bit DQT's (0.4.1)
+# 2001-04-16 fl   Extract DPI settings from JFIF files (0.4.2)
+# 2002-07-01 fl   Skip pad bytes before markers; identify Exif files (0.4.3)
+# 2003-04-25 fl   Added experimental EXIF decoder (0.5)
+# 2003-06-06 fl   Added experimental EXIF GPSinfo decoder
+# 2003-09-13 fl   Extract COM markers
+# 2009-09-06 fl   Added icc_profile support (from Florian Hoech)
+# 2009-03-06 fl   Changed CMYK handling; always use Adobe polarity (0.6)
+# 2009-03-08 fl   Added subsampling support (from Justin Huff).
+#
+# Copyright (c) 1997-2003 by Secret Labs AB.
+# Copyright (c) 1995-1996 by Fredrik Lundh.
+#
+# See the README file for information on usage and redistribution.
+#
+import array
+import io
+import math
+import os
+import struct
+import subprocess
+import sys
+import tempfile
+import warnings
+
+from . import Image, ImageFile, TiffImagePlugin
+from ._binary import i16be as i16
+from ._binary import i32be as i32
+from ._binary import o8
+from .JpegPresets import presets
+
+#
+# Parser
+
+
+def Skip(self, marker):
+    n = i16(self.fp.read(2)) - 2
+    ImageFile._safe_read(self.fp, n)
+
+
+def APP(self, marker):
+    #
+    # Application marker.  Store these in the APP dictionary.
+    # Also look for well-known application markers.
+
+    n = i16(self.fp.read(2)) - 2
+    s = ImageFile._safe_read(self.fp, n)
+
+    app = "APP%d" % (marker & 15)
+
+    self.app[app] = s  # compatibility
+    self.applist.append((app, s))
+
+    if marker == 0xFFE0 and s[:4] == b"JFIF":
+        # extract JFIF information
+        self.info["jfif"] = version = i16(s, 5)  # version
+        self.info["jfif_version"] = divmod(version, 256)
+        # extract JFIF properties
+        try:
+            jfif_unit = s[7]
+            jfif_density = i16(s, 8), i16(s, 10)
+        except Exception:
+            pass
+        else:
+            if jfif_unit == 1:
+                self.info["dpi"] = jfif_density
+            self.info["jfif_unit"] = jfif_unit
+            self.info["jfif_density"] = jfif_density
+    elif marker == 0xFFE1 and s[:5] == b"Exif\0":
+        if "exif" not in self.info:
+            # extract EXIF information (incomplete)
+            self.info["exif"] = s  # FIXME: value will change
+    elif marker == 0xFFE2 and s[:5] == b"FPXR\0":
+        # extract FlashPix information (incomplete)
+        self.info["flashpix"] = s  # FIXME: value will change
+    elif marker == 0xFFE2 and s[:12] == b"ICC_PROFILE\0":
+        # Since an ICC profile can be larger than the maximum size of
+        # a JPEG marker (64K), we need provisions to split it into
+        # multiple markers. The format defined by the ICC specifies
+        # one or more APP2 markers containing the following data:
+        #   Identifying string      ASCII "ICC_PROFILE\0"  (12 bytes)
+        #   Marker sequence number  1, 2, etc (1 byte)
+        #   Number of markers       Total of APP2's used (1 byte)
+        #   Profile data            (remainder of APP2 data)
+        # Decoders should use the marker sequence numbers to
+        # reassemble the profile, rather than assuming that the APP2
+        # markers appear in the correct sequence.
+        self.icclist.append(s)
+    elif marker == 0xFFED and s[:14] == b"Photoshop 3.0\x00":
+        # parse the image resource block
+        offset = 14
+        photoshop = self.info.setdefault("photoshop", {})
+        while s[offset : offset + 4] == b"8BIM":
+            try:
+                offset += 4
+                # resource code
+                code = i16(s, offset)
+                offset += 2
+                # resource name (usually empty)
+                name_len = s[offset]
+                # name = s[offset+1:offset+1+name_len]
+                offset += 1 + name_len
+                offset += offset & 1  # align
+                # resource data block
+                size = i32(s, offset)
+                offset += 4
+                data = s[offset : offset + size]
+                if code == 0x03ED:  # ResolutionInfo
+                    data = {
+                        "XResolution": i32(data, 0) / 65536,
+                        "DisplayedUnitsX": i16(data, 4),
+                        "YResolution": i32(data, 8) / 65536,
+                        "DisplayedUnitsY": i16(data, 12),
+                    }
+                photoshop[code] = data
+                offset += size
+                offset += offset & 1  # align
+            except struct.error:
+                break  # insufficient data
+
+    elif marker == 0xFFEE and s[:5] == b"Adobe":
+        self.info["adobe"] = i16(s, 5)
+        # extract Adobe custom properties
+        try:
+            adobe_transform = s[11]
+        except IndexError:
+            pass
+        else:
+            self.info["adobe_transform"] = adobe_transform
+    elif marker == 0xFFE2 and s[:4] == b"MPF\0":
+        # extract MPO information
+        self.info["mp"] = s[4:]
+        # offset is current location minus buffer size
+        # plus constant header size
+        self.info["mpoffset"] = self.fp.tell() - n + 4
+
+    # If DPI isn't in JPEG header, fetch from EXIF
+    if "dpi" not in self.info and "exif" in self.info:
+        try:
+            exif = self.getexif()
+            resolution_unit = exif[0x0128]
+            x_resolution = exif[0x011A]
+            try:
+                dpi = float(x_resolution[0]) / x_resolution[1]
+            except TypeError:
+                dpi = x_resolution
+            if math.isnan(dpi):
+                raise ValueError
+            if resolution_unit == 3:  # cm
+                # 1 dpcm = 2.54 dpi
+                dpi *= 2.54
+            self.info["dpi"] = dpi, dpi
+        except (TypeError, KeyError, SyntaxError, ValueError, ZeroDivisionError):
+            # SyntaxError for invalid/unreadable EXIF
+            # KeyError for dpi not included
+            # ZeroDivisionError for invalid dpi rational value
+            # ValueError or TypeError for dpi being an invalid float
+            self.info["dpi"] = 72, 72
+
+
+def COM(self, marker):
+    #
+    # Comment marker.  Store these in the APP dictionary.
+    n = i16(self.fp.read(2)) - 2
+    s = ImageFile._safe_read(self.fp, n)
+
+    self.info["comment"] = s
+    self.app["COM"] = s  # compatibility
+    self.applist.append(("COM", s))
+
+
+def SOF(self, marker):
+    #
+    # Start of frame marker.  Defines the size and mode of the
+    # image.  JPEG is colour blind, so we use some simple
+    # heuristics to map the number of layers to an appropriate
+    # mode.  Note that this could be made a bit brighter, by
+    # looking for JFIF and Adobe APP markers.
+
+    n = i16(self.fp.read(2)) - 2
+    s = ImageFile._safe_read(self.fp, n)
+    self._size = i16(s, 3), i16(s, 1)
+
+    self.bits = s[0]
+    if self.bits != 8:
+        raise SyntaxError(f"cannot handle {self.bits}-bit layers")
+
+    self.layers = s[5]
+    if self.layers == 1:
+        self.mode = "L"
+    elif self.layers == 3:
+        self.mode = "RGB"
+    elif self.layers == 4:
+        self.mode = "CMYK"
+    else:
+        raise SyntaxError(f"cannot handle {self.layers}-layer images")
+
+    if marker in [0xFFC2, 0xFFC6, 0xFFCA, 0xFFCE]:
+        self.info["progressive"] = self.info["progression"] = 1
+
+    if self.icclist:
+        # fixup icc profile
+        self.icclist.sort()  # sort by sequence number
+        if self.icclist[0][13] == len(self.icclist):
+            profile = []
+            for p in self.icclist:
+                profile.append(p[14:])
+            icc_profile = b"".join(profile)
+        else:
+            icc_profile = None  # wrong number of fragments
+        self.info["icc_profile"] = icc_profile
+        self.icclist = []
+
+    for i in range(6, len(s), 3):
+        t = s[i : i + 3]
+        # 4-tuples: id, vsamp, hsamp, qtable
+        self.layer.append((t[0], t[1] // 16, t[1] & 15, t[2]))
+
+
+def DQT(self, marker):
+    #
+    # Define quantization table.  Note that there might be more
+    # than one table in each marker.
+
+    # FIXME: The quantization tables can be used to estimate the
+    # compression quality.
+
+    n = i16(self.fp.read(2)) - 2
+    s = ImageFile._safe_read(self.fp, n)
+    while len(s):
+        v = s[0]
+        precision = 1 if (v // 16 == 0) else 2  # in bytes
+        qt_length = 1 + precision * 64
+        if len(s) < qt_length:
+            raise SyntaxError("bad quantization table marker")
+        data = array.array("B" if precision == 1 else "H", s[1:qt_length])
+        if sys.byteorder == "little" and precision > 1:
+            data.byteswap()  # the values are always big-endian
+        self.quantization[v & 15] = [data[i] for i in zigzag_index]
+        s = s[qt_length:]
+
+
+#
+# JPEG marker table
+
+MARKER = {
+    0xFFC0: ("SOF0", "Baseline DCT", SOF),
+    0xFFC1: ("SOF1", "Extended Sequential DCT", SOF),
+    0xFFC2: ("SOF2", "Progressive DCT", SOF),
+    0xFFC3: ("SOF3", "Spatial lossless", SOF),
+    0xFFC4: ("DHT", "Define Huffman table", Skip),
+    0xFFC5: ("SOF5", "Differential sequential DCT", SOF),
+    0xFFC6: ("SOF6", "Differential progressive DCT", SOF),
+    0xFFC7: ("SOF7", "Differential spatial", SOF),
+    0xFFC8: ("JPG", "Extension", None),
+    0xFFC9: ("SOF9", "Extended sequential DCT (AC)", SOF),
+    0xFFCA: ("SOF10", "Progressive DCT (AC)", SOF),
+    0xFFCB: ("SOF11", "Spatial lossless DCT (AC)", SOF),
+    0xFFCC: ("DAC", "Define arithmetic coding conditioning", Skip),
+    0xFFCD: ("SOF13", "Differential sequential DCT (AC)", SOF),
+    0xFFCE: ("SOF14", "Differential progressive DCT (AC)", SOF),
+    0xFFCF: ("SOF15", "Differential spatial (AC)", SOF),
+    0xFFD0: ("RST0", "Restart 0", None),
+    0xFFD1: ("RST1", "Restart 1", None),
+    0xFFD2: ("RST2", "Restart 2", None),
+    0xFFD3: ("RST3", "Restart 3", None),
+    0xFFD4: ("RST4", "Restart 4", None),
+    0xFFD5: ("RST5", "Restart 5", None),
+    0xFFD6: ("RST6", "Restart 6", None),
+    0xFFD7: ("RST7", "Restart 7", None),
+    0xFFD8: ("SOI", "Start of image", None),
+    0xFFD9: ("EOI", "End of image", None),
+    0xFFDA: ("SOS", "Start of scan", Skip),
+    0xFFDB: ("DQT", "Define quantization table", DQT),
+    0xFFDC: ("DNL", "Define number of lines", Skip),
+    0xFFDD: ("DRI", "Define restart interval", Skip),
+    0xFFDE: ("DHP", "Define hierarchical progression", SOF),
+    0xFFDF: ("EXP", "Expand reference component", Skip),
+    0xFFE0: ("APP0", "Application segment 0", APP),
+    0xFFE1: ("APP1", "Application segment 1", APP),
+    0xFFE2: ("APP2", "Application segment 2", APP),
+    0xFFE3: ("APP3", "Application segment 3", APP),
+    0xFFE4: ("APP4", "Application segment 4", APP),
+    0xFFE5: ("APP5", "Application segment 5", APP),
+    0xFFE6: ("APP6", "Application segment 6", APP),
+    0xFFE7: ("APP7", "Application segment 7", APP),
+    0xFFE8: ("APP8", "Application segment 8", APP),
+    0xFFE9: ("APP9", "Application segment 9", APP),
+    0xFFEA: ("APP10", "Application segment 10", APP),
+    0xFFEB: ("APP11", "Application segment 11", APP),
+    0xFFEC: ("APP12", "Application segment 12", APP),
+    0xFFED: ("APP13", "Application segment 13", APP),
+    0xFFEE: ("APP14", "Application segment 14", APP),
+    0xFFEF: ("APP15", "Application segment 15", APP),
+    0xFFF0: ("JPG0", "Extension 0", None),
+    0xFFF1: ("JPG1", "Extension 1", None),
+    0xFFF2: ("JPG2", "Extension 2", None),
+    0xFFF3: ("JPG3", "Extension 3", None),
+    0xFFF4: ("JPG4", "Extension 4", None),
+    0xFFF5: ("JPG5", "Extension 5", None),
+    0xFFF6: ("JPG6", "Extension 6", None),
+    0xFFF7: ("JPG7", "Extension 7", None),
+    0xFFF8: ("JPG8", "Extension 8", None),
+    0xFFF9: ("JPG9", "Extension 9", None),
+    0xFFFA: ("JPG10", "Extension 10", None),
+    0xFFFB: ("JPG11", "Extension 11", None),
+    0xFFFC: ("JPG12", "Extension 12", None),
+    0xFFFD: ("JPG13", "Extension 13", None),
+    0xFFFE: ("COM", "Comment", COM),
+}
+
+
+def _accept(prefix):
+    # Magic number was taken from https://en.wikipedia.org/wiki/JPEG
+    return prefix[0:3] == b"\xFF\xD8\xFF"
+
+
+##
+# Image plugin for JPEG and JFIF images.
+
+
+class JpegImageFile(ImageFile.ImageFile):
+
+    format = "JPEG"
+    format_description = "JPEG (ISO 10918)"
+
+    def _open(self):
+
+        s = self.fp.read(3)
+
+        if not _accept(s):
+            raise SyntaxError("not a JPEG file")
+        s = b"\xFF"
+
+        # Create attributes
+        self.bits = self.layers = 0
+
+        # JPEG specifics (internal)
+        self.layer = []
+        self.huffman_dc = {}
+        self.huffman_ac = {}
+        self.quantization = {}
+        self.app = {}  # compatibility
+        self.applist = []
+        self.icclist = []
+
+        while True:
+
+            i = s[0]
+            if i == 0xFF:
+                s = s + self.fp.read(1)
+                i = i16(s)
+            else:
+                # Skip non-0xFF junk
+                s = self.fp.read(1)
+                continue
+
+            if i in MARKER:
+                name, description, handler = MARKER[i]
+                if handler is not None:
+                    handler(self, i)
+                if i == 0xFFDA:  # start of scan
+                    rawmode = self.mode
+                    if self.mode == "CMYK":
+                        rawmode = "CMYK;I"  # assume adobe conventions
+                    self.tile = [("jpeg", (0, 0) + self.size, 0, (rawmode, ""))]
+                    # self.__offset = self.fp.tell()
+                    break
+                s = self.fp.read(1)
+            elif i == 0 or i == 0xFFFF:
+                # padded marker or junk; move on
+                s = b"\xff"
+            elif i == 0xFF00:  # Skip extraneous data (escaped 0xFF)
+                s = self.fp.read(1)
+            else:
+                raise SyntaxError("no marker found")
+
+    def load_read(self, read_bytes):
+        """
+        internal: read more image data
+        For premature EOF and LOAD_TRUNCATED_IMAGES adds EOI marker
+        so libjpeg can finish decoding
+        """
+        s = self.fp.read(read_bytes)
+
+        if not s and ImageFile.LOAD_TRUNCATED_IMAGES and not hasattr(self, "_ended"):
+            # Premature EOF.
+            # Pretend file is finished adding EOI marker
+            self._ended = True
+            return b"\xFF\xD9"
+
+        return s
+
+    def draft(self, mode, size):
+
+        if len(self.tile) != 1:
+            return
+
+        # Protect from second call
+        if self.decoderconfig:
+            return
+
+        d, e, o, a = self.tile[0]
+        scale = 1
+        original_size = self.size
+
+        if a[0] == "RGB" and mode in ["L", "YCbCr"]:
+            self.mode = mode
+            a = mode, ""
+
+        if size:
+            scale = min(self.size[0] // size[0], self.size[1] // size[1])
+            for s in [8, 4, 2, 1]:
+                if scale >= s:
+                    break
+            e = (
+                e[0],
+                e[1],
+                (e[2] - e[0] + s - 1) // s + e[0],
+                (e[3] - e[1] + s - 1) // s + e[1],
+            )
+            self._size = ((self.size[0] + s - 1) // s, (self.size[1] + s - 1) // s)
+            scale = s
+
+        self.tile = [(d, e, o, a)]
+        self.decoderconfig = (scale, 0)
+
+        box = (0, 0, original_size[0] / scale, original_size[1] / scale)
+        return (self.mode, box)
+
+    def load_djpeg(self):
+
+        # ALTERNATIVE: handle JPEGs via the IJG command line utilities
+
+        f, path = tempfile.mkstemp()
+        os.close(f)
+        if os.path.exists(self.filename):
+            subprocess.check_call(["djpeg", "-outfile", path, self.filename])
+        else:
+            raise ValueError("Invalid Filename")
+
+        try:
+            with Image.open(path) as _im:
+                _im.load()
+                self.im = _im.im
+        finally:
+            try:
+                os.unlink(path)
+            except OSError:
+                pass
+
+        self.mode = self.im.mode
+        self._size = self.im.size
+
+        self.tile = []
+
+    def _getexif(self):
+        return _getexif(self)
+
+    def _getmp(self):
+        return _getmp(self)
+
+    def getxmp(self):
+        """
+        Returns a dictionary containing the XMP tags.
+        Requires defusedxml to be installed.
+        :returns: XMP tags in a dictionary.
+        """
+
+        for segment, content in self.applist:
+            if segment == "APP1":
+                marker, xmp_tags = content.rsplit(b"\x00", 1)
+                if marker == b"http://ns.adobe.com/xap/1.0/":
+                    return self._getxmp(xmp_tags)
+        return {}
+
+
+def _getexif(self):
+    if "exif" not in self.info:
+        return None
+    return self.getexif()._get_merged_dict()
+
+
+def _getmp(self):
+    # Extract MP information.  This method was inspired by the "highly
+    # experimental" _getexif version that's been in use for years now,
+    # itself based on the ImageFileDirectory class in the TIFF plugin.
+
+    # The MP record essentially consists of a TIFF file embedded in a JPEG
+    # application marker.
+    try:
+        data = self.info["mp"]
+    except KeyError:
+        return None
+    file_contents = io.BytesIO(data)
+    head = file_contents.read(8)
+    endianness = ">" if head[:4] == b"\x4d\x4d\x00\x2a" else "<"
+    # process dictionary
+    try:
+        info = TiffImagePlugin.ImageFileDirectory_v2(head)
+        file_contents.seek(info.next)
+        info.load(file_contents)
+        mp = dict(info)
+    except Exception as e:
+        raise SyntaxError("malformed MP Index (unreadable directory)") from e
+    # it's an error not to have a number of images
+    try:
+        quant = mp[0xB001]
+    except KeyError as e:
+        raise SyntaxError("malformed MP Index (no number of images)") from e
+    # get MP entries
+    mpentries = []
+    try:
+        rawmpentries = mp[0xB002]
+        for entrynum in range(0, quant):
+            unpackedentry = struct.unpack_from(
+                f"{endianness}LLLHH", rawmpentries, entrynum * 16
+            )
+            labels = ("Attribute", "Size", "DataOffset", "EntryNo1", "EntryNo2")
+            mpentry = dict(zip(labels, unpackedentry))
+            mpentryattr = {
+                "DependentParentImageFlag": bool(mpentry["Attribute"] & (1 << 31)),
+                "DependentChildImageFlag": bool(mpentry["Attribute"] & (1 << 30)),
+                "RepresentativeImageFlag": bool(mpentry["Attribute"] & (1 << 29)),
+                "Reserved": (mpentry["Attribute"] & (3 << 27)) >> 27,
+                "ImageDataFormat": (mpentry["Attribute"] & (7 << 24)) >> 24,
+                "MPType": mpentry["Attribute"] & 0x00FFFFFF,
+            }
+            if mpentryattr["ImageDataFormat"] == 0:
+                mpentryattr["ImageDataFormat"] = "JPEG"
+            else:
+                raise SyntaxError("unsupported picture format in MPO")
+            mptypemap = {
+                0x000000: "Undefined",
+                0x010001: "Large Thumbnail (VGA Equivalent)",
+                0x010002: "Large Thumbnail (Full HD Equivalent)",
+                0x020001: "Multi-Frame Image (Panorama)",
+                0x020002: "Multi-Frame Image: (Disparity)",
+                0x020003: "Multi-Frame Image: (Multi-Angle)",
+                0x030000: "Baseline MP Primary Image",
+            }
+            mpentryattr["MPType"] = mptypemap.get(mpentryattr["MPType"], "Unknown")
+            mpentry["Attribute"] = mpentryattr
+            mpentries.append(mpentry)
+        mp[0xB002] = mpentries
+    except KeyError as e:
+        raise SyntaxError("malformed MP Index (bad MP Entry)") from e
+    # Next we should try and parse the individual image unique ID list;
+    # we don't because I've never seen this actually used in a real MPO
+    # file and so can't test it.
+    return mp
+
+
+# --------------------------------------------------------------------
+# stuff to save JPEG files
+
+RAWMODE = {
+    "1": "L",
+    "L": "L",
+    "RGB": "RGB",
+    "RGBX": "RGB",
+    "CMYK": "CMYK;I",  # assume adobe conventions
+    "YCbCr": "YCbCr",
+}
+
+# fmt: off
+zigzag_index = (
+    0,  1,  5,  6, 14, 15, 27, 28,
+    2,  4,  7, 13, 16, 26, 29, 42,
+    3,  8, 12, 17, 25, 30, 41, 43,
+    9, 11, 18, 24, 31, 40, 44, 53,
+    10, 19, 23, 32, 39, 45, 52, 54,
+    20, 22, 33, 38, 46, 51, 55, 60,
+    21, 34, 37, 47, 50, 56, 59, 61,
+    35, 36, 48, 49, 57, 58, 62, 63,
+)
+
+samplings = {
+    (1, 1, 1, 1, 1, 1): 0,
+    (2, 1, 1, 1, 1, 1): 1,
+    (2, 2, 1, 1, 1, 1): 2,
+}
+# fmt: on
+
+
+def convert_dict_qtables(qtables):
+    warnings.warn(
+        "convert_dict_qtables is deprecated and will be removed in Pillow 10"
+        "(2023-07-01). Conversion is no longer needed.",
+        DeprecationWarning,
+    )
+    return qtables
+
+
+def get_sampling(im):
+    # There's no subsampling when images have only 1 layer
+    # (grayscale images) or when they are CMYK (4 layers),
+    # so set subsampling to the default value.
+    #
+    # NOTE: currently Pillow can't encode JPEG to YCCK format.
+    # If YCCK support is added in the future, subsampling code will have
+    # to be updated (here and in JpegEncode.c) to deal with 4 layers.
+    if not hasattr(im, "layers") or im.layers in (1, 4):
+        return -1
+    sampling = im.layer[0][1:3] + im.layer[1][1:3] + im.layer[2][1:3]
+    return samplings.get(sampling, -1)
+
+
+def _save(im, fp, filename):
+
+    try:
+        rawmode = RAWMODE[im.mode]
+    except KeyError as e:
+        raise OSError(f"cannot write mode {im.mode} as JPEG") from e
+
+    info = im.encoderinfo
+
+    dpi = [round(x) for x in info.get("dpi", (0, 0))]
+
+    quality = info.get("quality", -1)
+    subsampling = info.get("subsampling", -1)
+    qtables = info.get("qtables")
+
+    if quality == "keep":
+        quality = -1
+        subsampling = "keep"
+        qtables = "keep"
+    elif quality in presets:
+        preset = presets[quality]
+        quality = -1
+        subsampling = preset.get("subsampling", -1)
+        qtables = preset.get("quantization")
+    elif not isinstance(quality, int):
+        raise ValueError("Invalid quality setting")
+    else:
+        if subsampling in presets:
+            subsampling = presets[subsampling].get("subsampling", -1)
+        if isinstance(qtables, str) and qtables in presets:
+            qtables = presets[qtables].get("quantization")
+
+    if subsampling == "4:4:4":
+        subsampling = 0
+    elif subsampling == "4:2:2":
+        subsampling = 1
+    elif subsampling == "4:2:0":
+        subsampling = 2
+    elif subsampling == "4:1:1":
+        # For compatibility. Before Pillow 4.3, 4:1:1 actually meant 4:2:0.
+        # Set 4:2:0 if someone is still using that value.
+        subsampling = 2
+    elif subsampling == "keep":
+        if im.format != "JPEG":
+            raise ValueError("Cannot use 'keep' when original image is not a JPEG")
+        subsampling = get_sampling(im)
+
+    def validate_qtables(qtables):
+        if qtables is None:
+            return qtables
+        if isinstance(qtables, str):
+            try:
+                lines = [
+                    int(num)
+                    for line in qtables.splitlines()
+                    for num in line.split("#", 1)[0].split()
+                ]
+            except ValueError as e:
+                raise ValueError("Invalid quantization table") from e
+            else:
+                qtables = [lines[s : s + 64] for s in range(0, len(lines), 64)]
+        if isinstance(qtables, (tuple, list, dict)):
+            if isinstance(qtables, dict):
+                qtables = [
+                    qtables[key] for key in range(len(qtables)) if key in qtables
+                ]
+            elif isinstance(qtables, tuple):
+                qtables = list(qtables)
+            if not (0 < len(qtables) < 5):
+                raise ValueError("None or too many quantization tables")
+            for idx, table in enumerate(qtables):
+                try:
+                    if len(table) != 64:
+                        raise TypeError
+                    table = array.array("H", table)
+                except TypeError as e:
+                    raise ValueError("Invalid quantization table") from e
+                else:
+                    qtables[idx] = list(table)
+            return qtables
+
+    if qtables == "keep":
+        if im.format != "JPEG":
+            raise ValueError("Cannot use 'keep' when original image is not a JPEG")
+        qtables = getattr(im, "quantization", None)
+    qtables = validate_qtables(qtables)
+
+    extra = b""
+
+    icc_profile = info.get("icc_profile")
+    if icc_profile:
+        ICC_OVERHEAD_LEN = 14
+        MAX_BYTES_IN_MARKER = 65533
+        MAX_DATA_BYTES_IN_MARKER = MAX_BYTES_IN_MARKER - ICC_OVERHEAD_LEN
+        markers = []
+        while icc_profile:
+            markers.append(icc_profile[:MAX_DATA_BYTES_IN_MARKER])
+            icc_profile = icc_profile[MAX_DATA_BYTES_IN_MARKER:]
+        i = 1
+        for marker in markers:
+            size = struct.pack(">H", 2 + ICC_OVERHEAD_LEN + len(marker))
+            extra += (
+                b"\xFF\xE2"
+                + size
+                + b"ICC_PROFILE\0"
+                + o8(i)
+                + o8(len(markers))
+                + marker
+            )
+            i += 1
+
+    # "progressive" is the official name, but older documentation
+    # says "progression"
+    # FIXME: issue a warning if the wrong form is used (post-1.1.7)
+    progressive = info.get("progressive", False) or info.get("progression", False)
+
+    optimize = info.get("optimize", False)
+
+    exif = info.get("exif", b"")
+    if isinstance(exif, Image.Exif):
+        exif = exif.tobytes()
+
+    # get keyword arguments
+    im.encoderconfig = (
+        quality,
+        progressive,
+        info.get("smooth", 0),
+        optimize,
+        info.get("streamtype", 0),
+        dpi[0],
+        dpi[1],
+        subsampling,
+        qtables,
+        extra,
+        exif,
+    )
+
+    # if we optimize, libjpeg needs a buffer big enough to hold the whole image
+    # in a shot. Guessing on the size, at im.size bytes. (raw pixel size is
+    # channels*size, this is a value that's been used in a django patch.
+    # https://github.com/matthewwithanm/django-imagekit/issues/50
+    bufsize = 0
+    if optimize or progressive:
+        # CMYK can be bigger
+        if im.mode == "CMYK":
+            bufsize = 4 * im.size[0] * im.size[1]
+        # keep sets quality to -1, but the actual value may be high.
+        elif quality >= 95 or quality == -1:
+            bufsize = 2 * im.size[0] * im.size[1]
+        else:
+            bufsize = im.size[0] * im.size[1]
+
+    # The EXIF info needs to be written as one block, + APP1, + one spare byte.
+    # Ensure that our buffer is big enough. Same with the icc_profile block.
+    bufsize = max(ImageFile.MAXBLOCK, bufsize, len(exif) + 5, len(extra) + 1)
+
+    ImageFile._save(im, fp, [("jpeg", (0, 0) + im.size, 0, rawmode)], bufsize)
+
+
+def _save_cjpeg(im, fp, filename):
+    # ALTERNATIVE: handle JPEGs via the IJG command line utilities.
+    tempfile = im._dump()
+    subprocess.check_call(["cjpeg", "-outfile", filename, tempfile])
+    try:
+        os.unlink(tempfile)
+    except OSError:
+        pass
+
+
+##
+# Factory for making JPEG and MPO instances
+def jpeg_factory(fp=None, filename=None):
+    im = JpegImageFile(fp, filename)
+    try:
+        mpheader = im._getmp()
+        if mpheader[45057] > 1:
+            # It's actually an MPO
+            from .MpoImagePlugin import MpoImageFile
+
+            # Don't reload everything, just convert it.
+            im = MpoImageFile.adopt(im, mpheader)
+    except (TypeError, IndexError):
+        # It is really a JPEG
+        pass
+    except SyntaxError:
+        warnings.warn(
+            "Image appears to be a malformed MPO file, it will be "
+            "interpreted as a base JPEG file"
+        )
+    return im
+
+
+# ---------------------------------------------------------------------
+# Registry stuff
+
+Image.register_open(JpegImageFile.format, jpeg_factory, _accept)
+Image.register_save(JpegImageFile.format, _save)
+
+Image.register_extensions(JpegImageFile.format, [".jfif", ".jpe", ".jpg", ".jpeg"])
+
+Image.register_mime(JpegImageFile.format, "image/jpeg")
diff --git a/.venv/lib/python3.7/site-packages/PIL/JpegPresets.py b/.venv/lib/python3.7/site-packages/PIL/JpegPresets.py
new file mode 100644
index 0000000..e5a5d17
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/JpegPresets.py
@@ -0,0 +1,240 @@
+"""
+JPEG quality settings equivalent to the Photoshop settings.
+Can be used when saving JPEG files.
+
+The following presets are available by default:
+``web_low``, ``web_medium``, ``web_high``, ``web_very_high``, ``web_maximum``,
+``low``, ``medium``, ``high``, ``maximum``.
+More presets can be added to the :py:data:`presets` dict if needed.
+
+To apply the preset, specify::
+
+  quality="preset_name"
+
+To apply only the quantization table::
+
+  qtables="preset_name"
+
+To apply only the subsampling setting::
+
+  subsampling="preset_name"
+
+Example::
+
+  im.save("image_name.jpg", quality="web_high")
+
+Subsampling
+-----------
+
+Subsampling is the practice of encoding images by implementing less resolution
+for chroma information than for luma information.
+(ref.: https://en.wikipedia.org/wiki/Chroma_subsampling)
+
+Possible subsampling values are 0, 1 and 2 that correspond to 4:4:4, 4:2:2 and
+4:2:0.
+
+You can get the subsampling of a JPEG with the
+:func:`.JpegImagePlugin.get_sampling` function.
+
+In JPEG compressed data a JPEG marker is used instead of an EXIF tag.
+(ref.: https://www.exiv2.org/tags.html)
+
+
+Quantization tables
+-------------------
+
+They are values use by the DCT (Discrete cosine transform) to remove
+*unnecessary* information from the image (the lossy part of the compression).
+(ref.: https://en.wikipedia.org/wiki/Quantization_matrix#Quantization_matrices,
+https://en.wikipedia.org/wiki/JPEG#Quantization)
+
+You can get the quantization tables of a JPEG with::
+
+  im.quantization
+
+This will return a dict with a number of lists. You can pass this dict
+directly as the qtables argument when saving a JPEG.
+
+The quantization table format in presets is a list with sublists. These formats
+are interchangeable.
+
+Libjpeg ref.:
+https://web.archive.org/web/20120328125543/http://www.jpegcameras.com/libjpeg/libjpeg-3.html
+
+"""
+
+# fmt: off
+presets = {
+            'web_low':      {'subsampling':  2,  # "4:2:0"
+                             'quantization': [
+                               [20, 16, 25, 39, 50, 46, 62, 68,
+                                16, 18, 23, 38, 38, 53, 65, 68,
+                                25, 23, 31, 38, 53, 65, 68, 68,
+                                39, 38, 38, 53, 65, 68, 68, 68,
+                                50, 38, 53, 65, 68, 68, 68, 68,
+                                46, 53, 65, 68, 68, 68, 68, 68,
+                                62, 65, 68, 68, 68, 68, 68, 68,
+                                68, 68, 68, 68, 68, 68, 68, 68],
+                               [21, 25, 32, 38, 54, 68, 68, 68,
+                                25, 28, 24, 38, 54, 68, 68, 68,
+                                32, 24, 32, 43, 66, 68, 68, 68,
+                                38, 38, 43, 53, 68, 68, 68, 68,
+                                54, 54, 66, 68, 68, 68, 68, 68,
+                                68, 68, 68, 68, 68, 68, 68, 68,
+                                68, 68, 68, 68, 68, 68, 68, 68,
+                                68, 68, 68, 68, 68, 68, 68, 68]
+                              ]},
+            'web_medium':   {'subsampling':  2,  # "4:2:0"
+                             'quantization': [
+                               [16, 11, 11, 16, 23, 27, 31, 30,
+                                11, 12, 12, 15, 20, 23, 23, 30,
+                                11, 12, 13, 16, 23, 26, 35, 47,
+                                16, 15, 16, 23, 26, 37, 47, 64,
+                                23, 20, 23, 26, 39, 51, 64, 64,
+                                27, 23, 26, 37, 51, 64, 64, 64,
+                                31, 23, 35, 47, 64, 64, 64, 64,
+                                30, 30, 47, 64, 64, 64, 64, 64],
+                               [17, 15, 17, 21, 20, 26, 38, 48,
+                                15, 19, 18, 17, 20, 26, 35, 43,
+                                17, 18, 20, 22, 26, 30, 46, 53,
+                                21, 17, 22, 28, 30, 39, 53, 64,
+                                20, 20, 26, 30, 39, 48, 64, 64,
+                                26, 26, 30, 39, 48, 63, 64, 64,
+                                38, 35, 46, 53, 64, 64, 64, 64,
+                                48, 43, 53, 64, 64, 64, 64, 64]
+                             ]},
+            'web_high':     {'subsampling':  0,  # "4:4:4"
+                             'quantization': [
+                               [6,   4,  4,  6,  9, 11, 12, 16,
+                                4,   5,  5,  6,  8, 10, 12, 12,
+                                4,   5,  5,  6, 10, 12, 14, 19,
+                                6,   6,  6, 11, 12, 15, 19, 28,
+                                9,   8, 10, 12, 16, 20, 27, 31,
+                                11, 10, 12, 15, 20, 27, 31, 31,
+                                12, 12, 14, 19, 27, 31, 31, 31,
+                                16, 12, 19, 28, 31, 31, 31, 31],
+                               [7,   7, 13, 24, 26, 31, 31, 31,
+                                7,  12, 16, 21, 31, 31, 31, 31,
+                                13, 16, 17, 31, 31, 31, 31, 31,
+                                24, 21, 31, 31, 31, 31, 31, 31,
+                                26, 31, 31, 31, 31, 31, 31, 31,
+                                31, 31, 31, 31, 31, 31, 31, 31,
+                                31, 31, 31, 31, 31, 31, 31, 31,
+                                31, 31, 31, 31, 31, 31, 31, 31]
+                             ]},
+            'web_very_high': {'subsampling':  0,  # "4:4:4"
+                              'quantization': [
+                               [2,   2,  2,  2,  3,  4,  5,  6,
+                                2,   2,  2,  2,  3,  4,  5,  6,
+                                2,   2,  2,  2,  4,  5,  7,  9,
+                                2,   2,  2,  4,  5,  7,  9, 12,
+                                3,   3,  4,  5,  8, 10, 12, 12,
+                                4,   4,  5,  7, 10, 12, 12, 12,
+                                5,   5,  7,  9, 12, 12, 12, 12,
+                                6,   6,  9, 12, 12, 12, 12, 12],
+                               [3,   3,  5,  9, 13, 15, 15, 15,
+                                3,   4,  6, 11, 14, 12, 12, 12,
+                                5,   6,  9, 14, 12, 12, 12, 12,
+                                9,  11, 14, 12, 12, 12, 12, 12,
+                                13, 14, 12, 12, 12, 12, 12, 12,
+                                15, 12, 12, 12, 12, 12, 12, 12,
+                                15, 12, 12, 12, 12, 12, 12, 12,
+                                15, 12, 12, 12, 12, 12, 12, 12]
+                              ]},
+            'web_maximum':  {'subsampling':  0,  # "4:4:4"
+                             'quantization': [
+                                [1,  1,  1,  1,  1,  1,  1,  1,
+                                 1,  1,  1,  1,  1,  1,  1,  1,
+                                 1,  1,  1,  1,  1,  1,  1,  2,
+                                 1,  1,  1,  1,  1,  1,  2,  2,
+                                 1,  1,  1,  1,  1,  2,  2,  3,
+                                 1,  1,  1,  1,  2,  2,  3,  3,
+                                 1,  1,  1,  2,  2,  3,  3,  3,
+                                 1,  1,  2,  2,  3,  3,  3,  3],
+                                [1,  1,  1,  2,  2,  3,  3,  3,
+                                 1,  1,  1,  2,  3,  3,  3,  3,
+                                 1,  1,  1,  3,  3,  3,  3,  3,
+                                 2,  2,  3,  3,  3,  3,  3,  3,
+                                 2,  3,  3,  3,  3,  3,  3,  3,
+                                 3,  3,  3,  3,  3,  3,  3,  3,
+                                 3,  3,  3,  3,  3,  3,  3,  3,
+                                 3,  3,  3,  3,  3,  3,  3,  3]
+                             ]},
+            'low':          {'subsampling':  2,  # "4:2:0"
+                             'quantization': [
+                               [18, 14, 14, 21, 30, 35, 34, 17,
+                                14, 16, 16, 19, 26, 23, 12, 12,
+                                14, 16, 17, 21, 23, 12, 12, 12,
+                                21, 19, 21, 23, 12, 12, 12, 12,
+                                30, 26, 23, 12, 12, 12, 12, 12,
+                                35, 23, 12, 12, 12, 12, 12, 12,
+                                34, 12, 12, 12, 12, 12, 12, 12,
+                                17, 12, 12, 12, 12, 12, 12, 12],
+                               [20, 19, 22, 27, 20, 20, 17, 17,
+                                19, 25, 23, 14, 14, 12, 12, 12,
+                                22, 23, 14, 14, 12, 12, 12, 12,
+                                27, 14, 14, 12, 12, 12, 12, 12,
+                                20, 14, 12, 12, 12, 12, 12, 12,
+                                20, 12, 12, 12, 12, 12, 12, 12,
+                                17, 12, 12, 12, 12, 12, 12, 12,
+                                17, 12, 12, 12, 12, 12, 12, 12]
+                             ]},
+            'medium':       {'subsampling':  2,  # "4:2:0"
+                             'quantization': [
+                               [12,  8,  8, 12, 17, 21, 24, 17,
+                                8,   9,  9, 11, 15, 19, 12, 12,
+                                8,   9, 10, 12, 19, 12, 12, 12,
+                                12, 11, 12, 21, 12, 12, 12, 12,
+                                17, 15, 19, 12, 12, 12, 12, 12,
+                                21, 19, 12, 12, 12, 12, 12, 12,
+                                24, 12, 12, 12, 12, 12, 12, 12,
+                                17, 12, 12, 12, 12, 12, 12, 12],
+                               [13, 11, 13, 16, 20, 20, 17, 17,
+                                11, 14, 14, 14, 14, 12, 12, 12,
+                                13, 14, 14, 14, 12, 12, 12, 12,
+                                16, 14, 14, 12, 12, 12, 12, 12,
+                                20, 14, 12, 12, 12, 12, 12, 12,
+                                20, 12, 12, 12, 12, 12, 12, 12,
+                                17, 12, 12, 12, 12, 12, 12, 12,
+                                17, 12, 12, 12, 12, 12, 12, 12]
+                             ]},
+            'high':         {'subsampling':  0,  # "4:4:4"
+                             'quantization': [
+                               [6,   4,  4,  6,  9, 11, 12, 16,
+                                4,   5,  5,  6,  8, 10, 12, 12,
+                                4,   5,  5,  6, 10, 12, 12, 12,
+                                6,   6,  6, 11, 12, 12, 12, 12,
+                                9,   8, 10, 12, 12, 12, 12, 12,
+                                11, 10, 12, 12, 12, 12, 12, 12,
+                                12, 12, 12, 12, 12, 12, 12, 12,
+                                16, 12, 12, 12, 12, 12, 12, 12],
+                               [7,   7, 13, 24, 20, 20, 17, 17,
+                                7,  12, 16, 14, 14, 12, 12, 12,
+                                13, 16, 14, 14, 12, 12, 12, 12,
+                                24, 14, 14, 12, 12, 12, 12, 12,
+                                20, 14, 12, 12, 12, 12, 12, 12,
+                                20, 12, 12, 12, 12, 12, 12, 12,
+                                17, 12, 12, 12, 12, 12, 12, 12,
+                                17, 12, 12, 12, 12, 12, 12, 12]
+                             ]},
+            'maximum':      {'subsampling':  0,  # "4:4:4"
+                             'quantization': [
+                               [2,   2,  2,  2,  3,  4,  5,  6,
+                                2,   2,  2,  2,  3,  4,  5,  6,
+                                2,   2,  2,  2,  4,  5,  7,  9,
+                                2,   2,  2,  4,  5,  7,  9, 12,
+                                3,   3,  4,  5,  8, 10, 12, 12,
+                                4,   4,  5,  7, 10, 12, 12, 12,
+                                5,   5,  7,  9, 12, 12, 12, 12,
+                                6,   6,  9, 12, 12, 12, 12, 12],
+                               [3,   3,  5,  9, 13, 15, 15, 15,
+                                3,   4,  6, 10, 14, 12, 12, 12,
+                                5,   6,  9, 14, 12, 12, 12, 12,
+                                9,  10, 14, 12, 12, 12, 12, 12,
+                                13, 14, 12, 12, 12, 12, 12, 12,
+                                15, 12, 12, 12, 12, 12, 12, 12,
+                                15, 12, 12, 12, 12, 12, 12, 12,
+                                15, 12, 12, 12, 12, 12, 12, 12]
+                             ]},
+}
+# fmt: on
diff --git a/.venv/lib/python3.7/site-packages/PIL/McIdasImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/McIdasImagePlugin.py
new file mode 100644
index 0000000..cd047fe
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/McIdasImagePlugin.py
@@ -0,0 +1,75 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# Basic McIdas support for PIL
+#
+# History:
+# 1997-05-05 fl  Created (8-bit images only)
+# 2009-03-08 fl  Added 16/32-bit support.
+#
+# Thanks to Richard Jones and Craig Swank for specs and samples.
+#
+# Copyright (c) Secret Labs AB 1997.
+# Copyright (c) Fredrik Lundh 1997.
+#
+# See the README file for information on usage and redistribution.
+#
+
+import struct
+
+from . import Image, ImageFile
+
+
+def _accept(s):
+    return s[:8] == b"\x00\x00\x00\x00\x00\x00\x00\x04"
+
+
+##
+# Image plugin for McIdas area images.
+
+
+class McIdasImageFile(ImageFile.ImageFile):
+
+    format = "MCIDAS"
+    format_description = "McIdas area file"
+
+    def _open(self):
+
+        # parse area file directory
+        s = self.fp.read(256)
+        if not _accept(s) or len(s) != 256:
+            raise SyntaxError("not an McIdas area file")
+
+        self.area_descriptor_raw = s
+        self.area_descriptor = w = [0] + list(struct.unpack("!64i", s))
+
+        # get mode
+        if w[11] == 1:
+            mode = rawmode = "L"
+        elif w[11] == 2:
+            # FIXME: add memory map support
+            mode = "I"
+            rawmode = "I;16B"
+        elif w[11] == 4:
+            # FIXME: add memory map support
+            mode = "I"
+            rawmode = "I;32B"
+        else:
+            raise SyntaxError("unsupported McIdas format")
+
+        self.mode = mode
+        self._size = w[10], w[9]
+
+        offset = w[34] + w[15]
+        stride = w[15] + w[10] * w[11] * w[14]
+
+        self.tile = [("raw", (0, 0) + self.size, offset, (rawmode, stride, 1))]
+
+
+# --------------------------------------------------------------------
+# registry
+
+Image.register_open(McIdasImageFile.format, McIdasImageFile, _accept)
+
+# no default extension
diff --git a/.venv/lib/python3.7/site-packages/PIL/MicImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/MicImagePlugin.py
new file mode 100644
index 0000000..9248b1b
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/MicImagePlugin.py
@@ -0,0 +1,107 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# Microsoft Image Composer support for PIL
+#
+# Notes:
+#       uses TiffImagePlugin.py to read the actual image streams
+#
+# History:
+#       97-01-20 fl     Created
+#
+# Copyright (c) Secret Labs AB 1997.
+# Copyright (c) Fredrik Lundh 1997.
+#
+# See the README file for information on usage and redistribution.
+#
+
+
+import olefile
+
+from . import Image, TiffImagePlugin
+
+#
+# --------------------------------------------------------------------
+
+
+def _accept(prefix):
+    return prefix[:8] == olefile.MAGIC
+
+
+##
+# Image plugin for Microsoft's Image Composer file format.
+
+
+class MicImageFile(TiffImagePlugin.TiffImageFile):
+
+    format = "MIC"
+    format_description = "Microsoft Image Composer"
+    _close_exclusive_fp_after_loading = False
+
+    def _open(self):
+
+        # read the OLE directory and see if this is a likely
+        # to be a Microsoft Image Composer file
+
+        try:
+            self.ole = olefile.OleFileIO(self.fp)
+        except OSError as e:
+            raise SyntaxError("not an MIC file; invalid OLE file") from e
+
+        # find ACI subfiles with Image members (maybe not the
+        # best way to identify MIC files, but what the... ;-)
+
+        self.images = []
+        for path in self.ole.listdir():
+            if path[1:] and path[0][-4:] == ".ACI" and path[1] == "Image":
+                self.images.append(path)
+
+        # if we didn't find any images, this is probably not
+        # an MIC file.
+        if not self.images:
+            raise SyntaxError("not an MIC file; no image entries")
+
+        self.__fp = self.fp
+        self.frame = None
+        self._n_frames = len(self.images)
+        self.is_animated = self._n_frames > 1
+
+        if len(self.images) > 1:
+            self._category = Image.CONTAINER
+
+        self.seek(0)
+
+    def seek(self, frame):
+        if not self._seek_check(frame):
+            return
+        try:
+            filename = self.images[frame]
+        except IndexError as e:
+            raise EOFError("no such frame") from e
+
+        self.fp = self.ole.openstream(filename)
+
+        TiffImagePlugin.TiffImageFile._open(self)
+
+        self.frame = frame
+
+    def tell(self):
+        return self.frame
+
+    def _close__fp(self):
+        try:
+            if self.__fp != self.fp:
+                self.__fp.close()
+        except AttributeError:
+            pass
+        finally:
+            self.__fp = None
+
+
+#
+# --------------------------------------------------------------------
+
+Image.register_open(MicImageFile.format, MicImageFile, _accept)
+
+Image.register_extension(MicImageFile.format, ".mic")
diff --git a/.venv/lib/python3.7/site-packages/PIL/MpegImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/MpegImagePlugin.py
new file mode 100644
index 0000000..a358dfd
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/MpegImagePlugin.py
@@ -0,0 +1,83 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# MPEG file handling
+#
+# History:
+#       95-09-09 fl     Created
+#
+# Copyright (c) Secret Labs AB 1997.
+# Copyright (c) Fredrik Lundh 1995.
+#
+# See the README file for information on usage and redistribution.
+#
+
+
+from . import Image, ImageFile
+from ._binary import i8
+
+#
+# Bitstream parser
+
+
+class BitStream:
+    def __init__(self, fp):
+        self.fp = fp
+        self.bits = 0
+        self.bitbuffer = 0
+
+    def next(self):
+        return i8(self.fp.read(1))
+
+    def peek(self, bits):
+        while self.bits < bits:
+            c = self.next()
+            if c < 0:
+                self.bits = 0
+                continue
+            self.bitbuffer = (self.bitbuffer << 8) + c
+            self.bits += 8
+        return self.bitbuffer >> (self.bits - bits) & (1 << bits) - 1
+
+    def skip(self, bits):
+        while self.bits < bits:
+            self.bitbuffer = (self.bitbuffer << 8) + i8(self.fp.read(1))
+            self.bits += 8
+        self.bits = self.bits - bits
+
+    def read(self, bits):
+        v = self.peek(bits)
+        self.bits = self.bits - bits
+        return v
+
+
+##
+# Image plugin for MPEG streams.  This plugin can identify a stream,
+# but it cannot read it.
+
+
+class MpegImageFile(ImageFile.ImageFile):
+
+    format = "MPEG"
+    format_description = "MPEG"
+
+    def _open(self):
+
+        s = BitStream(self.fp)
+
+        if s.read(32) != 0x1B3:
+            raise SyntaxError("not an MPEG file")
+
+        self.mode = "RGB"
+        self._size = s.read(12), s.read(12)
+
+
+# --------------------------------------------------------------------
+# Registry stuff
+
+Image.register_open(MpegImageFile.format, MpegImageFile)
+
+Image.register_extensions(MpegImageFile.format, [".mpg", ".mpeg"])
+
+Image.register_mime(MpegImageFile.format, "video/mpeg")
diff --git a/.venv/lib/python3.7/site-packages/PIL/MpoImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/MpoImagePlugin.py
new file mode 100644
index 0000000..7ccf27c
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/MpoImagePlugin.py
@@ -0,0 +1,135 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# MPO file handling
+#
+# See "Multi-Picture Format" (CIPA DC-007-Translation 2009, Standard of the
+# Camera & Imaging Products Association)
+#
+# The multi-picture object combines multiple JPEG images (with a modified EXIF
+# data format) into a single file. While it can theoretically be used much like
+# a GIF animation, it is commonly used to represent 3D photographs and is (as
+# of this writing) the most commonly used format by 3D cameras.
+#
+# History:
+# 2014-03-13 Feneric   Created
+#
+# See the README file for information on usage and redistribution.
+#
+
+from . import Image, ImageFile, JpegImagePlugin
+from ._binary import i16be as i16
+
+# def _accept(prefix):
+#     return JpegImagePlugin._accept(prefix)
+
+
+def _save(im, fp, filename):
+    # Note that we can only save the current frame at present
+    return JpegImagePlugin._save(im, fp, filename)
+
+
+##
+# Image plugin for MPO images.
+
+
+class MpoImageFile(JpegImagePlugin.JpegImageFile):
+
+    format = "MPO"
+    format_description = "MPO (CIPA DC-007)"
+    _close_exclusive_fp_after_loading = False
+
+    def _open(self):
+        self.fp.seek(0)  # prep the fp in order to pass the JPEG test
+        JpegImagePlugin.JpegImageFile._open(self)
+        self._after_jpeg_open()
+
+    def _after_jpeg_open(self, mpheader=None):
+        self.mpinfo = mpheader if mpheader is not None else self._getmp()
+        self.n_frames = self.mpinfo[0xB001]
+        self.__mpoffsets = [
+            mpent["DataOffset"] + self.info["mpoffset"] for mpent in self.mpinfo[0xB002]
+        ]
+        self.__mpoffsets[0] = 0
+        # Note that the following assertion will only be invalid if something
+        # gets broken within JpegImagePlugin.
+        assert self.n_frames == len(self.__mpoffsets)
+        del self.info["mpoffset"]  # no longer needed
+        self.is_animated = self.n_frames > 1
+        self.__fp = self.fp  # FIXME: hack
+        self.__fp.seek(self.__mpoffsets[0])  # get ready to read first frame
+        self.__frame = 0
+        self.offset = 0
+        # for now we can only handle reading and individual frame extraction
+        self.readonly = 1
+
+    def load_seek(self, pos):
+        self.__fp.seek(pos)
+
+    def seek(self, frame):
+        if not self._seek_check(frame):
+            return
+        self.fp = self.__fp
+        self.offset = self.__mpoffsets[frame]
+
+        self.fp.seek(self.offset + 2)  # skip SOI marker
+        segment = self.fp.read(2)
+        if not segment:
+            raise ValueError("No data found for frame")
+        if i16(segment) == 0xFFE1:  # APP1
+            n = i16(self.fp.read(2)) - 2
+            self.info["exif"] = ImageFile._safe_read(self.fp, n)
+
+            mptype = self.mpinfo[0xB002][frame]["Attribute"]["MPType"]
+            if mptype.startswith("Large Thumbnail"):
+                exif = self.getexif().get_ifd(0x8769)
+                if 40962 in exif and 40963 in exif:
+                    self._size = (exif[40962], exif[40963])
+        elif "exif" in self.info:
+            del self.info["exif"]
+
+        self.tile = [("jpeg", (0, 0) + self.size, self.offset, (self.mode, ""))]
+        self.__frame = frame
+
+    def tell(self):
+        return self.__frame
+
+    def _close__fp(self):
+        try:
+            if self.__fp != self.fp:
+                self.__fp.close()
+        except AttributeError:
+            pass
+        finally:
+            self.__fp = None
+
+    @staticmethod
+    def adopt(jpeg_instance, mpheader=None):
+        """
+        Transform the instance of JpegImageFile into
+        an instance of MpoImageFile.
+        After the call, the JpegImageFile is extended
+        to be an MpoImageFile.
+
+        This is essentially useful when opening a JPEG
+        file that reveals itself as an MPO, to avoid
+        double call to _open.
+        """
+        jpeg_instance.__class__ = MpoImageFile
+        jpeg_instance._after_jpeg_open(mpheader)
+        return jpeg_instance
+
+
+# ---------------------------------------------------------------------
+# Registry stuff
+
+# Note that since MPO shares a factory with JPEG, we do not need to do a
+# separate registration for it here.
+# Image.register_open(MpoImageFile.format,
+#                     JpegImagePlugin.jpeg_factory, _accept)
+Image.register_save(MpoImageFile.format, _save)
+
+Image.register_extension(MpoImageFile.format, ".mpo")
+
+Image.register_mime(MpoImageFile.format, "image/mpo")
diff --git a/.venv/lib/python3.7/site-packages/PIL/MspImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/MspImagePlugin.py
new file mode 100644
index 0000000..32b28d4
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/MspImagePlugin.py
@@ -0,0 +1,194 @@
+#
+# The Python Imaging Library.
+#
+# MSP file handling
+#
+# This is the format used by the Paint program in Windows 1 and 2.
+#
+# History:
+#       95-09-05 fl     Created
+#       97-01-03 fl     Read/write MSP images
+#       17-02-21 es     Fixed RLE interpretation
+#
+# Copyright (c) Secret Labs AB 1997.
+# Copyright (c) Fredrik Lundh 1995-97.
+# Copyright (c) Eric Soroos 2017.
+#
+# See the README file for information on usage and redistribution.
+#
+# More info on this format: https://archive.org/details/gg243631
+# Page 313:
+# Figure 205. Windows Paint Version 1: "DanM" Format
+# Figure 206. Windows Paint Version 2: "LinS" Format. Used in Windows V2.03
+#
+# See also: https://www.fileformat.info/format/mspaint/egff.htm
+
+import io
+import struct
+
+from . import Image, ImageFile
+from ._binary import i16le as i16
+from ._binary import o16le as o16
+
+#
+# read MSP files
+
+
+def _accept(prefix):
+    return prefix[:4] in [b"DanM", b"LinS"]
+
+
+##
+# Image plugin for Windows MSP images.  This plugin supports both
+# uncompressed (Windows 1.0).
+
+
+class MspImageFile(ImageFile.ImageFile):
+
+    format = "MSP"
+    format_description = "Windows Paint"
+
+    def _open(self):
+
+        # Header
+        s = self.fp.read(32)
+        if not _accept(s):
+            raise SyntaxError("not an MSP file")
+
+        # Header checksum
+        checksum = 0
+        for i in range(0, 32, 2):
+            checksum = checksum ^ i16(s, i)
+        if checksum != 0:
+            raise SyntaxError("bad MSP checksum")
+
+        self.mode = "1"
+        self._size = i16(s, 4), i16(s, 6)
+
+        if s[:4] == b"DanM":
+            self.tile = [("raw", (0, 0) + self.size, 32, ("1", 0, 1))]
+        else:
+            self.tile = [("MSP", (0, 0) + self.size, 32, None)]
+
+
+class MspDecoder(ImageFile.PyDecoder):
+    # The algo for the MSP decoder is from
+    # https://www.fileformat.info/format/mspaint/egff.htm
+    # cc-by-attribution -- That page references is taken from the
+    # Encyclopedia of Graphics File Formats and is licensed by
+    # O'Reilly under the Creative Common/Attribution license
+    #
+    # For RLE encoded files, the 32byte header is followed by a scan
+    # line map, encoded as one 16bit word of encoded byte length per
+    # line.
+    #
+    # NOTE: the encoded length of the line can be 0. This was not
+    # handled in the previous version of this encoder, and there's no
+    # mention of how to handle it in the documentation. From the few
+    # examples I've seen, I've assumed that it is a fill of the
+    # background color, in this case, white.
+    #
+    #
+    # Pseudocode of the decoder:
+    # Read a BYTE value as the RunType
+    #  If the RunType value is zero
+    #   Read next byte as the RunCount
+    #   Read the next byte as the RunValue
+    #   Write the RunValue byte RunCount times
+    #  If the RunType value is non-zero
+    #   Use this value as the RunCount
+    #   Read and write the next RunCount bytes literally
+    #
+    #  e.g.:
+    #  0x00 03 ff 05 00 01 02 03 04
+    #  would yield the bytes:
+    #  0xff ff ff 00 01 02 03 04
+    #
+    # which are then interpreted as a bit packed mode '1' image
+
+    _pulls_fd = True
+
+    def decode(self, buffer):
+
+        img = io.BytesIO()
+        blank_line = bytearray((0xFF,) * ((self.state.xsize + 7) // 8))
+        try:
+            self.fd.seek(32)
+            rowmap = struct.unpack_from(
+                f"<{self.state.ysize}H", self.fd.read(self.state.ysize * 2)
+            )
+        except struct.error as e:
+            raise OSError("Truncated MSP file in row map") from e
+
+        for x, rowlen in enumerate(rowmap):
+            try:
+                if rowlen == 0:
+                    img.write(blank_line)
+                    continue
+                row = self.fd.read(rowlen)
+                if len(row) != rowlen:
+                    raise OSError(
+                        "Truncated MSP file, expected %d bytes on row %s", (rowlen, x)
+                    )
+                idx = 0
+                while idx < rowlen:
+                    runtype = row[idx]
+                    idx += 1
+                    if runtype == 0:
+                        (runcount, runval) = struct.unpack_from("Bc", row, idx)
+                        img.write(runval * runcount)
+                        idx += 2
+                    else:
+                        runcount = runtype
+                        img.write(row[idx : idx + runcount])
+                        idx += runcount
+
+            except struct.error as e:
+                raise OSError(f"Corrupted MSP file in row {x}") from e
+
+        self.set_as_raw(img.getvalue(), ("1", 0, 1))
+
+        return 0, 0
+
+
+Image.register_decoder("MSP", MspDecoder)
+
+
+#
+# write MSP files (uncompressed only)
+
+
+def _save(im, fp, filename):
+
+    if im.mode != "1":
+        raise OSError(f"cannot write mode {im.mode} as MSP")
+
+    # create MSP header
+    header = [0] * 16
+
+    header[0], header[1] = i16(b"Da"), i16(b"nM")  # version 1
+    header[2], header[3] = im.size
+    header[4], header[5] = 1, 1
+    header[6], header[7] = 1, 1
+    header[8], header[9] = im.size
+
+    checksum = 0
+    for h in header:
+        checksum = checksum ^ h
+    header[12] = checksum  # FIXME: is this the right field?
+
+    # header
+    for h in header:
+        fp.write(o16(h))
+
+    # image body
+    ImageFile._save(im, fp, [("raw", (0, 0) + im.size, 32, ("1", 0, 1))])
+
+
+#
+# registry
+
+Image.register_open(MspImageFile.format, MspImageFile, _accept)
+Image.register_save(MspImageFile.format, _save)
+
+Image.register_extension(MspImageFile.format, ".msp")
diff --git a/.venv/lib/python3.7/site-packages/PIL/PSDraw.py b/.venv/lib/python3.7/site-packages/PIL/PSDraw.py
new file mode 100644
index 0000000..743c35f
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/PSDraw.py
@@ -0,0 +1,235 @@
+#
+# The Python Imaging Library
+# $Id$
+#
+# Simple PostScript graphics interface
+#
+# History:
+# 1996-04-20 fl   Created
+# 1999-01-10 fl   Added gsave/grestore to image method
+# 2005-05-04 fl   Fixed floating point issue in image (from Eric Etheridge)
+#
+# Copyright (c) 1997-2005 by Secret Labs AB.  All rights reserved.
+# Copyright (c) 1996 by Fredrik Lundh.
+#
+# See the README file for information on usage and redistribution.
+#
+
+import sys
+
+from . import EpsImagePlugin
+
+##
+# Simple PostScript graphics interface.
+
+
+class PSDraw:
+    """
+    Sets up printing to the given file. If ``fp`` is omitted,
+    ``sys.stdout.buffer`` or ``sys.stdout`` is assumed.
+    """
+
+    def __init__(self, fp=None):
+        if not fp:
+            try:
+                fp = sys.stdout.buffer
+            except AttributeError:
+                fp = sys.stdout
+        self.fp = fp
+
+    def begin_document(self, id=None):
+        """Set up printing of a document. (Write PostScript DSC header.)"""
+        # FIXME: incomplete
+        self.fp.write(
+            b"%!PS-Adobe-3.0\n"
+            b"save\n"
+            b"/showpage { } def\n"
+            b"%%EndComments\n"
+            b"%%BeginDocument\n"
+        )
+        # self.fp.write(ERROR_PS)  # debugging!
+        self.fp.write(EDROFF_PS)
+        self.fp.write(VDI_PS)
+        self.fp.write(b"%%EndProlog\n")
+        self.isofont = {}
+
+    def end_document(self):
+        """Ends printing. (Write PostScript DSC footer.)"""
+        self.fp.write(b"%%EndDocument\nrestore showpage\n%%End\n")
+        if hasattr(self.fp, "flush"):
+            self.fp.flush()
+
+    def setfont(self, font, size):
+        """
+        Selects which font to use.
+
+        :param font: A PostScript font name
+        :param size: Size in points.
+        """
+        font = bytes(font, "UTF-8")
+        if font not in self.isofont:
+            # reencode font
+            self.fp.write(b"/PSDraw-%s ISOLatin1Encoding /%s E\n" % (font, font))
+            self.isofont[font] = 1
+        # rough
+        self.fp.write(b"/F0 %d /PSDraw-%s F\n" % (size, font))
+
+    def line(self, xy0, xy1):
+        """
+        Draws a line between the two points. Coordinates are given in
+        PostScript point coordinates (72 points per inch, (0, 0) is the lower
+        left corner of the page).
+        """
+        self.fp.write(b"%d %d %d %d Vl\n" % (*xy0, *xy1))
+
+    def rectangle(self, box):
+        """
+        Draws a rectangle.
+
+        :param box: A 4-tuple of integers whose order and function is currently
+                    undocumented.
+
+                    Hint: the tuple is passed into this format string:
+
+                    .. code-block:: python
+
+                        %d %d M %d %d 0 Vr\n
+        """
+        self.fp.write(b"%d %d M %d %d 0 Vr\n" % box)
+
+    def text(self, xy, text):
+        """
+        Draws text at the given position. You must use
+        :py:meth:`~PIL.PSDraw.PSDraw.setfont` before calling this method.
+        """
+        text = bytes(text, "UTF-8")
+        text = b"\\(".join(text.split(b"("))
+        text = b"\\)".join(text.split(b")"))
+        xy += (text,)
+        self.fp.write(b"%d %d M (%s) S\n" % xy)
+
+    def image(self, box, im, dpi=None):
+        """Draw a PIL image, centered in the given box."""
+        # default resolution depends on mode
+        if not dpi:
+            if im.mode == "1":
+                dpi = 200  # fax
+            else:
+                dpi = 100  # greyscale
+        # image size (on paper)
+        x = im.size[0] * 72 / dpi
+        y = im.size[1] * 72 / dpi
+        # max allowed size
+        xmax = float(box[2] - box[0])
+        ymax = float(box[3] - box[1])
+        if x > xmax:
+            y = y * xmax / x
+            x = xmax
+        if y > ymax:
+            x = x * ymax / y
+            y = ymax
+        dx = (xmax - x) / 2 + box[0]
+        dy = (ymax - y) / 2 + box[1]
+        self.fp.write(b"gsave\n%f %f translate\n" % (dx, dy))
+        if (x, y) != im.size:
+            # EpsImagePlugin._save prints the image at (0,0,xsize,ysize)
+            sx = x / im.size[0]
+            sy = y / im.size[1]
+            self.fp.write(b"%f %f scale\n" % (sx, sy))
+        EpsImagePlugin._save(im, self.fp, None, 0)
+        self.fp.write(b"\ngrestore\n")
+
+
+# --------------------------------------------------------------------
+# PostScript driver
+
+#
+# EDROFF.PS -- PostScript driver for Edroff 2
+#
+# History:
+# 94-01-25 fl: created (edroff 2.04)
+#
+# Copyright (c) Fredrik Lundh 1994.
+#
+
+
+EDROFF_PS = b"""\
+/S { show } bind def
+/P { moveto show } bind def
+/M { moveto } bind def
+/X { 0 rmoveto } bind def
+/Y { 0 exch rmoveto } bind def
+/E {    findfont
+        dup maxlength dict begin
+        {
+                1 index /FID ne { def } { pop pop } ifelse
+        } forall
+        /Encoding exch def
+        dup /FontName exch def
+        currentdict end definefont pop
+} bind def
+/F {    findfont exch scalefont dup setfont
+        [ exch /setfont cvx ] cvx bind def
+} bind def
+"""
+
+#
+# VDI.PS -- PostScript driver for VDI meta commands
+#
+# History:
+# 94-01-25 fl: created (edroff 2.04)
+#
+# Copyright (c) Fredrik Lundh 1994.
+#
+
+VDI_PS = b"""\
+/Vm { moveto } bind def
+/Va { newpath arcn stroke } bind def
+/Vl { moveto lineto stroke } bind def
+/Vc { newpath 0 360 arc closepath } bind def
+/Vr {   exch dup 0 rlineto
+        exch dup neg 0 exch rlineto
+        exch neg 0 rlineto
+        0 exch rlineto
+        100 div setgray fill 0 setgray } bind def
+/Tm matrix def
+/Ve {   Tm currentmatrix pop
+        translate scale newpath 0 0 .5 0 360 arc closepath
+        Tm setmatrix
+} bind def
+/Vf { currentgray exch setgray fill setgray } bind def
+"""
+
+#
+# ERROR.PS -- Error handler
+#
+# History:
+# 89-11-21 fl: created (pslist 1.10)
+#
+
+ERROR_PS = b"""\
+/landscape false def
+/errorBUF 200 string def
+/errorNL { currentpoint 10 sub exch pop 72 exch moveto } def
+errordict begin /handleerror {
+    initmatrix /Courier findfont 10 scalefont setfont
+    newpath 72 720 moveto $error begin /newerror false def
+    (PostScript Error) show errorNL errorNL
+    (Error: ) show
+        /errorname load errorBUF cvs show errorNL errorNL
+    (Command: ) show
+        /command load dup type /stringtype ne { errorBUF cvs } if show
+        errorNL errorNL
+    (VMstatus: ) show
+        vmstatus errorBUF cvs show ( bytes available, ) show
+        errorBUF cvs show ( bytes used at level ) show
+        errorBUF cvs show errorNL errorNL
+    (Operand stargck: ) show errorNL /ostargck load {
+        dup type /stringtype ne { errorBUF cvs } if 72 0 rmoveto show errorNL
+    } forall errorNL
+    (Execution stargck: ) show errorNL /estargck load {
+        dup type /stringtype ne { errorBUF cvs } if 72 0 rmoveto show errorNL
+    } forall
+    end showpage
+} def end
+"""
diff --git a/.venv/lib/python3.7/site-packages/PIL/PaletteFile.py b/.venv/lib/python3.7/site-packages/PIL/PaletteFile.py
new file mode 100644
index 0000000..6ccaa1f
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/PaletteFile.py
@@ -0,0 +1,53 @@
+#
+# Python Imaging Library
+# $Id$
+#
+# stuff to read simple, teragon-style palette files
+#
+# History:
+#       97-08-23 fl     Created
+#
+# Copyright (c) Secret Labs AB 1997.
+# Copyright (c) Fredrik Lundh 1997.
+#
+# See the README file for information on usage and redistribution.
+#
+
+from ._binary import o8
+
+
+class PaletteFile:
+    """File handler for Teragon-style palette files."""
+
+    rawmode = "RGB"
+
+    def __init__(self, fp):
+
+        self.palette = [(i, i, i) for i in range(256)]
+
+        while True:
+
+            s = fp.readline()
+
+            if not s:
+                break
+            if s[0:1] == b"#":
+                continue
+            if len(s) > 100:
+                raise SyntaxError("bad palette file")
+
+            v = [int(x) for x in s.split()]
+            try:
+                [i, r, g, b] = v
+            except ValueError:
+                [i, r] = v
+                g = b = r
+
+            if 0 <= i <= 255:
+                self.palette[i] = o8(r) + o8(g) + o8(b)
+
+        self.palette = b"".join(self.palette)
+
+    def getpalette(self):
+
+        return self.palette, self.rawmode
diff --git a/.venv/lib/python3.7/site-packages/PIL/PalmImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/PalmImagePlugin.py
new file mode 100644
index 0000000..700f10e
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/PalmImagePlugin.py
@@ -0,0 +1,227 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+
+##
+# Image plugin for Palm pixmap images (output only).
+##
+
+from . import Image, ImageFile
+from ._binary import o8
+from ._binary import o16be as o16b
+
+# fmt: off
+_Palm8BitColormapValues = (
+    (255, 255, 255), (255, 204, 255), (255, 153, 255), (255, 102, 255),
+    (255,  51, 255), (255,   0, 255), (255, 255, 204), (255, 204, 204),
+    (255, 153, 204), (255, 102, 204), (255,  51, 204), (255,   0, 204),
+    (255, 255, 153), (255, 204, 153), (255, 153, 153), (255, 102, 153),
+    (255,  51, 153), (255,   0, 153), (204, 255, 255), (204, 204, 255),
+    (204, 153, 255), (204, 102, 255), (204,  51, 255), (204,   0, 255),
+    (204, 255, 204), (204, 204, 204), (204, 153, 204), (204, 102, 204),
+    (204,  51, 204), (204,   0, 204), (204, 255, 153), (204, 204, 153),
+    (204, 153, 153), (204, 102, 153), (204,  51, 153), (204,   0, 153),
+    (153, 255, 255), (153, 204, 255), (153, 153, 255), (153, 102, 255),
+    (153,  51, 255), (153,   0, 255), (153, 255, 204), (153, 204, 204),
+    (153, 153, 204), (153, 102, 204), (153,  51, 204), (153,   0, 204),
+    (153, 255, 153), (153, 204, 153), (153, 153, 153), (153, 102, 153),
+    (153,  51, 153), (153,   0, 153), (102, 255, 255), (102, 204, 255),
+    (102, 153, 255), (102, 102, 255), (102,  51, 255), (102,   0, 255),
+    (102, 255, 204), (102, 204, 204), (102, 153, 204), (102, 102, 204),
+    (102,  51, 204), (102,   0, 204), (102, 255, 153), (102, 204, 153),
+    (102, 153, 153), (102, 102, 153), (102,  51, 153), (102,   0, 153),
+    (51,  255, 255), (51,  204, 255), (51,  153, 255), (51,  102, 255),
+    (51,   51, 255), (51,    0, 255), (51,  255, 204), (51,  204, 204),
+    (51,  153, 204), (51,  102, 204), (51,   51, 204), (51,    0, 204),
+    (51,  255, 153), (51,  204, 153), (51,  153, 153), (51,  102, 153),
+    (51,   51, 153), (51,    0, 153), (0,   255, 255), (0,   204, 255),
+    (0,   153, 255), (0,   102, 255), (0,    51, 255), (0,     0, 255),
+    (0,   255, 204), (0,   204, 204), (0,   153, 204), (0,   102, 204),
+    (0,    51, 204), (0,     0, 204), (0,   255, 153), (0,   204, 153),
+    (0,   153, 153), (0,   102, 153), (0,    51, 153), (0,     0, 153),
+    (255, 255, 102), (255, 204, 102), (255, 153, 102), (255, 102, 102),
+    (255,  51, 102), (255,   0, 102), (255, 255,  51), (255, 204,  51),
+    (255, 153,  51), (255, 102,  51), (255,  51,  51), (255,   0,  51),
+    (255, 255,   0), (255, 204,   0), (255, 153,   0), (255, 102,   0),
+    (255,  51,   0), (255,   0,   0), (204, 255, 102), (204, 204, 102),
+    (204, 153, 102), (204, 102, 102), (204,  51, 102), (204,   0, 102),
+    (204, 255,  51), (204, 204,  51), (204, 153,  51), (204, 102,  51),
+    (204,  51,  51), (204,   0,  51), (204, 255,   0), (204, 204,   0),
+    (204, 153,   0), (204, 102,   0), (204,  51,   0), (204,   0,   0),
+    (153, 255, 102), (153, 204, 102), (153, 153, 102), (153, 102, 102),
+    (153,  51, 102), (153,   0, 102), (153, 255,  51), (153, 204,  51),
+    (153, 153,  51), (153, 102,  51), (153,  51,  51), (153,   0,  51),
+    (153, 255,   0), (153, 204,   0), (153, 153,   0), (153, 102,   0),
+    (153,  51,   0), (153,   0,   0), (102, 255, 102), (102, 204, 102),
+    (102, 153, 102), (102, 102, 102), (102,  51, 102), (102,   0, 102),
+    (102, 255,  51), (102, 204,  51), (102, 153,  51), (102, 102,  51),
+    (102,  51,  51), (102,   0,  51), (102, 255,   0), (102, 204,   0),
+    (102, 153,   0), (102, 102,   0), (102,  51,   0), (102,   0,   0),
+    (51,  255, 102), (51,  204, 102), (51,  153, 102), (51,  102, 102),
+    (51,   51, 102), (51,    0, 102), (51,  255,  51), (51,  204,  51),
+    (51,  153,  51), (51,  102,  51), (51,   51,  51), (51,    0,  51),
+    (51,  255,   0), (51,  204,   0), (51,  153,   0), (51,  102,   0),
+    (51,   51,   0), (51,    0,   0), (0,   255, 102), (0,   204, 102),
+    (0,   153, 102), (0,   102, 102), (0,    51, 102), (0,     0, 102),
+    (0,   255,  51), (0,   204,  51), (0,   153,  51), (0,   102,  51),
+    (0,    51,  51), (0,     0,  51), (0,   255,   0), (0,   204,   0),
+    (0,   153,   0), (0,   102,   0), (0,    51,   0), (17,   17,  17),
+    (34,   34,  34), (68,   68,  68), (85,   85,  85), (119, 119, 119),
+    (136, 136, 136), (170, 170, 170), (187, 187, 187), (221, 221, 221),
+    (238, 238, 238), (192, 192, 192), (128,   0,   0), (128,   0, 128),
+    (0,   128,   0), (0,   128, 128), (0,     0,   0), (0,     0,   0),
+    (0,     0,   0), (0,     0,   0), (0,     0,   0), (0,     0,   0),
+    (0,     0,   0), (0,     0,   0), (0,     0,   0), (0,     0,   0),
+    (0,     0,   0), (0,     0,   0), (0,     0,   0), (0,     0,   0),
+    (0,     0,   0), (0,     0,   0), (0,     0,   0), (0,     0,   0),
+    (0,     0,   0), (0,     0,   0), (0,     0,   0), (0,     0,   0),
+    (0,     0,   0), (0,     0,   0), (0,     0,   0), (0,     0,   0))
+# fmt: on
+
+
+# so build a prototype image to be used for palette resampling
+def build_prototype_image():
+    image = Image.new("L", (1, len(_Palm8BitColormapValues)))
+    image.putdata(list(range(len(_Palm8BitColormapValues))))
+    palettedata = ()
+    for colormapValue in _Palm8BitColormapValues:
+        palettedata += colormapValue
+    palettedata += (0, 0, 0) * (256 - len(_Palm8BitColormapValues))
+    image.putpalette(palettedata)
+    return image
+
+
+Palm8BitColormapImage = build_prototype_image()
+
+# OK, we now have in Palm8BitColormapImage,
+# a "P"-mode image with the right palette
+#
+# --------------------------------------------------------------------
+
+_FLAGS = {"custom-colormap": 0x4000, "is-compressed": 0x8000, "has-transparent": 0x2000}
+
+_COMPRESSION_TYPES = {"none": 0xFF, "rle": 0x01, "scanline": 0x00}
+
+
+#
+# --------------------------------------------------------------------
+
+##
+# (Internal) Image save plugin for the Palm format.
+
+
+def _save(im, fp, filename):
+
+    if im.mode == "P":
+
+        # we assume this is a color Palm image with the standard colormap,
+        # unless the "info" dict has a "custom-colormap" field
+
+        rawmode = "P"
+        bpp = 8
+        version = 1
+
+    elif im.mode == "L":
+        if im.encoderinfo.get("bpp") in (1, 2, 4):
+            # this is 8-bit grayscale, so we shift it to get the high-order bits,
+            # and invert it because
+            # Palm does greyscale from white (0) to black (1)
+            bpp = im.encoderinfo["bpp"]
+            im = im.point(
+                lambda x, shift=8 - bpp, maxval=(1 << bpp) - 1: maxval - (x >> shift)
+            )
+        elif im.info.get("bpp") in (1, 2, 4):
+            # here we assume that even though the inherent mode is 8-bit grayscale,
+            # only the lower bpp bits are significant.
+            # We invert them to match the Palm.
+            bpp = im.info["bpp"]
+            im = im.point(lambda x, maxval=(1 << bpp) - 1: maxval - (x & maxval))
+        else:
+            raise OSError(f"cannot write mode {im.mode} as Palm")
+
+        # we ignore the palette here
+        im.mode = "P"
+        rawmode = "P;" + str(bpp)
+        version = 1
+
+    elif im.mode == "1":
+
+        # monochrome -- write it inverted, as is the Palm standard
+        rawmode = "1;I"
+        bpp = 1
+        version = 0
+
+    else:
+
+        raise OSError(f"cannot write mode {im.mode} as Palm")
+
+    #
+    # make sure image data is available
+    im.load()
+
+    # write header
+
+    cols = im.size[0]
+    rows = im.size[1]
+
+    rowbytes = int((cols + (16 // bpp - 1)) / (16 // bpp)) * 2
+    transparent_index = 0
+    compression_type = _COMPRESSION_TYPES["none"]
+
+    flags = 0
+    if im.mode == "P" and "custom-colormap" in im.info:
+        flags = flags & _FLAGS["custom-colormap"]
+        colormapsize = 4 * 256 + 2
+        colormapmode = im.palette.mode
+        colormap = im.getdata().getpalette()
+    else:
+        colormapsize = 0
+
+    if "offset" in im.info:
+        offset = (rowbytes * rows + 16 + 3 + colormapsize) // 4
+    else:
+        offset = 0
+
+    fp.write(o16b(cols) + o16b(rows) + o16b(rowbytes) + o16b(flags))
+    fp.write(o8(bpp))
+    fp.write(o8(version))
+    fp.write(o16b(offset))
+    fp.write(o8(transparent_index))
+    fp.write(o8(compression_type))
+    fp.write(o16b(0))  # reserved by Palm
+
+    # now write colormap if necessary
+
+    if colormapsize > 0:
+        fp.write(o16b(256))
+        for i in range(256):
+            fp.write(o8(i))
+            if colormapmode == "RGB":
+                fp.write(
+                    o8(colormap[3 * i])
+                    + o8(colormap[3 * i + 1])
+                    + o8(colormap[3 * i + 2])
+                )
+            elif colormapmode == "RGBA":
+                fp.write(
+                    o8(colormap[4 * i])
+                    + o8(colormap[4 * i + 1])
+                    + o8(colormap[4 * i + 2])
+                )
+
+    # now convert data to raw form
+    ImageFile._save(im, fp, [("raw", (0, 0) + im.size, 0, (rawmode, rowbytes, 1))])
+
+    if hasattr(fp, "flush"):
+        fp.flush()
+
+
+#
+# --------------------------------------------------------------------
+
+Image.register_save("Palm", _save)
+
+Image.register_extension("Palm", ".palm")
+
+Image.register_mime("Palm", "image/palm")
diff --git a/.venv/lib/python3.7/site-packages/PIL/PcdImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/PcdImagePlugin.py
new file mode 100644
index 0000000..38caf5c
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/PcdImagePlugin.py
@@ -0,0 +1,63 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# PCD file handling
+#
+# History:
+#       96-05-10 fl     Created
+#       96-05-27 fl     Added draft mode (128x192, 256x384)
+#
+# Copyright (c) Secret Labs AB 1997.
+# Copyright (c) Fredrik Lundh 1996.
+#
+# See the README file for information on usage and redistribution.
+#
+
+
+from . import Image, ImageFile
+
+##
+# Image plugin for PhotoCD images.  This plugin only reads the 768x512
+# image from the file; higher resolutions are encoded in a proprietary
+# encoding.
+
+
+class PcdImageFile(ImageFile.ImageFile):
+
+    format = "PCD"
+    format_description = "Kodak PhotoCD"
+
+    def _open(self):
+
+        # rough
+        self.fp.seek(2048)
+        s = self.fp.read(2048)
+
+        if s[:4] != b"PCD_":
+            raise SyntaxError("not a PCD file")
+
+        orientation = s[1538] & 3
+        self.tile_post_rotate = None
+        if orientation == 1:
+            self.tile_post_rotate = 90
+        elif orientation == 3:
+            self.tile_post_rotate = -90
+
+        self.mode = "RGB"
+        self._size = 768, 512  # FIXME: not correct for rotated images!
+        self.tile = [("pcd", (0, 0) + self.size, 96 * 2048, None)]
+
+    def load_end(self):
+        if self.tile_post_rotate:
+            # Handle rotated PCDs
+            self.im = self.im.rotate(self.tile_post_rotate)
+            self._size = self.im.size
+
+
+#
+# registry
+
+Image.register_open(PcdImageFile.format, PcdImageFile)
+
+Image.register_extension(PcdImageFile.format, ".pcd")
diff --git a/.venv/lib/python3.7/site-packages/PIL/PcfFontFile.py b/.venv/lib/python3.7/site-packages/PIL/PcfFontFile.py
new file mode 100644
index 0000000..6a4eb22
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/PcfFontFile.py
@@ -0,0 +1,248 @@
+#
+# THIS IS WORK IN PROGRESS
+#
+# The Python Imaging Library
+# $Id$
+#
+# portable compiled font file parser
+#
+# history:
+# 1997-08-19 fl   created
+# 2003-09-13 fl   fixed loading of unicode fonts
+#
+# Copyright (c) 1997-2003 by Secret Labs AB.
+# Copyright (c) 1997-2003 by Fredrik Lundh.
+#
+# See the README file for information on usage and redistribution.
+#
+
+import io
+
+from . import FontFile, Image
+from ._binary import i8
+from ._binary import i16be as b16
+from ._binary import i16le as l16
+from ._binary import i32be as b32
+from ._binary import i32le as l32
+
+# --------------------------------------------------------------------
+# declarations
+
+PCF_MAGIC = 0x70636601  # "\x01fcp"
+
+PCF_PROPERTIES = 1 << 0
+PCF_ACCELERATORS = 1 << 1
+PCF_METRICS = 1 << 2
+PCF_BITMAPS = 1 << 3
+PCF_INK_METRICS = 1 << 4
+PCF_BDF_ENCODINGS = 1 << 5
+PCF_SWIDTHS = 1 << 6
+PCF_GLYPH_NAMES = 1 << 7
+PCF_BDF_ACCELERATORS = 1 << 8
+
+BYTES_PER_ROW = [
+    lambda bits: ((bits + 7) >> 3),
+    lambda bits: ((bits + 15) >> 3) & ~1,
+    lambda bits: ((bits + 31) >> 3) & ~3,
+    lambda bits: ((bits + 63) >> 3) & ~7,
+]
+
+
+def sz(s, o):
+    return s[o : s.index(b"\0", o)]
+
+
+class PcfFontFile(FontFile.FontFile):
+    """Font file plugin for the X11 PCF format."""
+
+    name = "name"
+
+    def __init__(self, fp, charset_encoding="iso8859-1"):
+
+        self.charset_encoding = charset_encoding
+
+        magic = l32(fp.read(4))
+        if magic != PCF_MAGIC:
+            raise SyntaxError("not a PCF file")
+
+        super().__init__()
+
+        count = l32(fp.read(4))
+        self.toc = {}
+        for i in range(count):
+            type = l32(fp.read(4))
+            self.toc[type] = l32(fp.read(4)), l32(fp.read(4)), l32(fp.read(4))
+
+        self.fp = fp
+
+        self.info = self._load_properties()
+
+        metrics = self._load_metrics()
+        bitmaps = self._load_bitmaps(metrics)
+        encoding = self._load_encoding()
+
+        #
+        # create glyph structure
+
+        for ch in range(256):
+            ix = encoding[ch]
+            if ix is not None:
+                x, y, l, r, w, a, d, f = metrics[ix]
+                glyph = (w, 0), (l, d - y, x + l, d), (0, 0, x, y), bitmaps[ix]
+                self.glyph[ch] = glyph
+
+    def _getformat(self, tag):
+
+        format, size, offset = self.toc[tag]
+
+        fp = self.fp
+        fp.seek(offset)
+
+        format = l32(fp.read(4))
+
+        if format & 4:
+            i16, i32 = b16, b32
+        else:
+            i16, i32 = l16, l32
+
+        return fp, format, i16, i32
+
+    def _load_properties(self):
+
+        #
+        # font properties
+
+        properties = {}
+
+        fp, format, i16, i32 = self._getformat(PCF_PROPERTIES)
+
+        nprops = i32(fp.read(4))
+
+        # read property description
+        p = []
+        for i in range(nprops):
+            p.append((i32(fp.read(4)), i8(fp.read(1)), i32(fp.read(4))))
+        if nprops & 3:
+            fp.seek(4 - (nprops & 3), io.SEEK_CUR)  # pad
+
+        data = fp.read(i32(fp.read(4)))
+
+        for k, s, v in p:
+            k = sz(data, k)
+            if s:
+                v = sz(data, v)
+            properties[k] = v
+
+        return properties
+
+    def _load_metrics(self):
+
+        #
+        # font metrics
+
+        metrics = []
+
+        fp, format, i16, i32 = self._getformat(PCF_METRICS)
+
+        append = metrics.append
+
+        if (format & 0xFF00) == 0x100:
+
+            # "compressed" metrics
+            for i in range(i16(fp.read(2))):
+                left = i8(fp.read(1)) - 128
+                right = i8(fp.read(1)) - 128
+                width = i8(fp.read(1)) - 128
+                ascent = i8(fp.read(1)) - 128
+                descent = i8(fp.read(1)) - 128
+                xsize = right - left
+                ysize = ascent + descent
+                append((xsize, ysize, left, right, width, ascent, descent, 0))
+
+        else:
+
+            # "jumbo" metrics
+            for i in range(i32(fp.read(4))):
+                left = i16(fp.read(2))
+                right = i16(fp.read(2))
+                width = i16(fp.read(2))
+                ascent = i16(fp.read(2))
+                descent = i16(fp.read(2))
+                attributes = i16(fp.read(2))
+                xsize = right - left
+                ysize = ascent + descent
+                append((xsize, ysize, left, right, width, ascent, descent, attributes))
+
+        return metrics
+
+    def _load_bitmaps(self, metrics):
+
+        #
+        # bitmap data
+
+        bitmaps = []
+
+        fp, format, i16, i32 = self._getformat(PCF_BITMAPS)
+
+        nbitmaps = i32(fp.read(4))
+
+        if nbitmaps != len(metrics):
+            raise OSError("Wrong number of bitmaps")
+
+        offsets = []
+        for i in range(nbitmaps):
+            offsets.append(i32(fp.read(4)))
+
+        bitmapSizes = []
+        for i in range(4):
+            bitmapSizes.append(i32(fp.read(4)))
+
+        # byteorder = format & 4  # non-zero => MSB
+        bitorder = format & 8  # non-zero => MSB
+        padindex = format & 3
+
+        bitmapsize = bitmapSizes[padindex]
+        offsets.append(bitmapsize)
+
+        data = fp.read(bitmapsize)
+
+        pad = BYTES_PER_ROW[padindex]
+        mode = "1;R"
+        if bitorder:
+            mode = "1"
+
+        for i in range(nbitmaps):
+            x, y, l, r, w, a, d, f = metrics[i]
+            b, e = offsets[i], offsets[i + 1]
+            bitmaps.append(Image.frombytes("1", (x, y), data[b:e], "raw", mode, pad(x)))
+
+        return bitmaps
+
+    def _load_encoding(self):
+
+        # map character code to bitmap index
+        encoding = [None] * 256
+
+        fp, format, i16, i32 = self._getformat(PCF_BDF_ENCODINGS)
+
+        firstCol, lastCol = i16(fp.read(2)), i16(fp.read(2))
+        firstRow, lastRow = i16(fp.read(2)), i16(fp.read(2))
+
+        i16(fp.read(2))  # default
+
+        nencoding = (lastCol - firstCol + 1) * (lastRow - firstRow + 1)
+
+        encodingOffsets = [i16(fp.read(2)) for _ in range(nencoding)]
+
+        for i in range(firstCol, len(encoding)):
+            try:
+                encodingOffset = encodingOffsets[
+                    ord(bytearray([i]).decode(self.charset_encoding))
+                ]
+                if encodingOffset != 0xFFFF:
+                    encoding[i] = encodingOffset
+            except UnicodeDecodeError:
+                # character is not supported in selected encoding
+                pass
+
+        return encoding
diff --git a/.venv/lib/python3.7/site-packages/PIL/PcxImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/PcxImagePlugin.py
new file mode 100644
index 0000000..d2e166b
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/PcxImagePlugin.py
@@ -0,0 +1,218 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# PCX file handling
+#
+# This format was originally used by ZSoft's popular PaintBrush
+# program for the IBM PC.  It is also supported by many MS-DOS and
+# Windows applications, including the Windows PaintBrush program in
+# Windows 3.
+#
+# history:
+# 1995-09-01 fl   Created
+# 1996-05-20 fl   Fixed RGB support
+# 1997-01-03 fl   Fixed 2-bit and 4-bit support
+# 1999-02-03 fl   Fixed 8-bit support (broken in 1.0b1)
+# 1999-02-07 fl   Added write support
+# 2002-06-09 fl   Made 2-bit and 4-bit support a bit more robust
+# 2002-07-30 fl   Seek from to current position, not beginning of file
+# 2003-06-03 fl   Extract DPI settings (info["dpi"])
+#
+# Copyright (c) 1997-2003 by Secret Labs AB.
+# Copyright (c) 1995-2003 by Fredrik Lundh.
+#
+# See the README file for information on usage and redistribution.
+#
+
+import io
+import logging
+
+from . import Image, ImageFile, ImagePalette
+from ._binary import i16le as i16
+from ._binary import o8
+from ._binary import o16le as o16
+
+logger = logging.getLogger(__name__)
+
+
+def _accept(prefix):
+    return prefix[0] == 10 and prefix[1] in [0, 2, 3, 5]
+
+
+##
+# Image plugin for Paintbrush images.
+
+
+class PcxImageFile(ImageFile.ImageFile):
+
+    format = "PCX"
+    format_description = "Paintbrush"
+
+    def _open(self):
+
+        # header
+        s = self.fp.read(128)
+        if not _accept(s):
+            raise SyntaxError("not a PCX file")
+
+        # image
+        bbox = i16(s, 4), i16(s, 6), i16(s, 8) + 1, i16(s, 10) + 1
+        if bbox[2] <= bbox[0] or bbox[3] <= bbox[1]:
+            raise SyntaxError("bad PCX image size")
+        logger.debug("BBox: %s %s %s %s", *bbox)
+
+        # format
+        version = s[1]
+        bits = s[3]
+        planes = s[65]
+        provided_stride = i16(s, 66)
+        logger.debug(
+            "PCX version %s, bits %s, planes %s, stride %s",
+            version,
+            bits,
+            planes,
+            provided_stride,
+        )
+
+        self.info["dpi"] = i16(s, 12), i16(s, 14)
+
+        if bits == 1 and planes == 1:
+            mode = rawmode = "1"
+
+        elif bits == 1 and planes in (2, 4):
+            mode = "P"
+            rawmode = "P;%dL" % planes
+            self.palette = ImagePalette.raw("RGB", s[16:64])
+
+        elif version == 5 and bits == 8 and planes == 1:
+            mode = rawmode = "L"
+            # FIXME: hey, this doesn't work with the incremental loader !!!
+            self.fp.seek(-769, io.SEEK_END)
+            s = self.fp.read(769)
+            if len(s) == 769 and s[0] == 12:
+                # check if the palette is linear greyscale
+                for i in range(256):
+                    if s[i * 3 + 1 : i * 3 + 4] != o8(i) * 3:
+                        mode = rawmode = "P"
+                        break
+                if mode == "P":
+                    self.palette = ImagePalette.raw("RGB", s[1:])
+            self.fp.seek(128)
+
+        elif version == 5 and bits == 8 and planes == 3:
+            mode = "RGB"
+            rawmode = "RGB;L"
+
+        else:
+            raise OSError("unknown PCX mode")
+
+        self.mode = mode
+        self._size = bbox[2] - bbox[0], bbox[3] - bbox[1]
+
+        # Don't trust the passed in stride.
+        # Calculate the approximate position for ourselves.
+        # CVE-2020-35653
+        stride = (self._size[0] * bits + 7) // 8
+
+        # While the specification states that this must be even,
+        # not all images follow this
+        if provided_stride != stride:
+            stride += stride % 2
+
+        bbox = (0, 0) + self.size
+        logger.debug("size: %sx%s", *self.size)
+
+        self.tile = [("pcx", bbox, self.fp.tell(), (rawmode, planes * stride))]
+
+
+# --------------------------------------------------------------------
+# save PCX files
+
+
+SAVE = {
+    # mode: (version, bits, planes, raw mode)
+    "1": (2, 1, 1, "1"),
+    "L": (5, 8, 1, "L"),
+    "P": (5, 8, 1, "P"),
+    "RGB": (5, 8, 3, "RGB;L"),
+}
+
+
+def _save(im, fp, filename):
+
+    try:
+        version, bits, planes, rawmode = SAVE[im.mode]
+    except KeyError as e:
+        raise ValueError(f"Cannot save {im.mode} images as PCX") from e
+
+    # bytes per plane
+    stride = (im.size[0] * bits + 7) // 8
+    # stride should be even
+    stride += stride % 2
+    # Stride needs to be kept in sync with the PcxEncode.c version.
+    # Ideally it should be passed in in the state, but the bytes value
+    # gets overwritten.
+
+    logger.debug(
+        "PcxImagePlugin._save: xwidth: %d, bits: %d, stride: %d",
+        im.size[0],
+        bits,
+        stride,
+    )
+
+    # under windows, we could determine the current screen size with
+    # "Image.core.display_mode()[1]", but I think that's overkill...
+
+    screen = im.size
+
+    dpi = 100, 100
+
+    # PCX header
+    fp.write(
+        o8(10)
+        + o8(version)
+        + o8(1)
+        + o8(bits)
+        + o16(0)
+        + o16(0)
+        + o16(im.size[0] - 1)
+        + o16(im.size[1] - 1)
+        + o16(dpi[0])
+        + o16(dpi[1])
+        + b"\0" * 24
+        + b"\xFF" * 24
+        + b"\0"
+        + o8(planes)
+        + o16(stride)
+        + o16(1)
+        + o16(screen[0])
+        + o16(screen[1])
+        + b"\0" * 54
+    )
+
+    assert fp.tell() == 128
+
+    ImageFile._save(im, fp, [("pcx", (0, 0) + im.size, 0, (rawmode, bits * planes))])
+
+    if im.mode == "P":
+        # colour palette
+        fp.write(o8(12))
+        fp.write(im.im.getpalette("RGB", "RGB"))  # 768 bytes
+    elif im.mode == "L":
+        # greyscale palette
+        fp.write(o8(12))
+        for i in range(256):
+            fp.write(o8(i) * 3)
+
+
+# --------------------------------------------------------------------
+# registry
+
+
+Image.register_open(PcxImageFile.format, PcxImageFile, _accept)
+Image.register_save(PcxImageFile.format, _save)
+
+Image.register_extension(PcxImageFile.format, ".pcx")
+
+Image.register_mime(PcxImageFile.format, "image/x-pcx")
diff --git a/.venv/lib/python3.7/site-packages/PIL/PdfImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/PdfImagePlugin.py
new file mode 100644
index 0000000..1131c63
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/PdfImagePlugin.py
@@ -0,0 +1,240 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# PDF (Acrobat) file handling
+#
+# History:
+# 1996-07-16 fl   Created
+# 1997-01-18 fl   Fixed header
+# 2004-02-21 fl   Fixes for 1/L/CMYK images, etc.
+# 2004-02-24 fl   Fixes for 1 and P images.
+#
+# Copyright (c) 1997-2004 by Secret Labs AB.  All rights reserved.
+# Copyright (c) 1996-1997 by Fredrik Lundh.
+#
+# See the README file for information on usage and redistribution.
+#
+
+##
+# Image plugin for PDF images (output only).
+##
+
+import io
+import os
+import time
+
+from . import Image, ImageFile, ImageSequence, PdfParser, __version__
+
+#
+# --------------------------------------------------------------------
+
+# object ids:
+#  1. catalogue
+#  2. pages
+#  3. image
+#  4. page
+#  5. page contents
+
+
+def _save_all(im, fp, filename):
+    _save(im, fp, filename, save_all=True)
+
+
+##
+# (Internal) Image save plugin for the PDF format.
+
+
+def _save(im, fp, filename, save_all=False):
+    is_appending = im.encoderinfo.get("append", False)
+    if is_appending:
+        existing_pdf = PdfParser.PdfParser(f=fp, filename=filename, mode="r+b")
+    else:
+        existing_pdf = PdfParser.PdfParser(f=fp, filename=filename, mode="w+b")
+
+    resolution = im.encoderinfo.get("resolution", 72.0)
+
+    info = {
+        "title": None
+        if is_appending
+        else os.path.splitext(os.path.basename(filename))[0],
+        "author": None,
+        "subject": None,
+        "keywords": None,
+        "creator": None,
+        "producer": None,
+        "creationDate": None if is_appending else time.gmtime(),
+        "modDate": None if is_appending else time.gmtime(),
+    }
+    for k, default in info.items():
+        v = im.encoderinfo.get(k) if k in im.encoderinfo else default
+        if v:
+            existing_pdf.info[k[0].upper() + k[1:]] = v
+
+    #
+    # make sure image data is available
+    im.load()
+
+    existing_pdf.start_writing()
+    existing_pdf.write_header()
+    existing_pdf.write_comment(f"created by Pillow {__version__} PDF driver")
+
+    #
+    # pages
+    ims = [im]
+    if save_all:
+        append_images = im.encoderinfo.get("append_images", [])
+        for append_im in append_images:
+            append_im.encoderinfo = im.encoderinfo.copy()
+            ims.append(append_im)
+    numberOfPages = 0
+    image_refs = []
+    page_refs = []
+    contents_refs = []
+    for im in ims:
+        im_numberOfPages = 1
+        if save_all:
+            try:
+                im_numberOfPages = im.n_frames
+            except AttributeError:
+                # Image format does not have n_frames.
+                # It is a single frame image
+                pass
+        numberOfPages += im_numberOfPages
+        for i in range(im_numberOfPages):
+            image_refs.append(existing_pdf.next_object_id(0))
+            page_refs.append(existing_pdf.next_object_id(0))
+            contents_refs.append(existing_pdf.next_object_id(0))
+            existing_pdf.pages.append(page_refs[-1])
+
+    #
+    # catalog and list of pages
+    existing_pdf.write_catalog()
+
+    pageNumber = 0
+    for imSequence in ims:
+        im_pages = ImageSequence.Iterator(imSequence) if save_all else [imSequence]
+        for im in im_pages:
+            # FIXME: Should replace ASCIIHexDecode with RunLengthDecode
+            # (packbits) or LZWDecode (tiff/lzw compression).  Note that
+            # PDF 1.2 also supports Flatedecode (zip compression).
+
+            bits = 8
+            params = None
+            decode = None
+
+            if im.mode == "1":
+                filter = "DCTDecode"
+                colorspace = PdfParser.PdfName("DeviceGray")
+                procset = "ImageB"  # grayscale
+                bits = 1
+            elif im.mode == "L":
+                filter = "DCTDecode"
+                # params = f"<< /Predictor 15 /Columns {width-2} >>"
+                colorspace = PdfParser.PdfName("DeviceGray")
+                procset = "ImageB"  # grayscale
+            elif im.mode == "P":
+                filter = "ASCIIHexDecode"
+                palette = im.getpalette()
+                colorspace = [
+                    PdfParser.PdfName("Indexed"),
+                    PdfParser.PdfName("DeviceRGB"),
+                    255,
+                    PdfParser.PdfBinary(palette),
+                ]
+                procset = "ImageI"  # indexed color
+            elif im.mode == "RGB":
+                filter = "DCTDecode"
+                colorspace = PdfParser.PdfName("DeviceRGB")
+                procset = "ImageC"  # color images
+            elif im.mode == "CMYK":
+                filter = "DCTDecode"
+                colorspace = PdfParser.PdfName("DeviceCMYK")
+                procset = "ImageC"  # color images
+                decode = [1, 0, 1, 0, 1, 0, 1, 0]
+            else:
+                raise ValueError(f"cannot save mode {im.mode}")
+
+            #
+            # image
+
+            op = io.BytesIO()
+
+            if filter == "ASCIIHexDecode":
+                ImageFile._save(im, op, [("hex", (0, 0) + im.size, 0, im.mode)])
+            elif filter == "DCTDecode":
+                Image.SAVE["JPEG"](im, op, filename)
+            elif filter == "FlateDecode":
+                ImageFile._save(im, op, [("zip", (0, 0) + im.size, 0, im.mode)])
+            elif filter == "RunLengthDecode":
+                ImageFile._save(im, op, [("packbits", (0, 0) + im.size, 0, im.mode)])
+            else:
+                raise ValueError(f"unsupported PDF filter ({filter})")
+
+            #
+            # Get image characteristics
+
+            width, height = im.size
+
+            existing_pdf.write_obj(
+                image_refs[pageNumber],
+                stream=op.getvalue(),
+                Type=PdfParser.PdfName("XObject"),
+                Subtype=PdfParser.PdfName("Image"),
+                Width=width,  # * 72.0 / resolution,
+                Height=height,  # * 72.0 / resolution,
+                Filter=PdfParser.PdfName(filter),
+                BitsPerComponent=bits,
+                Decode=decode,
+                DecodeParams=params,
+                ColorSpace=colorspace,
+            )
+
+            #
+            # page
+
+            existing_pdf.write_page(
+                page_refs[pageNumber],
+                Resources=PdfParser.PdfDict(
+                    ProcSet=[PdfParser.PdfName("PDF"), PdfParser.PdfName(procset)],
+                    XObject=PdfParser.PdfDict(image=image_refs[pageNumber]),
+                ),
+                MediaBox=[
+                    0,
+                    0,
+                    width * 72.0 / resolution,
+                    height * 72.0 / resolution,
+                ],
+                Contents=contents_refs[pageNumber],
+            )
+
+            #
+            # page contents
+
+            page_contents = b"q %f 0 0 %f 0 0 cm /image Do Q\n" % (
+                width * 72.0 / resolution,
+                height * 72.0 / resolution,
+            )
+
+            existing_pdf.write_obj(contents_refs[pageNumber], stream=page_contents)
+
+            pageNumber += 1
+
+    #
+    # trailer
+    existing_pdf.write_xref_and_trailer()
+    if hasattr(fp, "flush"):
+        fp.flush()
+    existing_pdf.close()
+
+
+#
+# --------------------------------------------------------------------
+
+
+Image.register_save("PDF", _save)
+Image.register_save_all("PDF", _save_all)
+
+Image.register_extension("PDF", ".pdf")
+
+Image.register_mime("PDF", "application/pdf")
diff --git a/.venv/lib/python3.7/site-packages/PIL/PdfParser.py b/.venv/lib/python3.7/site-packages/PIL/PdfParser.py
new file mode 100644
index 0000000..6ac9c7a
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/PdfParser.py
@@ -0,0 +1,998 @@
+import calendar
+import codecs
+import collections
+import mmap
+import os
+import re
+import time
+import zlib
+
+
+# see 7.9.2.2 Text String Type on page 86 and D.3 PDFDocEncoding Character Set
+# on page 656
+def encode_text(s):
+    return codecs.BOM_UTF16_BE + s.encode("utf_16_be")
+
+
+PDFDocEncoding = {
+    0x16: "\u0017",
+    0x18: "\u02D8",
+    0x19: "\u02C7",
+    0x1A: "\u02C6",
+    0x1B: "\u02D9",
+    0x1C: "\u02DD",
+    0x1D: "\u02DB",
+    0x1E: "\u02DA",
+    0x1F: "\u02DC",
+    0x80: "\u2022",
+    0x81: "\u2020",
+    0x82: "\u2021",
+    0x83: "\u2026",
+    0x84: "\u2014",
+    0x85: "\u2013",
+    0x86: "\u0192",
+    0x87: "\u2044",
+    0x88: "\u2039",
+    0x89: "\u203A",
+    0x8A: "\u2212",
+    0x8B: "\u2030",
+    0x8C: "\u201E",
+    0x8D: "\u201C",
+    0x8E: "\u201D",
+    0x8F: "\u2018",
+    0x90: "\u2019",
+    0x91: "\u201A",
+    0x92: "\u2122",
+    0x93: "\uFB01",
+    0x94: "\uFB02",
+    0x95: "\u0141",
+    0x96: "\u0152",
+    0x97: "\u0160",
+    0x98: "\u0178",
+    0x99: "\u017D",
+    0x9A: "\u0131",
+    0x9B: "\u0142",
+    0x9C: "\u0153",
+    0x9D: "\u0161",
+    0x9E: "\u017E",
+    0xA0: "\u20AC",
+}
+
+
+def decode_text(b):
+    if b[: len(codecs.BOM_UTF16_BE)] == codecs.BOM_UTF16_BE:
+        return b[len(codecs.BOM_UTF16_BE) :].decode("utf_16_be")
+    else:
+        return "".join(PDFDocEncoding.get(byte, chr(byte)) for byte in b)
+
+
+class PdfFormatError(RuntimeError):
+    """An error that probably indicates a syntactic or semantic error in the
+    PDF file structure"""
+
+    pass
+
+
+def check_format_condition(condition, error_message):
+    if not condition:
+        raise PdfFormatError(error_message)
+
+
+class IndirectReference(
+    collections.namedtuple("IndirectReferenceTuple", ["object_id", "generation"])
+):
+    def __str__(self):
+        return "%s %s R" % self
+
+    def __bytes__(self):
+        return self.__str__().encode("us-ascii")
+
+    def __eq__(self, other):
+        return (
+            other.__class__ is self.__class__
+            and other.object_id == self.object_id
+            and other.generation == self.generation
+        )
+
+    def __ne__(self, other):
+        return not (self == other)
+
+    def __hash__(self):
+        return hash((self.object_id, self.generation))
+
+
+class IndirectObjectDef(IndirectReference):
+    def __str__(self):
+        return "%s %s obj" % self
+
+
+class XrefTable:
+    def __init__(self):
+        self.existing_entries = {}  # object ID => (offset, generation)
+        self.new_entries = {}  # object ID => (offset, generation)
+        self.deleted_entries = {0: 65536}  # object ID => generation
+        self.reading_finished = False
+
+    def __setitem__(self, key, value):
+        if self.reading_finished:
+            self.new_entries[key] = value
+        else:
+            self.existing_entries[key] = value
+        if key in self.deleted_entries:
+            del self.deleted_entries[key]
+
+    def __getitem__(self, key):
+        try:
+            return self.new_entries[key]
+        except KeyError:
+            return self.existing_entries[key]
+
+    def __delitem__(self, key):
+        if key in self.new_entries:
+            generation = self.new_entries[key][1] + 1
+            del self.new_entries[key]
+            self.deleted_entries[key] = generation
+        elif key in self.existing_entries:
+            generation = self.existing_entries[key][1] + 1
+            self.deleted_entries[key] = generation
+        elif key in self.deleted_entries:
+            generation = self.deleted_entries[key]
+        else:
+            raise IndexError(
+                "object ID " + str(key) + " cannot be deleted because it doesn't exist"
+            )
+
+    def __contains__(self, key):
+        return key in self.existing_entries or key in self.new_entries
+
+    def __len__(self):
+        return len(
+            set(self.existing_entries.keys())
+            | set(self.new_entries.keys())
+            | set(self.deleted_entries.keys())
+        )
+
+    def keys(self):
+        return (
+            set(self.existing_entries.keys()) - set(self.deleted_entries.keys())
+        ) | set(self.new_entries.keys())
+
+    def write(self, f):
+        keys = sorted(set(self.new_entries.keys()) | set(self.deleted_entries.keys()))
+        deleted_keys = sorted(set(self.deleted_entries.keys()))
+        startxref = f.tell()
+        f.write(b"xref\n")
+        while keys:
+            # find a contiguous sequence of object IDs
+            prev = None
+            for index, key in enumerate(keys):
+                if prev is None or prev + 1 == key:
+                    prev = key
+                else:
+                    contiguous_keys = keys[:index]
+                    keys = keys[index:]
+                    break
+            else:
+                contiguous_keys = keys
+                keys = None
+            f.write(b"%d %d\n" % (contiguous_keys[0], len(contiguous_keys)))
+            for object_id in contiguous_keys:
+                if object_id in self.new_entries:
+                    f.write(b"%010d %05d n \n" % self.new_entries[object_id])
+                else:
+                    this_deleted_object_id = deleted_keys.pop(0)
+                    check_format_condition(
+                        object_id == this_deleted_object_id,
+                        f"expected the next deleted object ID to be {object_id}, "
+                        f"instead found {this_deleted_object_id}",
+                    )
+                    try:
+                        next_in_linked_list = deleted_keys[0]
+                    except IndexError:
+                        next_in_linked_list = 0
+                    f.write(
+                        b"%010d %05d f \n"
+                        % (next_in_linked_list, self.deleted_entries[object_id])
+                    )
+        return startxref
+
+
+class PdfName:
+    def __init__(self, name):
+        if isinstance(name, PdfName):
+            self.name = name.name
+        elif isinstance(name, bytes):
+            self.name = name
+        else:
+            self.name = name.encode("us-ascii")
+
+    def name_as_str(self):
+        return self.name.decode("us-ascii")
+
+    def __eq__(self, other):
+        return (
+            isinstance(other, PdfName) and other.name == self.name
+        ) or other == self.name
+
+    def __hash__(self):
+        return hash(self.name)
+
+    def __repr__(self):
+        return f"PdfName({repr(self.name)})"
+
+    @classmethod
+    def from_pdf_stream(cls, data):
+        return cls(PdfParser.interpret_name(data))
+
+    allowed_chars = set(range(33, 127)) - {ord(c) for c in "#%/()<>[]{}"}
+
+    def __bytes__(self):
+        result = bytearray(b"/")
+        for b in self.name:
+            if b in self.allowed_chars:
+                result.append(b)
+            else:
+                result.extend(b"#%02X" % b)
+        return bytes(result)
+
+
+class PdfArray(list):
+    def __bytes__(self):
+        return b"[ " + b" ".join(pdf_repr(x) for x in self) + b" ]"
+
+
+class PdfDict(collections.UserDict):
+    def __setattr__(self, key, value):
+        if key == "data":
+            collections.UserDict.__setattr__(self, key, value)
+        else:
+            self[key.encode("us-ascii")] = value
+
+    def __getattr__(self, key):
+        try:
+            value = self[key.encode("us-ascii")]
+        except KeyError as e:
+            raise AttributeError(key) from e
+        if isinstance(value, bytes):
+            value = decode_text(value)
+        if key.endswith("Date"):
+            if value.startswith("D:"):
+                value = value[2:]
+
+            relationship = "Z"
+            if len(value) > 17:
+                relationship = value[14]
+                offset = int(value[15:17]) * 60
+                if len(value) > 20:
+                    offset += int(value[18:20])
+
+            format = "%Y%m%d%H%M%S"[: len(value) - 2]
+            value = time.strptime(value[: len(format) + 2], format)
+            if relationship in ["+", "-"]:
+                offset *= 60
+                if relationship == "+":
+                    offset *= -1
+                value = time.gmtime(calendar.timegm(value) + offset)
+        return value
+
+    def __bytes__(self):
+        out = bytearray(b"<<")
+        for key, value in self.items():
+            if value is None:
+                continue
+            value = pdf_repr(value)
+            out.extend(b"\n")
+            out.extend(bytes(PdfName(key)))
+            out.extend(b" ")
+            out.extend(value)
+        out.extend(b"\n>>")
+        return bytes(out)
+
+
+class PdfBinary:
+    def __init__(self, data):
+        self.data = data
+
+    def __bytes__(self):
+        return b"<%s>" % b"".join(b"%02X" % b for b in self.data)
+
+
+class PdfStream:
+    def __init__(self, dictionary, buf):
+        self.dictionary = dictionary
+        self.buf = buf
+
+    def decode(self):
+        try:
+            filter = self.dictionary.Filter
+        except AttributeError:
+            return self.buf
+        if filter == b"FlateDecode":
+            try:
+                expected_length = self.dictionary.DL
+            except AttributeError:
+                expected_length = self.dictionary.Length
+            return zlib.decompress(self.buf, bufsize=int(expected_length))
+        else:
+            raise NotImplementedError(
+                f"stream filter {repr(self.dictionary.Filter)} unknown/unsupported"
+            )
+
+
+def pdf_repr(x):
+    if x is True:
+        return b"true"
+    elif x is False:
+        return b"false"
+    elif x is None:
+        return b"null"
+    elif isinstance(x, (PdfName, PdfDict, PdfArray, PdfBinary)):
+        return bytes(x)
+    elif isinstance(x, int):
+        return str(x).encode("us-ascii")
+    elif isinstance(x, float):
+        return str(x).encode("us-ascii")
+    elif isinstance(x, time.struct_time):
+        return b"(D:" + time.strftime("%Y%m%d%H%M%SZ", x).encode("us-ascii") + b")"
+    elif isinstance(x, dict):
+        return bytes(PdfDict(x))
+    elif isinstance(x, list):
+        return bytes(PdfArray(x))
+    elif isinstance(x, str):
+        return pdf_repr(encode_text(x))
+    elif isinstance(x, bytes):
+        # XXX escape more chars? handle binary garbage
+        x = x.replace(b"\\", b"\\\\")
+        x = x.replace(b"(", b"\\(")
+        x = x.replace(b")", b"\\)")
+        return b"(" + x + b")"
+    else:
+        return bytes(x)
+
+
+class PdfParser:
+    """Based on
+    https://www.adobe.com/content/dam/acom/en/devnet/acrobat/pdfs/PDF32000_2008.pdf
+    Supports PDF up to 1.4
+    """
+
+    def __init__(self, filename=None, f=None, buf=None, start_offset=0, mode="rb"):
+        if buf and f:
+            raise RuntimeError("specify buf or f or filename, but not both buf and f")
+        self.filename = filename
+        self.buf = buf
+        self.f = f
+        self.start_offset = start_offset
+        self.should_close_buf = False
+        self.should_close_file = False
+        if filename is not None and f is None:
+            self.f = f = open(filename, mode)
+            self.should_close_file = True
+        if f is not None:
+            self.buf = buf = self.get_buf_from_file(f)
+            self.should_close_buf = True
+            if not filename and hasattr(f, "name"):
+                self.filename = f.name
+        self.cached_objects = {}
+        if buf:
+            self.read_pdf_info()
+        else:
+            self.file_size_total = self.file_size_this = 0
+            self.root = PdfDict()
+            self.root_ref = None
+            self.info = PdfDict()
+            self.info_ref = None
+            self.page_tree_root = {}
+            self.pages = []
+            self.orig_pages = []
+            self.pages_ref = None
+            self.last_xref_section_offset = None
+            self.trailer_dict = {}
+            self.xref_table = XrefTable()
+        self.xref_table.reading_finished = True
+        if f:
+            self.seek_end()
+
+    def __enter__(self):
+        return self
+
+    def __exit__(self, exc_type, exc_value, traceback):
+        self.close()
+        return False  # do not suppress exceptions
+
+    def start_writing(self):
+        self.close_buf()
+        self.seek_end()
+
+    def close_buf(self):
+        try:
+            self.buf.close()
+        except AttributeError:
+            pass
+        self.buf = None
+
+    def close(self):
+        if self.should_close_buf:
+            self.close_buf()
+        if self.f is not None and self.should_close_file:
+            self.f.close()
+            self.f = None
+
+    def seek_end(self):
+        self.f.seek(0, os.SEEK_END)
+
+    def write_header(self):
+        self.f.write(b"%PDF-1.4\n")
+
+    def write_comment(self, s):
+        self.f.write(f"% {s}\n".encode())
+
+    def write_catalog(self):
+        self.del_root()
+        self.root_ref = self.next_object_id(self.f.tell())
+        self.pages_ref = self.next_object_id(0)
+        self.rewrite_pages()
+        self.write_obj(self.root_ref, Type=PdfName(b"Catalog"), Pages=self.pages_ref)
+        self.write_obj(
+            self.pages_ref,
+            Type=PdfName(b"Pages"),
+            Count=len(self.pages),
+            Kids=self.pages,
+        )
+        return self.root_ref
+
+    def rewrite_pages(self):
+        pages_tree_nodes_to_delete = []
+        for i, page_ref in enumerate(self.orig_pages):
+            page_info = self.cached_objects[page_ref]
+            del self.xref_table[page_ref.object_id]
+            pages_tree_nodes_to_delete.append(page_info[PdfName(b"Parent")])
+            if page_ref not in self.pages:
+                # the page has been deleted
+                continue
+            # make dict keys into strings for passing to write_page
+            stringified_page_info = {}
+            for key, value in page_info.items():
+                # key should be a PdfName
+                stringified_page_info[key.name_as_str()] = value
+            stringified_page_info["Parent"] = self.pages_ref
+            new_page_ref = self.write_page(None, **stringified_page_info)
+            for j, cur_page_ref in enumerate(self.pages):
+                if cur_page_ref == page_ref:
+                    # replace the page reference with the new one
+                    self.pages[j] = new_page_ref
+        # delete redundant Pages tree nodes from xref table
+        for pages_tree_node_ref in pages_tree_nodes_to_delete:
+            while pages_tree_node_ref:
+                pages_tree_node = self.cached_objects[pages_tree_node_ref]
+                if pages_tree_node_ref.object_id in self.xref_table:
+                    del self.xref_table[pages_tree_node_ref.object_id]
+                pages_tree_node_ref = pages_tree_node.get(b"Parent", None)
+        self.orig_pages = []
+
+    def write_xref_and_trailer(self, new_root_ref=None):
+        if new_root_ref:
+            self.del_root()
+            self.root_ref = new_root_ref
+        if self.info:
+            self.info_ref = self.write_obj(None, self.info)
+        start_xref = self.xref_table.write(self.f)
+        num_entries = len(self.xref_table)
+        trailer_dict = {b"Root": self.root_ref, b"Size": num_entries}
+        if self.last_xref_section_offset is not None:
+            trailer_dict[b"Prev"] = self.last_xref_section_offset
+        if self.info:
+            trailer_dict[b"Info"] = self.info_ref
+        self.last_xref_section_offset = start_xref
+        self.f.write(
+            b"trailer\n"
+            + bytes(PdfDict(trailer_dict))
+            + b"\nstartxref\n%d\n%%%%EOF" % start_xref
+        )
+
+    def write_page(self, ref, *objs, **dict_obj):
+        if isinstance(ref, int):
+            ref = self.pages[ref]
+        if "Type" not in dict_obj:
+            dict_obj["Type"] = PdfName(b"Page")
+        if "Parent" not in dict_obj:
+            dict_obj["Parent"] = self.pages_ref
+        return self.write_obj(ref, *objs, **dict_obj)
+
+    def write_obj(self, ref, *objs, **dict_obj):
+        f = self.f
+        if ref is None:
+            ref = self.next_object_id(f.tell())
+        else:
+            self.xref_table[ref.object_id] = (f.tell(), ref.generation)
+        f.write(bytes(IndirectObjectDef(*ref)))
+        stream = dict_obj.pop("stream", None)
+        if stream is not None:
+            dict_obj["Length"] = len(stream)
+        if dict_obj:
+            f.write(pdf_repr(dict_obj))
+        for obj in objs:
+            f.write(pdf_repr(obj))
+        if stream is not None:
+            f.write(b"stream\n")
+            f.write(stream)
+            f.write(b"\nendstream\n")
+        f.write(b"endobj\n")
+        return ref
+
+    def del_root(self):
+        if self.root_ref is None:
+            return
+        del self.xref_table[self.root_ref.object_id]
+        del self.xref_table[self.root[b"Pages"].object_id]
+
+    @staticmethod
+    def get_buf_from_file(f):
+        if hasattr(f, "getbuffer"):
+            return f.getbuffer()
+        elif hasattr(f, "getvalue"):
+            return f.getvalue()
+        else:
+            try:
+                return mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)
+            except ValueError:  # cannot mmap an empty file
+                return b""
+
+    def read_pdf_info(self):
+        self.file_size_total = len(self.buf)
+        self.file_size_this = self.file_size_total - self.start_offset
+        self.read_trailer()
+        self.root_ref = self.trailer_dict[b"Root"]
+        self.info_ref = self.trailer_dict.get(b"Info", None)
+        self.root = PdfDict(self.read_indirect(self.root_ref))
+        if self.info_ref is None:
+            self.info = PdfDict()
+        else:
+            self.info = PdfDict(self.read_indirect(self.info_ref))
+        check_format_condition(b"Type" in self.root, "/Type missing in Root")
+        check_format_condition(
+            self.root[b"Type"] == b"Catalog", "/Type in Root is not /Catalog"
+        )
+        check_format_condition(b"Pages" in self.root, "/Pages missing in Root")
+        check_format_condition(
+            isinstance(self.root[b"Pages"], IndirectReference),
+            "/Pages in Root is not an indirect reference",
+        )
+        self.pages_ref = self.root[b"Pages"]
+        self.page_tree_root = self.read_indirect(self.pages_ref)
+        self.pages = self.linearize_page_tree(self.page_tree_root)
+        # save the original list of page references
+        # in case the user modifies, adds or deletes some pages
+        # and we need to rewrite the pages and their list
+        self.orig_pages = self.pages[:]
+
+    def next_object_id(self, offset=None):
+        try:
+            # TODO: support reuse of deleted objects
+            reference = IndirectReference(max(self.xref_table.keys()) + 1, 0)
+        except ValueError:
+            reference = IndirectReference(1, 0)
+        if offset is not None:
+            self.xref_table[reference.object_id] = (offset, 0)
+        return reference
+
+    delimiter = br"[][()<>{}/%]"
+    delimiter_or_ws = br"[][()<>{}/%\000\011\012\014\015\040]"
+    whitespace = br"[\000\011\012\014\015\040]"
+    whitespace_or_hex = br"[\000\011\012\014\015\0400-9a-fA-F]"
+    whitespace_optional = whitespace + b"*"
+    whitespace_mandatory = whitespace + b"+"
+    # No "\012" aka "\n" or "\015" aka "\r":
+    whitespace_optional_no_nl = br"[\000\011\014\040]*"
+    newline_only = br"[\r\n]+"
+    newline = whitespace_optional_no_nl + newline_only + whitespace_optional_no_nl
+    re_trailer_end = re.compile(
+        whitespace_mandatory
+        + br"trailer"
+        + whitespace_optional
+        + br"\<\<(.*\>\>)"
+        + newline
+        + br"startxref"
+        + newline
+        + br"([0-9]+)"
+        + newline
+        + br"%%EOF"
+        + whitespace_optional
+        + br"$",
+        re.DOTALL,
+    )
+    re_trailer_prev = re.compile(
+        whitespace_optional
+        + br"trailer"
+        + whitespace_optional
+        + br"\<\<(.*?\>\>)"
+        + newline
+        + br"startxref"
+        + newline
+        + br"([0-9]+)"
+        + newline
+        + br"%%EOF"
+        + whitespace_optional,
+        re.DOTALL,
+    )
+
+    def read_trailer(self):
+        search_start_offset = len(self.buf) - 16384
+        if search_start_offset < self.start_offset:
+            search_start_offset = self.start_offset
+        m = self.re_trailer_end.search(self.buf, search_start_offset)
+        check_format_condition(m, "trailer end not found")
+        # make sure we found the LAST trailer
+        last_match = m
+        while m:
+            last_match = m
+            m = self.re_trailer_end.search(self.buf, m.start() + 16)
+        if not m:
+            m = last_match
+        trailer_data = m.group(1)
+        self.last_xref_section_offset = int(m.group(2))
+        self.trailer_dict = self.interpret_trailer(trailer_data)
+        self.xref_table = XrefTable()
+        self.read_xref_table(xref_section_offset=self.last_xref_section_offset)
+        if b"Prev" in self.trailer_dict:
+            self.read_prev_trailer(self.trailer_dict[b"Prev"])
+
+    def read_prev_trailer(self, xref_section_offset):
+        trailer_offset = self.read_xref_table(xref_section_offset=xref_section_offset)
+        m = self.re_trailer_prev.search(
+            self.buf[trailer_offset : trailer_offset + 16384]
+        )
+        check_format_condition(m, "previous trailer not found")
+        trailer_data = m.group(1)
+        check_format_condition(
+            int(m.group(2)) == xref_section_offset,
+            "xref section offset in previous trailer doesn't match what was expected",
+        )
+        trailer_dict = self.interpret_trailer(trailer_data)
+        if b"Prev" in trailer_dict:
+            self.read_prev_trailer(trailer_dict[b"Prev"])
+
+    re_whitespace_optional = re.compile(whitespace_optional)
+    re_name = re.compile(
+        whitespace_optional
+        + br"/([!-$&'*-.0-;=?-Z\\^-z|~]+)(?="
+        + delimiter_or_ws
+        + br")"
+    )
+    re_dict_start = re.compile(whitespace_optional + br"\<\<")
+    re_dict_end = re.compile(whitespace_optional + br"\>\>" + whitespace_optional)
+
+    @classmethod
+    def interpret_trailer(cls, trailer_data):
+        trailer = {}
+        offset = 0
+        while True:
+            m = cls.re_name.match(trailer_data, offset)
+            if not m:
+                m = cls.re_dict_end.match(trailer_data, offset)
+                check_format_condition(
+                    m and m.end() == len(trailer_data),
+                    "name not found in trailer, remaining data: "
+                    + repr(trailer_data[offset:]),
+                )
+                break
+            key = cls.interpret_name(m.group(1))
+            value, offset = cls.get_value(trailer_data, m.end())
+            trailer[key] = value
+        check_format_condition(
+            b"Size" in trailer and isinstance(trailer[b"Size"], int),
+            "/Size not in trailer or not an integer",
+        )
+        check_format_condition(
+            b"Root" in trailer and isinstance(trailer[b"Root"], IndirectReference),
+            "/Root not in trailer or not an indirect reference",
+        )
+        return trailer
+
+    re_hashes_in_name = re.compile(br"([^#]*)(#([0-9a-fA-F]{2}))?")
+
+    @classmethod
+    def interpret_name(cls, raw, as_text=False):
+        name = b""
+        for m in cls.re_hashes_in_name.finditer(raw):
+            if m.group(3):
+                name += m.group(1) + bytearray.fromhex(m.group(3).decode("us-ascii"))
+            else:
+                name += m.group(1)
+        if as_text:
+            return name.decode("utf-8")
+        else:
+            return bytes(name)
+
+    re_null = re.compile(whitespace_optional + br"null(?=" + delimiter_or_ws + br")")
+    re_true = re.compile(whitespace_optional + br"true(?=" + delimiter_or_ws + br")")
+    re_false = re.compile(whitespace_optional + br"false(?=" + delimiter_or_ws + br")")
+    re_int = re.compile(
+        whitespace_optional + br"([-+]?[0-9]+)(?=" + delimiter_or_ws + br")"
+    )
+    re_real = re.compile(
+        whitespace_optional
+        + br"([-+]?([0-9]+\.[0-9]*|[0-9]*\.[0-9]+))(?="
+        + delimiter_or_ws
+        + br")"
+    )
+    re_array_start = re.compile(whitespace_optional + br"\[")
+    re_array_end = re.compile(whitespace_optional + br"]")
+    re_string_hex = re.compile(
+        whitespace_optional + br"\<(" + whitespace_or_hex + br"*)\>"
+    )
+    re_string_lit = re.compile(whitespace_optional + br"\(")
+    re_indirect_reference = re.compile(
+        whitespace_optional
+        + br"([-+]?[0-9]+)"
+        + whitespace_mandatory
+        + br"([-+]?[0-9]+)"
+        + whitespace_mandatory
+        + br"R(?="
+        + delimiter_or_ws
+        + br")"
+    )
+    re_indirect_def_start = re.compile(
+        whitespace_optional
+        + br"([-+]?[0-9]+)"
+        + whitespace_mandatory
+        + br"([-+]?[0-9]+)"
+        + whitespace_mandatory
+        + br"obj(?="
+        + delimiter_or_ws
+        + br")"
+    )
+    re_indirect_def_end = re.compile(
+        whitespace_optional + br"endobj(?=" + delimiter_or_ws + br")"
+    )
+    re_comment = re.compile(
+        br"(" + whitespace_optional + br"%[^\r\n]*" + newline + br")*"
+    )
+    re_stream_start = re.compile(whitespace_optional + br"stream\r?\n")
+    re_stream_end = re.compile(
+        whitespace_optional + br"endstream(?=" + delimiter_or_ws + br")"
+    )
+
+    @classmethod
+    def get_value(cls, data, offset, expect_indirect=None, max_nesting=-1):
+        if max_nesting == 0:
+            return None, None
+        m = cls.re_comment.match(data, offset)
+        if m:
+            offset = m.end()
+        m = cls.re_indirect_def_start.match(data, offset)
+        if m:
+            check_format_condition(
+                int(m.group(1)) > 0,
+                "indirect object definition: object ID must be greater than 0",
+            )
+            check_format_condition(
+                int(m.group(2)) >= 0,
+                "indirect object definition: generation must be non-negative",
+            )
+            check_format_condition(
+                expect_indirect is None
+                or expect_indirect
+                == IndirectReference(int(m.group(1)), int(m.group(2))),
+                "indirect object definition different than expected",
+            )
+            object, offset = cls.get_value(data, m.end(), max_nesting=max_nesting - 1)
+            if offset is None:
+                return object, None
+            m = cls.re_indirect_def_end.match(data, offset)
+            check_format_condition(m, "indirect object definition end not found")
+            return object, m.end()
+        check_format_condition(
+            not expect_indirect, "indirect object definition not found"
+        )
+        m = cls.re_indirect_reference.match(data, offset)
+        if m:
+            check_format_condition(
+                int(m.group(1)) > 0,
+                "indirect object reference: object ID must be greater than 0",
+            )
+            check_format_condition(
+                int(m.group(2)) >= 0,
+                "indirect object reference: generation must be non-negative",
+            )
+            return IndirectReference(int(m.group(1)), int(m.group(2))), m.end()
+        m = cls.re_dict_start.match(data, offset)
+        if m:
+            offset = m.end()
+            result = {}
+            m = cls.re_dict_end.match(data, offset)
+            while not m:
+                key, offset = cls.get_value(data, offset, max_nesting=max_nesting - 1)
+                if offset is None:
+                    return result, None
+                value, offset = cls.get_value(data, offset, max_nesting=max_nesting - 1)
+                result[key] = value
+                if offset is None:
+                    return result, None
+                m = cls.re_dict_end.match(data, offset)
+            offset = m.end()
+            m = cls.re_stream_start.match(data, offset)
+            if m:
+                try:
+                    stream_len = int(result[b"Length"])
+                except (TypeError, KeyError, ValueError) as e:
+                    raise PdfFormatError(
+                        "bad or missing Length in stream dict (%r)"
+                        % result.get(b"Length", None)
+                    ) from e
+                stream_data = data[m.end() : m.end() + stream_len]
+                m = cls.re_stream_end.match(data, m.end() + stream_len)
+                check_format_condition(m, "stream end not found")
+                offset = m.end()
+                result = PdfStream(PdfDict(result), stream_data)
+            else:
+                result = PdfDict(result)
+            return result, offset
+        m = cls.re_array_start.match(data, offset)
+        if m:
+            offset = m.end()
+            result = []
+            m = cls.re_array_end.match(data, offset)
+            while not m:
+                value, offset = cls.get_value(data, offset, max_nesting=max_nesting - 1)
+                result.append(value)
+                if offset is None:
+                    return result, None
+                m = cls.re_array_end.match(data, offset)
+            return result, m.end()
+        m = cls.re_null.match(data, offset)
+        if m:
+            return None, m.end()
+        m = cls.re_true.match(data, offset)
+        if m:
+            return True, m.end()
+        m = cls.re_false.match(data, offset)
+        if m:
+            return False, m.end()
+        m = cls.re_name.match(data, offset)
+        if m:
+            return PdfName(cls.interpret_name(m.group(1))), m.end()
+        m = cls.re_int.match(data, offset)
+        if m:
+            return int(m.group(1)), m.end()
+        m = cls.re_real.match(data, offset)
+        if m:
+            # XXX Decimal instead of float???
+            return float(m.group(1)), m.end()
+        m = cls.re_string_hex.match(data, offset)
+        if m:
+            # filter out whitespace
+            hex_string = bytearray(
+                b for b in m.group(1) if b in b"0123456789abcdefABCDEF"
+            )
+            if len(hex_string) % 2 == 1:
+                # append a 0 if the length is not even - yes, at the end
+                hex_string.append(ord(b"0"))
+            return bytearray.fromhex(hex_string.decode("us-ascii")), m.end()
+        m = cls.re_string_lit.match(data, offset)
+        if m:
+            return cls.get_literal_string(data, m.end())
+        # return None, offset  # fallback (only for debugging)
+        raise PdfFormatError("unrecognized object: " + repr(data[offset : offset + 32]))
+
+    re_lit_str_token = re.compile(
+        br"(\\[nrtbf()\\])|(\\[0-9]{1,3})|(\\(\r\n|\r|\n))|(\r\n|\r|\n)|(\()|(\))"
+    )
+    escaped_chars = {
+        b"n": b"\n",
+        b"r": b"\r",
+        b"t": b"\t",
+        b"b": b"\b",
+        b"f": b"\f",
+        b"(": b"(",
+        b")": b")",
+        b"\\": b"\\",
+        ord(b"n"): b"\n",
+        ord(b"r"): b"\r",
+        ord(b"t"): b"\t",
+        ord(b"b"): b"\b",
+        ord(b"f"): b"\f",
+        ord(b"("): b"(",
+        ord(b")"): b")",
+        ord(b"\\"): b"\\",
+    }
+
+    @classmethod
+    def get_literal_string(cls, data, offset):
+        nesting_depth = 0
+        result = bytearray()
+        for m in cls.re_lit_str_token.finditer(data, offset):
+            result.extend(data[offset : m.start()])
+            if m.group(1):
+                result.extend(cls.escaped_chars[m.group(1)[1]])
+            elif m.group(2):
+                result.append(int(m.group(2)[1:], 8))
+            elif m.group(3):
+                pass
+            elif m.group(5):
+                result.extend(b"\n")
+            elif m.group(6):
+                result.extend(b"(")
+                nesting_depth += 1
+            elif m.group(7):
+                if nesting_depth == 0:
+                    return bytes(result), m.end()
+                result.extend(b")")
+                nesting_depth -= 1
+            offset = m.end()
+        raise PdfFormatError("unfinished literal string")
+
+    re_xref_section_start = re.compile(whitespace_optional + br"xref" + newline)
+    re_xref_subsection_start = re.compile(
+        whitespace_optional
+        + br"([0-9]+)"
+        + whitespace_mandatory
+        + br"([0-9]+)"
+        + whitespace_optional
+        + newline_only
+    )
+    re_xref_entry = re.compile(br"([0-9]{10}) ([0-9]{5}) ([fn])( \r| \n|\r\n)")
+
+    def read_xref_table(self, xref_section_offset):
+        subsection_found = False
+        m = self.re_xref_section_start.match(
+            self.buf, xref_section_offset + self.start_offset
+        )
+        check_format_condition(m, "xref section start not found")
+        offset = m.end()
+        while True:
+            m = self.re_xref_subsection_start.match(self.buf, offset)
+            if not m:
+                check_format_condition(
+                    subsection_found, "xref subsection start not found"
+                )
+                break
+            subsection_found = True
+            offset = m.end()
+            first_object = int(m.group(1))
+            num_objects = int(m.group(2))
+            for i in range(first_object, first_object + num_objects):
+                m = self.re_xref_entry.match(self.buf, offset)
+                check_format_condition(m, "xref entry not found")
+                offset = m.end()
+                is_free = m.group(3) == b"f"
+                generation = int(m.group(2))
+                if not is_free:
+                    new_entry = (int(m.group(1)), generation)
+                    check_format_condition(
+                        i not in self.xref_table or self.xref_table[i] == new_entry,
+                        "xref entry duplicated (and not identical)",
+                    )
+                    self.xref_table[i] = new_entry
+        return offset
+
+    def read_indirect(self, ref, max_nesting=-1):
+        offset, generation = self.xref_table[ref[0]]
+        check_format_condition(
+            generation == ref[1],
+            f"expected to find generation {ref[1]} for object ID {ref[0]} in xref "
+            f"table, instead found generation {generation} at offset {offset}",
+        )
+        value = self.get_value(
+            self.buf,
+            offset + self.start_offset,
+            expect_indirect=IndirectReference(*ref),
+            max_nesting=max_nesting,
+        )[0]
+        self.cached_objects[ref] = value
+        return value
+
+    def linearize_page_tree(self, node=None):
+        if node is None:
+            node = self.page_tree_root
+        check_format_condition(
+            node[b"Type"] == b"Pages", "/Type of page tree node is not /Pages"
+        )
+        pages = []
+        for kid in node[b"Kids"]:
+            kid_object = self.read_indirect(kid)
+            if kid_object[b"Type"] == b"Page":
+                pages.append(kid)
+            else:
+                pages.extend(self.linearize_page_tree(node=kid_object))
+        return pages
diff --git a/.venv/lib/python3.7/site-packages/PIL/PixarImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/PixarImagePlugin.py
new file mode 100644
index 0000000..c4860b6
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/PixarImagePlugin.py
@@ -0,0 +1,70 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# PIXAR raster support for PIL
+#
+# history:
+#       97-01-29 fl     Created
+#
+# notes:
+#       This is incomplete; it is based on a few samples created with
+#       Photoshop 2.5 and 3.0, and a summary description provided by
+#       Greg Coats <gcoats@labiris.er.usgs.gov>.  Hopefully, "L" and
+#       "RGBA" support will be added in future versions.
+#
+# Copyright (c) Secret Labs AB 1997.
+# Copyright (c) Fredrik Lundh 1997.
+#
+# See the README file for information on usage and redistribution.
+#
+
+from . import Image, ImageFile
+from ._binary import i16le as i16
+
+#
+# helpers
+
+
+def _accept(prefix):
+    return prefix[:4] == b"\200\350\000\000"
+
+
+##
+# Image plugin for PIXAR raster images.
+
+
+class PixarImageFile(ImageFile.ImageFile):
+
+    format = "PIXAR"
+    format_description = "PIXAR raster image"
+
+    def _open(self):
+
+        # assuming a 4-byte magic label
+        s = self.fp.read(4)
+        if not _accept(s):
+            raise SyntaxError("not a PIXAR file")
+
+        # read rest of header
+        s = s + self.fp.read(508)
+
+        self._size = i16(s, 418), i16(s, 416)
+
+        # get channel/depth descriptions
+        mode = i16(s, 424), i16(s, 426)
+
+        if mode == (14, 2):
+            self.mode = "RGB"
+        # FIXME: to be continued...
+
+        # create tile descriptor (assuming "dumped")
+        self.tile = [("raw", (0, 0) + self.size, 1024, (self.mode, 0, 1))]
+
+
+#
+# --------------------------------------------------------------------
+
+Image.register_open(PixarImageFile.format, PixarImageFile, _accept)
+
+Image.register_extension(PixarImageFile.format, ".pxr")
diff --git a/.venv/lib/python3.7/site-packages/PIL/PngImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/PngImagePlugin.py
new file mode 100644
index 0000000..0f596f1
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/PngImagePlugin.py
@@ -0,0 +1,1406 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# PNG support code
+#
+# See "PNG (Portable Network Graphics) Specification, version 1.0;
+# W3C Recommendation", 1996-10-01, Thomas Boutell (ed.).
+#
+# history:
+# 1996-05-06 fl   Created (couldn't resist it)
+# 1996-12-14 fl   Upgraded, added read and verify support (0.2)
+# 1996-12-15 fl   Separate PNG stream parser
+# 1996-12-29 fl   Added write support, added getchunks
+# 1996-12-30 fl   Eliminated circular references in decoder (0.3)
+# 1998-07-12 fl   Read/write 16-bit images as mode I (0.4)
+# 2001-02-08 fl   Added transparency support (from Zircon) (0.5)
+# 2001-04-16 fl   Don't close data source in "open" method (0.6)
+# 2004-02-24 fl   Don't even pretend to support interlaced files (0.7)
+# 2004-08-31 fl   Do basic sanity check on chunk identifiers (0.8)
+# 2004-09-20 fl   Added PngInfo chunk container
+# 2004-12-18 fl   Added DPI read support (based on code by Niki Spahiev)
+# 2008-08-13 fl   Added tRNS support for RGB images
+# 2009-03-06 fl   Support for preserving ICC profiles (by Florian Hoech)
+# 2009-03-08 fl   Added zTXT support (from Lowell Alleman)
+# 2009-03-29 fl   Read interlaced PNG files (from Conrado Porto Lopes Gouvua)
+#
+# Copyright (c) 1997-2009 by Secret Labs AB
+# Copyright (c) 1996 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+import itertools
+import logging
+import re
+import struct
+import warnings
+import zlib
+
+from . import Image, ImageChops, ImageFile, ImagePalette, ImageSequence
+from ._binary import i16be as i16
+from ._binary import i32be as i32
+from ._binary import o8
+from ._binary import o16be as o16
+from ._binary import o32be as o32
+
+logger = logging.getLogger(__name__)
+
+is_cid = re.compile(br"\w\w\w\w").match
+
+
+_MAGIC = b"\211PNG\r\n\032\n"
+
+
+_MODES = {
+    # supported bits/color combinations, and corresponding modes/rawmodes
+    # Greyscale
+    (1, 0): ("1", "1"),
+    (2, 0): ("L", "L;2"),
+    (4, 0): ("L", "L;4"),
+    (8, 0): ("L", "L"),
+    (16, 0): ("I", "I;16B"),
+    # Truecolour
+    (8, 2): ("RGB", "RGB"),
+    (16, 2): ("RGB", "RGB;16B"),
+    # Indexed-colour
+    (1, 3): ("P", "P;1"),
+    (2, 3): ("P", "P;2"),
+    (4, 3): ("P", "P;4"),
+    (8, 3): ("P", "P"),
+    # Greyscale with alpha
+    (8, 4): ("LA", "LA"),
+    (16, 4): ("RGBA", "LA;16B"),  # LA;16B->LA not yet available
+    # Truecolour with alpha
+    (8, 6): ("RGBA", "RGBA"),
+    (16, 6): ("RGBA", "RGBA;16B"),
+}
+
+
+_simple_palette = re.compile(b"^\xff*\x00\xff*$")
+
+MAX_TEXT_CHUNK = ImageFile.SAFEBLOCK
+"""
+Maximum decompressed size for a iTXt or zTXt chunk.
+Eliminates decompression bombs where compressed chunks can expand 1000x.
+See :ref:`Text in PNG File Format<png-text>`.
+"""
+MAX_TEXT_MEMORY = 64 * MAX_TEXT_CHUNK
+"""
+Set the maximum total text chunk size.
+See :ref:`Text in PNG File Format<png-text>`.
+"""
+
+
+# APNG frame disposal modes
+APNG_DISPOSE_OP_NONE = 0
+"""
+No disposal is done on this frame before rendering the next frame.
+See :ref:`Saving APNG sequences<apng-saving>`.
+"""
+APNG_DISPOSE_OP_BACKGROUND = 1
+"""
+This frame’s modified region is cleared to fully transparent black before rendering
+the next frame.
+See :ref:`Saving APNG sequences<apng-saving>`.
+"""
+APNG_DISPOSE_OP_PREVIOUS = 2
+"""
+This frame’s modified region is reverted to the previous frame’s contents before
+rendering the next frame.
+See :ref:`Saving APNG sequences<apng-saving>`.
+"""
+
+# APNG frame blend modes
+APNG_BLEND_OP_SOURCE = 0
+"""
+All color components of this frame, including alpha, overwrite the previous output
+image contents.
+See :ref:`Saving APNG sequences<apng-saving>`.
+"""
+APNG_BLEND_OP_OVER = 1
+"""
+This frame should be alpha composited with the previous output image contents.
+See :ref:`Saving APNG sequences<apng-saving>`.
+"""
+
+
+def _safe_zlib_decompress(s):
+    dobj = zlib.decompressobj()
+    plaintext = dobj.decompress(s, MAX_TEXT_CHUNK)
+    if dobj.unconsumed_tail:
+        raise ValueError("Decompressed Data Too Large")
+    return plaintext
+
+
+def _crc32(data, seed=0):
+    return zlib.crc32(data, seed) & 0xFFFFFFFF
+
+
+# --------------------------------------------------------------------
+# Support classes.  Suitable for PNG and related formats like MNG etc.
+
+
+class ChunkStream:
+    def __init__(self, fp):
+
+        self.fp = fp
+        self.queue = []
+
+    def read(self):
+        """Fetch a new chunk. Returns header information."""
+        cid = None
+
+        if self.queue:
+            cid, pos, length = self.queue.pop()
+            self.fp.seek(pos)
+        else:
+            s = self.fp.read(8)
+            cid = s[4:]
+            pos = self.fp.tell()
+            length = i32(s)
+
+        if not is_cid(cid):
+            if not ImageFile.LOAD_TRUNCATED_IMAGES:
+                raise SyntaxError(f"broken PNG file (chunk {repr(cid)})")
+
+        return cid, pos, length
+
+    def __enter__(self):
+        return self
+
+    def __exit__(self, *args):
+        self.close()
+
+    def close(self):
+        self.queue = self.crc = self.fp = None
+
+    def push(self, cid, pos, length):
+
+        self.queue.append((cid, pos, length))
+
+    def call(self, cid, pos, length):
+        """Call the appropriate chunk handler"""
+
+        logger.debug("STREAM %r %s %s", cid, pos, length)
+        return getattr(self, "chunk_" + cid.decode("ascii"))(pos, length)
+
+    def crc(self, cid, data):
+        """Read and verify checksum"""
+
+        # Skip CRC checks for ancillary chunks if allowed to load truncated
+        # images
+        # 5th byte of first char is 1 [specs, section 5.4]
+        if ImageFile.LOAD_TRUNCATED_IMAGES and (cid[0] >> 5 & 1):
+            self.crc_skip(cid, data)
+            return
+
+        try:
+            crc1 = _crc32(data, _crc32(cid))
+            crc2 = i32(self.fp.read(4))
+            if crc1 != crc2:
+                raise SyntaxError(
+                    f"broken PNG file (bad header checksum in {repr(cid)})"
+                )
+        except struct.error as e:
+            raise SyntaxError(
+                f"broken PNG file (incomplete checksum in {repr(cid)})"
+            ) from e
+
+    def crc_skip(self, cid, data):
+        """Read checksum.  Used if the C module is not present"""
+
+        self.fp.read(4)
+
+    def verify(self, endchunk=b"IEND"):
+
+        # Simple approach; just calculate checksum for all remaining
+        # blocks.  Must be called directly after open.
+
+        cids = []
+
+        while True:
+            try:
+                cid, pos, length = self.read()
+            except struct.error as e:
+                raise OSError("truncated PNG file") from e
+
+            if cid == endchunk:
+                break
+            self.crc(cid, ImageFile._safe_read(self.fp, length))
+            cids.append(cid)
+
+        return cids
+
+
+class iTXt(str):
+    """
+    Subclass of string to allow iTXt chunks to look like strings while
+    keeping their extra information
+
+    """
+
+    @staticmethod
+    def __new__(cls, text, lang=None, tkey=None):
+        """
+        :param cls: the class to use when creating the instance
+        :param text: value for this key
+        :param lang: language code
+        :param tkey: UTF-8 version of the key name
+        """
+
+        self = str.__new__(cls, text)
+        self.lang = lang
+        self.tkey = tkey
+        return self
+
+
+class PngInfo:
+    """
+    PNG chunk container (for use with save(pnginfo=))
+
+    """
+
+    def __init__(self):
+        self.chunks = []
+
+    def add(self, cid, data, after_idat=False):
+        """Appends an arbitrary chunk. Use with caution.
+
+        :param cid: a byte string, 4 bytes long.
+        :param data: a byte string of the encoded data
+        :param after_idat: for use with private chunks. Whether the chunk
+                           should be written after IDAT
+
+        """
+
+        chunk = [cid, data]
+        if after_idat:
+            chunk.append(True)
+        self.chunks.append(tuple(chunk))
+
+    def add_itxt(self, key, value, lang="", tkey="", zip=False):
+        """Appends an iTXt chunk.
+
+        :param key: latin-1 encodable text key name
+        :param value: value for this key
+        :param lang: language code
+        :param tkey: UTF-8 version of the key name
+        :param zip: compression flag
+
+        """
+
+        if not isinstance(key, bytes):
+            key = key.encode("latin-1", "strict")
+        if not isinstance(value, bytes):
+            value = value.encode("utf-8", "strict")
+        if not isinstance(lang, bytes):
+            lang = lang.encode("utf-8", "strict")
+        if not isinstance(tkey, bytes):
+            tkey = tkey.encode("utf-8", "strict")
+
+        if zip:
+            self.add(
+                b"iTXt",
+                key + b"\0\x01\0" + lang + b"\0" + tkey + b"\0" + zlib.compress(value),
+            )
+        else:
+            self.add(b"iTXt", key + b"\0\0\0" + lang + b"\0" + tkey + b"\0" + value)
+
+    def add_text(self, key, value, zip=False):
+        """Appends a text chunk.
+
+        :param key: latin-1 encodable text key name
+        :param value: value for this key, text or an
+           :py:class:`PIL.PngImagePlugin.iTXt` instance
+        :param zip: compression flag
+
+        """
+        if isinstance(value, iTXt):
+            return self.add_itxt(key, value, value.lang, value.tkey, zip=zip)
+
+        # The tEXt chunk stores latin-1 text
+        if not isinstance(value, bytes):
+            try:
+                value = value.encode("latin-1", "strict")
+            except UnicodeError:
+                return self.add_itxt(key, value, zip=zip)
+
+        if not isinstance(key, bytes):
+            key = key.encode("latin-1", "strict")
+
+        if zip:
+            self.add(b"zTXt", key + b"\0\0" + zlib.compress(value))
+        else:
+            self.add(b"tEXt", key + b"\0" + value)
+
+
+# --------------------------------------------------------------------
+# PNG image stream (IHDR/IEND)
+
+
+class PngStream(ChunkStream):
+    def __init__(self, fp):
+        super().__init__(fp)
+
+        # local copies of Image attributes
+        self.im_info = {}
+        self.im_text = {}
+        self.im_size = (0, 0)
+        self.im_mode = None
+        self.im_tile = None
+        self.im_palette = None
+        self.im_custom_mimetype = None
+        self.im_n_frames = None
+        self._seq_num = None
+        self.rewind_state = None
+
+        self.text_memory = 0
+
+    def check_text_memory(self, chunklen):
+        self.text_memory += chunklen
+        if self.text_memory > MAX_TEXT_MEMORY:
+            raise ValueError(
+                "Too much memory used in text chunks: "
+                f"{self.text_memory}>MAX_TEXT_MEMORY"
+            )
+
+    def save_rewind(self):
+        self.rewind_state = {
+            "info": self.im_info.copy(),
+            "tile": self.im_tile,
+            "seq_num": self._seq_num,
+        }
+
+    def rewind(self):
+        self.im_info = self.rewind_state["info"]
+        self.im_tile = self.rewind_state["tile"]
+        self._seq_num = self.rewind_state["seq_num"]
+
+    def chunk_iCCP(self, pos, length):
+
+        # ICC profile
+        s = ImageFile._safe_read(self.fp, length)
+        # according to PNG spec, the iCCP chunk contains:
+        # Profile name  1-79 bytes (character string)
+        # Null separator        1 byte (null character)
+        # Compression method    1 byte (0)
+        # Compressed profile    n bytes (zlib with deflate compression)
+        i = s.find(b"\0")
+        logger.debug("iCCP profile name %r", s[:i])
+        logger.debug("Compression method %s", s[i])
+        comp_method = s[i]
+        if comp_method != 0:
+            raise SyntaxError(f"Unknown compression method {comp_method} in iCCP chunk")
+        try:
+            icc_profile = _safe_zlib_decompress(s[i + 2 :])
+        except ValueError:
+            if ImageFile.LOAD_TRUNCATED_IMAGES:
+                icc_profile = None
+            else:
+                raise
+        except zlib.error:
+            icc_profile = None  # FIXME
+        self.im_info["icc_profile"] = icc_profile
+        return s
+
+    def chunk_IHDR(self, pos, length):
+
+        # image header
+        s = ImageFile._safe_read(self.fp, length)
+        self.im_size = i32(s, 0), i32(s, 4)
+        try:
+            self.im_mode, self.im_rawmode = _MODES[(s[8], s[9])]
+        except Exception:
+            pass
+        if s[12]:
+            self.im_info["interlace"] = 1
+        if s[11]:
+            raise SyntaxError("unknown filter category")
+        return s
+
+    def chunk_IDAT(self, pos, length):
+
+        # image data
+        if "bbox" in self.im_info:
+            tile = [("zip", self.im_info["bbox"], pos, self.im_rawmode)]
+        else:
+            if self.im_n_frames is not None:
+                self.im_info["default_image"] = True
+            tile = [("zip", (0, 0) + self.im_size, pos, self.im_rawmode)]
+        self.im_tile = tile
+        self.im_idat = length
+        raise EOFError
+
+    def chunk_IEND(self, pos, length):
+
+        # end of PNG image
+        raise EOFError
+
+    def chunk_PLTE(self, pos, length):
+
+        # palette
+        s = ImageFile._safe_read(self.fp, length)
+        if self.im_mode == "P":
+            self.im_palette = "RGB", s
+        return s
+
+    def chunk_tRNS(self, pos, length):
+
+        # transparency
+        s = ImageFile._safe_read(self.fp, length)
+        if self.im_mode == "P":
+            if _simple_palette.match(s):
+                # tRNS contains only one full-transparent entry,
+                # other entries are full opaque
+                i = s.find(b"\0")
+                if i >= 0:
+                    self.im_info["transparency"] = i
+            else:
+                # otherwise, we have a byte string with one alpha value
+                # for each palette entry
+                self.im_info["transparency"] = s
+        elif self.im_mode in ("1", "L", "I"):
+            self.im_info["transparency"] = i16(s)
+        elif self.im_mode == "RGB":
+            self.im_info["transparency"] = i16(s), i16(s, 2), i16(s, 4)
+        return s
+
+    def chunk_gAMA(self, pos, length):
+        # gamma setting
+        s = ImageFile._safe_read(self.fp, length)
+        self.im_info["gamma"] = i32(s) / 100000.0
+        return s
+
+    def chunk_cHRM(self, pos, length):
+        # chromaticity, 8 unsigned ints, actual value is scaled by 100,000
+        # WP x,y, Red x,y, Green x,y Blue x,y
+
+        s = ImageFile._safe_read(self.fp, length)
+        raw_vals = struct.unpack(">%dI" % (len(s) // 4), s)
+        self.im_info["chromaticity"] = tuple(elt / 100000.0 for elt in raw_vals)
+        return s
+
+    def chunk_sRGB(self, pos, length):
+        # srgb rendering intent, 1 byte
+        # 0 perceptual
+        # 1 relative colorimetric
+        # 2 saturation
+        # 3 absolute colorimetric
+
+        s = ImageFile._safe_read(self.fp, length)
+        self.im_info["srgb"] = s[0]
+        return s
+
+    def chunk_pHYs(self, pos, length):
+
+        # pixels per unit
+        s = ImageFile._safe_read(self.fp, length)
+        px, py = i32(s, 0), i32(s, 4)
+        unit = s[8]
+        if unit == 1:  # meter
+            dpi = px * 0.0254, py * 0.0254
+            self.im_info["dpi"] = dpi
+        elif unit == 0:
+            self.im_info["aspect"] = px, py
+        return s
+
+    def chunk_tEXt(self, pos, length):
+
+        # text
+        s = ImageFile._safe_read(self.fp, length)
+        try:
+            k, v = s.split(b"\0", 1)
+        except ValueError:
+            # fallback for broken tEXt tags
+            k = s
+            v = b""
+        if k:
+            k = k.decode("latin-1", "strict")
+            v_str = v.decode("latin-1", "replace")
+
+            self.im_info[k] = v if k == "exif" else v_str
+            self.im_text[k] = v_str
+            self.check_text_memory(len(v_str))
+
+        return s
+
+    def chunk_zTXt(self, pos, length):
+
+        # compressed text
+        s = ImageFile._safe_read(self.fp, length)
+        try:
+            k, v = s.split(b"\0", 1)
+        except ValueError:
+            k = s
+            v = b""
+        if v:
+            comp_method = v[0]
+        else:
+            comp_method = 0
+        if comp_method != 0:
+            raise SyntaxError(f"Unknown compression method {comp_method} in zTXt chunk")
+        try:
+            v = _safe_zlib_decompress(v[1:])
+        except ValueError:
+            if ImageFile.LOAD_TRUNCATED_IMAGES:
+                v = b""
+            else:
+                raise
+        except zlib.error:
+            v = b""
+
+        if k:
+            k = k.decode("latin-1", "strict")
+            v = v.decode("latin-1", "replace")
+
+            self.im_info[k] = self.im_text[k] = v
+            self.check_text_memory(len(v))
+
+        return s
+
+    def chunk_iTXt(self, pos, length):
+
+        # international text
+        r = s = ImageFile._safe_read(self.fp, length)
+        try:
+            k, r = r.split(b"\0", 1)
+        except ValueError:
+            return s
+        if len(r) < 2:
+            return s
+        cf, cm, r = r[0], r[1], r[2:]
+        try:
+            lang, tk, v = r.split(b"\0", 2)
+        except ValueError:
+            return s
+        if cf != 0:
+            if cm == 0:
+                try:
+                    v = _safe_zlib_decompress(v)
+                except ValueError:
+                    if ImageFile.LOAD_TRUNCATED_IMAGES:
+                        return s
+                    else:
+                        raise
+                except zlib.error:
+                    return s
+            else:
+                return s
+        try:
+            k = k.decode("latin-1", "strict")
+            lang = lang.decode("utf-8", "strict")
+            tk = tk.decode("utf-8", "strict")
+            v = v.decode("utf-8", "strict")
+        except UnicodeError:
+            return s
+
+        self.im_info[k] = self.im_text[k] = iTXt(v, lang, tk)
+        self.check_text_memory(len(v))
+
+        return s
+
+    def chunk_eXIf(self, pos, length):
+        s = ImageFile._safe_read(self.fp, length)
+        self.im_info["exif"] = b"Exif\x00\x00" + s
+        return s
+
+    # APNG chunks
+    def chunk_acTL(self, pos, length):
+        s = ImageFile._safe_read(self.fp, length)
+        if self.im_n_frames is not None:
+            self.im_n_frames = None
+            warnings.warn("Invalid APNG, will use default PNG image if possible")
+            return s
+        n_frames = i32(s)
+        if n_frames == 0 or n_frames > 0x80000000:
+            warnings.warn("Invalid APNG, will use default PNG image if possible")
+            return s
+        self.im_n_frames = n_frames
+        self.im_info["loop"] = i32(s, 4)
+        self.im_custom_mimetype = "image/apng"
+        return s
+
+    def chunk_fcTL(self, pos, length):
+        s = ImageFile._safe_read(self.fp, length)
+        seq = i32(s)
+        if (self._seq_num is None and seq != 0) or (
+            self._seq_num is not None and self._seq_num != seq - 1
+        ):
+            raise SyntaxError("APNG contains frame sequence errors")
+        self._seq_num = seq
+        width, height = i32(s, 4), i32(s, 8)
+        px, py = i32(s, 12), i32(s, 16)
+        im_w, im_h = self.im_size
+        if px + width > im_w or py + height > im_h:
+            raise SyntaxError("APNG contains invalid frames")
+        self.im_info["bbox"] = (px, py, px + width, py + height)
+        delay_num, delay_den = i16(s, 20), i16(s, 22)
+        if delay_den == 0:
+            delay_den = 100
+        self.im_info["duration"] = float(delay_num) / float(delay_den) * 1000
+        self.im_info["disposal"] = s[24]
+        self.im_info["blend"] = s[25]
+        return s
+
+    def chunk_fdAT(self, pos, length):
+        s = ImageFile._safe_read(self.fp, 4)
+        seq = i32(s)
+        if self._seq_num != seq - 1:
+            raise SyntaxError("APNG contains frame sequence errors")
+        self._seq_num = seq
+        return self.chunk_IDAT(pos + 4, length - 4)
+
+
+# --------------------------------------------------------------------
+# PNG reader
+
+
+def _accept(prefix):
+    return prefix[:8] == _MAGIC
+
+
+##
+# Image plugin for PNG images.
+
+
+class PngImageFile(ImageFile.ImageFile):
+
+    format = "PNG"
+    format_description = "Portable network graphics"
+
+    def _open(self):
+
+        if not _accept(self.fp.read(8)):
+            raise SyntaxError("not a PNG file")
+        self.__fp = self.fp
+        self.__frame = 0
+
+        #
+        # Parse headers up to the first IDAT or fDAT chunk
+
+        self.private_chunks = []
+        self.png = PngStream(self.fp)
+
+        while True:
+
+            #
+            # get next chunk
+
+            cid, pos, length = self.png.read()
+
+            try:
+                s = self.png.call(cid, pos, length)
+            except EOFError:
+                break
+            except AttributeError:
+                logger.debug("%r %s %s (unknown)", cid, pos, length)
+                s = ImageFile._safe_read(self.fp, length)
+                if cid[1:2].islower():
+                    self.private_chunks.append((cid, s))
+
+            self.png.crc(cid, s)
+
+        #
+        # Copy relevant attributes from the PngStream.  An alternative
+        # would be to let the PngStream class modify these attributes
+        # directly, but that introduces circular references which are
+        # difficult to break if things go wrong in the decoder...
+        # (believe me, I've tried ;-)
+
+        self.mode = self.png.im_mode
+        self._size = self.png.im_size
+        self.info = self.png.im_info
+        self._text = None
+        self.tile = self.png.im_tile
+        self.custom_mimetype = self.png.im_custom_mimetype
+        self.n_frames = self.png.im_n_frames or 1
+        self.default_image = self.info.get("default_image", False)
+
+        if self.png.im_palette:
+            rawmode, data = self.png.im_palette
+            self.palette = ImagePalette.raw(rawmode, data)
+
+        if cid == b"fdAT":
+            self.__prepare_idat = length - 4
+        else:
+            self.__prepare_idat = length  # used by load_prepare()
+
+        if self.png.im_n_frames is not None:
+            self._close_exclusive_fp_after_loading = False
+            self.png.save_rewind()
+            self.__rewind_idat = self.__prepare_idat
+            self.__rewind = self.__fp.tell()
+            if self.default_image:
+                # IDAT chunk contains default image and not first animation frame
+                self.n_frames += 1
+            self._seek(0)
+        self.is_animated = self.n_frames > 1
+
+    @property
+    def text(self):
+        # experimental
+        if self._text is None:
+            # iTxt, tEXt and zTXt chunks may appear at the end of the file
+            # So load the file to ensure that they are read
+            if self.is_animated:
+                frame = self.__frame
+                # for APNG, seek to the final frame before loading
+                self.seek(self.n_frames - 1)
+            self.load()
+            if self.is_animated:
+                self.seek(frame)
+        return self._text
+
+    def verify(self):
+        """Verify PNG file"""
+
+        if self.fp is None:
+            raise RuntimeError("verify must be called directly after open")
+
+        # back up to beginning of IDAT block
+        self.fp.seek(self.tile[0][2] - 8)
+
+        self.png.verify()
+        self.png.close()
+
+        if self._exclusive_fp:
+            self.fp.close()
+        self.fp = None
+
+    def seek(self, frame):
+        if not self._seek_check(frame):
+            return
+        if frame < self.__frame:
+            self._seek(0, True)
+
+        last_frame = self.__frame
+        for f in range(self.__frame + 1, frame + 1):
+            try:
+                self._seek(f)
+            except EOFError as e:
+                self.seek(last_frame)
+                raise EOFError("no more images in APNG file") from e
+
+    def _seek(self, frame, rewind=False):
+        if frame == 0:
+            if rewind:
+                self.__fp.seek(self.__rewind)
+                self.png.rewind()
+                self.__prepare_idat = self.__rewind_idat
+                self.im = None
+                if self.pyaccess:
+                    self.pyaccess = None
+                self.info = self.png.im_info
+                self.tile = self.png.im_tile
+                self.fp = self.__fp
+            self._prev_im = None
+            self.dispose = None
+            self.default_image = self.info.get("default_image", False)
+            self.dispose_op = self.info.get("disposal")
+            self.blend_op = self.info.get("blend")
+            self.dispose_extent = self.info.get("bbox")
+            self.__frame = 0
+        else:
+            if frame != self.__frame + 1:
+                raise ValueError(f"cannot seek to frame {frame}")
+
+            # ensure previous frame was loaded
+            self.load()
+
+            if self.dispose:
+                self.im.paste(self.dispose, self.dispose_extent)
+            self._prev_im = self.im.copy()
+
+            self.fp = self.__fp
+
+            # advance to the next frame
+            if self.__prepare_idat:
+                ImageFile._safe_read(self.fp, self.__prepare_idat)
+                self.__prepare_idat = 0
+            frame_start = False
+            while True:
+                self.fp.read(4)  # CRC
+
+                try:
+                    cid, pos, length = self.png.read()
+                except (struct.error, SyntaxError):
+                    break
+
+                if cid == b"IEND":
+                    raise EOFError("No more images in APNG file")
+                if cid == b"fcTL":
+                    if frame_start:
+                        # there must be at least one fdAT chunk between fcTL chunks
+                        raise SyntaxError("APNG missing frame data")
+                    frame_start = True
+
+                try:
+                    self.png.call(cid, pos, length)
+                except UnicodeDecodeError:
+                    break
+                except EOFError:
+                    if cid == b"fdAT":
+                        length -= 4
+                        if frame_start:
+                            self.__prepare_idat = length
+                            break
+                    ImageFile._safe_read(self.fp, length)
+                except AttributeError:
+                    logger.debug("%r %s %s (unknown)", cid, pos, length)
+                    ImageFile._safe_read(self.fp, length)
+
+            self.__frame = frame
+            self.tile = self.png.im_tile
+            self.dispose_op = self.info.get("disposal")
+            self.blend_op = self.info.get("blend")
+            self.dispose_extent = self.info.get("bbox")
+
+            if not self.tile:
+                raise EOFError
+
+        # setup frame disposal (actual disposal done when needed in the next _seek())
+        if self._prev_im is None and self.dispose_op == APNG_DISPOSE_OP_PREVIOUS:
+            self.dispose_op = APNG_DISPOSE_OP_BACKGROUND
+
+        if self.dispose_op == APNG_DISPOSE_OP_PREVIOUS:
+            self.dispose = self._prev_im.copy()
+            self.dispose = self._crop(self.dispose, self.dispose_extent)
+        elif self.dispose_op == APNG_DISPOSE_OP_BACKGROUND:
+            self.dispose = Image.core.fill(self.mode, self.size)
+            self.dispose = self._crop(self.dispose, self.dispose_extent)
+        else:
+            self.dispose = None
+
+    def tell(self):
+        return self.__frame
+
+    def load_prepare(self):
+        """internal: prepare to read PNG file"""
+
+        if self.info.get("interlace"):
+            self.decoderconfig = self.decoderconfig + (1,)
+
+        self.__idat = self.__prepare_idat  # used by load_read()
+        ImageFile.ImageFile.load_prepare(self)
+
+    def load_read(self, read_bytes):
+        """internal: read more image data"""
+
+        while self.__idat == 0:
+            # end of chunk, skip forward to next one
+
+            self.fp.read(4)  # CRC
+
+            cid, pos, length = self.png.read()
+
+            if cid not in [b"IDAT", b"DDAT", b"fdAT"]:
+                self.png.push(cid, pos, length)
+                return b""
+
+            if cid == b"fdAT":
+                try:
+                    self.png.call(cid, pos, length)
+                except EOFError:
+                    pass
+                self.__idat = length - 4  # sequence_num has already been read
+            else:
+                self.__idat = length  # empty chunks are allowed
+
+        # read more data from this chunk
+        if read_bytes <= 0:
+            read_bytes = self.__idat
+        else:
+            read_bytes = min(read_bytes, self.__idat)
+
+        self.__idat = self.__idat - read_bytes
+
+        return self.fp.read(read_bytes)
+
+    def load_end(self):
+        """internal: finished reading image data"""
+        if self.__idat != 0:
+            self.fp.read(self.__idat)
+        while True:
+            self.fp.read(4)  # CRC
+
+            try:
+                cid, pos, length = self.png.read()
+            except (struct.error, SyntaxError):
+                break
+
+            if cid == b"IEND":
+                break
+            elif cid == b"fcTL" and self.is_animated:
+                # start of the next frame, stop reading
+                self.__prepare_idat = 0
+                self.png.push(cid, pos, length)
+                break
+
+            try:
+                self.png.call(cid, pos, length)
+            except UnicodeDecodeError:
+                break
+            except EOFError:
+                if cid == b"fdAT":
+                    length -= 4
+                ImageFile._safe_read(self.fp, length)
+            except AttributeError:
+                logger.debug("%r %s %s (unknown)", cid, pos, length)
+                s = ImageFile._safe_read(self.fp, length)
+                if cid[1:2].islower():
+                    self.private_chunks.append((cid, s, True))
+        self._text = self.png.im_text
+        if not self.is_animated:
+            self.png.close()
+            self.png = None
+        else:
+            if self._prev_im and self.blend_op == APNG_BLEND_OP_OVER:
+                updated = self._crop(self.im, self.dispose_extent)
+                self._prev_im.paste(
+                    updated, self.dispose_extent, updated.convert("RGBA")
+                )
+                self.im = self._prev_im
+                if self.pyaccess:
+                    self.pyaccess = None
+
+    def _getexif(self):
+        if "exif" not in self.info:
+            self.load()
+        if "exif" not in self.info and "Raw profile type exif" not in self.info:
+            return None
+        return self.getexif()._get_merged_dict()
+
+    def getexif(self):
+        if "exif" not in self.info:
+            self.load()
+
+        return super().getexif()
+
+    def getxmp(self):
+        """
+        Returns a dictionary containing the XMP tags.
+        Requires defusedxml to be installed.
+        :returns: XMP tags in a dictionary.
+        """
+        return (
+            self._getxmp(self.info["XML:com.adobe.xmp"])
+            if "XML:com.adobe.xmp" in self.info
+            else {}
+        )
+
+    def _close__fp(self):
+        try:
+            if self.__fp != self.fp:
+                self.__fp.close()
+        except AttributeError:
+            pass
+        finally:
+            self.__fp = None
+
+
+# --------------------------------------------------------------------
+# PNG writer
+
+_OUTMODES = {
+    # supported PIL modes, and corresponding rawmodes/bits/color combinations
+    "1": ("1", b"\x01\x00"),
+    "L;1": ("L;1", b"\x01\x00"),
+    "L;2": ("L;2", b"\x02\x00"),
+    "L;4": ("L;4", b"\x04\x00"),
+    "L": ("L", b"\x08\x00"),
+    "LA": ("LA", b"\x08\x04"),
+    "I": ("I;16B", b"\x10\x00"),
+    "I;16": ("I;16B", b"\x10\x00"),
+    "P;1": ("P;1", b"\x01\x03"),
+    "P;2": ("P;2", b"\x02\x03"),
+    "P;4": ("P;4", b"\x04\x03"),
+    "P": ("P", b"\x08\x03"),
+    "RGB": ("RGB", b"\x08\x02"),
+    "RGBA": ("RGBA", b"\x08\x06"),
+}
+
+
+def putchunk(fp, cid, *data):
+    """Write a PNG chunk (including CRC field)"""
+
+    data = b"".join(data)
+
+    fp.write(o32(len(data)) + cid)
+    fp.write(data)
+    crc = _crc32(data, _crc32(cid))
+    fp.write(o32(crc))
+
+
+class _idat:
+    # wrap output from the encoder in IDAT chunks
+
+    def __init__(self, fp, chunk):
+        self.fp = fp
+        self.chunk = chunk
+
+    def write(self, data):
+        self.chunk(self.fp, b"IDAT", data)
+
+
+class _fdat:
+    # wrap encoder output in fdAT chunks
+
+    def __init__(self, fp, chunk, seq_num):
+        self.fp = fp
+        self.chunk = chunk
+        self.seq_num = seq_num
+
+    def write(self, data):
+        self.chunk(self.fp, b"fdAT", o32(self.seq_num), data)
+        self.seq_num += 1
+
+
+def _write_multiple_frames(im, fp, chunk, rawmode):
+    default_image = im.encoderinfo.get("default_image", im.info.get("default_image"))
+    duration = im.encoderinfo.get("duration", im.info.get("duration", 0))
+    loop = im.encoderinfo.get("loop", im.info.get("loop", 0))
+    disposal = im.encoderinfo.get(
+        "disposal", im.info.get("disposal", APNG_DISPOSE_OP_NONE)
+    )
+    blend = im.encoderinfo.get("blend", im.info.get("blend", APNG_BLEND_OP_SOURCE))
+
+    if default_image:
+        chain = itertools.chain(im.encoderinfo.get("append_images", []))
+    else:
+        chain = itertools.chain([im], im.encoderinfo.get("append_images", []))
+
+    im_frames = []
+    frame_count = 0
+    for im_seq in chain:
+        for im_frame in ImageSequence.Iterator(im_seq):
+            im_frame = im_frame.copy()
+            if im_frame.mode != im.mode:
+                if im.mode == "P":
+                    im_frame = im_frame.convert(im.mode, palette=im.palette)
+                else:
+                    im_frame = im_frame.convert(im.mode)
+            encoderinfo = im.encoderinfo.copy()
+            if isinstance(duration, (list, tuple)):
+                encoderinfo["duration"] = duration[frame_count]
+            if isinstance(disposal, (list, tuple)):
+                encoderinfo["disposal"] = disposal[frame_count]
+            if isinstance(blend, (list, tuple)):
+                encoderinfo["blend"] = blend[frame_count]
+            frame_count += 1
+
+            if im_frames:
+                previous = im_frames[-1]
+                prev_disposal = previous["encoderinfo"].get("disposal")
+                prev_blend = previous["encoderinfo"].get("blend")
+                if prev_disposal == APNG_DISPOSE_OP_PREVIOUS and len(im_frames) < 2:
+                    prev_disposal = APNG_DISPOSE_OP_BACKGROUND
+
+                if prev_disposal == APNG_DISPOSE_OP_BACKGROUND:
+                    base_im = previous["im"]
+                    dispose = Image.core.fill("RGBA", im.size, (0, 0, 0, 0))
+                    bbox = previous["bbox"]
+                    if bbox:
+                        dispose = dispose.crop(bbox)
+                    else:
+                        bbox = (0, 0) + im.size
+                    base_im.paste(dispose, bbox)
+                elif prev_disposal == APNG_DISPOSE_OP_PREVIOUS:
+                    base_im = im_frames[-2]["im"]
+                else:
+                    base_im = previous["im"]
+                delta = ImageChops.subtract_modulo(
+                    im_frame.convert("RGB"), base_im.convert("RGB")
+                )
+                bbox = delta.getbbox()
+                if (
+                    not bbox
+                    and prev_disposal == encoderinfo.get("disposal")
+                    and prev_blend == encoderinfo.get("blend")
+                ):
+                    if isinstance(duration, (list, tuple)):
+                        previous["encoderinfo"]["duration"] += encoderinfo["duration"]
+                    continue
+            else:
+                bbox = None
+            im_frames.append({"im": im_frame, "bbox": bbox, "encoderinfo": encoderinfo})
+
+    # animation control
+    chunk(
+        fp,
+        b"acTL",
+        o32(len(im_frames)),  # 0: num_frames
+        o32(loop),  # 4: num_plays
+    )
+
+    # default image IDAT (if it exists)
+    if default_image:
+        ImageFile._save(im, _idat(fp, chunk), [("zip", (0, 0) + im.size, 0, rawmode)])
+
+    seq_num = 0
+    for frame, frame_data in enumerate(im_frames):
+        im_frame = frame_data["im"]
+        if not frame_data["bbox"]:
+            bbox = (0, 0) + im_frame.size
+        else:
+            bbox = frame_data["bbox"]
+            im_frame = im_frame.crop(bbox)
+        size = im_frame.size
+        encoderinfo = frame_data["encoderinfo"]
+        frame_duration = int(round(encoderinfo.get("duration", duration)))
+        frame_disposal = encoderinfo.get("disposal", disposal)
+        frame_blend = encoderinfo.get("blend", blend)
+        # frame control
+        chunk(
+            fp,
+            b"fcTL",
+            o32(seq_num),  # sequence_number
+            o32(size[0]),  # width
+            o32(size[1]),  # height
+            o32(bbox[0]),  # x_offset
+            o32(bbox[1]),  # y_offset
+            o16(frame_duration),  # delay_numerator
+            o16(1000),  # delay_denominator
+            o8(frame_disposal),  # dispose_op
+            o8(frame_blend),  # blend_op
+        )
+        seq_num += 1
+        # frame data
+        if frame == 0 and not default_image:
+            # first frame must be in IDAT chunks for backwards compatibility
+            ImageFile._save(
+                im_frame,
+                _idat(fp, chunk),
+                [("zip", (0, 0) + im_frame.size, 0, rawmode)],
+            )
+        else:
+            fdat_chunks = _fdat(fp, chunk, seq_num)
+            ImageFile._save(
+                im_frame,
+                fdat_chunks,
+                [("zip", (0, 0) + im_frame.size, 0, rawmode)],
+            )
+            seq_num = fdat_chunks.seq_num
+
+
+def _save_all(im, fp, filename):
+    _save(im, fp, filename, save_all=True)
+
+
+def _save(im, fp, filename, chunk=putchunk, save_all=False):
+    # save an image to disk (called by the save method)
+
+    mode = im.mode
+
+    if mode == "P":
+
+        #
+        # attempt to minimize storage requirements for palette images
+        if "bits" in im.encoderinfo:
+            # number of bits specified by user
+            colors = min(1 << im.encoderinfo["bits"], 256)
+        else:
+            # check palette contents
+            if im.palette:
+                colors = max(min(len(im.palette.getdata()[1]) // 3, 256), 1)
+            else:
+                colors = 256
+
+        if colors <= 16:
+            if colors <= 2:
+                bits = 1
+            elif colors <= 4:
+                bits = 2
+            else:
+                bits = 4
+            mode = f"{mode};{bits}"
+
+    # encoder options
+    im.encoderconfig = (
+        im.encoderinfo.get("optimize", False),
+        im.encoderinfo.get("compress_level", -1),
+        im.encoderinfo.get("compress_type", -1),
+        im.encoderinfo.get("dictionary", b""),
+    )
+
+    # get the corresponding PNG mode
+    try:
+        rawmode, mode = _OUTMODES[mode]
+    except KeyError as e:
+        raise OSError(f"cannot write mode {mode} as PNG") from e
+
+    #
+    # write minimal PNG file
+
+    fp.write(_MAGIC)
+
+    chunk(
+        fp,
+        b"IHDR",
+        o32(im.size[0]),  # 0: size
+        o32(im.size[1]),
+        mode,  # 8: depth/type
+        b"\0",  # 10: compression
+        b"\0",  # 11: filter category
+        b"\0",  # 12: interlace flag
+    )
+
+    chunks = [b"cHRM", b"gAMA", b"sBIT", b"sRGB", b"tIME"]
+
+    icc = im.encoderinfo.get("icc_profile", im.info.get("icc_profile"))
+    if icc:
+        # ICC profile
+        # according to PNG spec, the iCCP chunk contains:
+        # Profile name  1-79 bytes (character string)
+        # Null separator        1 byte (null character)
+        # Compression method    1 byte (0)
+        # Compressed profile    n bytes (zlib with deflate compression)
+        name = b"ICC Profile"
+        data = name + b"\0\0" + zlib.compress(icc)
+        chunk(fp, b"iCCP", data)
+
+        # You must either have sRGB or iCCP.
+        # Disallow sRGB chunks when an iCCP-chunk has been emitted.
+        chunks.remove(b"sRGB")
+
+    info = im.encoderinfo.get("pnginfo")
+    if info:
+        chunks_multiple_allowed = [b"sPLT", b"iTXt", b"tEXt", b"zTXt"]
+        for info_chunk in info.chunks:
+            cid, data = info_chunk[:2]
+            if cid in chunks:
+                chunks.remove(cid)
+                chunk(fp, cid, data)
+            elif cid in chunks_multiple_allowed:
+                chunk(fp, cid, data)
+            elif cid[1:2].islower():
+                # Private chunk
+                after_idat = info_chunk[2:3]
+                if not after_idat:
+                    chunk(fp, cid, data)
+
+    if im.mode == "P":
+        palette_byte_number = colors * 3
+        palette_bytes = im.im.getpalette("RGB")[:palette_byte_number]
+        while len(palette_bytes) < palette_byte_number:
+            palette_bytes += b"\0"
+        chunk(fp, b"PLTE", palette_bytes)
+
+    transparency = im.encoderinfo.get("transparency", im.info.get("transparency", None))
+
+    if transparency or transparency == 0:
+        if im.mode == "P":
+            # limit to actual palette size
+            alpha_bytes = colors
+            if isinstance(transparency, bytes):
+                chunk(fp, b"tRNS", transparency[:alpha_bytes])
+            else:
+                transparency = max(0, min(255, transparency))
+                alpha = b"\xFF" * transparency + b"\0"
+                chunk(fp, b"tRNS", alpha[:alpha_bytes])
+        elif im.mode in ("1", "L", "I"):
+            transparency = max(0, min(65535, transparency))
+            chunk(fp, b"tRNS", o16(transparency))
+        elif im.mode == "RGB":
+            red, green, blue = transparency
+            chunk(fp, b"tRNS", o16(red) + o16(green) + o16(blue))
+        else:
+            if "transparency" in im.encoderinfo:
+                # don't bother with transparency if it's an RGBA
+                # and it's in the info dict. It's probably just stale.
+                raise OSError("cannot use transparency for this mode")
+    else:
+        if im.mode == "P" and im.im.getpalettemode() == "RGBA":
+            alpha = im.im.getpalette("RGBA", "A")
+            alpha_bytes = colors
+            chunk(fp, b"tRNS", alpha[:alpha_bytes])
+
+    dpi = im.encoderinfo.get("dpi")
+    if dpi:
+        chunk(
+            fp,
+            b"pHYs",
+            o32(int(dpi[0] / 0.0254 + 0.5)),
+            o32(int(dpi[1] / 0.0254 + 0.5)),
+            b"\x01",
+        )
+
+    if info:
+        chunks = [b"bKGD", b"hIST"]
+        for info_chunk in info.chunks:
+            cid, data = info_chunk[:2]
+            if cid in chunks:
+                chunks.remove(cid)
+                chunk(fp, cid, data)
+
+    exif = im.encoderinfo.get("exif", im.info.get("exif"))
+    if exif:
+        if isinstance(exif, Image.Exif):
+            exif = exif.tobytes(8)
+        if exif.startswith(b"Exif\x00\x00"):
+            exif = exif[6:]
+        chunk(fp, b"eXIf", exif)
+
+    if save_all:
+        _write_multiple_frames(im, fp, chunk, rawmode)
+    else:
+        ImageFile._save(im, _idat(fp, chunk), [("zip", (0, 0) + im.size, 0, rawmode)])
+
+    if info:
+        for info_chunk in info.chunks:
+            cid, data = info_chunk[:2]
+            if cid[1:2].islower():
+                # Private chunk
+                after_idat = info_chunk[2:3]
+                if after_idat:
+                    chunk(fp, cid, data)
+
+    chunk(fp, b"IEND", b"")
+
+    if hasattr(fp, "flush"):
+        fp.flush()
+
+
+# --------------------------------------------------------------------
+# PNG chunk converter
+
+
+def getchunks(im, **params):
+    """Return a list of PNG chunks representing this image."""
+
+    class collector:
+        data = []
+
+        def write(self, data):
+            pass
+
+        def append(self, chunk):
+            self.data.append(chunk)
+
+    def append(fp, cid, *data):
+        data = b"".join(data)
+        crc = o32(_crc32(data, _crc32(cid)))
+        fp.append((cid, data, crc))
+
+    fp = collector()
+
+    try:
+        im.encoderinfo = params
+        _save(im, fp, None, append)
+    finally:
+        del im.encoderinfo
+
+    return fp.data
+
+
+# --------------------------------------------------------------------
+# Registry
+
+Image.register_open(PngImageFile.format, PngImageFile, _accept)
+Image.register_save(PngImageFile.format, _save)
+Image.register_save_all(PngImageFile.format, _save_all)
+
+Image.register_extensions(PngImageFile.format, [".png", ".apng"])
+
+Image.register_mime(PngImageFile.format, "image/png")
diff --git a/.venv/lib/python3.7/site-packages/PIL/PpmImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/PpmImagePlugin.py
new file mode 100644
index 0000000..abf4d65
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/PpmImagePlugin.py
@@ -0,0 +1,164 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# PPM support for PIL
+#
+# History:
+#       96-03-24 fl     Created
+#       98-03-06 fl     Write RGBA images (as RGB, that is)
+#
+# Copyright (c) Secret Labs AB 1997-98.
+# Copyright (c) Fredrik Lundh 1996.
+#
+# See the README file for information on usage and redistribution.
+#
+
+
+from . import Image, ImageFile
+
+#
+# --------------------------------------------------------------------
+
+b_whitespace = b"\x20\x09\x0a\x0b\x0c\x0d"
+
+MODES = {
+    # standard
+    b"P4": "1",
+    b"P5": "L",
+    b"P6": "RGB",
+    # extensions
+    b"P0CMYK": "CMYK",
+    # PIL extensions (for test purposes only)
+    b"PyP": "P",
+    b"PyRGBA": "RGBA",
+    b"PyCMYK": "CMYK",
+}
+
+
+def _accept(prefix):
+    return prefix[0:1] == b"P" and prefix[1] in b"0456y"
+
+
+##
+# Image plugin for PBM, PGM, and PPM images.
+
+
+class PpmImageFile(ImageFile.ImageFile):
+
+    format = "PPM"
+    format_description = "Pbmplus image"
+
+    def _token(self, s=b""):
+        while True:  # read until next whitespace
+            c = self.fp.read(1)
+            if not c or c in b_whitespace:
+                break
+            if c > b"\x79":
+                raise ValueError("Expected ASCII value, found binary")
+            s = s + c
+            if len(s) > 9:
+                raise ValueError("Expected int, got > 9 digits")
+        return s
+
+    def _open(self):
+
+        # check magic
+        s = self.fp.read(1)
+        if s != b"P":
+            raise SyntaxError("not a PPM file")
+        magic_number = self._token(s)
+        mode = MODES[magic_number]
+
+        self.custom_mimetype = {
+            b"P4": "image/x-portable-bitmap",
+            b"P5": "image/x-portable-graymap",
+            b"P6": "image/x-portable-pixmap",
+        }.get(magic_number)
+
+        if mode == "1":
+            self.mode = "1"
+            rawmode = "1;I"
+        else:
+            self.mode = rawmode = mode
+
+        for ix in range(3):
+            while True:
+                while True:
+                    s = self.fp.read(1)
+                    if s not in b_whitespace:
+                        break
+                    if s == b"":
+                        raise ValueError("File does not extend beyond magic number")
+                if s != b"#":
+                    break
+                s = self.fp.readline()
+            s = int(self._token(s))
+            if ix == 0:
+                xsize = s
+            elif ix == 1:
+                ysize = s
+                if mode == "1":
+                    break
+            elif ix == 2:
+                # maxgrey
+                if s > 255:
+                    if not mode == "L":
+                        raise ValueError(f"Too many colors for band: {s}")
+                    if s < 2 ** 16:
+                        self.mode = "I"
+                        rawmode = "I;16B"
+                    else:
+                        self.mode = "I"
+                        rawmode = "I;32B"
+
+        self._size = xsize, ysize
+        self.tile = [("raw", (0, 0, xsize, ysize), self.fp.tell(), (rawmode, 0, 1))]
+
+
+#
+# --------------------------------------------------------------------
+
+
+def _save(im, fp, filename):
+    if im.mode == "1":
+        rawmode, head = "1;I", b"P4"
+    elif im.mode == "L":
+        rawmode, head = "L", b"P5"
+    elif im.mode == "I":
+        if im.getextrema()[1] < 2 ** 16:
+            rawmode, head = "I;16B", b"P5"
+        else:
+            rawmode, head = "I;32B", b"P5"
+    elif im.mode == "RGB":
+        rawmode, head = "RGB", b"P6"
+    elif im.mode == "RGBA":
+        rawmode, head = "RGB", b"P6"
+    else:
+        raise OSError(f"cannot write mode {im.mode} as PPM")
+    fp.write(head + ("\n%d %d\n" % im.size).encode("ascii"))
+    if head == b"P6":
+        fp.write(b"255\n")
+    if head == b"P5":
+        if rawmode == "L":
+            fp.write(b"255\n")
+        elif rawmode == "I;16B":
+            fp.write(b"65535\n")
+        elif rawmode == "I;32B":
+            fp.write(b"2147483648\n")
+    ImageFile._save(im, fp, [("raw", (0, 0) + im.size, 0, (rawmode, 0, 1))])
+
+    # ALTERNATIVE: save via builtin debug function
+    # im._dump(filename)
+
+
+#
+# --------------------------------------------------------------------
+
+
+Image.register_open(PpmImageFile.format, PpmImageFile, _accept)
+Image.register_save(PpmImageFile.format, _save)
+
+Image.register_extensions(PpmImageFile.format, [".pbm", ".pgm", ".ppm", ".pnm"])
+
+Image.register_mime(PpmImageFile.format, "image/x-portable-anymap")
diff --git a/.venv/lib/python3.7/site-packages/PIL/PsdImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/PsdImagePlugin.py
new file mode 100644
index 0000000..04b21e3
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/PsdImagePlugin.py
@@ -0,0 +1,325 @@
+#
+# The Python Imaging Library
+# $Id$
+#
+# Adobe PSD 2.5/3.0 file handling
+#
+# History:
+# 1995-09-01 fl   Created
+# 1997-01-03 fl   Read most PSD images
+# 1997-01-18 fl   Fixed P and CMYK support
+# 2001-10-21 fl   Added seek/tell support (for layers)
+#
+# Copyright (c) 1997-2001 by Secret Labs AB.
+# Copyright (c) 1995-2001 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+import io
+
+from . import Image, ImageFile, ImagePalette
+from ._binary import i8
+from ._binary import i16be as i16
+from ._binary import i32be as i32
+from ._binary import si16be as si16
+
+MODES = {
+    # (photoshop mode, bits) -> (pil mode, required channels)
+    (0, 1): ("1", 1),
+    (0, 8): ("L", 1),
+    (1, 8): ("L", 1),
+    (2, 8): ("P", 1),
+    (3, 8): ("RGB", 3),
+    (4, 8): ("CMYK", 4),
+    (7, 8): ("L", 1),  # FIXME: multilayer
+    (8, 8): ("L", 1),  # duotone
+    (9, 8): ("LAB", 3),
+}
+
+
+# --------------------------------------------------------------------.
+# read PSD images
+
+
+def _accept(prefix):
+    return prefix[:4] == b"8BPS"
+
+
+##
+# Image plugin for Photoshop images.
+
+
+class PsdImageFile(ImageFile.ImageFile):
+
+    format = "PSD"
+    format_description = "Adobe Photoshop"
+    _close_exclusive_fp_after_loading = False
+
+    def _open(self):
+
+        read = self.fp.read
+
+        #
+        # header
+
+        s = read(26)
+        if not _accept(s) or i16(s, 4) != 1:
+            raise SyntaxError("not a PSD file")
+
+        psd_bits = i16(s, 22)
+        psd_channels = i16(s, 12)
+        psd_mode = i16(s, 24)
+
+        mode, channels = MODES[(psd_mode, psd_bits)]
+
+        if channels > psd_channels:
+            raise OSError("not enough channels")
+
+        self.mode = mode
+        self._size = i32(s, 18), i32(s, 14)
+
+        #
+        # color mode data
+
+        size = i32(read(4))
+        if size:
+            data = read(size)
+            if mode == "P" and size == 768:
+                self.palette = ImagePalette.raw("RGB;L", data)
+
+        #
+        # image resources
+
+        self.resources = []
+
+        size = i32(read(4))
+        if size:
+            # load resources
+            end = self.fp.tell() + size
+            while self.fp.tell() < end:
+                read(4)  # signature
+                id = i16(read(2))
+                name = read(i8(read(1)))
+                if not (len(name) & 1):
+                    read(1)  # padding
+                data = read(i32(read(4)))
+                if len(data) & 1:
+                    read(1)  # padding
+                self.resources.append((id, name, data))
+                if id == 1039:  # ICC profile
+                    self.info["icc_profile"] = data
+
+        #
+        # layer and mask information
+
+        self.layers = []
+
+        size = i32(read(4))
+        if size:
+            end = self.fp.tell() + size
+            size = i32(read(4))
+            if size:
+                _layer_data = io.BytesIO(ImageFile._safe_read(self.fp, size))
+                self.layers = _layerinfo(_layer_data, size)
+            self.fp.seek(end)
+        self.n_frames = len(self.layers)
+        self.is_animated = self.n_frames > 1
+
+        #
+        # image descriptor
+
+        self.tile = _maketile(self.fp, mode, (0, 0) + self.size, channels)
+
+        # keep the file open
+        self.__fp = self.fp
+        self.frame = 1
+        self._min_frame = 1
+
+    def seek(self, layer):
+        if not self._seek_check(layer):
+            return
+
+        # seek to given layer (1..max)
+        try:
+            name, mode, bbox, tile = self.layers[layer - 1]
+            self.mode = mode
+            self.tile = tile
+            self.frame = layer
+            self.fp = self.__fp
+            return name, bbox
+        except IndexError as e:
+            raise EOFError("no such layer") from e
+
+    def tell(self):
+        # return layer number (0=image, 1..max=layers)
+        return self.frame
+
+    def load_prepare(self):
+        # create image memory if necessary
+        if not self.im or self.im.mode != self.mode or self.im.size != self.size:
+            self.im = Image.core.fill(self.mode, self.size, 0)
+        # create palette (optional)
+        if self.mode == "P":
+            Image.Image.load(self)
+
+    def _close__fp(self):
+        try:
+            if self.__fp != self.fp:
+                self.__fp.close()
+        except AttributeError:
+            pass
+        finally:
+            self.__fp = None
+
+
+def _layerinfo(fp, ct_bytes):
+    # read layerinfo block
+    layers = []
+
+    def read(size):
+        return ImageFile._safe_read(fp, size)
+
+    ct = si16(read(2))
+
+    # sanity check
+    if ct_bytes < (abs(ct) * 20):
+        raise SyntaxError("Layer block too short for number of layers requested")
+
+    for i in range(abs(ct)):
+
+        # bounding box
+        y0 = i32(read(4))
+        x0 = i32(read(4))
+        y1 = i32(read(4))
+        x1 = i32(read(4))
+
+        # image info
+        info = []
+        mode = []
+        ct_types = i16(read(2))
+        types = list(range(ct_types))
+        if len(types) > 4:
+            continue
+
+        for i in types:
+            type = i16(read(2))
+
+            if type == 65535:
+                m = "A"
+            else:
+                m = "RGBA"[type]
+
+            mode.append(m)
+            size = i32(read(4))
+            info.append((m, size))
+
+        # figure out the image mode
+        mode.sort()
+        if mode == ["R"]:
+            mode = "L"
+        elif mode == ["B", "G", "R"]:
+            mode = "RGB"
+        elif mode == ["A", "B", "G", "R"]:
+            mode = "RGBA"
+        else:
+            mode = None  # unknown
+
+        # skip over blend flags and extra information
+        read(12)  # filler
+        name = ""
+        size = i32(read(4))  # length of the extra data field
+        combined = 0
+        if size:
+            data_end = fp.tell() + size
+
+            length = i32(read(4))
+            if length:
+                fp.seek(length - 16, io.SEEK_CUR)
+            combined += length + 4
+
+            length = i32(read(4))
+            if length:
+                fp.seek(length, io.SEEK_CUR)
+            combined += length + 4
+
+            length = i8(read(1))
+            if length:
+                # Don't know the proper encoding,
+                # Latin-1 should be a good guess
+                name = read(length).decode("latin-1", "replace")
+            combined += length + 1
+
+            fp.seek(data_end)
+        layers.append((name, mode, (x0, y0, x1, y1)))
+
+    # get tiles
+    i = 0
+    for name, mode, bbox in layers:
+        tile = []
+        for m in mode:
+            t = _maketile(fp, m, bbox, 1)
+            if t:
+                tile.extend(t)
+        layers[i] = name, mode, bbox, tile
+        i += 1
+
+    return layers
+
+
+def _maketile(file, mode, bbox, channels):
+
+    tile = None
+    read = file.read
+
+    compression = i16(read(2))
+
+    xsize = bbox[2] - bbox[0]
+    ysize = bbox[3] - bbox[1]
+
+    offset = file.tell()
+
+    if compression == 0:
+        #
+        # raw compression
+        tile = []
+        for channel in range(channels):
+            layer = mode[channel]
+            if mode == "CMYK":
+                layer += ";I"
+            tile.append(("raw", bbox, offset, layer))
+            offset = offset + xsize * ysize
+
+    elif compression == 1:
+        #
+        # packbits compression
+        i = 0
+        tile = []
+        bytecount = read(channels * ysize * 2)
+        offset = file.tell()
+        for channel in range(channels):
+            layer = mode[channel]
+            if mode == "CMYK":
+                layer += ";I"
+            tile.append(("packbits", bbox, offset, layer))
+            for y in range(ysize):
+                offset = offset + i16(bytecount, i)
+                i += 2
+
+    file.seek(offset)
+
+    if offset & 1:
+        read(1)  # padding
+
+    return tile
+
+
+# --------------------------------------------------------------------
+# registry
+
+
+Image.register_open(PsdImageFile.format, PsdImageFile, _accept)
+
+Image.register_extension(PsdImageFile.format, ".psd")
+
+Image.register_mime(PsdImageFile.format, "image/vnd.adobe.photoshop")
diff --git a/.venv/lib/python3.7/site-packages/PIL/PyAccess.py b/.venv/lib/python3.7/site-packages/PIL/PyAccess.py
new file mode 100644
index 0000000..eeaa0cc
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/PyAccess.py
@@ -0,0 +1,353 @@
+#
+# The Python Imaging Library
+# Pillow fork
+#
+# Python implementation of the PixelAccess Object
+#
+# Copyright (c) 1997-2009 by Secret Labs AB.  All rights reserved.
+# Copyright (c) 1995-2009 by Fredrik Lundh.
+# Copyright (c) 2013 Eric Soroos
+#
+# See the README file for information on usage and redistribution
+#
+
+# Notes:
+#
+#  * Implements the pixel access object following Access.
+#  * Does not implement the line functions, as they don't appear to be used
+#  * Taking only the tuple form, which is used from python.
+#    * Fill.c uses the integer form, but it's still going to use the old
+#      Access.c implementation.
+#
+
+import logging
+import sys
+
+try:
+    from cffi import FFI
+
+    defs = """
+    struct Pixel_RGBA {
+        unsigned char r,g,b,a;
+    };
+    struct Pixel_I16 {
+        unsigned char l,r;
+    };
+    """
+    ffi = FFI()
+    ffi.cdef(defs)
+except ImportError as ex:
+    # Allow error import for doc purposes, but error out when accessing
+    # anything in core.
+    from ._util import deferred_error
+
+    FFI = ffi = deferred_error(ex)
+
+logger = logging.getLogger(__name__)
+
+
+class PyAccess:
+    def __init__(self, img, readonly=False):
+        vals = dict(img.im.unsafe_ptrs)
+        self.readonly = readonly
+        self.image8 = ffi.cast("unsigned char **", vals["image8"])
+        self.image32 = ffi.cast("int **", vals["image32"])
+        self.image = ffi.cast("unsigned char **", vals["image"])
+        self.xsize, self.ysize = img.im.size
+        self._img = img
+
+        # Keep pointer to im object to prevent dereferencing.
+        self._im = img.im
+        if self._im.mode == "P":
+            self._palette = img.palette
+
+        # Debugging is polluting test traces, only useful here
+        # when hacking on PyAccess
+        # logger.debug("%s", vals)
+        self._post_init()
+
+    def _post_init(self):
+        pass
+
+    def __setitem__(self, xy, color):
+        """
+        Modifies the pixel at x,y. The color is given as a single
+        numerical value for single band images, and a tuple for
+        multi-band images
+
+        :param xy: The pixel coordinate, given as (x, y). See
+           :ref:`coordinate-system`.
+        :param color: The pixel value.
+        """
+        if self.readonly:
+            raise ValueError("Attempt to putpixel a read only image")
+        (x, y) = xy
+        if x < 0:
+            x = self.xsize + x
+        if y < 0:
+            y = self.ysize + y
+        (x, y) = self.check_xy((x, y))
+
+        if (
+            self._im.mode == "P"
+            and isinstance(color, (list, tuple))
+            and len(color) in [3, 4]
+        ):
+            # RGB or RGBA value for a P image
+            color = self._palette.getcolor(color, self._img)
+
+        return self.set_pixel(x, y, color)
+
+    def __getitem__(self, xy):
+        """
+        Returns the pixel at x,y. The pixel is returned as a single
+        value for single band images or a tuple for multiple band
+        images
+
+        :param xy: The pixel coordinate, given as (x, y). See
+          :ref:`coordinate-system`.
+        :returns: a pixel value for single band images, a tuple of
+          pixel values for multiband images.
+        """
+        (x, y) = xy
+        if x < 0:
+            x = self.xsize + x
+        if y < 0:
+            y = self.ysize + y
+        (x, y) = self.check_xy((x, y))
+        return self.get_pixel(x, y)
+
+    putpixel = __setitem__
+    getpixel = __getitem__
+
+    def check_xy(self, xy):
+        (x, y) = xy
+        if not (0 <= x < self.xsize and 0 <= y < self.ysize):
+            raise ValueError("pixel location out of range")
+        return xy
+
+
+class _PyAccess32_2(PyAccess):
+    """PA, LA, stored in first and last bytes of a 32 bit word"""
+
+    def _post_init(self, *args, **kwargs):
+        self.pixels = ffi.cast("struct Pixel_RGBA **", self.image32)
+
+    def get_pixel(self, x, y):
+        pixel = self.pixels[y][x]
+        return (pixel.r, pixel.a)
+
+    def set_pixel(self, x, y, color):
+        pixel = self.pixels[y][x]
+        # tuple
+        pixel.r = min(color[0], 255)
+        pixel.a = min(color[1], 255)
+
+
+class _PyAccess32_3(PyAccess):
+    """RGB and friends, stored in the first three bytes of a 32 bit word"""
+
+    def _post_init(self, *args, **kwargs):
+        self.pixels = ffi.cast("struct Pixel_RGBA **", self.image32)
+
+    def get_pixel(self, x, y):
+        pixel = self.pixels[y][x]
+        return (pixel.r, pixel.g, pixel.b)
+
+    def set_pixel(self, x, y, color):
+        pixel = self.pixels[y][x]
+        # tuple
+        pixel.r = min(color[0], 255)
+        pixel.g = min(color[1], 255)
+        pixel.b = min(color[2], 255)
+        pixel.a = 255
+
+
+class _PyAccess32_4(PyAccess):
+    """RGBA etc, all 4 bytes of a 32 bit word"""
+
+    def _post_init(self, *args, **kwargs):
+        self.pixels = ffi.cast("struct Pixel_RGBA **", self.image32)
+
+    def get_pixel(self, x, y):
+        pixel = self.pixels[y][x]
+        return (pixel.r, pixel.g, pixel.b, pixel.a)
+
+    def set_pixel(self, x, y, color):
+        pixel = self.pixels[y][x]
+        # tuple
+        pixel.r = min(color[0], 255)
+        pixel.g = min(color[1], 255)
+        pixel.b = min(color[2], 255)
+        pixel.a = min(color[3], 255)
+
+
+class _PyAccess8(PyAccess):
+    """1, L, P, 8 bit images stored as uint8"""
+
+    def _post_init(self, *args, **kwargs):
+        self.pixels = self.image8
+
+    def get_pixel(self, x, y):
+        return self.pixels[y][x]
+
+    def set_pixel(self, x, y, color):
+        try:
+            # integer
+            self.pixels[y][x] = min(color, 255)
+        except TypeError:
+            # tuple
+            self.pixels[y][x] = min(color[0], 255)
+
+
+class _PyAccessI16_N(PyAccess):
+    """I;16 access, native bitendian without conversion"""
+
+    def _post_init(self, *args, **kwargs):
+        self.pixels = ffi.cast("unsigned short **", self.image)
+
+    def get_pixel(self, x, y):
+        return self.pixels[y][x]
+
+    def set_pixel(self, x, y, color):
+        try:
+            # integer
+            self.pixels[y][x] = min(color, 65535)
+        except TypeError:
+            # tuple
+            self.pixels[y][x] = min(color[0], 65535)
+
+
+class _PyAccessI16_L(PyAccess):
+    """I;16L access, with conversion"""
+
+    def _post_init(self, *args, **kwargs):
+        self.pixels = ffi.cast("struct Pixel_I16 **", self.image)
+
+    def get_pixel(self, x, y):
+        pixel = self.pixels[y][x]
+        return pixel.l + pixel.r * 256
+
+    def set_pixel(self, x, y, color):
+        pixel = self.pixels[y][x]
+        try:
+            color = min(color, 65535)
+        except TypeError:
+            color = min(color[0], 65535)
+
+        pixel.l = color & 0xFF  # noqa: E741
+        pixel.r = color >> 8
+
+
+class _PyAccessI16_B(PyAccess):
+    """I;16B access, with conversion"""
+
+    def _post_init(self, *args, **kwargs):
+        self.pixels = ffi.cast("struct Pixel_I16 **", self.image)
+
+    def get_pixel(self, x, y):
+        pixel = self.pixels[y][x]
+        return pixel.l * 256 + pixel.r
+
+    def set_pixel(self, x, y, color):
+        pixel = self.pixels[y][x]
+        try:
+            color = min(color, 65535)
+        except Exception:
+            color = min(color[0], 65535)
+
+        pixel.l = color >> 8  # noqa: E741
+        pixel.r = color & 0xFF
+
+
+class _PyAccessI32_N(PyAccess):
+    """Signed Int32 access, native endian"""
+
+    def _post_init(self, *args, **kwargs):
+        self.pixels = self.image32
+
+    def get_pixel(self, x, y):
+        return self.pixels[y][x]
+
+    def set_pixel(self, x, y, color):
+        self.pixels[y][x] = color
+
+
+class _PyAccessI32_Swap(PyAccess):
+    """I;32L/B access, with byteswapping conversion"""
+
+    def _post_init(self, *args, **kwargs):
+        self.pixels = self.image32
+
+    def reverse(self, i):
+        orig = ffi.new("int *", i)
+        chars = ffi.cast("unsigned char *", orig)
+        chars[0], chars[1], chars[2], chars[3] = chars[3], chars[2], chars[1], chars[0]
+        return ffi.cast("int *", chars)[0]
+
+    def get_pixel(self, x, y):
+        return self.reverse(self.pixels[y][x])
+
+    def set_pixel(self, x, y, color):
+        self.pixels[y][x] = self.reverse(color)
+
+
+class _PyAccessF(PyAccess):
+    """32 bit float access"""
+
+    def _post_init(self, *args, **kwargs):
+        self.pixels = ffi.cast("float **", self.image32)
+
+    def get_pixel(self, x, y):
+        return self.pixels[y][x]
+
+    def set_pixel(self, x, y, color):
+        try:
+            # not a tuple
+            self.pixels[y][x] = color
+        except TypeError:
+            # tuple
+            self.pixels[y][x] = color[0]
+
+
+mode_map = {
+    "1": _PyAccess8,
+    "L": _PyAccess8,
+    "P": _PyAccess8,
+    "LA": _PyAccess32_2,
+    "La": _PyAccess32_2,
+    "PA": _PyAccess32_2,
+    "RGB": _PyAccess32_3,
+    "LAB": _PyAccess32_3,
+    "HSV": _PyAccess32_3,
+    "YCbCr": _PyAccess32_3,
+    "RGBA": _PyAccess32_4,
+    "RGBa": _PyAccess32_4,
+    "RGBX": _PyAccess32_4,
+    "CMYK": _PyAccess32_4,
+    "F": _PyAccessF,
+    "I": _PyAccessI32_N,
+}
+
+if sys.byteorder == "little":
+    mode_map["I;16"] = _PyAccessI16_N
+    mode_map["I;16L"] = _PyAccessI16_N
+    mode_map["I;16B"] = _PyAccessI16_B
+
+    mode_map["I;32L"] = _PyAccessI32_N
+    mode_map["I;32B"] = _PyAccessI32_Swap
+else:
+    mode_map["I;16"] = _PyAccessI16_L
+    mode_map["I;16L"] = _PyAccessI16_L
+    mode_map["I;16B"] = _PyAccessI16_N
+
+    mode_map["I;32L"] = _PyAccessI32_Swap
+    mode_map["I;32B"] = _PyAccessI32_N
+
+
+def new(img, readonly=False):
+    access_type = mode_map.get(img.mode, None)
+    if not access_type:
+        logger.debug("PyAccess Not Implemented: %s", img.mode)
+        return None
+    return access_type(img, readonly)
diff --git a/.venv/lib/python3.7/site-packages/PIL/SgiImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/SgiImagePlugin.py
new file mode 100644
index 0000000..5f1ef6e
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/SgiImagePlugin.py
@@ -0,0 +1,230 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# SGI image file handling
+#
+# See "The SGI Image File Format (Draft version 0.97)", Paul Haeberli.
+# <ftp://ftp.sgi.com/graphics/SGIIMAGESPEC>
+#
+#
+# History:
+# 2017-22-07 mb   Add RLE decompression
+# 2016-16-10 mb   Add save method without compression
+# 1995-09-10 fl   Created
+#
+# Copyright (c) 2016 by Mickael Bonfill.
+# Copyright (c) 2008 by Karsten Hiddemann.
+# Copyright (c) 1997 by Secret Labs AB.
+# Copyright (c) 1995 by Fredrik Lundh.
+#
+# See the README file for information on usage and redistribution.
+#
+
+
+import os
+import struct
+
+from . import Image, ImageFile
+from ._binary import i16be as i16
+from ._binary import o8
+
+
+def _accept(prefix):
+    return len(prefix) >= 2 and i16(prefix) == 474
+
+
+MODES = {
+    (1, 1, 1): "L",
+    (1, 2, 1): "L",
+    (2, 1, 1): "L;16B",
+    (2, 2, 1): "L;16B",
+    (1, 3, 3): "RGB",
+    (2, 3, 3): "RGB;16B",
+    (1, 3, 4): "RGBA",
+    (2, 3, 4): "RGBA;16B",
+}
+
+
+##
+# Image plugin for SGI images.
+class SgiImageFile(ImageFile.ImageFile):
+
+    format = "SGI"
+    format_description = "SGI Image File Format"
+
+    def _open(self):
+
+        # HEAD
+        headlen = 512
+        s = self.fp.read(headlen)
+
+        if not _accept(s):
+            raise ValueError("Not an SGI image file")
+
+        # compression : verbatim or RLE
+        compression = s[2]
+
+        # bpc : 1 or 2 bytes (8bits or 16bits)
+        bpc = s[3]
+
+        # dimension : 1, 2 or 3 (depending on xsize, ysize and zsize)
+        dimension = i16(s, 4)
+
+        # xsize : width
+        xsize = i16(s, 6)
+
+        # ysize : height
+        ysize = i16(s, 8)
+
+        # zsize : channels count
+        zsize = i16(s, 10)
+
+        # layout
+        layout = bpc, dimension, zsize
+
+        # determine mode from bits/zsize
+        rawmode = ""
+        try:
+            rawmode = MODES[layout]
+        except KeyError:
+            pass
+
+        if rawmode == "":
+            raise ValueError("Unsupported SGI image mode")
+
+        self._size = xsize, ysize
+        self.mode = rawmode.split(";")[0]
+        if self.mode == "RGB":
+            self.custom_mimetype = "image/rgb"
+
+        # orientation -1 : scanlines begins at the bottom-left corner
+        orientation = -1
+
+        # decoder info
+        if compression == 0:
+            pagesize = xsize * ysize * bpc
+            if bpc == 2:
+                self.tile = [
+                    ("SGI16", (0, 0) + self.size, headlen, (self.mode, 0, orientation))
+                ]
+            else:
+                self.tile = []
+                offset = headlen
+                for layer in self.mode:
+                    self.tile.append(
+                        ("raw", (0, 0) + self.size, offset, (layer, 0, orientation))
+                    )
+                    offset += pagesize
+        elif compression == 1:
+            self.tile = [
+                ("sgi_rle", (0, 0) + self.size, headlen, (rawmode, orientation, bpc))
+            ]
+
+
+def _save(im, fp, filename):
+    if im.mode != "RGB" and im.mode != "RGBA" and im.mode != "L":
+        raise ValueError("Unsupported SGI image mode")
+
+    # Get the keyword arguments
+    info = im.encoderinfo
+
+    # Byte-per-pixel precision, 1 = 8bits per pixel
+    bpc = info.get("bpc", 1)
+
+    if bpc not in (1, 2):
+        raise ValueError("Unsupported number of bytes per pixel")
+
+    # Flip the image, since the origin of SGI file is the bottom-left corner
+    orientation = -1
+    # Define the file as SGI File Format
+    magicNumber = 474
+    # Run-Length Encoding Compression - Unsupported at this time
+    rle = 0
+
+    # Number of dimensions (x,y,z)
+    dim = 3
+    # X Dimension = width / Y Dimension = height
+    x, y = im.size
+    if im.mode == "L" and y == 1:
+        dim = 1
+    elif im.mode == "L":
+        dim = 2
+    # Z Dimension: Number of channels
+    z = len(im.mode)
+
+    if dim == 1 or dim == 2:
+        z = 1
+
+    # assert we've got the right number of bands.
+    if len(im.getbands()) != z:
+        raise ValueError(
+            f"incorrect number of bands in SGI write: {z} vs {len(im.getbands())}"
+        )
+
+    # Minimum Byte value
+    pinmin = 0
+    # Maximum Byte value (255 = 8bits per pixel)
+    pinmax = 255
+    # Image name (79 characters max, truncated below in write)
+    imgName = os.path.splitext(os.path.basename(filename))[0]
+    imgName = imgName.encode("ascii", "ignore")
+    # Standard representation of pixel in the file
+    colormap = 0
+    fp.write(struct.pack(">h", magicNumber))
+    fp.write(o8(rle))
+    fp.write(o8(bpc))
+    fp.write(struct.pack(">H", dim))
+    fp.write(struct.pack(">H", x))
+    fp.write(struct.pack(">H", y))
+    fp.write(struct.pack(">H", z))
+    fp.write(struct.pack(">l", pinmin))
+    fp.write(struct.pack(">l", pinmax))
+    fp.write(struct.pack("4s", b""))  # dummy
+    fp.write(struct.pack("79s", imgName))  # truncates to 79 chars
+    fp.write(struct.pack("s", b""))  # force null byte after imgname
+    fp.write(struct.pack(">l", colormap))
+    fp.write(struct.pack("404s", b""))  # dummy
+
+    rawmode = "L"
+    if bpc == 2:
+        rawmode = "L;16B"
+
+    for channel in im.split():
+        fp.write(channel.tobytes("raw", rawmode, 0, orientation))
+
+    if hasattr(fp, "flush"):
+        fp.flush()
+
+
+class SGI16Decoder(ImageFile.PyDecoder):
+    _pulls_fd = True
+
+    def decode(self, buffer):
+        rawmode, stride, orientation = self.args
+        pagesize = self.state.xsize * self.state.ysize
+        zsize = len(self.mode)
+        self.fd.seek(512)
+
+        for band in range(zsize):
+            channel = Image.new("L", (self.state.xsize, self.state.ysize))
+            channel.frombytes(
+                self.fd.read(2 * pagesize), "raw", "L;16B", stride, orientation
+            )
+            self.im.putband(channel.im, band)
+
+        return -1, 0
+
+
+#
+# registry
+
+
+Image.register_decoder("SGI16", SGI16Decoder)
+Image.register_open(SgiImageFile.format, SgiImageFile, _accept)
+Image.register_save(SgiImageFile.format, _save)
+Image.register_mime(SgiImageFile.format, "image/sgi")
+
+Image.register_extensions(SgiImageFile.format, [".bw", ".rgb", ".rgba", ".sgi"])
+
+# End of file
diff --git a/.venv/lib/python3.7/site-packages/PIL/SpiderImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/SpiderImagePlugin.py
new file mode 100644
index 0000000..062af9f
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/SpiderImagePlugin.py
@@ -0,0 +1,324 @@
+#
+# The Python Imaging Library.
+#
+# SPIDER image file handling
+#
+# History:
+# 2004-08-02    Created BB
+# 2006-03-02    added save method
+# 2006-03-13    added support for stack images
+#
+# Copyright (c) 2004 by Health Research Inc. (HRI) RENSSELAER, NY 12144.
+# Copyright (c) 2004 by William Baxter.
+# Copyright (c) 2004 by Secret Labs AB.
+# Copyright (c) 2004 by Fredrik Lundh.
+#
+
+##
+# Image plugin for the Spider image format.  This format is is used
+# by the SPIDER software, in processing image data from electron
+# microscopy and tomography.
+##
+
+#
+# SpiderImagePlugin.py
+#
+# The Spider image format is used by SPIDER software, in processing
+# image data from electron microscopy and tomography.
+#
+# Spider home page:
+# https://spider.wadsworth.org/spider_doc/spider/docs/spider.html
+#
+# Details about the Spider image format:
+# https://spider.wadsworth.org/spider_doc/spider/docs/image_doc.html
+#
+import os
+import struct
+import sys
+
+from PIL import Image, ImageFile
+
+
+def isInt(f):
+    try:
+        i = int(f)
+        if f - i == 0:
+            return 1
+        else:
+            return 0
+    except (ValueError, OverflowError):
+        return 0
+
+
+iforms = [1, 3, -11, -12, -21, -22]
+
+
+# There is no magic number to identify Spider files, so just check a
+# series of header locations to see if they have reasonable values.
+# Returns no. of bytes in the header, if it is a valid Spider header,
+# otherwise returns 0
+
+
+def isSpiderHeader(t):
+    h = (99,) + t  # add 1 value so can use spider header index start=1
+    # header values 1,2,5,12,13,22,23 should be integers
+    for i in [1, 2, 5, 12, 13, 22, 23]:
+        if not isInt(h[i]):
+            return 0
+    # check iform
+    iform = int(h[5])
+    if iform not in iforms:
+        return 0
+    # check other header values
+    labrec = int(h[13])  # no. records in file header
+    labbyt = int(h[22])  # total no. of bytes in header
+    lenbyt = int(h[23])  # record length in bytes
+    if labbyt != (labrec * lenbyt):
+        return 0
+    # looks like a valid header
+    return labbyt
+
+
+def isSpiderImage(filename):
+    with open(filename, "rb") as fp:
+        f = fp.read(92)  # read 23 * 4 bytes
+    t = struct.unpack(">23f", f)  # try big-endian first
+    hdrlen = isSpiderHeader(t)
+    if hdrlen == 0:
+        t = struct.unpack("<23f", f)  # little-endian
+        hdrlen = isSpiderHeader(t)
+    return hdrlen
+
+
+class SpiderImageFile(ImageFile.ImageFile):
+
+    format = "SPIDER"
+    format_description = "Spider 2D image"
+    _close_exclusive_fp_after_loading = False
+
+    def _open(self):
+        # check header
+        n = 27 * 4  # read 27 float values
+        f = self.fp.read(n)
+
+        try:
+            self.bigendian = 1
+            t = struct.unpack(">27f", f)  # try big-endian first
+            hdrlen = isSpiderHeader(t)
+            if hdrlen == 0:
+                self.bigendian = 0
+                t = struct.unpack("<27f", f)  # little-endian
+                hdrlen = isSpiderHeader(t)
+            if hdrlen == 0:
+                raise SyntaxError("not a valid Spider file")
+        except struct.error as e:
+            raise SyntaxError("not a valid Spider file") from e
+
+        h = (99,) + t  # add 1 value : spider header index starts at 1
+        iform = int(h[5])
+        if iform != 1:
+            raise SyntaxError("not a Spider 2D image")
+
+        self._size = int(h[12]), int(h[2])  # size in pixels (width, height)
+        self.istack = int(h[24])
+        self.imgnumber = int(h[27])
+
+        if self.istack == 0 and self.imgnumber == 0:
+            # stk=0, img=0: a regular 2D image
+            offset = hdrlen
+            self._nimages = 1
+        elif self.istack > 0 and self.imgnumber == 0:
+            # stk>0, img=0: Opening the stack for the first time
+            self.imgbytes = int(h[12]) * int(h[2]) * 4
+            self.hdrlen = hdrlen
+            self._nimages = int(h[26])
+            # Point to the first image in the stack
+            offset = hdrlen * 2
+            self.imgnumber = 1
+        elif self.istack == 0 and self.imgnumber > 0:
+            # stk=0, img>0: an image within the stack
+            offset = hdrlen + self.stkoffset
+            self.istack = 2  # So Image knows it's still a stack
+        else:
+            raise SyntaxError("inconsistent stack header values")
+
+        if self.bigendian:
+            self.rawmode = "F;32BF"
+        else:
+            self.rawmode = "F;32F"
+        self.mode = "F"
+
+        self.tile = [("raw", (0, 0) + self.size, offset, (self.rawmode, 0, 1))]
+        self.__fp = self.fp  # FIXME: hack
+
+    @property
+    def n_frames(self):
+        return self._nimages
+
+    @property
+    def is_animated(self):
+        return self._nimages > 1
+
+    # 1st image index is zero (although SPIDER imgnumber starts at 1)
+    def tell(self):
+        if self.imgnumber < 1:
+            return 0
+        else:
+            return self.imgnumber - 1
+
+    def seek(self, frame):
+        if self.istack == 0:
+            raise EOFError("attempt to seek in a non-stack file")
+        if not self._seek_check(frame):
+            return
+        self.stkoffset = self.hdrlen + frame * (self.hdrlen + self.imgbytes)
+        self.fp = self.__fp
+        self.fp.seek(self.stkoffset)
+        self._open()
+
+    # returns a byte image after rescaling to 0..255
+    def convert2byte(self, depth=255):
+        (minimum, maximum) = self.getextrema()
+        m = 1
+        if maximum != minimum:
+            m = depth / (maximum - minimum)
+        b = -m * minimum
+        return self.point(lambda i, m=m, b=b: i * m + b).convert("L")
+
+    # returns a ImageTk.PhotoImage object, after rescaling to 0..255
+    def tkPhotoImage(self):
+        from PIL import ImageTk
+
+        return ImageTk.PhotoImage(self.convert2byte(), palette=256)
+
+    def _close__fp(self):
+        try:
+            if self.__fp != self.fp:
+                self.__fp.close()
+        except AttributeError:
+            pass
+        finally:
+            self.__fp = None
+
+
+# --------------------------------------------------------------------
+# Image series
+
+# given a list of filenames, return a list of images
+def loadImageSeries(filelist=None):
+    """create a list of :py:class:`~PIL.Image.Image` objects for use in a montage"""
+    if filelist is None or len(filelist) < 1:
+        return
+
+    imglist = []
+    for img in filelist:
+        if not os.path.exists(img):
+            print(f"unable to find {img}")
+            continue
+        try:
+            with Image.open(img) as im:
+                im = im.convert2byte()
+        except Exception:
+            if not isSpiderImage(img):
+                print(img + " is not a Spider image file")
+            continue
+        im.info["filename"] = img
+        imglist.append(im)
+    return imglist
+
+
+# --------------------------------------------------------------------
+# For saving images in Spider format
+
+
+def makeSpiderHeader(im):
+    nsam, nrow = im.size
+    lenbyt = nsam * 4  # There are labrec records in the header
+    labrec = int(1024 / lenbyt)
+    if 1024 % lenbyt != 0:
+        labrec += 1
+    labbyt = labrec * lenbyt
+    hdr = []
+    nvalues = int(labbyt / 4)
+    for i in range(nvalues):
+        hdr.append(0.0)
+
+    if len(hdr) < 23:
+        return []
+
+    # NB these are Fortran indices
+    hdr[1] = 1.0  # nslice (=1 for an image)
+    hdr[2] = float(nrow)  # number of rows per slice
+    hdr[5] = 1.0  # iform for 2D image
+    hdr[12] = float(nsam)  # number of pixels per line
+    hdr[13] = float(labrec)  # number of records in file header
+    hdr[22] = float(labbyt)  # total number of bytes in header
+    hdr[23] = float(lenbyt)  # record length in bytes
+
+    # adjust for Fortran indexing
+    hdr = hdr[1:]
+    hdr.append(0.0)
+    # pack binary data into a string
+    hdrstr = []
+    for v in hdr:
+        hdrstr.append(struct.pack("f", v))
+    return hdrstr
+
+
+def _save(im, fp, filename):
+    if im.mode[0] != "F":
+        im = im.convert("F")
+
+    hdr = makeSpiderHeader(im)
+    if len(hdr) < 256:
+        raise OSError("Error creating Spider header")
+
+    # write the SPIDER header
+    fp.writelines(hdr)
+
+    rawmode = "F;32NF"  # 32-bit native floating point
+    ImageFile._save(im, fp, [("raw", (0, 0) + im.size, 0, (rawmode, 0, 1))])
+
+
+def _save_spider(im, fp, filename):
+    # get the filename extension and register it with Image
+    ext = os.path.splitext(filename)[1]
+    Image.register_extension(SpiderImageFile.format, ext)
+    _save(im, fp, filename)
+
+
+# --------------------------------------------------------------------
+
+
+Image.register_open(SpiderImageFile.format, SpiderImageFile)
+Image.register_save(SpiderImageFile.format, _save_spider)
+
+if __name__ == "__main__":
+
+    if len(sys.argv) < 2:
+        print("Syntax: python3 SpiderImagePlugin.py [infile] [outfile]")
+        sys.exit()
+
+    filename = sys.argv[1]
+    if not isSpiderImage(filename):
+        print("input image must be in Spider format")
+        sys.exit()
+
+    with Image.open(filename) as im:
+        print("image: " + str(im))
+        print("format: " + str(im.format))
+        print("size: " + str(im.size))
+        print("mode: " + str(im.mode))
+        print("max, min: ", end=" ")
+        print(im.getextrema())
+
+        if len(sys.argv) > 2:
+            outfile = sys.argv[2]
+
+            # perform some image operation
+            im = im.transpose(Image.FLIP_LEFT_RIGHT)
+            print(
+                f"saving a flipped version of {os.path.basename(filename)} "
+                f"as {outfile} "
+            )
+            im.save(outfile, SpiderImageFile.format)
diff --git a/.venv/lib/python3.7/site-packages/PIL/SunImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/SunImagePlugin.py
new file mode 100644
index 0000000..c03759a
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/SunImagePlugin.py
@@ -0,0 +1,136 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# Sun image file handling
+#
+# History:
+# 1995-09-10 fl   Created
+# 1996-05-28 fl   Fixed 32-bit alignment
+# 1998-12-29 fl   Import ImagePalette module
+# 2001-12-18 fl   Fixed palette loading (from Jean-Claude Rimbault)
+#
+# Copyright (c) 1997-2001 by Secret Labs AB
+# Copyright (c) 1995-1996 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+
+from . import Image, ImageFile, ImagePalette
+from ._binary import i32be as i32
+
+
+def _accept(prefix):
+    return len(prefix) >= 4 and i32(prefix) == 0x59A66A95
+
+
+##
+# Image plugin for Sun raster files.
+
+
+class SunImageFile(ImageFile.ImageFile):
+
+    format = "SUN"
+    format_description = "Sun Raster File"
+
+    def _open(self):
+
+        # The Sun Raster file header is 32 bytes in length
+        # and has the following format:
+
+        #     typedef struct _SunRaster
+        #     {
+        #         DWORD MagicNumber;      /* Magic (identification) number */
+        #         DWORD Width;            /* Width of image in pixels */
+        #         DWORD Height;           /* Height of image in pixels */
+        #         DWORD Depth;            /* Number of bits per pixel */
+        #         DWORD Length;           /* Size of image data in bytes */
+        #         DWORD Type;             /* Type of raster file */
+        #         DWORD ColorMapType;     /* Type of color map */
+        #         DWORD ColorMapLength;   /* Size of the color map in bytes */
+        #     } SUNRASTER;
+
+        # HEAD
+        s = self.fp.read(32)
+        if not _accept(s):
+            raise SyntaxError("not an SUN raster file")
+
+        offset = 32
+
+        self._size = i32(s, 4), i32(s, 8)
+
+        depth = i32(s, 12)
+        # data_length = i32(s, 16)   # unreliable, ignore.
+        file_type = i32(s, 20)
+        palette_type = i32(s, 24)  # 0: None, 1: RGB, 2: Raw/arbitrary
+        palette_length = i32(s, 28)
+
+        if depth == 1:
+            self.mode, rawmode = "1", "1;I"
+        elif depth == 4:
+            self.mode, rawmode = "L", "L;4"
+        elif depth == 8:
+            self.mode = rawmode = "L"
+        elif depth == 24:
+            if file_type == 3:
+                self.mode, rawmode = "RGB", "RGB"
+            else:
+                self.mode, rawmode = "RGB", "BGR"
+        elif depth == 32:
+            if file_type == 3:
+                self.mode, rawmode = "RGB", "RGBX"
+            else:
+                self.mode, rawmode = "RGB", "BGRX"
+        else:
+            raise SyntaxError("Unsupported Mode/Bit Depth")
+
+        if palette_length:
+            if palette_length > 1024:
+                raise SyntaxError("Unsupported Color Palette Length")
+
+            if palette_type != 1:
+                raise SyntaxError("Unsupported Palette Type")
+
+            offset = offset + palette_length
+            self.palette = ImagePalette.raw("RGB;L", self.fp.read(palette_length))
+            if self.mode == "L":
+                self.mode = "P"
+                rawmode = rawmode.replace("L", "P")
+
+        # 16 bit boundaries on stride
+        stride = ((self.size[0] * depth + 15) // 16) * 2
+
+        # file type: Type is the version (or flavor) of the bitmap
+        # file. The following values are typically found in the Type
+        # field:
+        # 0000h Old
+        # 0001h Standard
+        # 0002h Byte-encoded
+        # 0003h RGB format
+        # 0004h TIFF format
+        # 0005h IFF format
+        # FFFFh Experimental
+
+        # Old and standard are the same, except for the length tag.
+        # byte-encoded is run-length-encoded
+        # RGB looks similar to standard, but RGB byte order
+        # TIFF and IFF mean that they were converted from T/IFF
+        # Experimental means that it's something else.
+        # (https://www.fileformat.info/format/sunraster/egff.htm)
+
+        if file_type in (0, 1, 3, 4, 5):
+            self.tile = [("raw", (0, 0) + self.size, offset, (rawmode, stride))]
+        elif file_type == 2:
+            self.tile = [("sun_rle", (0, 0) + self.size, offset, rawmode)]
+        else:
+            raise SyntaxError("Unsupported Sun Raster file type")
+
+
+#
+# registry
+
+
+Image.register_open(SunImageFile.format, SunImageFile, _accept)
+
+Image.register_extension(SunImageFile.format, ".ras")
diff --git a/.venv/lib/python3.7/site-packages/PIL/TarIO.py b/.venv/lib/python3.7/site-packages/PIL/TarIO.py
new file mode 100644
index 0000000..d108362
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/TarIO.py
@@ -0,0 +1,65 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# read files from within a tar file
+#
+# History:
+# 95-06-18 fl   Created
+# 96-05-28 fl   Open files in binary mode
+#
+# Copyright (c) Secret Labs AB 1997.
+# Copyright (c) Fredrik Lundh 1995-96.
+#
+# See the README file for information on usage and redistribution.
+#
+
+import io
+
+from . import ContainerIO
+
+
+class TarIO(ContainerIO.ContainerIO):
+    """A file object that provides read access to a given member of a TAR file."""
+
+    def __init__(self, tarfile, file):
+        """
+        Create file object.
+
+        :param tarfile: Name of TAR file.
+        :param file: Name of member file.
+        """
+        self.fh = open(tarfile, "rb")
+
+        while True:
+
+            s = self.fh.read(512)
+            if len(s) != 512:
+                raise OSError("unexpected end of tar file")
+
+            name = s[:100].decode("utf-8")
+            i = name.find("\0")
+            if i == 0:
+                raise OSError("cannot find subfile")
+            if i > 0:
+                name = name[:i]
+
+            size = int(s[124:135], 8)
+
+            if file == name:
+                break
+
+            self.fh.seek((size + 511) & (~511), io.SEEK_CUR)
+
+        # Open region
+        super().__init__(self.fh, self.fh.tell(), size)
+
+    # Context manager support
+    def __enter__(self):
+        return self
+
+    def __exit__(self, *args):
+        self.close()
+
+    def close(self):
+        self.fh.close()
diff --git a/.venv/lib/python3.7/site-packages/PIL/TgaImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/TgaImagePlugin.py
new file mode 100644
index 0000000..ed63da9
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/TgaImagePlugin.py
@@ -0,0 +1,253 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# TGA file handling
+#
+# History:
+# 95-09-01 fl   created (reads 24-bit files only)
+# 97-01-04 fl   support more TGA versions, including compressed images
+# 98-07-04 fl   fixed orientation and alpha layer bugs
+# 98-09-11 fl   fixed orientation for runlength decoder
+#
+# Copyright (c) Secret Labs AB 1997-98.
+# Copyright (c) Fredrik Lundh 1995-97.
+#
+# See the README file for information on usage and redistribution.
+#
+
+
+import warnings
+
+from . import Image, ImageFile, ImagePalette
+from ._binary import i16le as i16
+from ._binary import o8
+from ._binary import o16le as o16
+
+#
+# --------------------------------------------------------------------
+# Read RGA file
+
+
+MODES = {
+    # map imagetype/depth to rawmode
+    (1, 8): "P",
+    (3, 1): "1",
+    (3, 8): "L",
+    (3, 16): "LA",
+    (2, 16): "BGR;5",
+    (2, 24): "BGR",
+    (2, 32): "BGRA",
+}
+
+
+##
+# Image plugin for Targa files.
+
+
+class TgaImageFile(ImageFile.ImageFile):
+
+    format = "TGA"
+    format_description = "Targa"
+
+    def _open(self):
+
+        # process header
+        s = self.fp.read(18)
+
+        id_len = s[0]
+
+        colormaptype = s[1]
+        imagetype = s[2]
+
+        depth = s[16]
+
+        flags = s[17]
+
+        self._size = i16(s, 12), i16(s, 14)
+
+        # validate header fields
+        if (
+            colormaptype not in (0, 1)
+            or self.size[0] <= 0
+            or self.size[1] <= 0
+            or depth not in (1, 8, 16, 24, 32)
+        ):
+            raise SyntaxError("not a TGA file")
+
+        # image mode
+        if imagetype in (3, 11):
+            self.mode = "L"
+            if depth == 1:
+                self.mode = "1"  # ???
+            elif depth == 16:
+                self.mode = "LA"
+        elif imagetype in (1, 9):
+            self.mode = "P"
+        elif imagetype in (2, 10):
+            self.mode = "RGB"
+            if depth == 32:
+                self.mode = "RGBA"
+        else:
+            raise SyntaxError("unknown TGA mode")
+
+        # orientation
+        orientation = flags & 0x30
+        self._flip_horizontally = orientation in [0x10, 0x30]
+        if orientation in [0x20, 0x30]:
+            orientation = 1
+        elif orientation in [0, 0x10]:
+            orientation = -1
+        else:
+            raise SyntaxError("unknown TGA orientation")
+
+        self.info["orientation"] = orientation
+
+        if imagetype & 8:
+            self.info["compression"] = "tga_rle"
+
+        if id_len:
+            self.info["id_section"] = self.fp.read(id_len)
+
+        if colormaptype:
+            # read palette
+            start, size, mapdepth = i16(s, 3), i16(s, 5), s[7]
+            if mapdepth == 16:
+                self.palette = ImagePalette.raw(
+                    "BGR;15", b"\0" * 2 * start + self.fp.read(2 * size)
+                )
+            elif mapdepth == 24:
+                self.palette = ImagePalette.raw(
+                    "BGR", b"\0" * 3 * start + self.fp.read(3 * size)
+                )
+            elif mapdepth == 32:
+                self.palette = ImagePalette.raw(
+                    "BGRA", b"\0" * 4 * start + self.fp.read(4 * size)
+                )
+
+        # setup tile descriptor
+        try:
+            rawmode = MODES[(imagetype & 7, depth)]
+            if imagetype & 8:
+                # compressed
+                self.tile = [
+                    (
+                        "tga_rle",
+                        (0, 0) + self.size,
+                        self.fp.tell(),
+                        (rawmode, orientation, depth),
+                    )
+                ]
+            else:
+                self.tile = [
+                    (
+                        "raw",
+                        (0, 0) + self.size,
+                        self.fp.tell(),
+                        (rawmode, 0, orientation),
+                    )
+                ]
+        except KeyError:
+            pass  # cannot decode
+
+    def load_end(self):
+        if self._flip_horizontally:
+            self.im = self.im.transpose(Image.FLIP_LEFT_RIGHT)
+
+
+#
+# --------------------------------------------------------------------
+# Write TGA file
+
+
+SAVE = {
+    "1": ("1", 1, 0, 3),
+    "L": ("L", 8, 0, 3),
+    "LA": ("LA", 16, 0, 3),
+    "P": ("P", 8, 1, 1),
+    "RGB": ("BGR", 24, 0, 2),
+    "RGBA": ("BGRA", 32, 0, 2),
+}
+
+
+def _save(im, fp, filename):
+
+    try:
+        rawmode, bits, colormaptype, imagetype = SAVE[im.mode]
+    except KeyError as e:
+        raise OSError(f"cannot write mode {im.mode} as TGA") from e
+
+    if "rle" in im.encoderinfo:
+        rle = im.encoderinfo["rle"]
+    else:
+        compression = im.encoderinfo.get("compression", im.info.get("compression"))
+        rle = compression == "tga_rle"
+    if rle:
+        imagetype += 8
+
+    id_section = im.encoderinfo.get("id_section", im.info.get("id_section", ""))
+    id_len = len(id_section)
+    if id_len > 255:
+        id_len = 255
+        id_section = id_section[:255]
+        warnings.warn("id_section has been trimmed to 255 characters")
+
+    if colormaptype:
+        colormapfirst, colormaplength, colormapentry = 0, 256, 24
+    else:
+        colormapfirst, colormaplength, colormapentry = 0, 0, 0
+
+    if im.mode in ("LA", "RGBA"):
+        flags = 8
+    else:
+        flags = 0
+
+    orientation = im.encoderinfo.get("orientation", im.info.get("orientation", -1))
+    if orientation > 0:
+        flags = flags | 0x20
+
+    fp.write(
+        o8(id_len)
+        + o8(colormaptype)
+        + o8(imagetype)
+        + o16(colormapfirst)
+        + o16(colormaplength)
+        + o8(colormapentry)
+        + o16(0)
+        + o16(0)
+        + o16(im.size[0])
+        + o16(im.size[1])
+        + o8(bits)
+        + o8(flags)
+    )
+
+    if id_section:
+        fp.write(id_section)
+
+    if colormaptype:
+        fp.write(im.im.getpalette("RGB", "BGR"))
+
+    if rle:
+        ImageFile._save(
+            im, fp, [("tga_rle", (0, 0) + im.size, 0, (rawmode, orientation))]
+        )
+    else:
+        ImageFile._save(
+            im, fp, [("raw", (0, 0) + im.size, 0, (rawmode, 0, orientation))]
+        )
+
+    # write targa version 2 footer
+    fp.write(b"\000" * 8 + b"TRUEVISION-XFILE." + b"\000")
+
+
+#
+# --------------------------------------------------------------------
+# Registry
+
+
+Image.register_open(TgaImageFile.format, TgaImageFile)
+Image.register_save(TgaImageFile.format, _save)
+
+Image.register_extensions(TgaImageFile.format, [".tga", ".icb", ".vda", ".vst"])
+
+Image.register_mime(TgaImageFile.format, "image/x-tga")
diff --git a/.venv/lib/python3.7/site-packages/PIL/TiffImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/TiffImagePlugin.py
new file mode 100644
index 0000000..5df5c4f
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/TiffImagePlugin.py
@@ -0,0 +1,2054 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# TIFF file handling
+#
+# TIFF is a flexible, if somewhat aged, image file format originally
+# defined by Aldus.  Although TIFF supports a wide variety of pixel
+# layouts and compression methods, the name doesn't really stand for
+# "thousands of incompatible file formats," it just feels that way.
+#
+# To read TIFF data from a stream, the stream must be seekable.  For
+# progressive decoding, make sure to use TIFF files where the tag
+# directory is placed first in the file.
+#
+# History:
+# 1995-09-01 fl   Created
+# 1996-05-04 fl   Handle JPEGTABLES tag
+# 1996-05-18 fl   Fixed COLORMAP support
+# 1997-01-05 fl   Fixed PREDICTOR support
+# 1997-08-27 fl   Added support for rational tags (from Perry Stoll)
+# 1998-01-10 fl   Fixed seek/tell (from Jan Blom)
+# 1998-07-15 fl   Use private names for internal variables
+# 1999-06-13 fl   Rewritten for PIL 1.0 (1.0)
+# 2000-10-11 fl   Additional fixes for Python 2.0 (1.1)
+# 2001-04-17 fl   Fixed rewind support (seek to frame 0) (1.2)
+# 2001-05-12 fl   Added write support for more tags (from Greg Couch) (1.3)
+# 2001-12-18 fl   Added workaround for broken Matrox library
+# 2002-01-18 fl   Don't mess up if photometric tag is missing (D. Alan Stewart)
+# 2003-05-19 fl   Check FILLORDER tag
+# 2003-09-26 fl   Added RGBa support
+# 2004-02-24 fl   Added DPI support; fixed rational write support
+# 2005-02-07 fl   Added workaround for broken Corel Draw 10 files
+# 2006-01-09 fl   Added support for float/double tags (from Russell Nelson)
+#
+# Copyright (c) 1997-2006 by Secret Labs AB.  All rights reserved.
+# Copyright (c) 1995-1997 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+import io
+import itertools
+import logging
+import os
+import struct
+import warnings
+from collections.abc import MutableMapping
+from fractions import Fraction
+from numbers import Number, Rational
+
+from . import Image, ImageFile, ImageOps, ImagePalette, TiffTags
+from ._binary import o8
+from .TiffTags import TYPES
+
+logger = logging.getLogger(__name__)
+
+# Set these to true to force use of libtiff for reading or writing.
+READ_LIBTIFF = False
+WRITE_LIBTIFF = False
+IFD_LEGACY_API = True
+STRIP_SIZE = 65536
+
+II = b"II"  # little-endian (Intel style)
+MM = b"MM"  # big-endian (Motorola style)
+
+#
+# --------------------------------------------------------------------
+# Read TIFF files
+
+# a few tag names, just to make the code below a bit more readable
+IMAGEWIDTH = 256
+IMAGELENGTH = 257
+BITSPERSAMPLE = 258
+COMPRESSION = 259
+PHOTOMETRIC_INTERPRETATION = 262
+FILLORDER = 266
+IMAGEDESCRIPTION = 270
+STRIPOFFSETS = 273
+SAMPLESPERPIXEL = 277
+ROWSPERSTRIP = 278
+STRIPBYTECOUNTS = 279
+X_RESOLUTION = 282
+Y_RESOLUTION = 283
+PLANAR_CONFIGURATION = 284
+RESOLUTION_UNIT = 296
+TRANSFERFUNCTION = 301
+SOFTWARE = 305
+DATE_TIME = 306
+ARTIST = 315
+PREDICTOR = 317
+COLORMAP = 320
+TILEWIDTH = 322
+TILELENGTH = 323
+TILEOFFSETS = 324
+TILEBYTECOUNTS = 325
+SUBIFD = 330
+EXTRASAMPLES = 338
+SAMPLEFORMAT = 339
+JPEGTABLES = 347
+YCBCRSUBSAMPLING = 530
+REFERENCEBLACKWHITE = 532
+COPYRIGHT = 33432
+IPTC_NAA_CHUNK = 33723  # newsphoto properties
+PHOTOSHOP_CHUNK = 34377  # photoshop properties
+ICCPROFILE = 34675
+EXIFIFD = 34665
+XMP = 700
+JPEGQUALITY = 65537  # pseudo-tag by libtiff
+
+# https://github.com/imagej/ImageJA/blob/master/src/main/java/ij/io/TiffDecoder.java
+IMAGEJ_META_DATA_BYTE_COUNTS = 50838
+IMAGEJ_META_DATA = 50839
+
+COMPRESSION_INFO = {
+    # Compression => pil compression name
+    1: "raw",
+    2: "tiff_ccitt",
+    3: "group3",
+    4: "group4",
+    5: "tiff_lzw",
+    6: "tiff_jpeg",  # obsolete
+    7: "jpeg",
+    8: "tiff_adobe_deflate",
+    32771: "tiff_raw_16",  # 16-bit padding
+    32773: "packbits",
+    32809: "tiff_thunderscan",
+    32946: "tiff_deflate",
+    34676: "tiff_sgilog",
+    34677: "tiff_sgilog24",
+    34925: "lzma",
+    50000: "zstd",
+    50001: "webp",
+}
+
+COMPRESSION_INFO_REV = {v: k for k, v in COMPRESSION_INFO.items()}
+
+OPEN_INFO = {
+    # (ByteOrder, PhotoInterpretation, SampleFormat, FillOrder, BitsPerSample,
+    #  ExtraSamples) => mode, rawmode
+    (II, 0, (1,), 1, (1,), ()): ("1", "1;I"),
+    (MM, 0, (1,), 1, (1,), ()): ("1", "1;I"),
+    (II, 0, (1,), 2, (1,), ()): ("1", "1;IR"),
+    (MM, 0, (1,), 2, (1,), ()): ("1", "1;IR"),
+    (II, 1, (1,), 1, (1,), ()): ("1", "1"),
+    (MM, 1, (1,), 1, (1,), ()): ("1", "1"),
+    (II, 1, (1,), 2, (1,), ()): ("1", "1;R"),
+    (MM, 1, (1,), 2, (1,), ()): ("1", "1;R"),
+    (II, 0, (1,), 1, (2,), ()): ("L", "L;2I"),
+    (MM, 0, (1,), 1, (2,), ()): ("L", "L;2I"),
+    (II, 0, (1,), 2, (2,), ()): ("L", "L;2IR"),
+    (MM, 0, (1,), 2, (2,), ()): ("L", "L;2IR"),
+    (II, 1, (1,), 1, (2,), ()): ("L", "L;2"),
+    (MM, 1, (1,), 1, (2,), ()): ("L", "L;2"),
+    (II, 1, (1,), 2, (2,), ()): ("L", "L;2R"),
+    (MM, 1, (1,), 2, (2,), ()): ("L", "L;2R"),
+    (II, 0, (1,), 1, (4,), ()): ("L", "L;4I"),
+    (MM, 0, (1,), 1, (4,), ()): ("L", "L;4I"),
+    (II, 0, (1,), 2, (4,), ()): ("L", "L;4IR"),
+    (MM, 0, (1,), 2, (4,), ()): ("L", "L;4IR"),
+    (II, 1, (1,), 1, (4,), ()): ("L", "L;4"),
+    (MM, 1, (1,), 1, (4,), ()): ("L", "L;4"),
+    (II, 1, (1,), 2, (4,), ()): ("L", "L;4R"),
+    (MM, 1, (1,), 2, (4,), ()): ("L", "L;4R"),
+    (II, 0, (1,), 1, (8,), ()): ("L", "L;I"),
+    (MM, 0, (1,), 1, (8,), ()): ("L", "L;I"),
+    (II, 0, (1,), 2, (8,), ()): ("L", "L;IR"),
+    (MM, 0, (1,), 2, (8,), ()): ("L", "L;IR"),
+    (II, 1, (1,), 1, (8,), ()): ("L", "L"),
+    (MM, 1, (1,), 1, (8,), ()): ("L", "L"),
+    (II, 1, (1,), 2, (8,), ()): ("L", "L;R"),
+    (MM, 1, (1,), 2, (8,), ()): ("L", "L;R"),
+    (II, 1, (1,), 1, (12,), ()): ("I;16", "I;12"),
+    (II, 1, (1,), 1, (16,), ()): ("I;16", "I;16"),
+    (MM, 1, (1,), 1, (16,), ()): ("I;16B", "I;16B"),
+    (II, 1, (2,), 1, (16,), ()): ("I", "I;16S"),
+    (MM, 1, (2,), 1, (16,), ()): ("I", "I;16BS"),
+    (II, 0, (3,), 1, (32,), ()): ("F", "F;32F"),
+    (MM, 0, (3,), 1, (32,), ()): ("F", "F;32BF"),
+    (II, 1, (1,), 1, (32,), ()): ("I", "I;32N"),
+    (II, 1, (2,), 1, (32,), ()): ("I", "I;32S"),
+    (MM, 1, (2,), 1, (32,), ()): ("I", "I;32BS"),
+    (II, 1, (3,), 1, (32,), ()): ("F", "F;32F"),
+    (MM, 1, (3,), 1, (32,), ()): ("F", "F;32BF"),
+    (II, 1, (1,), 1, (8, 8), (2,)): ("LA", "LA"),
+    (MM, 1, (1,), 1, (8, 8), (2,)): ("LA", "LA"),
+    (II, 2, (1,), 1, (8, 8, 8), ()): ("RGB", "RGB"),
+    (MM, 2, (1,), 1, (8, 8, 8), ()): ("RGB", "RGB"),
+    (II, 2, (1,), 2, (8, 8, 8), ()): ("RGB", "RGB;R"),
+    (MM, 2, (1,), 2, (8, 8, 8), ()): ("RGB", "RGB;R"),
+    (II, 2, (1,), 1, (8, 8, 8, 8), ()): ("RGBA", "RGBA"),  # missing ExtraSamples
+    (MM, 2, (1,), 1, (8, 8, 8, 8), ()): ("RGBA", "RGBA"),  # missing ExtraSamples
+    (II, 2, (1,), 1, (8, 8, 8, 8), (0,)): ("RGBX", "RGBX"),
+    (MM, 2, (1,), 1, (8, 8, 8, 8), (0,)): ("RGBX", "RGBX"),
+    (II, 2, (1,), 1, (8, 8, 8, 8, 8), (0, 0)): ("RGBX", "RGBXX"),
+    (MM, 2, (1,), 1, (8, 8, 8, 8, 8), (0, 0)): ("RGBX", "RGBXX"),
+    (II, 2, (1,), 1, (8, 8, 8, 8, 8, 8), (0, 0, 0)): ("RGBX", "RGBXXX"),
+    (MM, 2, (1,), 1, (8, 8, 8, 8, 8, 8), (0, 0, 0)): ("RGBX", "RGBXXX"),
+    (II, 2, (1,), 1, (8, 8, 8, 8), (1,)): ("RGBA", "RGBa"),
+    (MM, 2, (1,), 1, (8, 8, 8, 8), (1,)): ("RGBA", "RGBa"),
+    (II, 2, (1,), 1, (8, 8, 8, 8, 8), (1, 0)): ("RGBA", "RGBaX"),
+    (MM, 2, (1,), 1, (8, 8, 8, 8, 8), (1, 0)): ("RGBA", "RGBaX"),
+    (II, 2, (1,), 1, (8, 8, 8, 8, 8, 8), (1, 0, 0)): ("RGBA", "RGBaXX"),
+    (MM, 2, (1,), 1, (8, 8, 8, 8, 8, 8), (1, 0, 0)): ("RGBA", "RGBaXX"),
+    (II, 2, (1,), 1, (8, 8, 8, 8), (2,)): ("RGBA", "RGBA"),
+    (MM, 2, (1,), 1, (8, 8, 8, 8), (2,)): ("RGBA", "RGBA"),
+    (II, 2, (1,), 1, (8, 8, 8, 8, 8), (2, 0)): ("RGBA", "RGBAX"),
+    (MM, 2, (1,), 1, (8, 8, 8, 8, 8), (2, 0)): ("RGBA", "RGBAX"),
+    (II, 2, (1,), 1, (8, 8, 8, 8, 8, 8), (2, 0, 0)): ("RGBA", "RGBAXX"),
+    (MM, 2, (1,), 1, (8, 8, 8, 8, 8, 8), (2, 0, 0)): ("RGBA", "RGBAXX"),
+    (II, 2, (1,), 1, (8, 8, 8, 8), (999,)): ("RGBA", "RGBA"),  # Corel Draw 10
+    (MM, 2, (1,), 1, (8, 8, 8, 8), (999,)): ("RGBA", "RGBA"),  # Corel Draw 10
+    (II, 2, (1,), 1, (16, 16, 16), ()): ("RGB", "RGB;16L"),
+    (MM, 2, (1,), 1, (16, 16, 16), ()): ("RGB", "RGB;16B"),
+    (II, 2, (1,), 1, (16, 16, 16, 16), ()): ("RGBA", "RGBA;16L"),
+    (MM, 2, (1,), 1, (16, 16, 16, 16), ()): ("RGBA", "RGBA;16B"),
+    (II, 2, (1,), 1, (16, 16, 16, 16), (0,)): ("RGBX", "RGBX;16L"),
+    (MM, 2, (1,), 1, (16, 16, 16, 16), (0,)): ("RGBX", "RGBX;16B"),
+    (II, 2, (1,), 1, (16, 16, 16, 16), (1,)): ("RGBA", "RGBa;16L"),
+    (MM, 2, (1,), 1, (16, 16, 16, 16), (1,)): ("RGBA", "RGBa;16B"),
+    (II, 2, (1,), 1, (16, 16, 16, 16), (2,)): ("RGBA", "RGBA;16L"),
+    (MM, 2, (1,), 1, (16, 16, 16, 16), (2,)): ("RGBA", "RGBA;16B"),
+    (II, 3, (1,), 1, (1,), ()): ("P", "P;1"),
+    (MM, 3, (1,), 1, (1,), ()): ("P", "P;1"),
+    (II, 3, (1,), 2, (1,), ()): ("P", "P;1R"),
+    (MM, 3, (1,), 2, (1,), ()): ("P", "P;1R"),
+    (II, 3, (1,), 1, (2,), ()): ("P", "P;2"),
+    (MM, 3, (1,), 1, (2,), ()): ("P", "P;2"),
+    (II, 3, (1,), 2, (2,), ()): ("P", "P;2R"),
+    (MM, 3, (1,), 2, (2,), ()): ("P", "P;2R"),
+    (II, 3, (1,), 1, (4,), ()): ("P", "P;4"),
+    (MM, 3, (1,), 1, (4,), ()): ("P", "P;4"),
+    (II, 3, (1,), 2, (4,), ()): ("P", "P;4R"),
+    (MM, 3, (1,), 2, (4,), ()): ("P", "P;4R"),
+    (II, 3, (1,), 1, (8,), ()): ("P", "P"),
+    (MM, 3, (1,), 1, (8,), ()): ("P", "P"),
+    (II, 3, (1,), 1, (8, 8), (2,)): ("PA", "PA"),
+    (MM, 3, (1,), 1, (8, 8), (2,)): ("PA", "PA"),
+    (II, 3, (1,), 2, (8,), ()): ("P", "P;R"),
+    (MM, 3, (1,), 2, (8,), ()): ("P", "P;R"),
+    (II, 5, (1,), 1, (8, 8, 8, 8), ()): ("CMYK", "CMYK"),
+    (MM, 5, (1,), 1, (8, 8, 8, 8), ()): ("CMYK", "CMYK"),
+    (II, 5, (1,), 1, (8, 8, 8, 8, 8), (0,)): ("CMYK", "CMYKX"),
+    (MM, 5, (1,), 1, (8, 8, 8, 8, 8), (0,)): ("CMYK", "CMYKX"),
+    (II, 5, (1,), 1, (8, 8, 8, 8, 8, 8), (0, 0)): ("CMYK", "CMYKXX"),
+    (MM, 5, (1,), 1, (8, 8, 8, 8, 8, 8), (0, 0)): ("CMYK", "CMYKXX"),
+    (II, 5, (1,), 1, (16, 16, 16, 16), ()): ("CMYK", "CMYK;16L"),
+    # JPEG compressed images handled by LibTiff and auto-converted to RGBX
+    # Minimal Baseline TIFF requires YCbCr images to have 3 SamplesPerPixel
+    (II, 6, (1,), 1, (8, 8, 8), ()): ("RGB", "RGBX"),
+    (MM, 6, (1,), 1, (8, 8, 8), ()): ("RGB", "RGBX"),
+    (II, 8, (1,), 1, (8, 8, 8), ()): ("LAB", "LAB"),
+    (MM, 8, (1,), 1, (8, 8, 8), ()): ("LAB", "LAB"),
+}
+
+PREFIXES = [
+    b"MM\x00\x2A",  # Valid TIFF header with big-endian byte order
+    b"II\x2A\x00",  # Valid TIFF header with little-endian byte order
+    b"MM\x2A\x00",  # Invalid TIFF header, assume big-endian
+    b"II\x00\x2A",  # Invalid TIFF header, assume little-endian
+]
+
+
+def _accept(prefix):
+    return prefix[:4] in PREFIXES
+
+
+def _limit_rational(val, max_val):
+    inv = abs(val) > 1
+    n_d = IFDRational(1 / val if inv else val).limit_rational(max_val)
+    return n_d[::-1] if inv else n_d
+
+
+def _limit_signed_rational(val, max_val, min_val):
+    frac = Fraction(val)
+    n_d = frac.numerator, frac.denominator
+
+    if min(n_d) < min_val:
+        n_d = _limit_rational(val, abs(min_val))
+
+    if max(n_d) > max_val:
+        val = Fraction(*n_d)
+        n_d = _limit_rational(val, max_val)
+
+    return n_d
+
+
+##
+# Wrapper for TIFF IFDs.
+
+_load_dispatch = {}
+_write_dispatch = {}
+
+
+class IFDRational(Rational):
+    """Implements a rational class where 0/0 is a legal value to match
+    the in the wild use of exif rationals.
+
+    e.g., DigitalZoomRatio - 0.00/0.00  indicates that no digital zoom was used
+    """
+
+    """ If the denominator is 0, store this as a float('nan'), otherwise store
+    as a fractions.Fraction(). Delegate as appropriate
+
+    """
+
+    __slots__ = ("_numerator", "_denominator", "_val")
+
+    def __init__(self, value, denominator=1):
+        """
+        :param value: either an integer numerator, a
+        float/rational/other number, or an IFDRational
+        :param denominator: Optional integer denominator
+        """
+        if isinstance(value, IFDRational):
+            self._numerator = value.numerator
+            self._denominator = value.denominator
+            self._val = value._val
+            return
+
+        if isinstance(value, Fraction):
+            self._numerator = value.numerator
+            self._denominator = value.denominator
+        else:
+            self._numerator = value
+            self._denominator = denominator
+
+        if denominator == 0:
+            self._val = float("nan")
+        elif denominator == 1:
+            self._val = Fraction(value)
+        else:
+            self._val = Fraction(value, denominator)
+
+    @property
+    def numerator(a):
+        return a._numerator
+
+    @property
+    def denominator(a):
+        return a._denominator
+
+    def limit_rational(self, max_denominator):
+        """
+
+        :param max_denominator: Integer, the maximum denominator value
+        :returns: Tuple of (numerator, denominator)
+        """
+
+        if self.denominator == 0:
+            return (self.numerator, self.denominator)
+
+        f = self._val.limit_denominator(max_denominator)
+        return (f.numerator, f.denominator)
+
+    def __repr__(self):
+        return str(float(self._val))
+
+    def __hash__(self):
+        return self._val.__hash__()
+
+    def __eq__(self, other):
+        val = self._val
+        if isinstance(other, IFDRational):
+            other = other._val
+        if isinstance(other, float):
+            val = float(val)
+        return val == other
+
+    def __getstate__(self):
+        return [self._val, self._numerator, self._denominator]
+
+    def __setstate__(self, state):
+        IFDRational.__init__(self, 0)
+        _val, _numerator, _denominator = state
+        self._val = _val
+        self._numerator = _numerator
+        self._denominator = _denominator
+
+    def _delegate(op):
+        def delegate(self, *args):
+            return getattr(self._val, op)(*args)
+
+        return delegate
+
+    """ a = ['add','radd', 'sub', 'rsub', 'mul', 'rmul',
+             'truediv', 'rtruediv', 'floordiv', 'rfloordiv',
+             'mod','rmod', 'pow','rpow', 'pos', 'neg',
+             'abs', 'trunc', 'lt', 'gt', 'le', 'ge', 'bool',
+             'ceil', 'floor', 'round']
+        print("\n".join("__%s__ = _delegate('__%s__')" % (s,s) for s in a))
+        """
+
+    __add__ = _delegate("__add__")
+    __radd__ = _delegate("__radd__")
+    __sub__ = _delegate("__sub__")
+    __rsub__ = _delegate("__rsub__")
+    __mul__ = _delegate("__mul__")
+    __rmul__ = _delegate("__rmul__")
+    __truediv__ = _delegate("__truediv__")
+    __rtruediv__ = _delegate("__rtruediv__")
+    __floordiv__ = _delegate("__floordiv__")
+    __rfloordiv__ = _delegate("__rfloordiv__")
+    __mod__ = _delegate("__mod__")
+    __rmod__ = _delegate("__rmod__")
+    __pow__ = _delegate("__pow__")
+    __rpow__ = _delegate("__rpow__")
+    __pos__ = _delegate("__pos__")
+    __neg__ = _delegate("__neg__")
+    __abs__ = _delegate("__abs__")
+    __trunc__ = _delegate("__trunc__")
+    __lt__ = _delegate("__lt__")
+    __gt__ = _delegate("__gt__")
+    __le__ = _delegate("__le__")
+    __ge__ = _delegate("__ge__")
+    __bool__ = _delegate("__bool__")
+    __ceil__ = _delegate("__ceil__")
+    __floor__ = _delegate("__floor__")
+    __round__ = _delegate("__round__")
+
+
+class ImageFileDirectory_v2(MutableMapping):
+    """This class represents a TIFF tag directory.  To speed things up, we
+    don't decode tags unless they're asked for.
+
+    Exposes a dictionary interface of the tags in the directory::
+
+        ifd = ImageFileDirectory_v2()
+        ifd[key] = 'Some Data'
+        ifd.tagtype[key] = TiffTags.ASCII
+        print(ifd[key])
+        'Some Data'
+
+    Individual values are returned as the strings or numbers, sequences are
+    returned as tuples of the values.
+
+    The tiff metadata type of each item is stored in a dictionary of
+    tag types in
+    :attr:`~PIL.TiffImagePlugin.ImageFileDirectory_v2.tagtype`. The types
+    are read from a tiff file, guessed from the type added, or added
+    manually.
+
+    Data Structures:
+
+        * ``self.tagtype = {}``
+
+          * Key: numerical TIFF tag number
+          * Value: integer corresponding to the data type from
+            :py:data:`.TiffTags.TYPES`
+
+          .. versionadded:: 3.0.0
+
+    'Internal' data structures:
+
+        * ``self._tags_v2 = {}``
+
+          * Key: numerical TIFF tag number
+          * Value: decoded data, as tuple for multiple values
+
+        * ``self._tagdata = {}``
+
+          * Key: numerical TIFF tag number
+          * Value: undecoded byte string from file
+
+        * ``self._tags_v1 = {}``
+
+          * Key: numerical TIFF tag number
+          * Value: decoded data in the v1 format
+
+    Tags will be found in the private attributes ``self._tagdata``, and in
+    ``self._tags_v2`` once decoded.
+
+    ``self.legacy_api`` is a value for internal use, and shouldn't be changed
+    from outside code. In cooperation with
+    :py:class:`~PIL.TiffImagePlugin.ImageFileDirectory_v1`, if ``legacy_api``
+    is true, then decoded tags will be populated into both ``_tags_v1`` and
+    ``_tags_v2``. ``_tags_v2`` will be used if this IFD is used in the TIFF
+    save routine. Tags should be read from ``_tags_v1`` if
+    ``legacy_api == true``.
+
+    """
+
+    def __init__(self, ifh=b"II\052\0\0\0\0\0", prefix=None, group=None):
+        """Initialize an ImageFileDirectory.
+
+        To construct an ImageFileDirectory from a real file, pass the 8-byte
+        magic header to the constructor.  To only set the endianness, pass it
+        as the 'prefix' keyword argument.
+
+        :param ifh: One of the accepted magic headers (cf. PREFIXES); also sets
+              endianness.
+        :param prefix: Override the endianness of the file.
+        """
+        if ifh[:4] not in PREFIXES:
+            raise SyntaxError(f"not a TIFF file (header {repr(ifh)} not valid)")
+        self._prefix = prefix if prefix is not None else ifh[:2]
+        if self._prefix == MM:
+            self._endian = ">"
+        elif self._prefix == II:
+            self._endian = "<"
+        else:
+            raise SyntaxError("not a TIFF IFD")
+        self.group = group
+        self.tagtype = {}
+        """ Dictionary of tag types """
+        self.reset()
+        (self.next,) = self._unpack("L", ifh[4:])
+        self._legacy_api = False
+
+    prefix = property(lambda self: self._prefix)
+    offset = property(lambda self: self._offset)
+    legacy_api = property(lambda self: self._legacy_api)
+
+    @legacy_api.setter
+    def legacy_api(self, value):
+        raise Exception("Not allowing setting of legacy api")
+
+    def reset(self):
+        self._tags_v1 = {}  # will remain empty if legacy_api is false
+        self._tags_v2 = {}  # main tag storage
+        self._tagdata = {}
+        self.tagtype = {}  # added 2008-06-05 by Florian Hoech
+        self._next = None
+        self._offset = None
+
+    def __str__(self):
+        return str(dict(self))
+
+    def named(self):
+        """
+        :returns: dict of name|key: value
+
+        Returns the complete tag dictionary, with named tags where possible.
+        """
+        return {
+            TiffTags.lookup(code, self.group).name: value
+            for code, value in self.items()
+        }
+
+    def __len__(self):
+        return len(set(self._tagdata) | set(self._tags_v2))
+
+    def __getitem__(self, tag):
+        if tag not in self._tags_v2:  # unpack on the fly
+            data = self._tagdata[tag]
+            typ = self.tagtype[tag]
+            size, handler = self._load_dispatch[typ]
+            self[tag] = handler(self, data, self.legacy_api)  # check type
+        val = self._tags_v2[tag]
+        if self.legacy_api and not isinstance(val, (tuple, bytes)):
+            val = (val,)
+        return val
+
+    def __contains__(self, tag):
+        return tag in self._tags_v2 or tag in self._tagdata
+
+    def __setitem__(self, tag, value):
+        self._setitem(tag, value, self.legacy_api)
+
+    def _setitem(self, tag, value, legacy_api):
+        basetypes = (Number, bytes, str)
+
+        info = TiffTags.lookup(tag, self.group)
+        values = [value] if isinstance(value, basetypes) else value
+
+        if tag not in self.tagtype:
+            if info.type:
+                self.tagtype[tag] = info.type
+            else:
+                self.tagtype[tag] = TiffTags.UNDEFINED
+                if all(isinstance(v, IFDRational) for v in values):
+                    self.tagtype[tag] = (
+                        TiffTags.RATIONAL
+                        if all(v >= 0 for v in values)
+                        else TiffTags.SIGNED_RATIONAL
+                    )
+                elif all(isinstance(v, int) for v in values):
+                    if all(0 <= v < 2 ** 16 for v in values):
+                        self.tagtype[tag] = TiffTags.SHORT
+                    elif all(-(2 ** 15) < v < 2 ** 15 for v in values):
+                        self.tagtype[tag] = TiffTags.SIGNED_SHORT
+                    else:
+                        self.tagtype[tag] = (
+                            TiffTags.LONG
+                            if all(v >= 0 for v in values)
+                            else TiffTags.SIGNED_LONG
+                        )
+                elif all(isinstance(v, float) for v in values):
+                    self.tagtype[tag] = TiffTags.DOUBLE
+                elif all(isinstance(v, str) for v in values):
+                    self.tagtype[tag] = TiffTags.ASCII
+                elif all(isinstance(v, bytes) for v in values):
+                    self.tagtype[tag] = TiffTags.BYTE
+
+        if self.tagtype[tag] == TiffTags.UNDEFINED:
+            values = [
+                v.encode("ascii", "replace") if isinstance(v, str) else v
+                for v in values
+            ]
+        elif self.tagtype[tag] == TiffTags.RATIONAL:
+            values = [float(v) if isinstance(v, int) else v for v in values]
+
+        is_ifd = self.tagtype[tag] == TiffTags.LONG and isinstance(values, dict)
+        if not is_ifd:
+            values = tuple(info.cvt_enum(value) for value in values)
+
+        dest = self._tags_v1 if legacy_api else self._tags_v2
+
+        # Three branches:
+        # Spec'd length == 1, Actual length 1, store as element
+        # Spec'd length == 1, Actual > 1, Warn and truncate. Formerly barfed.
+        # No Spec, Actual length 1, Formerly (<4.2) returned a 1 element tuple.
+        # Don't mess with the legacy api, since it's frozen.
+        if not is_ifd and (
+            (info.length == 1)
+            or self.tagtype[tag] == TiffTags.BYTE
+            or (info.length is None and len(values) == 1 and not legacy_api)
+        ):
+            # Don't mess with the legacy api, since it's frozen.
+            if legacy_api and self.tagtype[tag] in [
+                TiffTags.RATIONAL,
+                TiffTags.SIGNED_RATIONAL,
+            ]:  # rationals
+                values = (values,)
+            try:
+                (dest[tag],) = values
+            except ValueError:
+                # We've got a builtin tag with 1 expected entry
+                warnings.warn(
+                    f"Metadata Warning, tag {tag} had too many entries: "
+                    f"{len(values)}, expected 1"
+                )
+                dest[tag] = values[0]
+
+        else:
+            # Spec'd length > 1 or undefined
+            # Unspec'd, and length > 1
+            dest[tag] = values
+
+    def __delitem__(self, tag):
+        self._tags_v2.pop(tag, None)
+        self._tags_v1.pop(tag, None)
+        self._tagdata.pop(tag, None)
+
+    def __iter__(self):
+        return iter(set(self._tagdata) | set(self._tags_v2))
+
+    def _unpack(self, fmt, data):
+        return struct.unpack(self._endian + fmt, data)
+
+    def _pack(self, fmt, *values):
+        return struct.pack(self._endian + fmt, *values)
+
+    def _register_loader(idx, size):
+        def decorator(func):
+            from .TiffTags import TYPES
+
+            if func.__name__.startswith("load_"):
+                TYPES[idx] = func.__name__[5:].replace("_", " ")
+            _load_dispatch[idx] = size, func  # noqa: F821
+            return func
+
+        return decorator
+
+    def _register_writer(idx):
+        def decorator(func):
+            _write_dispatch[idx] = func  # noqa: F821
+            return func
+
+        return decorator
+
+    def _register_basic(idx_fmt_name):
+        from .TiffTags import TYPES
+
+        idx, fmt, name = idx_fmt_name
+        TYPES[idx] = name
+        size = struct.calcsize("=" + fmt)
+        _load_dispatch[idx] = (  # noqa: F821
+            size,
+            lambda self, data, legacy_api=True: (
+                self._unpack(f"{len(data) // size}{fmt}", data)
+            ),
+        )
+        _write_dispatch[idx] = lambda self, *values: (  # noqa: F821
+            b"".join(self._pack(fmt, value) for value in values)
+        )
+
+    list(
+        map(
+            _register_basic,
+            [
+                (TiffTags.SHORT, "H", "short"),
+                (TiffTags.LONG, "L", "long"),
+                (TiffTags.SIGNED_BYTE, "b", "signed byte"),
+                (TiffTags.SIGNED_SHORT, "h", "signed short"),
+                (TiffTags.SIGNED_LONG, "l", "signed long"),
+                (TiffTags.FLOAT, "f", "float"),
+                (TiffTags.DOUBLE, "d", "double"),
+                (TiffTags.IFD, "L", "long"),
+            ],
+        )
+    )
+
+    @_register_loader(1, 1)  # Basic type, except for the legacy API.
+    def load_byte(self, data, legacy_api=True):
+        return data
+
+    @_register_writer(1)  # Basic type, except for the legacy API.
+    def write_byte(self, data):
+        return data
+
+    @_register_loader(2, 1)
+    def load_string(self, data, legacy_api=True):
+        if data.endswith(b"\0"):
+            data = data[:-1]
+        return data.decode("latin-1", "replace")
+
+    @_register_writer(2)
+    def write_string(self, value):
+        # remerge of https://github.com/python-pillow/Pillow/pull/1416
+        return b"" + value.encode("ascii", "replace") + b"\0"
+
+    @_register_loader(5, 8)
+    def load_rational(self, data, legacy_api=True):
+        vals = self._unpack(f"{len(data) // 4}L", data)
+
+        def combine(a, b):
+            return (a, b) if legacy_api else IFDRational(a, b)
+
+        return tuple(combine(num, denom) for num, denom in zip(vals[::2], vals[1::2]))
+
+    @_register_writer(5)
+    def write_rational(self, *values):
+        return b"".join(
+            self._pack("2L", *_limit_rational(frac, 2 ** 32 - 1)) for frac in values
+        )
+
+    @_register_loader(7, 1)
+    def load_undefined(self, data, legacy_api=True):
+        return data
+
+    @_register_writer(7)
+    def write_undefined(self, value):
+        return value
+
+    @_register_loader(10, 8)
+    def load_signed_rational(self, data, legacy_api=True):
+        vals = self._unpack(f"{len(data) // 4}l", data)
+
+        def combine(a, b):
+            return (a, b) if legacy_api else IFDRational(a, b)
+
+        return tuple(combine(num, denom) for num, denom in zip(vals[::2], vals[1::2]))
+
+    @_register_writer(10)
+    def write_signed_rational(self, *values):
+        return b"".join(
+            self._pack("2l", *_limit_signed_rational(frac, 2 ** 31 - 1, -(2 ** 31)))
+            for frac in values
+        )
+
+    def _ensure_read(self, fp, size):
+        ret = fp.read(size)
+        if len(ret) != size:
+            raise OSError(
+                "Corrupt EXIF data.  "
+                f"Expecting to read {size} bytes but only got {len(ret)}. "
+            )
+        return ret
+
+    def load(self, fp):
+
+        self.reset()
+        self._offset = fp.tell()
+
+        try:
+            for i in range(self._unpack("H", self._ensure_read(fp, 2))[0]):
+                tag, typ, count, data = self._unpack("HHL4s", self._ensure_read(fp, 12))
+
+                tagname = TiffTags.lookup(tag, self.group).name
+                typname = TYPES.get(typ, "unknown")
+                msg = f"tag: {tagname} ({tag}) - type: {typname} ({typ})"
+
+                try:
+                    unit_size, handler = self._load_dispatch[typ]
+                except KeyError:
+                    logger.debug(msg + f" - unsupported type {typ}")
+                    continue  # ignore unsupported type
+                size = count * unit_size
+                if size > 4:
+                    here = fp.tell()
+                    (offset,) = self._unpack("L", data)
+                    msg += f" Tag Location: {here} - Data Location: {offset}"
+                    fp.seek(offset)
+                    data = ImageFile._safe_read(fp, size)
+                    fp.seek(here)
+                else:
+                    data = data[:size]
+
+                if len(data) != size:
+                    warnings.warn(
+                        "Possibly corrupt EXIF data.  "
+                        f"Expecting to read {size} bytes but only got {len(data)}."
+                        f" Skipping tag {tag}"
+                    )
+                    logger.debug(msg)
+                    continue
+
+                if not data:
+                    logger.debug(msg)
+                    continue
+
+                self._tagdata[tag] = data
+                self.tagtype[tag] = typ
+
+                msg += " - value: " + (
+                    "<table: %d bytes>" % size if size > 32 else repr(data)
+                )
+                logger.debug(msg)
+
+            (self.next,) = self._unpack("L", self._ensure_read(fp, 4))
+        except OSError as msg:
+            warnings.warn(str(msg))
+            return
+
+    def tobytes(self, offset=0):
+        # FIXME What about tagdata?
+        result = self._pack("H", len(self._tags_v2))
+
+        entries = []
+        offset = offset + len(result) + len(self._tags_v2) * 12 + 4
+        stripoffsets = None
+
+        # pass 1: convert tags to binary format
+        # always write tags in ascending order
+        for tag, value in sorted(self._tags_v2.items()):
+            if tag == STRIPOFFSETS:
+                stripoffsets = len(entries)
+            typ = self.tagtype.get(tag)
+            logger.debug(f"Tag {tag}, Type: {typ}, Value: {repr(value)}")
+            is_ifd = typ == TiffTags.LONG and isinstance(value, dict)
+            if is_ifd:
+                if self._endian == "<":
+                    ifh = b"II\x2A\x00\x08\x00\x00\x00"
+                else:
+                    ifh = b"MM\x00\x2A\x00\x00\x00\x08"
+                ifd = ImageFileDirectory_v2(ifh, group=tag)
+                values = self._tags_v2[tag]
+                for ifd_tag, ifd_value in values.items():
+                    ifd[ifd_tag] = ifd_value
+                data = ifd.tobytes(offset)
+            else:
+                values = value if isinstance(value, tuple) else (value,)
+                data = self._write_dispatch[typ](self, *values)
+
+            tagname = TiffTags.lookup(tag, self.group).name
+            typname = "ifd" if is_ifd else TYPES.get(typ, "unknown")
+            msg = f"save: {tagname} ({tag}) - type: {typname} ({typ})"
+            msg += " - value: " + (
+                "<table: %d bytes>" % len(data) if len(data) >= 16 else str(values)
+            )
+            logger.debug(msg)
+
+            # count is sum of lengths for string and arbitrary data
+            if is_ifd:
+                count = 1
+            elif typ in [TiffTags.BYTE, TiffTags.ASCII, TiffTags.UNDEFINED]:
+                count = len(data)
+            else:
+                count = len(values)
+            # figure out if data fits into the entry
+            if len(data) <= 4:
+                entries.append((tag, typ, count, data.ljust(4, b"\0"), b""))
+            else:
+                entries.append((tag, typ, count, self._pack("L", offset), data))
+                offset += (len(data) + 1) // 2 * 2  # pad to word
+
+        # update strip offset data to point beyond auxiliary data
+        if stripoffsets is not None:
+            tag, typ, count, value, data = entries[stripoffsets]
+            if data:
+                raise NotImplementedError("multistrip support not yet implemented")
+            value = self._pack("L", self._unpack("L", value)[0] + offset)
+            entries[stripoffsets] = tag, typ, count, value, data
+
+        # pass 2: write entries to file
+        for tag, typ, count, value, data in entries:
+            logger.debug(f"{tag} {typ} {count} {repr(value)} {repr(data)}")
+            result += self._pack("HHL4s", tag, typ, count, value)
+
+        # -- overwrite here for multi-page --
+        result += b"\0\0\0\0"  # end of entries
+
+        # pass 3: write auxiliary data to file
+        for tag, typ, count, value, data in entries:
+            result += data
+            if len(data) & 1:
+                result += b"\0"
+
+        return result
+
+    def save(self, fp):
+
+        if fp.tell() == 0:  # skip TIFF header on subsequent pages
+            # tiff header -- PIL always starts the first IFD at offset 8
+            fp.write(self._prefix + self._pack("HL", 42, 8))
+
+        offset = fp.tell()
+        result = self.tobytes(offset)
+        fp.write(result)
+        return offset + len(result)
+
+
+ImageFileDirectory_v2._load_dispatch = _load_dispatch
+ImageFileDirectory_v2._write_dispatch = _write_dispatch
+for idx, name in TYPES.items():
+    name = name.replace(" ", "_")
+    setattr(ImageFileDirectory_v2, "load_" + name, _load_dispatch[idx][1])
+    setattr(ImageFileDirectory_v2, "write_" + name, _write_dispatch[idx])
+del _load_dispatch, _write_dispatch, idx, name
+
+
+# Legacy ImageFileDirectory support.
+class ImageFileDirectory_v1(ImageFileDirectory_v2):
+    """This class represents the **legacy** interface to a TIFF tag directory.
+
+    Exposes a dictionary interface of the tags in the directory::
+
+        ifd = ImageFileDirectory_v1()
+        ifd[key] = 'Some Data'
+        ifd.tagtype[key] = TiffTags.ASCII
+        print(ifd[key])
+        ('Some Data',)
+
+    Also contains a dictionary of tag types as read from the tiff image file,
+    :attr:`~PIL.TiffImagePlugin.ImageFileDirectory_v1.tagtype`.
+
+    Values are returned as a tuple.
+
+    ..  deprecated:: 3.0.0
+    """
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+        self._legacy_api = True
+
+    tags = property(lambda self: self._tags_v1)
+    tagdata = property(lambda self: self._tagdata)
+
+    # defined in ImageFileDirectory_v2
+    tagtype: dict
+    """Dictionary of tag types"""
+
+    @classmethod
+    def from_v2(cls, original):
+        """Returns an
+        :py:class:`~PIL.TiffImagePlugin.ImageFileDirectory_v1`
+        instance with the same data as is contained in the original
+        :py:class:`~PIL.TiffImagePlugin.ImageFileDirectory_v2`
+        instance.
+
+        :returns: :py:class:`~PIL.TiffImagePlugin.ImageFileDirectory_v1`
+
+        """
+
+        ifd = cls(prefix=original.prefix)
+        ifd._tagdata = original._tagdata
+        ifd.tagtype = original.tagtype
+        ifd.next = original.next  # an indicator for multipage tiffs
+        return ifd
+
+    def to_v2(self):
+        """Returns an
+        :py:class:`~PIL.TiffImagePlugin.ImageFileDirectory_v2`
+        instance with the same data as is contained in the original
+        :py:class:`~PIL.TiffImagePlugin.ImageFileDirectory_v1`
+        instance.
+
+        :returns: :py:class:`~PIL.TiffImagePlugin.ImageFileDirectory_v2`
+
+        """
+
+        ifd = ImageFileDirectory_v2(prefix=self.prefix)
+        ifd._tagdata = dict(self._tagdata)
+        ifd.tagtype = dict(self.tagtype)
+        ifd._tags_v2 = dict(self._tags_v2)
+        return ifd
+
+    def __contains__(self, tag):
+        return tag in self._tags_v1 or tag in self._tagdata
+
+    def __len__(self):
+        return len(set(self._tagdata) | set(self._tags_v1))
+
+    def __iter__(self):
+        return iter(set(self._tagdata) | set(self._tags_v1))
+
+    def __setitem__(self, tag, value):
+        for legacy_api in (False, True):
+            self._setitem(tag, value, legacy_api)
+
+    def __getitem__(self, tag):
+        if tag not in self._tags_v1:  # unpack on the fly
+            data = self._tagdata[tag]
+            typ = self.tagtype[tag]
+            size, handler = self._load_dispatch[typ]
+            for legacy in (False, True):
+                self._setitem(tag, handler(self, data, legacy), legacy)
+        val = self._tags_v1[tag]
+        if not isinstance(val, (tuple, bytes)):
+            val = (val,)
+        return val
+
+
+# undone -- switch this pointer when IFD_LEGACY_API == False
+ImageFileDirectory = ImageFileDirectory_v1
+
+
+##
+# Image plugin for TIFF files.
+
+
+class TiffImageFile(ImageFile.ImageFile):
+
+    format = "TIFF"
+    format_description = "Adobe TIFF"
+    _close_exclusive_fp_after_loading = False
+
+    def __init__(self, fp=None, filename=None):
+        self.tag_v2 = None
+        """ Image file directory (tag dictionary) """
+
+        self.tag = None
+        """ Legacy tag entries """
+
+        super().__init__(fp, filename)
+
+    def _open(self):
+        """Open the first image in a TIFF file"""
+
+        # Header
+        ifh = self.fp.read(8)
+
+        self.tag_v2 = ImageFileDirectory_v2(ifh)
+
+        # legacy IFD entries will be filled in later
+        self.ifd = None
+
+        # setup frame pointers
+        self.__first = self.__next = self.tag_v2.next
+        self.__frame = -1
+        self.__fp = self.fp
+        self._frame_pos = []
+        self._n_frames = None
+
+        logger.debug("*** TiffImageFile._open ***")
+        logger.debug(f"- __first: {self.__first}")
+        logger.debug(f"- ifh: {repr(ifh)}")  # Use repr to avoid str(bytes)
+
+        # and load the first frame
+        self._seek(0)
+
+    @property
+    def n_frames(self):
+        if self._n_frames is None:
+            current = self.tell()
+            self._seek(len(self._frame_pos))
+            while self._n_frames is None:
+                self._seek(self.tell() + 1)
+            self.seek(current)
+        return self._n_frames
+
+    def seek(self, frame):
+        """Select a given frame as current image"""
+        if not self._seek_check(frame):
+            return
+        self._seek(frame)
+        # Create a new core image object on second and
+        # subsequent frames in the image. Image may be
+        # different size/mode.
+        Image._decompression_bomb_check(self.size)
+        self.im = Image.core.new(self.mode, self.size)
+
+    def _seek(self, frame):
+        self.fp = self.__fp
+
+        # reset buffered io handle in case fp
+        # was passed to libtiff, invalidating the buffer
+        self.fp.tell()
+
+        while len(self._frame_pos) <= frame:
+            if not self.__next:
+                raise EOFError("no more images in TIFF file")
+            logger.debug(
+                f"Seeking to frame {frame}, on frame {self.__frame}, "
+                f"__next {self.__next}, location: {self.fp.tell()}"
+            )
+            self.fp.seek(self.__next)
+            self._frame_pos.append(self.__next)
+            logger.debug("Loading tags, location: %s" % self.fp.tell())
+            self.tag_v2.load(self.fp)
+            if self.tag_v2.next in self._frame_pos:
+                # This IFD has already been processed
+                # Declare this to be the end of the image
+                self.__next = 0
+            else:
+                self.__next = self.tag_v2.next
+            if self.__next == 0:
+                self._n_frames = frame + 1
+            if len(self._frame_pos) == 1:
+                self.is_animated = self.__next != 0
+            self.__frame += 1
+        self.fp.seek(self._frame_pos[frame])
+        self.tag_v2.load(self.fp)
+        # fill the legacy tag/ifd entries
+        self.tag = self.ifd = ImageFileDirectory_v1.from_v2(self.tag_v2)
+        self.__frame = frame
+        self._setup()
+
+    def tell(self):
+        """Return the current frame number"""
+        return self.__frame
+
+    def getxmp(self):
+        """
+        Returns a dictionary containing the XMP tags.
+        Requires defusedxml to be installed.
+        :returns: XMP tags in a dictionary.
+        """
+        return self._getxmp(self.tag_v2[700]) if 700 in self.tag_v2 else {}
+
+    def load(self):
+        if self.tile and self.use_load_libtiff:
+            return self._load_libtiff()
+        return super().load()
+
+    def load_end(self):
+        if self._tile_orientation:
+            method = {
+                2: Image.FLIP_LEFT_RIGHT,
+                3: Image.ROTATE_180,
+                4: Image.FLIP_TOP_BOTTOM,
+                5: Image.TRANSPOSE,
+                6: Image.ROTATE_270,
+                7: Image.TRANSVERSE,
+                8: Image.ROTATE_90,
+            }.get(self._tile_orientation)
+            if method is not None:
+                self.im = self.im.transpose(method)
+                self._size = self.im.size
+
+        # allow closing if we're on the first frame, there's no next
+        # This is the ImageFile.load path only, libtiff specific below.
+        if not self.is_animated:
+            self._close_exclusive_fp_after_loading = True
+
+            # reset buffered io handle in case fp
+            # was passed to libtiff, invalidating the buffer
+            self.fp.tell()
+
+            # load IFD data from fp before it is closed
+            exif = self.getexif()
+            for key in TiffTags.TAGS_V2_GROUPS.keys():
+                if key not in exif:
+                    continue
+                exif.get_ifd(key)
+
+    def _load_libtiff(self):
+        """Overload method triggered when we detect a compressed tiff
+        Calls out to libtiff"""
+
+        Image.Image.load(self)
+
+        self.load_prepare()
+
+        if not len(self.tile) == 1:
+            raise OSError("Not exactly one tile")
+
+        # (self._compression, (extents tuple),
+        #   0, (rawmode, self._compression, fp))
+        extents = self.tile[0][1]
+        args = list(self.tile[0][3])
+
+        # To be nice on memory footprint, if there's a
+        # file descriptor, use that instead of reading
+        # into a string in python.
+        # libtiff closes the file descriptor, so pass in a dup.
+        try:
+            fp = hasattr(self.fp, "fileno") and os.dup(self.fp.fileno())
+            # flush the file descriptor, prevents error on pypy 2.4+
+            # should also eliminate the need for fp.tell
+            # in _seek
+            if hasattr(self.fp, "flush"):
+                self.fp.flush()
+        except OSError:
+            # io.BytesIO have a fileno, but returns an OSError if
+            # it doesn't use a file descriptor.
+            fp = False
+
+        if fp:
+            args[2] = fp
+
+        decoder = Image._getdecoder(
+            self.mode, "libtiff", tuple(args), self.decoderconfig
+        )
+        try:
+            decoder.setimage(self.im, extents)
+        except ValueError as e:
+            raise OSError("Couldn't set the image") from e
+
+        close_self_fp = self._exclusive_fp and not self.is_animated
+        if hasattr(self.fp, "getvalue"):
+            # We've got a stringio like thing passed in. Yay for all in memory.
+            # The decoder needs the entire file in one shot, so there's not
+            # a lot we can do here other than give it the entire file.
+            # unless we could do something like get the address of the
+            # underlying string for stringio.
+            #
+            # Rearranging for supporting byteio items, since they have a fileno
+            # that returns an OSError if there's no underlying fp. Easier to
+            # deal with here by reordering.
+            logger.debug("have getvalue. just sending in a string from getvalue")
+            n, err = decoder.decode(self.fp.getvalue())
+        elif fp:
+            # we've got a actual file on disk, pass in the fp.
+            logger.debug("have fileno, calling fileno version of the decoder.")
+            if not close_self_fp:
+                self.fp.seek(0)
+            # 4 bytes, otherwise the trace might error out
+            n, err = decoder.decode(b"fpfp")
+        else:
+            # we have something else.
+            logger.debug("don't have fileno or getvalue. just reading")
+            self.fp.seek(0)
+            # UNDONE -- so much for that buffer size thing.
+            n, err = decoder.decode(self.fp.read())
+
+        self.tile = []
+        self.readonly = 0
+
+        self.load_end()
+
+        # libtiff closed the fp in a, we need to close self.fp, if possible
+        if close_self_fp:
+            self.fp.close()
+            self.fp = None  # might be shared
+
+        if err < 0:
+            raise OSError(err)
+
+        return Image.Image.load(self)
+
+    def _setup(self):
+        """Setup this image object based on current tags"""
+
+        if 0xBC01 in self.tag_v2:
+            raise OSError("Windows Media Photo files not yet supported")
+
+        # extract relevant tags
+        self._compression = COMPRESSION_INFO[self.tag_v2.get(COMPRESSION, 1)]
+        self._planar_configuration = self.tag_v2.get(PLANAR_CONFIGURATION, 1)
+
+        # photometric is a required tag, but not everyone is reading
+        # the specification
+        photo = self.tag_v2.get(PHOTOMETRIC_INTERPRETATION, 0)
+
+        # old style jpeg compression images most certainly are YCbCr
+        if self._compression == "tiff_jpeg":
+            photo = 6
+
+        fillorder = self.tag_v2.get(FILLORDER, 1)
+
+        logger.debug("*** Summary ***")
+        logger.debug(f"- compression: {self._compression}")
+        logger.debug(f"- photometric_interpretation: {photo}")
+        logger.debug(f"- planar_configuration: {self._planar_configuration}")
+        logger.debug(f"- fill_order: {fillorder}")
+        logger.debug(f"- YCbCr subsampling: {self.tag.get(530)}")
+
+        # size
+        xsize = int(self.tag_v2.get(IMAGEWIDTH))
+        ysize = int(self.tag_v2.get(IMAGELENGTH))
+        self._size = xsize, ysize
+
+        logger.debug(f"- size: {self.size}")
+
+        sampleFormat = self.tag_v2.get(SAMPLEFORMAT, (1,))
+        if len(sampleFormat) > 1 and max(sampleFormat) == min(sampleFormat) == 1:
+            # SAMPLEFORMAT is properly per band, so an RGB image will
+            # be (1,1,1).  But, we don't support per band pixel types,
+            # and anything more than one band is a uint8. So, just
+            # take the first element. Revisit this if adding support
+            # for more exotic images.
+            sampleFormat = (1,)
+
+        bps_tuple = self.tag_v2.get(BITSPERSAMPLE, (1,))
+        extra_tuple = self.tag_v2.get(EXTRASAMPLES, ())
+        if photo in (2, 6, 8):  # RGB, YCbCr, LAB
+            bps_count = 3
+        elif photo == 5:  # CMYK
+            bps_count = 4
+        else:
+            bps_count = 1
+        bps_count += len(extra_tuple)
+        # Some files have only one value in bps_tuple,
+        # while should have more. Fix it
+        if bps_count > len(bps_tuple) and len(bps_tuple) == 1:
+            bps_tuple = bps_tuple * bps_count
+
+        samplesPerPixel = self.tag_v2.get(
+            SAMPLESPERPIXEL,
+            3 if self._compression == "tiff_jpeg" and photo in (2, 6) else 1,
+        )
+        if len(bps_tuple) != samplesPerPixel:
+            raise SyntaxError("unknown data organization")
+
+        # mode: check photometric interpretation and bits per pixel
+        key = (
+            self.tag_v2.prefix,
+            photo,
+            sampleFormat,
+            fillorder,
+            bps_tuple,
+            extra_tuple,
+        )
+        logger.debug(f"format key: {key}")
+        try:
+            self.mode, rawmode = OPEN_INFO[key]
+        except KeyError as e:
+            logger.debug("- unsupported format")
+            raise SyntaxError("unknown pixel mode") from e
+
+        logger.debug(f"- raw mode: {rawmode}")
+        logger.debug(f"- pil mode: {self.mode}")
+
+        self.info["compression"] = self._compression
+
+        xres = self.tag_v2.get(X_RESOLUTION, 1)
+        yres = self.tag_v2.get(Y_RESOLUTION, 1)
+
+        if xres and yres:
+            resunit = self.tag_v2.get(RESOLUTION_UNIT)
+            if resunit == 2:  # dots per inch
+                self.info["dpi"] = (xres, yres)
+            elif resunit == 3:  # dots per centimeter. convert to dpi
+                self.info["dpi"] = (xres * 2.54, yres * 2.54)
+            elif resunit is None:  # used to default to 1, but now 2)
+                self.info["dpi"] = (xres, yres)
+                # For backward compatibility,
+                # we also preserve the old behavior
+                self.info["resolution"] = xres, yres
+            else:  # No absolute unit of measurement
+                self.info["resolution"] = xres, yres
+
+        # build tile descriptors
+        x = y = layer = 0
+        self.tile = []
+        self.use_load_libtiff = READ_LIBTIFF or self._compression != "raw"
+        if self.use_load_libtiff:
+            # Decoder expects entire file as one tile.
+            # There's a buffer size limit in load (64k)
+            # so large g4 images will fail if we use that
+            # function.
+            #
+            # Setup the one tile for the whole image, then
+            # use the _load_libtiff function.
+
+            # libtiff handles the fillmode for us, so 1;IR should
+            # actually be 1;I. Including the R double reverses the
+            # bits, so stripes of the image are reversed.  See
+            # https://github.com/python-pillow/Pillow/issues/279
+            if fillorder == 2:
+                # Replace fillorder with fillorder=1
+                key = key[:3] + (1,) + key[4:]
+                logger.debug(f"format key: {key}")
+                # this should always work, since all the
+                # fillorder==2 modes have a corresponding
+                # fillorder=1 mode
+                self.mode, rawmode = OPEN_INFO[key]
+            # libtiff always returns the bytes in native order.
+            # we're expecting image byte order. So, if the rawmode
+            # contains I;16, we need to convert from native to image
+            # byte order.
+            if rawmode == "I;16":
+                rawmode = "I;16N"
+            if ";16B" in rawmode:
+                rawmode = rawmode.replace(";16B", ";16N")
+            if ";16L" in rawmode:
+                rawmode = rawmode.replace(";16L", ";16N")
+
+            # YCbCr images with new jpeg compression with pixels in one plane
+            # unpacked straight into RGB values
+            if (
+                photo == 6
+                and self._compression == "jpeg"
+                and self._planar_configuration == 1
+            ):
+                rawmode = "RGB"
+
+            # Offset in the tile tuple is 0, we go from 0,0 to
+            # w,h, and we only do this once -- eds
+            a = (rawmode, self._compression, False, self.tag_v2.offset)
+            self.tile.append(("libtiff", (0, 0, xsize, ysize), 0, a))
+
+        elif STRIPOFFSETS in self.tag_v2 or TILEOFFSETS in self.tag_v2:
+            # striped image
+            if STRIPOFFSETS in self.tag_v2:
+                offsets = self.tag_v2[STRIPOFFSETS]
+                h = self.tag_v2.get(ROWSPERSTRIP, ysize)
+                w = self.size[0]
+            else:
+                # tiled image
+                offsets = self.tag_v2[TILEOFFSETS]
+                w = self.tag_v2.get(322)
+                h = self.tag_v2.get(323)
+
+            for offset in offsets:
+                if x + w > xsize:
+                    stride = w * sum(bps_tuple) / 8  # bytes per line
+                else:
+                    stride = 0
+
+                tile_rawmode = rawmode
+                if self._planar_configuration == 2:
+                    # each band on it's own layer
+                    tile_rawmode = rawmode[layer]
+                    # adjust stride width accordingly
+                    stride /= bps_count
+
+                a = (tile_rawmode, int(stride), 1)
+                self.tile.append(
+                    (
+                        self._compression,
+                        (x, y, min(x + w, xsize), min(y + h, ysize)),
+                        offset,
+                        a,
+                    )
+                )
+                x = x + w
+                if x >= self.size[0]:
+                    x, y = 0, y + h
+                    if y >= self.size[1]:
+                        x = y = 0
+                        layer += 1
+        else:
+            logger.debug("- unsupported data organization")
+            raise SyntaxError("unknown data organization")
+
+        # Fix up info.
+        if ICCPROFILE in self.tag_v2:
+            self.info["icc_profile"] = self.tag_v2[ICCPROFILE]
+
+        # fixup palette descriptor
+
+        if self.mode in ["P", "PA"]:
+            palette = [o8(b // 256) for b in self.tag_v2[COLORMAP]]
+            self.palette = ImagePalette.raw("RGB;L", b"".join(palette))
+
+        self._tile_orientation = self.tag_v2.get(0x0112)
+
+    def _close__fp(self):
+        try:
+            if self.__fp != self.fp:
+                self.__fp.close()
+        except AttributeError:
+            pass
+        finally:
+            self.__fp = None
+
+
+#
+# --------------------------------------------------------------------
+# Write TIFF files
+
+# little endian is default except for image modes with
+# explicit big endian byte-order
+
+SAVE_INFO = {
+    # mode => rawmode, byteorder, photometrics,
+    #           sampleformat, bitspersample, extra
+    "1": ("1", II, 1, 1, (1,), None),
+    "L": ("L", II, 1, 1, (8,), None),
+    "LA": ("LA", II, 1, 1, (8, 8), 2),
+    "P": ("P", II, 3, 1, (8,), None),
+    "PA": ("PA", II, 3, 1, (8, 8), 2),
+    "I": ("I;32S", II, 1, 2, (32,), None),
+    "I;16": ("I;16", II, 1, 1, (16,), None),
+    "I;16S": ("I;16S", II, 1, 2, (16,), None),
+    "F": ("F;32F", II, 1, 3, (32,), None),
+    "RGB": ("RGB", II, 2, 1, (8, 8, 8), None),
+    "RGBX": ("RGBX", II, 2, 1, (8, 8, 8, 8), 0),
+    "RGBA": ("RGBA", II, 2, 1, (8, 8, 8, 8), 2),
+    "CMYK": ("CMYK", II, 5, 1, (8, 8, 8, 8), None),
+    "YCbCr": ("YCbCr", II, 6, 1, (8, 8, 8), None),
+    "LAB": ("LAB", II, 8, 1, (8, 8, 8), None),
+    "I;32BS": ("I;32BS", MM, 1, 2, (32,), None),
+    "I;16B": ("I;16B", MM, 1, 1, (16,), None),
+    "I;16BS": ("I;16BS", MM, 1, 2, (16,), None),
+    "F;32BF": ("F;32BF", MM, 1, 3, (32,), None),
+}
+
+
+def _save(im, fp, filename):
+
+    try:
+        rawmode, prefix, photo, format, bits, extra = SAVE_INFO[im.mode]
+    except KeyError as e:
+        raise OSError(f"cannot write mode {im.mode} as TIFF") from e
+
+    ifd = ImageFileDirectory_v2(prefix=prefix)
+
+    encoderinfo = im.encoderinfo
+    encoderconfig = im.encoderconfig
+    compression = encoderinfo.get("compression", im.info.get("compression"))
+    if compression is None:
+        compression = "raw"
+    elif compression == "tiff_jpeg":
+        # OJPEG is obsolete, so use new-style JPEG compression instead
+        compression = "jpeg"
+    elif compression == "tiff_deflate":
+        compression = "tiff_adobe_deflate"
+
+    libtiff = WRITE_LIBTIFF or compression != "raw"
+
+    # required for color libtiff images
+    ifd[PLANAR_CONFIGURATION] = getattr(im, "_planar_configuration", 1)
+
+    ifd[IMAGEWIDTH] = im.size[0]
+    ifd[IMAGELENGTH] = im.size[1]
+
+    # write any arbitrary tags passed in as an ImageFileDirectory
+    if "tiffinfo" in encoderinfo:
+        info = encoderinfo["tiffinfo"]
+    elif "exif" in encoderinfo:
+        info = encoderinfo["exif"]
+        if isinstance(info, bytes):
+            exif = Image.Exif()
+            exif.load(info)
+            info = exif
+    else:
+        info = {}
+    logger.debug("Tiffinfo Keys: %s" % list(info))
+    if isinstance(info, ImageFileDirectory_v1):
+        info = info.to_v2()
+    for key in info:
+        if isinstance(info, Image.Exif) and key in TiffTags.TAGS_V2_GROUPS.keys():
+            ifd[key] = info.get_ifd(key)
+        else:
+            ifd[key] = info.get(key)
+        try:
+            ifd.tagtype[key] = info.tagtype[key]
+        except Exception:
+            pass  # might not be an IFD. Might not have populated type
+
+    # additions written by Greg Couch, gregc@cgl.ucsf.edu
+    # inspired by image-sig posting from Kevin Cazabon, kcazabon@home.com
+    if hasattr(im, "tag_v2"):
+        # preserve tags from original TIFF image file
+        for key in (
+            RESOLUTION_UNIT,
+            X_RESOLUTION,
+            Y_RESOLUTION,
+            IPTC_NAA_CHUNK,
+            PHOTOSHOP_CHUNK,
+            XMP,
+        ):
+            if key in im.tag_v2:
+                ifd[key] = im.tag_v2[key]
+                ifd.tagtype[key] = im.tag_v2.tagtype[key]
+
+    # preserve ICC profile (should also work when saving other formats
+    # which support profiles as TIFF) -- 2008-06-06 Florian Hoech
+    icc = encoderinfo.get("icc_profile", im.info.get("icc_profile"))
+    if icc:
+        ifd[ICCPROFILE] = icc
+
+    for key, name in [
+        (IMAGEDESCRIPTION, "description"),
+        (X_RESOLUTION, "resolution"),
+        (Y_RESOLUTION, "resolution"),
+        (X_RESOLUTION, "x_resolution"),
+        (Y_RESOLUTION, "y_resolution"),
+        (RESOLUTION_UNIT, "resolution_unit"),
+        (SOFTWARE, "software"),
+        (DATE_TIME, "date_time"),
+        (ARTIST, "artist"),
+        (COPYRIGHT, "copyright"),
+    ]:
+        if name in encoderinfo:
+            ifd[key] = encoderinfo[name]
+
+    dpi = encoderinfo.get("dpi")
+    if dpi:
+        ifd[RESOLUTION_UNIT] = 2
+        ifd[X_RESOLUTION] = dpi[0]
+        ifd[Y_RESOLUTION] = dpi[1]
+
+    if bits != (1,):
+        ifd[BITSPERSAMPLE] = bits
+        if len(bits) != 1:
+            ifd[SAMPLESPERPIXEL] = len(bits)
+    if extra is not None:
+        ifd[EXTRASAMPLES] = extra
+    if format != 1:
+        ifd[SAMPLEFORMAT] = format
+
+    if PHOTOMETRIC_INTERPRETATION not in ifd:
+        ifd[PHOTOMETRIC_INTERPRETATION] = photo
+    elif im.mode in ("1", "L") and ifd[PHOTOMETRIC_INTERPRETATION] == 0:
+        if im.mode == "1":
+            inverted_im = im.copy()
+            px = inverted_im.load()
+            for y in range(inverted_im.height):
+                for x in range(inverted_im.width):
+                    px[x, y] = 0 if px[x, y] == 255 else 255
+            im = inverted_im
+        else:
+            im = ImageOps.invert(im)
+
+    if im.mode in ["P", "PA"]:
+        lut = im.im.getpalette("RGB", "RGB;L")
+        ifd[COLORMAP] = tuple(v * 256 for v in lut)
+    # data orientation
+    stride = len(bits) * ((im.size[0] * bits[0] + 7) // 8)
+    # aim for given strip size (64 KB by default) when using libtiff writer
+    if libtiff:
+        rows_per_strip = 1 if stride == 0 else min(STRIP_SIZE // stride, im.size[1])
+        # JPEG encoder expects multiple of 8 rows
+        if compression == "jpeg":
+            rows_per_strip = min(((rows_per_strip + 7) // 8) * 8, im.size[1])
+    else:
+        rows_per_strip = im.size[1]
+    if rows_per_strip == 0:
+        rows_per_strip = 1
+    strip_byte_counts = 1 if stride == 0 else stride * rows_per_strip
+    strips_per_image = (im.size[1] + rows_per_strip - 1) // rows_per_strip
+    ifd[ROWSPERSTRIP] = rows_per_strip
+    if strip_byte_counts >= 2 ** 16:
+        ifd.tagtype[STRIPBYTECOUNTS] = TiffTags.LONG
+    ifd[STRIPBYTECOUNTS] = (strip_byte_counts,) * (strips_per_image - 1) + (
+        stride * im.size[1] - strip_byte_counts * (strips_per_image - 1),
+    )
+    ifd[STRIPOFFSETS] = tuple(
+        range(0, strip_byte_counts * strips_per_image, strip_byte_counts)
+    )  # this is adjusted by IFD writer
+    # no compression by default:
+    ifd[COMPRESSION] = COMPRESSION_INFO_REV.get(compression, 1)
+
+    if im.mode == "YCbCr":
+        for tag, value in {
+            YCBCRSUBSAMPLING: (1, 1),
+            REFERENCEBLACKWHITE: (0, 255, 128, 255, 128, 255),
+        }.items():
+            ifd.setdefault(tag, value)
+
+    blocklist = [TILEWIDTH, TILELENGTH, TILEOFFSETS, TILEBYTECOUNTS]
+    if libtiff:
+        if "quality" in encoderinfo:
+            quality = encoderinfo["quality"]
+            if not isinstance(quality, int) or quality < 0 or quality > 100:
+                raise ValueError("Invalid quality setting")
+            if compression != "jpeg":
+                raise ValueError(
+                    "quality setting only supported for 'jpeg' compression"
+                )
+            ifd[JPEGQUALITY] = quality
+
+        logger.debug("Saving using libtiff encoder")
+        logger.debug("Items: %s" % sorted(ifd.items()))
+        _fp = 0
+        if hasattr(fp, "fileno"):
+            try:
+                fp.seek(0)
+                _fp = os.dup(fp.fileno())
+            except io.UnsupportedOperation:
+                pass
+
+        # optional types for non core tags
+        types = {}
+        # STRIPOFFSETS and STRIPBYTECOUNTS are added by the library
+        # based on the data in the strip.
+        # The other tags expect arrays with a certain length (fixed or depending on
+        # BITSPERSAMPLE, etc), passing arrays with a different length will result in
+        # segfaults. Block these tags until we add extra validation.
+        # SUBIFD may also cause a segfault.
+        blocklist += [
+            REFERENCEBLACKWHITE,
+            STRIPBYTECOUNTS,
+            STRIPOFFSETS,
+            TRANSFERFUNCTION,
+            SUBIFD,
+        ]
+
+        atts = {}
+        # bits per sample is a single short in the tiff directory, not a list.
+        atts[BITSPERSAMPLE] = bits[0]
+        # Merge the ones that we have with (optional) more bits from
+        # the original file, e.g x,y resolution so that we can
+        # save(load('')) == original file.
+        legacy_ifd = {}
+        if hasattr(im, "tag"):
+            legacy_ifd = im.tag.to_v2()
+
+        # SAMPLEFORMAT is determined by the image format and should not be copied
+        # from legacy_ifd.
+        supplied_tags = {**getattr(im, "tag_v2", {}), **legacy_ifd}
+        if SAMPLEFORMAT in supplied_tags:
+            del supplied_tags[SAMPLEFORMAT]
+
+        for tag, value in itertools.chain(ifd.items(), supplied_tags.items()):
+            # Libtiff can only process certain core items without adding
+            # them to the custom dictionary.
+            # Custom items are supported for int, float, unicode, string and byte
+            # values. Other types and tuples require a tagtype.
+            if tag not in TiffTags.LIBTIFF_CORE:
+                if not Image.core.libtiff_support_custom_tags:
+                    continue
+
+                if tag in ifd.tagtype:
+                    types[tag] = ifd.tagtype[tag]
+                elif not (isinstance(value, (int, float, str, bytes))):
+                    continue
+                else:
+                    type = TiffTags.lookup(tag).type
+                    if type:
+                        types[tag] = type
+            if tag not in atts and tag not in blocklist:
+                if isinstance(value, str):
+                    atts[tag] = value.encode("ascii", "replace") + b"\0"
+                elif isinstance(value, IFDRational):
+                    atts[tag] = float(value)
+                else:
+                    atts[tag] = value
+
+        if SAMPLEFORMAT in atts and len(atts[SAMPLEFORMAT]) == 1:
+            atts[SAMPLEFORMAT] = atts[SAMPLEFORMAT][0]
+
+        logger.debug("Converted items: %s" % sorted(atts.items()))
+
+        # libtiff always expects the bytes in native order.
+        # we're storing image byte order. So, if the rawmode
+        # contains I;16, we need to convert from native to image
+        # byte order.
+        if im.mode in ("I;16B", "I;16"):
+            rawmode = "I;16N"
+
+        # Pass tags as sorted list so that the tags are set in a fixed order.
+        # This is required by libtiff for some tags. For example, the JPEGQUALITY
+        # pseudo tag requires that the COMPRESS tag was already set.
+        tags = list(atts.items())
+        tags.sort()
+        a = (rawmode, compression, _fp, filename, tags, types)
+        e = Image._getencoder(im.mode, "libtiff", a, encoderconfig)
+        e.setimage(im.im, (0, 0) + im.size)
+        while True:
+            # undone, change to self.decodermaxblock:
+            l, s, d = e.encode(16 * 1024)
+            if not _fp:
+                fp.write(d)
+            if s:
+                break
+        if s < 0:
+            raise OSError(f"encoder error {s} when writing image file")
+
+    else:
+        for tag in blocklist:
+            del ifd[tag]
+        offset = ifd.save(fp)
+
+        ImageFile._save(
+            im, fp, [("raw", (0, 0) + im.size, offset, (rawmode, stride, 1))]
+        )
+
+    # -- helper for multi-page save --
+    if "_debug_multipage" in encoderinfo:
+        # just to access o32 and o16 (using correct byte order)
+        im._debug_multipage = ifd
+
+
+class AppendingTiffWriter:
+    fieldSizes = [
+        0,  # None
+        1,  # byte
+        1,  # ascii
+        2,  # short
+        4,  # long
+        8,  # rational
+        1,  # sbyte
+        1,  # undefined
+        2,  # sshort
+        4,  # slong
+        8,  # srational
+        4,  # float
+        8,  # double
+    ]
+
+    #    StripOffsets = 273
+    #    FreeOffsets = 288
+    #    TileOffsets = 324
+    #    JPEGQTables = 519
+    #    JPEGDCTables = 520
+    #    JPEGACTables = 521
+    Tags = {273, 288, 324, 519, 520, 521}
+
+    def __init__(self, fn, new=False):
+        if hasattr(fn, "read"):
+            self.f = fn
+            self.close_fp = False
+        else:
+            self.name = fn
+            self.close_fp = True
+            try:
+                self.f = open(fn, "w+b" if new else "r+b")
+            except OSError:
+                self.f = open(fn, "w+b")
+        self.beginning = self.f.tell()
+        self.setup()
+
+    def setup(self):
+        # Reset everything.
+        self.f.seek(self.beginning, os.SEEK_SET)
+
+        self.whereToWriteNewIFDOffset = None
+        self.offsetOfNewPage = 0
+
+        self.IIMM = IIMM = self.f.read(4)
+        if not IIMM:
+            # empty file - first page
+            self.isFirst = True
+            return
+
+        self.isFirst = False
+        if IIMM == b"II\x2a\x00":
+            self.setEndian("<")
+        elif IIMM == b"MM\x00\x2a":
+            self.setEndian(">")
+        else:
+            raise RuntimeError("Invalid TIFF file header")
+
+        self.skipIFDs()
+        self.goToEnd()
+
+    def finalize(self):
+        if self.isFirst:
+            return
+
+        # fix offsets
+        self.f.seek(self.offsetOfNewPage)
+
+        IIMM = self.f.read(4)
+        if not IIMM:
+            # raise RuntimeError("nothing written into new page")
+            # Make it easy to finish a frame without committing to a new one.
+            return
+
+        if IIMM != self.IIMM:
+            raise RuntimeError("IIMM of new page doesn't match IIMM of first page")
+
+        IFDoffset = self.readLong()
+        IFDoffset += self.offsetOfNewPage
+        self.f.seek(self.whereToWriteNewIFDOffset)
+        self.writeLong(IFDoffset)
+        self.f.seek(IFDoffset)
+        self.fixIFD()
+
+    def newFrame(self):
+        # Call this to finish a frame.
+        self.finalize()
+        self.setup()
+
+    def __enter__(self):
+        return self
+
+    def __exit__(self, exc_type, exc_value, traceback):
+        if self.close_fp:
+            self.close()
+        return False
+
+    def tell(self):
+        return self.f.tell() - self.offsetOfNewPage
+
+    def seek(self, offset, whence=io.SEEK_SET):
+        if whence == os.SEEK_SET:
+            offset += self.offsetOfNewPage
+
+        self.f.seek(offset, whence)
+        return self.tell()
+
+    def goToEnd(self):
+        self.f.seek(0, os.SEEK_END)
+        pos = self.f.tell()
+
+        # pad to 16 byte boundary
+        padBytes = 16 - pos % 16
+        if 0 < padBytes < 16:
+            self.f.write(bytes(padBytes))
+        self.offsetOfNewPage = self.f.tell()
+
+    def setEndian(self, endian):
+        self.endian = endian
+        self.longFmt = self.endian + "L"
+        self.shortFmt = self.endian + "H"
+        self.tagFormat = self.endian + "HHL"
+
+    def skipIFDs(self):
+        while True:
+            IFDoffset = self.readLong()
+            if IFDoffset == 0:
+                self.whereToWriteNewIFDOffset = self.f.tell() - 4
+                break
+
+            self.f.seek(IFDoffset)
+            numTags = self.readShort()
+            self.f.seek(numTags * 12, os.SEEK_CUR)
+
+    def write(self, data):
+        return self.f.write(data)
+
+    def readShort(self):
+        (value,) = struct.unpack(self.shortFmt, self.f.read(2))
+        return value
+
+    def readLong(self):
+        (value,) = struct.unpack(self.longFmt, self.f.read(4))
+        return value
+
+    def rewriteLastShortToLong(self, value):
+        self.f.seek(-2, os.SEEK_CUR)
+        bytesWritten = self.f.write(struct.pack(self.longFmt, value))
+        if bytesWritten is not None and bytesWritten != 4:
+            raise RuntimeError(f"wrote only {bytesWritten} bytes but wanted 4")
+
+    def rewriteLastShort(self, value):
+        self.f.seek(-2, os.SEEK_CUR)
+        bytesWritten = self.f.write(struct.pack(self.shortFmt, value))
+        if bytesWritten is not None and bytesWritten != 2:
+            raise RuntimeError(f"wrote only {bytesWritten} bytes but wanted 2")
+
+    def rewriteLastLong(self, value):
+        self.f.seek(-4, os.SEEK_CUR)
+        bytesWritten = self.f.write(struct.pack(self.longFmt, value))
+        if bytesWritten is not None and bytesWritten != 4:
+            raise RuntimeError(f"wrote only {bytesWritten} bytes but wanted 4")
+
+    def writeShort(self, value):
+        bytesWritten = self.f.write(struct.pack(self.shortFmt, value))
+        if bytesWritten is not None and bytesWritten != 2:
+            raise RuntimeError(f"wrote only {bytesWritten} bytes but wanted 2")
+
+    def writeLong(self, value):
+        bytesWritten = self.f.write(struct.pack(self.longFmt, value))
+        if bytesWritten is not None and bytesWritten != 4:
+            raise RuntimeError(f"wrote only {bytesWritten} bytes but wanted 4")
+
+    def close(self):
+        self.finalize()
+        self.f.close()
+
+    def fixIFD(self):
+        numTags = self.readShort()
+
+        for i in range(numTags):
+            tag, fieldType, count = struct.unpack(self.tagFormat, self.f.read(8))
+
+            fieldSize = self.fieldSizes[fieldType]
+            totalSize = fieldSize * count
+            isLocal = totalSize <= 4
+            if not isLocal:
+                offset = self.readLong()
+                offset += self.offsetOfNewPage
+                self.rewriteLastLong(offset)
+
+            if tag in self.Tags:
+                curPos = self.f.tell()
+
+                if isLocal:
+                    self.fixOffsets(
+                        count, isShort=(fieldSize == 2), isLong=(fieldSize == 4)
+                    )
+                    self.f.seek(curPos + 4)
+                else:
+                    self.f.seek(offset)
+                    self.fixOffsets(
+                        count, isShort=(fieldSize == 2), isLong=(fieldSize == 4)
+                    )
+                    self.f.seek(curPos)
+
+                offset = curPos = None
+
+            elif isLocal:
+                # skip the locally stored value that is not an offset
+                self.f.seek(4, os.SEEK_CUR)
+
+    def fixOffsets(self, count, isShort=False, isLong=False):
+        if not isShort and not isLong:
+            raise RuntimeError("offset is neither short nor long")
+
+        for i in range(count):
+            offset = self.readShort() if isShort else self.readLong()
+            offset += self.offsetOfNewPage
+            if isShort and offset >= 65536:
+                # offset is now too large - we must convert shorts to longs
+                if count != 1:
+                    raise RuntimeError("not implemented")  # XXX TODO
+
+                # simple case - the offset is just one and therefore it is
+                # local (not referenced with another offset)
+                self.rewriteLastShortToLong(offset)
+                self.f.seek(-10, os.SEEK_CUR)
+                self.writeShort(TiffTags.LONG)  # rewrite the type to LONG
+                self.f.seek(8, os.SEEK_CUR)
+            elif isShort:
+                self.rewriteLastShort(offset)
+            else:
+                self.rewriteLastLong(offset)
+
+
+def _save_all(im, fp, filename):
+    encoderinfo = im.encoderinfo.copy()
+    encoderconfig = im.encoderconfig
+    append_images = list(encoderinfo.get("append_images", []))
+    if not hasattr(im, "n_frames") and not append_images:
+        return _save(im, fp, filename)
+
+    cur_idx = im.tell()
+    try:
+        with AppendingTiffWriter(fp) as tf:
+            for ims in [im] + append_images:
+                ims.encoderinfo = encoderinfo
+                ims.encoderconfig = encoderconfig
+                if not hasattr(ims, "n_frames"):
+                    nfr = 1
+                else:
+                    nfr = ims.n_frames
+
+                for idx in range(nfr):
+                    ims.seek(idx)
+                    ims.load()
+                    _save(ims, tf, filename)
+                    tf.newFrame()
+    finally:
+        im.seek(cur_idx)
+
+
+#
+# --------------------------------------------------------------------
+# Register
+
+Image.register_open(TiffImageFile.format, TiffImageFile, _accept)
+Image.register_save(TiffImageFile.format, _save)
+Image.register_save_all(TiffImageFile.format, _save_all)
+
+Image.register_extensions(TiffImageFile.format, [".tif", ".tiff"])
+
+Image.register_mime(TiffImageFile.format, "image/tiff")
diff --git a/.venv/lib/python3.7/site-packages/PIL/TiffTags.py b/.venv/lib/python3.7/site-packages/PIL/TiffTags.py
new file mode 100644
index 0000000..88856aa
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/TiffTags.py
@@ -0,0 +1,521 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# TIFF tags
+#
+# This module provides clear-text names for various well-known
+# TIFF tags.  the TIFF codec works just fine without it.
+#
+# Copyright (c) Secret Labs AB 1999.
+#
+# See the README file for information on usage and redistribution.
+#
+
+##
+# This module provides constants and clear-text names for various
+# well-known TIFF tags.
+##
+
+from collections import namedtuple
+
+
+class TagInfo(namedtuple("_TagInfo", "value name type length enum")):
+    __slots__ = []
+
+    def __new__(cls, value=None, name="unknown", type=None, length=None, enum=None):
+        return super().__new__(cls, value, name, type, length, enum or {})
+
+    def cvt_enum(self, value):
+        # Using get will call hash(value), which can be expensive
+        # for some types (e.g. Fraction). Since self.enum is rarely
+        # used, it's usually better to test it first.
+        return self.enum.get(value, value) if self.enum else value
+
+
+def lookup(tag, group=None):
+    """
+    :param tag: Integer tag number
+    :returns: Taginfo namedtuple, From the TAGS_V2 info if possible,
+        otherwise just populating the value and name from TAGS.
+        If the tag is not recognized, "unknown" is returned for the name
+
+    """
+
+    if group is not None:
+        info = TAGS_V2_GROUPS[group].get(tag) if group in TAGS_V2_GROUPS else None
+    else:
+        info = TAGS_V2.get(tag)
+    return info or TagInfo(tag, TAGS.get(tag, "unknown"))
+
+
+##
+# Map tag numbers to tag info.
+#
+#  id: (Name, Type, Length, enum_values)
+#
+# The length here differs from the length in the tiff spec.  For
+# numbers, the tiff spec is for the number of fields returned. We
+# agree here.  For string-like types, the tiff spec uses the length of
+# field in bytes.  In Pillow, we are using the number of expected
+# fields, in general 1 for string-like types.
+
+
+BYTE = 1
+ASCII = 2
+SHORT = 3
+LONG = 4
+RATIONAL = 5
+SIGNED_BYTE = 6
+UNDEFINED = 7
+SIGNED_SHORT = 8
+SIGNED_LONG = 9
+SIGNED_RATIONAL = 10
+FLOAT = 11
+DOUBLE = 12
+IFD = 13
+
+TAGS_V2 = {
+    254: ("NewSubfileType", LONG, 1),
+    255: ("SubfileType", SHORT, 1),
+    256: ("ImageWidth", LONG, 1),
+    257: ("ImageLength", LONG, 1),
+    258: ("BitsPerSample", SHORT, 0),
+    259: (
+        "Compression",
+        SHORT,
+        1,
+        {
+            "Uncompressed": 1,
+            "CCITT 1d": 2,
+            "Group 3 Fax": 3,
+            "Group 4 Fax": 4,
+            "LZW": 5,
+            "JPEG": 6,
+            "PackBits": 32773,
+        },
+    ),
+    262: (
+        "PhotometricInterpretation",
+        SHORT,
+        1,
+        {
+            "WhiteIsZero": 0,
+            "BlackIsZero": 1,
+            "RGB": 2,
+            "RGB Palette": 3,
+            "Transparency Mask": 4,
+            "CMYK": 5,
+            "YCbCr": 6,
+            "CieLAB": 8,
+            "CFA": 32803,  # TIFF/EP, Adobe DNG
+            "LinearRaw": 32892,  # Adobe DNG
+        },
+    ),
+    263: ("Threshholding", SHORT, 1),
+    264: ("CellWidth", SHORT, 1),
+    265: ("CellLength", SHORT, 1),
+    266: ("FillOrder", SHORT, 1),
+    269: ("DocumentName", ASCII, 1),
+    270: ("ImageDescription", ASCII, 1),
+    271: ("Make", ASCII, 1),
+    272: ("Model", ASCII, 1),
+    273: ("StripOffsets", LONG, 0),
+    274: ("Orientation", SHORT, 1),
+    277: ("SamplesPerPixel", SHORT, 1),
+    278: ("RowsPerStrip", LONG, 1),
+    279: ("StripByteCounts", LONG, 0),
+    280: ("MinSampleValue", SHORT, 0),
+    281: ("MaxSampleValue", SHORT, 0),
+    282: ("XResolution", RATIONAL, 1),
+    283: ("YResolution", RATIONAL, 1),
+    284: ("PlanarConfiguration", SHORT, 1, {"Contiguous": 1, "Separate": 2}),
+    285: ("PageName", ASCII, 1),
+    286: ("XPosition", RATIONAL, 1),
+    287: ("YPosition", RATIONAL, 1),
+    288: ("FreeOffsets", LONG, 1),
+    289: ("FreeByteCounts", LONG, 1),
+    290: ("GrayResponseUnit", SHORT, 1),
+    291: ("GrayResponseCurve", SHORT, 0),
+    292: ("T4Options", LONG, 1),
+    293: ("T6Options", LONG, 1),
+    296: ("ResolutionUnit", SHORT, 1, {"none": 1, "inch": 2, "cm": 3}),
+    297: ("PageNumber", SHORT, 2),
+    301: ("TransferFunction", SHORT, 0),
+    305: ("Software", ASCII, 1),
+    306: ("DateTime", ASCII, 1),
+    315: ("Artist", ASCII, 1),
+    316: ("HostComputer", ASCII, 1),
+    317: ("Predictor", SHORT, 1, {"none": 1, "Horizontal Differencing": 2}),
+    318: ("WhitePoint", RATIONAL, 2),
+    319: ("PrimaryChromaticities", RATIONAL, 6),
+    320: ("ColorMap", SHORT, 0),
+    321: ("HalftoneHints", SHORT, 2),
+    322: ("TileWidth", LONG, 1),
+    323: ("TileLength", LONG, 1),
+    324: ("TileOffsets", LONG, 0),
+    325: ("TileByteCounts", LONG, 0),
+    332: ("InkSet", SHORT, 1),
+    333: ("InkNames", ASCII, 1),
+    334: ("NumberOfInks", SHORT, 1),
+    336: ("DotRange", SHORT, 0),
+    337: ("TargetPrinter", ASCII, 1),
+    338: ("ExtraSamples", SHORT, 0),
+    339: ("SampleFormat", SHORT, 0),
+    340: ("SMinSampleValue", DOUBLE, 0),
+    341: ("SMaxSampleValue", DOUBLE, 0),
+    342: ("TransferRange", SHORT, 6),
+    347: ("JPEGTables", UNDEFINED, 1),
+    # obsolete JPEG tags
+    512: ("JPEGProc", SHORT, 1),
+    513: ("JPEGInterchangeFormat", LONG, 1),
+    514: ("JPEGInterchangeFormatLength", LONG, 1),
+    515: ("JPEGRestartInterval", SHORT, 1),
+    517: ("JPEGLosslessPredictors", SHORT, 0),
+    518: ("JPEGPointTransforms", SHORT, 0),
+    519: ("JPEGQTables", LONG, 0),
+    520: ("JPEGDCTables", LONG, 0),
+    521: ("JPEGACTables", LONG, 0),
+    529: ("YCbCrCoefficients", RATIONAL, 3),
+    530: ("YCbCrSubSampling", SHORT, 2),
+    531: ("YCbCrPositioning", SHORT, 1),
+    532: ("ReferenceBlackWhite", RATIONAL, 6),
+    700: ("XMP", BYTE, 0),
+    33432: ("Copyright", ASCII, 1),
+    33723: ("IptcNaaInfo", UNDEFINED, 1),
+    34377: ("PhotoshopInfo", BYTE, 0),
+    # FIXME add more tags here
+    34665: ("ExifIFD", LONG, 1),
+    34675: ("ICCProfile", UNDEFINED, 1),
+    34853: ("GPSInfoIFD", LONG, 1),
+    36864: ("ExifVersion", UNDEFINED, 1),
+    40965: ("InteroperabilityIFD", LONG, 1),
+    41730: ("CFAPattern", UNDEFINED, 1),
+    # MPInfo
+    45056: ("MPFVersion", UNDEFINED, 1),
+    45057: ("NumberOfImages", LONG, 1),
+    45058: ("MPEntry", UNDEFINED, 1),
+    45059: ("ImageUIDList", UNDEFINED, 0),  # UNDONE, check
+    45060: ("TotalFrames", LONG, 1),
+    45313: ("MPIndividualNum", LONG, 1),
+    45569: ("PanOrientation", LONG, 1),
+    45570: ("PanOverlap_H", RATIONAL, 1),
+    45571: ("PanOverlap_V", RATIONAL, 1),
+    45572: ("BaseViewpointNum", LONG, 1),
+    45573: ("ConvergenceAngle", SIGNED_RATIONAL, 1),
+    45574: ("BaselineLength", RATIONAL, 1),
+    45575: ("VerticalDivergence", SIGNED_RATIONAL, 1),
+    45576: ("AxisDistance_X", SIGNED_RATIONAL, 1),
+    45577: ("AxisDistance_Y", SIGNED_RATIONAL, 1),
+    45578: ("AxisDistance_Z", SIGNED_RATIONAL, 1),
+    45579: ("YawAngle", SIGNED_RATIONAL, 1),
+    45580: ("PitchAngle", SIGNED_RATIONAL, 1),
+    45581: ("RollAngle", SIGNED_RATIONAL, 1),
+    40960: ("FlashPixVersion", UNDEFINED, 1),
+    50741: ("MakerNoteSafety", SHORT, 1, {"Unsafe": 0, "Safe": 1}),
+    50780: ("BestQualityScale", RATIONAL, 1),
+    50838: ("ImageJMetaDataByteCounts", LONG, 0),  # Can be more than one
+    50839: ("ImageJMetaData", UNDEFINED, 1),  # see Issue #2006
+}
+TAGS_V2_GROUPS = {
+    # ExifIFD
+    34665: {
+        36864: ("ExifVersion", UNDEFINED, 1),
+        40960: ("FlashPixVersion", UNDEFINED, 1),
+        40965: ("InteroperabilityIFD", LONG, 1),
+        41730: ("CFAPattern", UNDEFINED, 1),
+    },
+    # GPSInfoIFD
+    34853: {},
+    # InteroperabilityIFD
+    40965: {1: ("InteropIndex", ASCII, 1), 2: ("InteropVersion", UNDEFINED, 1)},
+}
+
+# Legacy Tags structure
+# these tags aren't included above, but were in the previous versions
+TAGS = {
+    347: "JPEGTables",
+    700: "XMP",
+    # Additional Exif Info
+    32932: "Wang Annotation",
+    33434: "ExposureTime",
+    33437: "FNumber",
+    33445: "MD FileTag",
+    33446: "MD ScalePixel",
+    33447: "MD ColorTable",
+    33448: "MD LabName",
+    33449: "MD SampleInfo",
+    33450: "MD PrepDate",
+    33451: "MD PrepTime",
+    33452: "MD FileUnits",
+    33550: "ModelPixelScaleTag",
+    33723: "IptcNaaInfo",
+    33918: "INGR Packet Data Tag",
+    33919: "INGR Flag Registers",
+    33920: "IrasB Transformation Matrix",
+    33922: "ModelTiepointTag",
+    34264: "ModelTransformationTag",
+    34377: "PhotoshopInfo",
+    34735: "GeoKeyDirectoryTag",
+    34736: "GeoDoubleParamsTag",
+    34737: "GeoAsciiParamsTag",
+    34850: "ExposureProgram",
+    34852: "SpectralSensitivity",
+    34855: "ISOSpeedRatings",
+    34856: "OECF",
+    34864: "SensitivityType",
+    34865: "StandardOutputSensitivity",
+    34866: "RecommendedExposureIndex",
+    34867: "ISOSpeed",
+    34868: "ISOSpeedLatitudeyyy",
+    34869: "ISOSpeedLatitudezzz",
+    34908: "HylaFAX FaxRecvParams",
+    34909: "HylaFAX FaxSubAddress",
+    34910: "HylaFAX FaxRecvTime",
+    36864: "ExifVersion",
+    36867: "DateTimeOriginal",
+    36868: "DateTImeDigitized",
+    37121: "ComponentsConfiguration",
+    37122: "CompressedBitsPerPixel",
+    37724: "ImageSourceData",
+    37377: "ShutterSpeedValue",
+    37378: "ApertureValue",
+    37379: "BrightnessValue",
+    37380: "ExposureBiasValue",
+    37381: "MaxApertureValue",
+    37382: "SubjectDistance",
+    37383: "MeteringMode",
+    37384: "LightSource",
+    37385: "Flash",
+    37386: "FocalLength",
+    37396: "SubjectArea",
+    37500: "MakerNote",
+    37510: "UserComment",
+    37520: "SubSec",
+    37521: "SubSecTimeOriginal",
+    37522: "SubsecTimeDigitized",
+    40960: "FlashPixVersion",
+    40961: "ColorSpace",
+    40962: "PixelXDimension",
+    40963: "PixelYDimension",
+    40964: "RelatedSoundFile",
+    40965: "InteroperabilityIFD",
+    41483: "FlashEnergy",
+    41484: "SpatialFrequencyResponse",
+    41486: "FocalPlaneXResolution",
+    41487: "FocalPlaneYResolution",
+    41488: "FocalPlaneResolutionUnit",
+    41492: "SubjectLocation",
+    41493: "ExposureIndex",
+    41495: "SensingMethod",
+    41728: "FileSource",
+    41729: "SceneType",
+    41730: "CFAPattern",
+    41985: "CustomRendered",
+    41986: "ExposureMode",
+    41987: "WhiteBalance",
+    41988: "DigitalZoomRatio",
+    41989: "FocalLengthIn35mmFilm",
+    41990: "SceneCaptureType",
+    41991: "GainControl",
+    41992: "Contrast",
+    41993: "Saturation",
+    41994: "Sharpness",
+    41995: "DeviceSettingDescription",
+    41996: "SubjectDistanceRange",
+    42016: "ImageUniqueID",
+    42032: "CameraOwnerName",
+    42033: "BodySerialNumber",
+    42034: "LensSpecification",
+    42035: "LensMake",
+    42036: "LensModel",
+    42037: "LensSerialNumber",
+    42112: "GDAL_METADATA",
+    42113: "GDAL_NODATA",
+    42240: "Gamma",
+    50215: "Oce Scanjob Description",
+    50216: "Oce Application Selector",
+    50217: "Oce Identification Number",
+    50218: "Oce ImageLogic Characteristics",
+    # Adobe DNG
+    50706: "DNGVersion",
+    50707: "DNGBackwardVersion",
+    50708: "UniqueCameraModel",
+    50709: "LocalizedCameraModel",
+    50710: "CFAPlaneColor",
+    50711: "CFALayout",
+    50712: "LinearizationTable",
+    50713: "BlackLevelRepeatDim",
+    50714: "BlackLevel",
+    50715: "BlackLevelDeltaH",
+    50716: "BlackLevelDeltaV",
+    50717: "WhiteLevel",
+    50718: "DefaultScale",
+    50719: "DefaultCropOrigin",
+    50720: "DefaultCropSize",
+    50721: "ColorMatrix1",
+    50722: "ColorMatrix2",
+    50723: "CameraCalibration1",
+    50724: "CameraCalibration2",
+    50725: "ReductionMatrix1",
+    50726: "ReductionMatrix2",
+    50727: "AnalogBalance",
+    50728: "AsShotNeutral",
+    50729: "AsShotWhiteXY",
+    50730: "BaselineExposure",
+    50731: "BaselineNoise",
+    50732: "BaselineSharpness",
+    50733: "BayerGreenSplit",
+    50734: "LinearResponseLimit",
+    50735: "CameraSerialNumber",
+    50736: "LensInfo",
+    50737: "ChromaBlurRadius",
+    50738: "AntiAliasStrength",
+    50740: "DNGPrivateData",
+    50778: "CalibrationIlluminant1",
+    50779: "CalibrationIlluminant2",
+    50784: "Alias Layer Metadata",
+}
+
+
+def _populate():
+    for k, v in TAGS_V2.items():
+        # Populate legacy structure.
+        TAGS[k] = v[0]
+        if len(v) == 4:
+            for sk, sv in v[3].items():
+                TAGS[(k, sv)] = sk
+
+        TAGS_V2[k] = TagInfo(k, *v)
+
+    for group, tags in TAGS_V2_GROUPS.items():
+        for k, v in tags.items():
+            tags[k] = TagInfo(k, *v)
+
+
+_populate()
+##
+# Map type numbers to type names -- defined in ImageFileDirectory.
+
+TYPES = {}
+
+# was:
+# TYPES = {
+#     1: "byte",
+#     2: "ascii",
+#     3: "short",
+#     4: "long",
+#     5: "rational",
+#     6: "signed byte",
+#     7: "undefined",
+#     8: "signed short",
+#     9: "signed long",
+#     10: "signed rational",
+#     11: "float",
+#     12: "double",
+# }
+
+#
+# These tags are handled by default in libtiff, without
+# adding to the custom dictionary. From tif_dir.c, searching for
+# case TIFFTAG in the _TIFFVSetField function:
+# Line: item.
+# 148: case TIFFTAG_SUBFILETYPE:
+# 151: case TIFFTAG_IMAGEWIDTH:
+# 154: case TIFFTAG_IMAGELENGTH:
+# 157: case TIFFTAG_BITSPERSAMPLE:
+# 181: case TIFFTAG_COMPRESSION:
+# 202: case TIFFTAG_PHOTOMETRIC:
+# 205: case TIFFTAG_THRESHHOLDING:
+# 208: case TIFFTAG_FILLORDER:
+# 214: case TIFFTAG_ORIENTATION:
+# 221: case TIFFTAG_SAMPLESPERPIXEL:
+# 228: case TIFFTAG_ROWSPERSTRIP:
+# 238: case TIFFTAG_MINSAMPLEVALUE:
+# 241: case TIFFTAG_MAXSAMPLEVALUE:
+# 244: case TIFFTAG_SMINSAMPLEVALUE:
+# 247: case TIFFTAG_SMAXSAMPLEVALUE:
+# 250: case TIFFTAG_XRESOLUTION:
+# 256: case TIFFTAG_YRESOLUTION:
+# 262: case TIFFTAG_PLANARCONFIG:
+# 268: case TIFFTAG_XPOSITION:
+# 271: case TIFFTAG_YPOSITION:
+# 274: case TIFFTAG_RESOLUTIONUNIT:
+# 280: case TIFFTAG_PAGENUMBER:
+# 284: case TIFFTAG_HALFTONEHINTS:
+# 288: case TIFFTAG_COLORMAP:
+# 294: case TIFFTAG_EXTRASAMPLES:
+# 298: case TIFFTAG_MATTEING:
+# 305: case TIFFTAG_TILEWIDTH:
+# 316: case TIFFTAG_TILELENGTH:
+# 327: case TIFFTAG_TILEDEPTH:
+# 333: case TIFFTAG_DATATYPE:
+# 344: case TIFFTAG_SAMPLEFORMAT:
+# 361: case TIFFTAG_IMAGEDEPTH:
+# 364: case TIFFTAG_SUBIFD:
+# 376: case TIFFTAG_YCBCRPOSITIONING:
+# 379: case TIFFTAG_YCBCRSUBSAMPLING:
+# 383: case TIFFTAG_TRANSFERFUNCTION:
+# 389: case TIFFTAG_REFERENCEBLACKWHITE:
+# 393: case TIFFTAG_INKNAMES:
+
+# Following pseudo-tags are also handled by default in libtiff:
+# TIFFTAG_JPEGQUALITY 65537
+
+# some of these are not in our TAGS_V2 dict and were included from tiff.h
+
+# This list also exists in encode.c
+LIBTIFF_CORE = {
+    255,
+    256,
+    257,
+    258,
+    259,
+    262,
+    263,
+    266,
+    274,
+    277,
+    278,
+    280,
+    281,
+    340,
+    341,
+    282,
+    283,
+    284,
+    286,
+    287,
+    296,
+    297,
+    321,
+    320,
+    338,
+    32995,
+    322,
+    323,
+    32998,
+    32996,
+    339,
+    32997,
+    330,
+    531,
+    530,
+    301,
+    532,
+    333,
+    # as above
+    269,  # this has been in our tests forever, and works
+    65537,
+}
+
+LIBTIFF_CORE.remove(255)  # We don't have support for subfiletypes
+LIBTIFF_CORE.remove(322)  # We don't have support for writing tiled images with libtiff
+LIBTIFF_CORE.remove(323)  # Tiled images
+LIBTIFF_CORE.remove(333)  # Ink Names either
+
+# Note to advanced users: There may be combinations of these
+# parameters and values that when added properly, will work and
+# produce valid tiff images that may work in your application.
+# It is safe to add and remove tags from this set from Pillow's point
+# of view so long as you test against libtiff.
diff --git a/.venv/lib/python3.7/site-packages/PIL/WalImageFile.py b/.venv/lib/python3.7/site-packages/PIL/WalImageFile.py
new file mode 100644
index 0000000..1354ad3
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/WalImageFile.py
@@ -0,0 +1,127 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# WAL file handling
+#
+# History:
+# 2003-04-23 fl   created
+#
+# Copyright (c) 2003 by Fredrik Lundh.
+#
+# See the README file for information on usage and redistribution.
+#
+
+"""
+This reader is based on the specification available from:
+https://www.flipcode.com/archives/Quake_2_BSP_File_Format.shtml
+and has been tested with a few sample files found using google.
+
+.. note::
+    This format cannot be automatically recognized, so the reader
+    is not registered for use with :py:func:`PIL.Image.open()`.
+    To open a WAL file, use the :py:func:`PIL.WalImageFile.open()` function instead.
+"""
+
+from . import Image, ImageFile
+from ._binary import i32le as i32
+
+
+class WalImageFile(ImageFile.ImageFile):
+
+    format = "WAL"
+    format_description = "Quake2 Texture"
+
+    def _open(self):
+        self.mode = "P"
+
+        # read header fields
+        header = self.fp.read(32 + 24 + 32 + 12)
+        self._size = i32(header, 32), i32(header, 36)
+        Image._decompression_bomb_check(self.size)
+
+        # load pixel data
+        offset = i32(header, 40)
+        self.fp.seek(offset)
+
+        # strings are null-terminated
+        self.info["name"] = header[:32].split(b"\0", 1)[0]
+        next_name = header[56 : 56 + 32].split(b"\0", 1)[0]
+        if next_name:
+            self.info["next_name"] = next_name
+
+    def load(self):
+        if self.im:
+            # Already loaded
+            return
+
+        self.im = Image.core.new(self.mode, self.size)
+        self.frombytes(self.fp.read(self.size[0] * self.size[1]))
+        self.putpalette(quake2palette)
+        Image.Image.load(self)
+
+
+def open(filename):
+    """
+    Load texture from a Quake2 WAL texture file.
+
+    By default, a Quake2 standard palette is attached to the texture.
+    To override the palette, use the :py:func:`PIL.Image.Image.putpalette()` method.
+
+    :param filename: WAL file name, or an opened file handle.
+    :returns: An image instance.
+    """
+    return WalImageFile(filename)
+
+
+quake2palette = (
+    # default palette taken from piffo 0.93 by Hans Häggström
+    b"\x01\x01\x01\x0b\x0b\x0b\x12\x12\x12\x17\x17\x17\x1b\x1b\x1b\x1e"
+    b"\x1e\x1e\x22\x22\x22\x26\x26\x26\x29\x29\x29\x2c\x2c\x2c\x2f\x2f"
+    b"\x2f\x32\x32\x32\x35\x35\x35\x37\x37\x37\x3a\x3a\x3a\x3c\x3c\x3c"
+    b"\x24\x1e\x13\x22\x1c\x12\x20\x1b\x12\x1f\x1a\x10\x1d\x19\x10\x1b"
+    b"\x17\x0f\x1a\x16\x0f\x18\x14\x0d\x17\x13\x0d\x16\x12\x0d\x14\x10"
+    b"\x0b\x13\x0f\x0b\x10\x0d\x0a\x0f\x0b\x0a\x0d\x0b\x07\x0b\x0a\x07"
+    b"\x23\x23\x26\x22\x22\x25\x22\x20\x23\x21\x1f\x22\x20\x1e\x20\x1f"
+    b"\x1d\x1e\x1d\x1b\x1c\x1b\x1a\x1a\x1a\x19\x19\x18\x17\x17\x17\x16"
+    b"\x16\x14\x14\x14\x13\x13\x13\x10\x10\x10\x0f\x0f\x0f\x0d\x0d\x0d"
+    b"\x2d\x28\x20\x29\x24\x1c\x27\x22\x1a\x25\x1f\x17\x38\x2e\x1e\x31"
+    b"\x29\x1a\x2c\x25\x17\x26\x20\x14\x3c\x30\x14\x37\x2c\x13\x33\x28"
+    b"\x12\x2d\x24\x10\x28\x1f\x0f\x22\x1a\x0b\x1b\x14\x0a\x13\x0f\x07"
+    b"\x31\x1a\x16\x30\x17\x13\x2e\x16\x10\x2c\x14\x0d\x2a\x12\x0b\x27"
+    b"\x0f\x0a\x25\x0f\x07\x21\x0d\x01\x1e\x0b\x01\x1c\x0b\x01\x1a\x0b"
+    b"\x01\x18\x0a\x01\x16\x0a\x01\x13\x0a\x01\x10\x07\x01\x0d\x07\x01"
+    b"\x29\x23\x1e\x27\x21\x1c\x26\x20\x1b\x25\x1f\x1a\x23\x1d\x19\x21"
+    b"\x1c\x18\x20\x1b\x17\x1e\x19\x16\x1c\x18\x14\x1b\x17\x13\x19\x14"
+    b"\x10\x17\x13\x0f\x14\x10\x0d\x12\x0f\x0b\x0f\x0b\x0a\x0b\x0a\x07"
+    b"\x26\x1a\x0f\x23\x19\x0f\x20\x17\x0f\x1c\x16\x0f\x19\x13\x0d\x14"
+    b"\x10\x0b\x10\x0d\x0a\x0b\x0a\x07\x33\x22\x1f\x35\x29\x26\x37\x2f"
+    b"\x2d\x39\x35\x34\x37\x39\x3a\x33\x37\x39\x30\x34\x36\x2b\x31\x34"
+    b"\x27\x2e\x31\x22\x2b\x2f\x1d\x28\x2c\x17\x25\x2a\x0f\x20\x26\x0d"
+    b"\x1e\x25\x0b\x1c\x22\x0a\x1b\x20\x07\x19\x1e\x07\x17\x1b\x07\x14"
+    b"\x18\x01\x12\x16\x01\x0f\x12\x01\x0b\x0d\x01\x07\x0a\x01\x01\x01"
+    b"\x2c\x21\x21\x2a\x1f\x1f\x29\x1d\x1d\x27\x1c\x1c\x26\x1a\x1a\x24"
+    b"\x18\x18\x22\x17\x17\x21\x16\x16\x1e\x13\x13\x1b\x12\x12\x18\x10"
+    b"\x10\x16\x0d\x0d\x12\x0b\x0b\x0d\x0a\x0a\x0a\x07\x07\x01\x01\x01"
+    b"\x2e\x30\x29\x2d\x2e\x27\x2b\x2c\x26\x2a\x2a\x24\x28\x29\x23\x27"
+    b"\x27\x21\x26\x26\x1f\x24\x24\x1d\x22\x22\x1c\x1f\x1f\x1a\x1c\x1c"
+    b"\x18\x19\x19\x16\x17\x17\x13\x13\x13\x10\x0f\x0f\x0d\x0b\x0b\x0a"
+    b"\x30\x1e\x1b\x2d\x1c\x19\x2c\x1a\x17\x2a\x19\x14\x28\x17\x13\x26"
+    b"\x16\x10\x24\x13\x0f\x21\x12\x0d\x1f\x10\x0b\x1c\x0f\x0a\x19\x0d"
+    b"\x0a\x16\x0b\x07\x12\x0a\x07\x0f\x07\x01\x0a\x01\x01\x01\x01\x01"
+    b"\x28\x29\x38\x26\x27\x36\x25\x26\x34\x24\x24\x31\x22\x22\x2f\x20"
+    b"\x21\x2d\x1e\x1f\x2a\x1d\x1d\x27\x1b\x1b\x25\x19\x19\x21\x17\x17"
+    b"\x1e\x14\x14\x1b\x13\x12\x17\x10\x0f\x13\x0d\x0b\x0f\x0a\x07\x07"
+    b"\x2f\x32\x29\x2d\x30\x26\x2b\x2e\x24\x29\x2c\x21\x27\x2a\x1e\x25"
+    b"\x28\x1c\x23\x26\x1a\x21\x25\x18\x1e\x22\x14\x1b\x1f\x10\x19\x1c"
+    b"\x0d\x17\x1a\x0a\x13\x17\x07\x10\x13\x01\x0d\x0f\x01\x0a\x0b\x01"
+    b"\x01\x3f\x01\x13\x3c\x0b\x1b\x39\x10\x20\x35\x14\x23\x31\x17\x23"
+    b"\x2d\x18\x23\x29\x18\x3f\x3f\x3f\x3f\x3f\x39\x3f\x3f\x31\x3f\x3f"
+    b"\x2a\x3f\x3f\x20\x3f\x3f\x14\x3f\x3c\x12\x3f\x39\x0f\x3f\x35\x0b"
+    b"\x3f\x32\x07\x3f\x2d\x01\x3d\x2a\x01\x3b\x26\x01\x39\x21\x01\x37"
+    b"\x1d\x01\x34\x1a\x01\x32\x16\x01\x2f\x12\x01\x2d\x0f\x01\x2a\x0b"
+    b"\x01\x27\x07\x01\x23\x01\x01\x1d\x01\x01\x17\x01\x01\x10\x01\x01"
+    b"\x3d\x01\x01\x19\x19\x3f\x3f\x01\x01\x01\x01\x3f\x16\x16\x13\x10"
+    b"\x10\x0f\x0d\x0d\x0b\x3c\x2e\x2a\x36\x27\x20\x30\x21\x18\x29\x1b"
+    b"\x10\x3c\x39\x37\x37\x32\x2f\x31\x2c\x28\x2b\x26\x21\x30\x22\x20"
+)
diff --git a/.venv/lib/python3.7/site-packages/PIL/WebPImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/WebPImagePlugin.py
new file mode 100644
index 0000000..590161f
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/WebPImagePlugin.py
@@ -0,0 +1,351 @@
+from io import BytesIO
+
+from . import Image, ImageFile
+
+try:
+    from . import _webp
+
+    SUPPORTED = True
+except ImportError:
+    SUPPORTED = False
+
+
+_VALID_WEBP_MODES = {"RGBX": True, "RGBA": True, "RGB": True}
+
+_VALID_WEBP_LEGACY_MODES = {"RGB": True, "RGBA": True}
+
+_VP8_MODES_BY_IDENTIFIER = {
+    b"VP8 ": "RGB",
+    b"VP8X": "RGBA",
+    b"VP8L": "RGBA",  # lossless
+}
+
+
+def _accept(prefix):
+    is_riff_file_format = prefix[:4] == b"RIFF"
+    is_webp_file = prefix[8:12] == b"WEBP"
+    is_valid_vp8_mode = prefix[12:16] in _VP8_MODES_BY_IDENTIFIER
+
+    if is_riff_file_format and is_webp_file and is_valid_vp8_mode:
+        if not SUPPORTED:
+            return (
+                "image file could not be identified because WEBP support not installed"
+            )
+        return True
+
+
+class WebPImageFile(ImageFile.ImageFile):
+
+    format = "WEBP"
+    format_description = "WebP image"
+    __loaded = 0
+    __logical_frame = 0
+
+    def _open(self):
+        if not _webp.HAVE_WEBPANIM:
+            # Legacy mode
+            data, width, height, self.mode, icc_profile, exif = _webp.WebPDecode(
+                self.fp.read()
+            )
+            if icc_profile:
+                self.info["icc_profile"] = icc_profile
+            if exif:
+                self.info["exif"] = exif
+            self._size = width, height
+            self.fp = BytesIO(data)
+            self.tile = [("raw", (0, 0) + self.size, 0, self.mode)]
+            self.n_frames = 1
+            self.is_animated = False
+            return
+
+        # Use the newer AnimDecoder API to parse the (possibly) animated file,
+        # and access muxed chunks like ICC/EXIF/XMP.
+        self._decoder = _webp.WebPAnimDecoder(self.fp.read())
+
+        # Get info from decoder
+        width, height, loop_count, bgcolor, frame_count, mode = self._decoder.get_info()
+        self._size = width, height
+        self.info["loop"] = loop_count
+        bg_a, bg_r, bg_g, bg_b = (
+            (bgcolor >> 24) & 0xFF,
+            (bgcolor >> 16) & 0xFF,
+            (bgcolor >> 8) & 0xFF,
+            bgcolor & 0xFF,
+        )
+        self.info["background"] = (bg_r, bg_g, bg_b, bg_a)
+        self.n_frames = frame_count
+        self.is_animated = self.n_frames > 1
+        self.mode = "RGB" if mode == "RGBX" else mode
+        self.rawmode = mode
+        self.tile = []
+
+        # Attempt to read ICC / EXIF / XMP chunks from file
+        icc_profile = self._decoder.get_chunk("ICCP")
+        exif = self._decoder.get_chunk("EXIF")
+        xmp = self._decoder.get_chunk("XMP ")
+        if icc_profile:
+            self.info["icc_profile"] = icc_profile
+        if exif:
+            self.info["exif"] = exif
+        if xmp:
+            self.info["xmp"] = xmp
+
+        # Initialize seek state
+        self._reset(reset=False)
+
+    def _getexif(self):
+        if "exif" not in self.info:
+            return None
+        return self.getexif()._get_merged_dict()
+
+    def seek(self, frame):
+        if not self._seek_check(frame):
+            return
+
+        # Set logical frame to requested position
+        self.__logical_frame = frame
+
+    def _reset(self, reset=True):
+        if reset:
+            self._decoder.reset()
+        self.__physical_frame = 0
+        self.__loaded = -1
+        self.__timestamp = 0
+
+    def _get_next(self):
+        # Get next frame
+        ret = self._decoder.get_next()
+        self.__physical_frame += 1
+
+        # Check if an error occurred
+        if ret is None:
+            self._reset()  # Reset just to be safe
+            self.seek(0)
+            raise EOFError("failed to decode next frame in WebP file")
+
+        # Compute duration
+        data, timestamp = ret
+        duration = timestamp - self.__timestamp
+        self.__timestamp = timestamp
+
+        # libwebp gives frame end, adjust to start of frame
+        timestamp -= duration
+        return data, timestamp, duration
+
+    def _seek(self, frame):
+        if self.__physical_frame == frame:
+            return  # Nothing to do
+        if frame < self.__physical_frame:
+            self._reset()  # Rewind to beginning
+        while self.__physical_frame < frame:
+            self._get_next()  # Advance to the requested frame
+
+    def load(self):
+        if _webp.HAVE_WEBPANIM:
+            if self.__loaded != self.__logical_frame:
+                self._seek(self.__logical_frame)
+
+                # We need to load the image data for this frame
+                data, timestamp, duration = self._get_next()
+                self.info["timestamp"] = timestamp
+                self.info["duration"] = duration
+                self.__loaded = self.__logical_frame
+
+                # Set tile
+                if self.fp and self._exclusive_fp:
+                    self.fp.close()
+                self.fp = BytesIO(data)
+                self.tile = [("raw", (0, 0) + self.size, 0, self.rawmode)]
+
+        return super().load()
+
+    def tell(self):
+        if not _webp.HAVE_WEBPANIM:
+            return super().tell()
+
+        return self.__logical_frame
+
+
+def _save_all(im, fp, filename):
+    encoderinfo = im.encoderinfo.copy()
+    append_images = list(encoderinfo.get("append_images", []))
+
+    # If total frame count is 1, then save using the legacy API, which
+    # will preserve non-alpha modes
+    total = 0
+    for ims in [im] + append_images:
+        total += getattr(ims, "n_frames", 1)
+    if total == 1:
+        _save(im, fp, filename)
+        return
+
+    background = (0, 0, 0, 0)
+    if "background" in encoderinfo:
+        background = encoderinfo["background"]
+    elif "background" in im.info:
+        background = im.info["background"]
+        if isinstance(background, int):
+            # GifImagePlugin stores a global color table index in
+            # info["background"]. So it must be converted to an RGBA value
+            palette = im.getpalette()
+            if palette:
+                r, g, b = palette[background * 3 : (background + 1) * 3]
+                background = (r, g, b, 0)
+
+    duration = im.encoderinfo.get("duration", im.info.get("duration"))
+    loop = im.encoderinfo.get("loop", 0)
+    minimize_size = im.encoderinfo.get("minimize_size", False)
+    kmin = im.encoderinfo.get("kmin", None)
+    kmax = im.encoderinfo.get("kmax", None)
+    allow_mixed = im.encoderinfo.get("allow_mixed", False)
+    verbose = False
+    lossless = im.encoderinfo.get("lossless", False)
+    quality = im.encoderinfo.get("quality", 80)
+    method = im.encoderinfo.get("method", 0)
+    icc_profile = im.encoderinfo.get("icc_profile") or ""
+    exif = im.encoderinfo.get("exif", "")
+    if isinstance(exif, Image.Exif):
+        exif = exif.tobytes()
+    xmp = im.encoderinfo.get("xmp", "")
+    if allow_mixed:
+        lossless = False
+
+    # Sensible keyframe defaults are from gif2webp.c script
+    if kmin is None:
+        kmin = 9 if lossless else 3
+    if kmax is None:
+        kmax = 17 if lossless else 5
+
+    # Validate background color
+    if (
+        not isinstance(background, (list, tuple))
+        or len(background) != 4
+        or not all(v >= 0 and v < 256 for v in background)
+    ):
+        raise OSError(
+            "Background color is not an RGBA tuple clamped to (0-255): %s"
+            % str(background)
+        )
+
+    # Convert to packed uint
+    bg_r, bg_g, bg_b, bg_a = background
+    background = (bg_a << 24) | (bg_r << 16) | (bg_g << 8) | (bg_b << 0)
+
+    # Setup the WebP animation encoder
+    enc = _webp.WebPAnimEncoder(
+        im.size[0],
+        im.size[1],
+        background,
+        loop,
+        minimize_size,
+        kmin,
+        kmax,
+        allow_mixed,
+        verbose,
+    )
+
+    # Add each frame
+    frame_idx = 0
+    timestamp = 0
+    cur_idx = im.tell()
+    try:
+        for ims in [im] + append_images:
+            # Get # of frames in this image
+            nfr = getattr(ims, "n_frames", 1)
+
+            for idx in range(nfr):
+                ims.seek(idx)
+                ims.load()
+
+                # Make sure image mode is supported
+                frame = ims
+                rawmode = ims.mode
+                if ims.mode not in _VALID_WEBP_MODES:
+                    alpha = (
+                        "A" in ims.mode
+                        or "a" in ims.mode
+                        or (ims.mode == "P" and "A" in ims.im.getpalettemode())
+                    )
+                    rawmode = "RGBA" if alpha else "RGB"
+                    frame = ims.convert(rawmode)
+
+                if rawmode == "RGB":
+                    # For faster conversion, use RGBX
+                    rawmode = "RGBX"
+
+                # Append the frame to the animation encoder
+                enc.add(
+                    frame.tobytes("raw", rawmode),
+                    timestamp,
+                    frame.size[0],
+                    frame.size[1],
+                    rawmode,
+                    lossless,
+                    quality,
+                    method,
+                )
+
+                # Update timestamp and frame index
+                if isinstance(duration, (list, tuple)):
+                    timestamp += duration[frame_idx]
+                else:
+                    timestamp += duration
+                frame_idx += 1
+
+    finally:
+        im.seek(cur_idx)
+
+    # Force encoder to flush frames
+    enc.add(None, timestamp, 0, 0, "", lossless, quality, 0)
+
+    # Get the final output from the encoder
+    data = enc.assemble(icc_profile, exif, xmp)
+    if data is None:
+        raise OSError("cannot write file as WebP (encoder returned None)")
+
+    fp.write(data)
+
+
+def _save(im, fp, filename):
+    lossless = im.encoderinfo.get("lossless", False)
+    quality = im.encoderinfo.get("quality", 80)
+    icc_profile = im.encoderinfo.get("icc_profile") or ""
+    exif = im.encoderinfo.get("exif", "")
+    if isinstance(exif, Image.Exif):
+        exif = exif.tobytes()
+    xmp = im.encoderinfo.get("xmp", "")
+    method = im.encoderinfo.get("method", 4)
+
+    if im.mode not in _VALID_WEBP_LEGACY_MODES:
+        alpha = (
+            "A" in im.mode
+            or "a" in im.mode
+            or (im.mode == "P" and "transparency" in im.info)
+        )
+        im = im.convert("RGBA" if alpha else "RGB")
+
+    data = _webp.WebPEncode(
+        im.tobytes(),
+        im.size[0],
+        im.size[1],
+        lossless,
+        float(quality),
+        im.mode,
+        icc_profile,
+        method,
+        exif,
+        xmp,
+    )
+    if data is None:
+        raise OSError("cannot write file as WebP (encoder returned None)")
+
+    fp.write(data)
+
+
+Image.register_open(WebPImageFile.format, WebPImageFile, _accept)
+if SUPPORTED:
+    Image.register_save(WebPImageFile.format, _save)
+    if _webp.HAVE_WEBPANIM:
+        Image.register_save_all(WebPImageFile.format, _save_all)
+    Image.register_extension(WebPImageFile.format, ".webp")
+    Image.register_mime(WebPImageFile.format, "image/webp")
diff --git a/.venv/lib/python3.7/site-packages/PIL/WmfImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/WmfImagePlugin.py
new file mode 100644
index 0000000..27f5d2f
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/WmfImagePlugin.py
@@ -0,0 +1,178 @@
+#
+# The Python Imaging Library
+# $Id$
+#
+# WMF stub codec
+#
+# history:
+# 1996-12-14 fl   Created
+# 2004-02-22 fl   Turned into a stub driver
+# 2004-02-23 fl   Added EMF support
+#
+# Copyright (c) Secret Labs AB 1997-2004.  All rights reserved.
+# Copyright (c) Fredrik Lundh 1996.
+#
+# See the README file for information on usage and redistribution.
+#
+# WMF/EMF reference documentation:
+# https://winprotocoldoc.blob.core.windows.net/productionwindowsarchives/MS-WMF/[MS-WMF].pdf
+# http://wvware.sourceforge.net/caolan/index.html
+# http://wvware.sourceforge.net/caolan/ora-wmf.html
+
+from . import Image, ImageFile
+from ._binary import i16le as word
+from ._binary import i32le as dword
+from ._binary import si16le as short
+from ._binary import si32le as _long
+
+_handler = None
+
+
+def register_handler(handler):
+    """
+    Install application-specific WMF image handler.
+
+    :param handler: Handler object.
+    """
+    global _handler
+    _handler = handler
+
+
+if hasattr(Image.core, "drawwmf"):
+    # install default handler (windows only)
+
+    class WmfHandler:
+        def open(self, im):
+            im.mode = "RGB"
+            self.bbox = im.info["wmf_bbox"]
+
+        def load(self, im):
+            im.fp.seek(0)  # rewind
+            return Image.frombytes(
+                "RGB",
+                im.size,
+                Image.core.drawwmf(im.fp.read(), im.size, self.bbox),
+                "raw",
+                "BGR",
+                (im.size[0] * 3 + 3) & -4,
+                -1,
+            )
+
+    register_handler(WmfHandler())
+
+#
+# --------------------------------------------------------------------
+# Read WMF file
+
+
+def _accept(prefix):
+    return (
+        prefix[:6] == b"\xd7\xcd\xc6\x9a\x00\x00" or prefix[:4] == b"\x01\x00\x00\x00"
+    )
+
+
+##
+# Image plugin for Windows metafiles.
+
+
+class WmfStubImageFile(ImageFile.StubImageFile):
+
+    format = "WMF"
+    format_description = "Windows Metafile"
+
+    def _open(self):
+        self._inch = None
+
+        # check placable header
+        s = self.fp.read(80)
+
+        if s[:6] == b"\xd7\xcd\xc6\x9a\x00\x00":
+
+            # placeable windows metafile
+
+            # get units per inch
+            self._inch = word(s, 14)
+
+            # get bounding box
+            x0 = short(s, 6)
+            y0 = short(s, 8)
+            x1 = short(s, 10)
+            y1 = short(s, 12)
+
+            # normalize size to 72 dots per inch
+            self.info["dpi"] = 72
+            size = (
+                (x1 - x0) * self.info["dpi"] // self._inch,
+                (y1 - y0) * self.info["dpi"] // self._inch,
+            )
+
+            self.info["wmf_bbox"] = x0, y0, x1, y1
+
+            # sanity check (standard metafile header)
+            if s[22:26] != b"\x01\x00\t\x00":
+                raise SyntaxError("Unsupported WMF file format")
+
+        elif dword(s) == 1 and s[40:44] == b" EMF":
+            # enhanced metafile
+
+            # get bounding box
+            x0 = _long(s, 8)
+            y0 = _long(s, 12)
+            x1 = _long(s, 16)
+            y1 = _long(s, 20)
+
+            # get frame (in 0.01 millimeter units)
+            frame = _long(s, 24), _long(s, 28), _long(s, 32), _long(s, 36)
+
+            size = x1 - x0, y1 - y0
+
+            # calculate dots per inch from bbox and frame
+            xdpi = 2540.0 * (x1 - y0) / (frame[2] - frame[0])
+            ydpi = 2540.0 * (y1 - y0) / (frame[3] - frame[1])
+
+            self.info["wmf_bbox"] = x0, y0, x1, y1
+
+            if xdpi == ydpi:
+                self.info["dpi"] = xdpi
+            else:
+                self.info["dpi"] = xdpi, ydpi
+
+        else:
+            raise SyntaxError("Unsupported file format")
+
+        self.mode = "RGB"
+        self._size = size
+
+        loader = self._load()
+        if loader:
+            loader.open(self)
+
+    def _load(self):
+        return _handler
+
+    def load(self, dpi=None):
+        if dpi is not None and self._inch is not None:
+            self.info["dpi"] = dpi
+            x0, y0, x1, y1 = self.info["wmf_bbox"]
+            self._size = (
+                (x1 - x0) * self.info["dpi"] // self._inch,
+                (y1 - y0) * self.info["dpi"] // self._inch,
+            )
+        super().load()
+
+
+def _save(im, fp, filename):
+    if _handler is None or not hasattr(_handler, "save"):
+        raise OSError("WMF save handler not installed")
+    _handler.save(im, fp, filename)
+
+
+#
+# --------------------------------------------------------------------
+# Registry stuff
+
+
+Image.register_open(WmfStubImageFile.format, WmfStubImageFile, _accept)
+Image.register_save(WmfStubImageFile.format, _save)
+
+Image.register_extensions(WmfStubImageFile.format, [".wmf", ".emf"])
diff --git a/.venv/lib/python3.7/site-packages/PIL/XVThumbImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/XVThumbImagePlugin.py
new file mode 100644
index 0000000..4efedb7
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/XVThumbImagePlugin.py
@@ -0,0 +1,78 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# XV Thumbnail file handler by Charles E. "Gene" Cash
+# (gcash@magicnet.net)
+#
+# see xvcolor.c and xvbrowse.c in the sources to John Bradley's XV,
+# available from ftp://ftp.cis.upenn.edu/pub/xv/
+#
+# history:
+# 98-08-15 cec  created (b/w only)
+# 98-12-09 cec  added color palette
+# 98-12-28 fl   added to PIL (with only a few very minor modifications)
+#
+# To do:
+# FIXME: make save work (this requires quantization support)
+#
+
+from . import Image, ImageFile, ImagePalette
+from ._binary import o8
+
+_MAGIC = b"P7 332"
+
+# standard color palette for thumbnails (RGB332)
+PALETTE = b""
+for r in range(8):
+    for g in range(8):
+        for b in range(4):
+            PALETTE = PALETTE + (
+                o8((r * 255) // 7) + o8((g * 255) // 7) + o8((b * 255) // 3)
+            )
+
+
+def _accept(prefix):
+    return prefix[:6] == _MAGIC
+
+
+##
+# Image plugin for XV thumbnail images.
+
+
+class XVThumbImageFile(ImageFile.ImageFile):
+
+    format = "XVThumb"
+    format_description = "XV thumbnail image"
+
+    def _open(self):
+
+        # check magic
+        if not _accept(self.fp.read(6)):
+            raise SyntaxError("not an XV thumbnail file")
+
+        # Skip to beginning of next line
+        self.fp.readline()
+
+        # skip info comments
+        while True:
+            s = self.fp.readline()
+            if not s:
+                raise SyntaxError("Unexpected EOF reading XV thumbnail file")
+            if s[0] != 35:  # ie. when not a comment: '#'
+                break
+
+        # parse header line (already read)
+        s = s.strip().split()
+
+        self.mode = "P"
+        self._size = int(s[0]), int(s[1])
+
+        self.palette = ImagePalette.raw("RGB", PALETTE)
+
+        self.tile = [("raw", (0, 0) + self.size, self.fp.tell(), (self.mode, 0, 1))]
+
+
+# --------------------------------------------------------------------
+
+Image.register_open(XVThumbImageFile.format, XVThumbImageFile, _accept)
diff --git a/.venv/lib/python3.7/site-packages/PIL/XbmImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/XbmImagePlugin.py
new file mode 100644
index 0000000..644cfb3
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/XbmImagePlugin.py
@@ -0,0 +1,94 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# XBM File handling
+#
+# History:
+# 1995-09-08 fl   Created
+# 1996-11-01 fl   Added save support
+# 1997-07-07 fl   Made header parser more tolerant
+# 1997-07-22 fl   Fixed yet another parser bug
+# 2001-02-17 fl   Use 're' instead of 'regex' (Python 2.1) (0.4)
+# 2001-05-13 fl   Added hotspot handling (based on code from Bernhard Herzog)
+# 2004-02-24 fl   Allow some whitespace before first #define
+#
+# Copyright (c) 1997-2004 by Secret Labs AB
+# Copyright (c) 1996-1997 by Fredrik Lundh
+#
+# See the README file for information on usage and redistribution.
+#
+
+import re
+
+from . import Image, ImageFile
+
+# XBM header
+xbm_head = re.compile(
+    br"\s*#define[ \t]+.*_width[ \t]+(?P<width>[0-9]+)[\r\n]+"
+    b"#define[ \t]+.*_height[ \t]+(?P<height>[0-9]+)[\r\n]+"
+    b"(?P<hotspot>"
+    b"#define[ \t]+[^_]*_x_hot[ \t]+(?P<xhot>[0-9]+)[\r\n]+"
+    b"#define[ \t]+[^_]*_y_hot[ \t]+(?P<yhot>[0-9]+)[\r\n]+"
+    b")?"
+    b"[\\000-\\377]*_bits\\[\\]"
+)
+
+
+def _accept(prefix):
+    return prefix.lstrip()[:7] == b"#define"
+
+
+##
+# Image plugin for X11 bitmaps.
+
+
+class XbmImageFile(ImageFile.ImageFile):
+
+    format = "XBM"
+    format_description = "X11 Bitmap"
+
+    def _open(self):
+
+        m = xbm_head.match(self.fp.read(512))
+
+        if m:
+
+            xsize = int(m.group("width"))
+            ysize = int(m.group("height"))
+
+            if m.group("hotspot"):
+                self.info["hotspot"] = (int(m.group("xhot")), int(m.group("yhot")))
+
+            self.mode = "1"
+            self._size = xsize, ysize
+
+            self.tile = [("xbm", (0, 0) + self.size, m.end(), None)]
+
+
+def _save(im, fp, filename):
+
+    if im.mode != "1":
+        raise OSError(f"cannot write mode {im.mode} as XBM")
+
+    fp.write(f"#define im_width {im.size[0]}\n".encode("ascii"))
+    fp.write(f"#define im_height {im.size[1]}\n".encode("ascii"))
+
+    hotspot = im.encoderinfo.get("hotspot")
+    if hotspot:
+        fp.write(f"#define im_x_hot {hotspot[0]}\n".encode("ascii"))
+        fp.write(f"#define im_y_hot {hotspot[1]}\n".encode("ascii"))
+
+    fp.write(b"static char im_bits[] = {\n")
+
+    ImageFile._save(im, fp, [("xbm", (0, 0) + im.size, 0, None)])
+
+    fp.write(b"};\n")
+
+
+Image.register_open(XbmImageFile.format, XbmImageFile, _accept)
+Image.register_save(XbmImageFile.format, _save)
+
+Image.register_extension(XbmImageFile.format, ".xbm")
+
+Image.register_mime(XbmImageFile.format, "image/xbm")
diff --git a/.venv/lib/python3.7/site-packages/PIL/XpmImagePlugin.py b/.venv/lib/python3.7/site-packages/PIL/XpmImagePlugin.py
new file mode 100644
index 0000000..ebd65ba
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/XpmImagePlugin.py
@@ -0,0 +1,130 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# XPM File handling
+#
+# History:
+# 1996-12-29 fl   Created
+# 2001-02-17 fl   Use 're' instead of 'regex' (Python 2.1) (0.7)
+#
+# Copyright (c) Secret Labs AB 1997-2001.
+# Copyright (c) Fredrik Lundh 1996-2001.
+#
+# See the README file for information on usage and redistribution.
+#
+
+
+import re
+
+from . import Image, ImageFile, ImagePalette
+from ._binary import o8
+
+# XPM header
+xpm_head = re.compile(b'"([0-9]*) ([0-9]*) ([0-9]*) ([0-9]*)')
+
+
+def _accept(prefix):
+    return prefix[:9] == b"/* XPM */"
+
+
+##
+# Image plugin for X11 pixel maps.
+
+
+class XpmImageFile(ImageFile.ImageFile):
+
+    format = "XPM"
+    format_description = "X11 Pixel Map"
+
+    def _open(self):
+
+        if not _accept(self.fp.read(9)):
+            raise SyntaxError("not an XPM file")
+
+        # skip forward to next string
+        while True:
+            s = self.fp.readline()
+            if not s:
+                raise SyntaxError("broken XPM file")
+            m = xpm_head.match(s)
+            if m:
+                break
+
+        self._size = int(m.group(1)), int(m.group(2))
+
+        pal = int(m.group(3))
+        bpp = int(m.group(4))
+
+        if pal > 256 or bpp != 1:
+            raise ValueError("cannot read this XPM file")
+
+        #
+        # load palette description
+
+        palette = [b"\0\0\0"] * 256
+
+        for i in range(pal):
+
+            s = self.fp.readline()
+            if s[-2:] == b"\r\n":
+                s = s[:-2]
+            elif s[-1:] in b"\r\n":
+                s = s[:-1]
+
+            c = s[1]
+            s = s[2:-2].split()
+
+            for i in range(0, len(s), 2):
+
+                if s[i] == b"c":
+
+                    # process colour key
+                    rgb = s[i + 1]
+                    if rgb == b"None":
+                        self.info["transparency"] = c
+                    elif rgb[0:1] == b"#":
+                        # FIXME: handle colour names (see ImagePalette.py)
+                        rgb = int(rgb[1:], 16)
+                        palette[c] = (
+                            o8((rgb >> 16) & 255) + o8((rgb >> 8) & 255) + o8(rgb & 255)
+                        )
+                    else:
+                        # unknown colour
+                        raise ValueError("cannot read this XPM file")
+                    break
+
+            else:
+
+                # missing colour key
+                raise ValueError("cannot read this XPM file")
+
+        self.mode = "P"
+        self.palette = ImagePalette.raw("RGB", b"".join(palette))
+
+        self.tile = [("raw", (0, 0) + self.size, self.fp.tell(), ("P", 0, 1))]
+
+    def load_read(self, bytes):
+
+        #
+        # load all image data in one chunk
+
+        xsize, ysize = self.size
+
+        s = [None] * ysize
+
+        for i in range(ysize):
+            s[i] = self.fp.readline()[1 : xsize + 1].ljust(xsize)
+
+        return b"".join(s)
+
+
+#
+# Registry
+
+
+Image.register_open(XpmImageFile.format, XpmImageFile, _accept)
+
+Image.register_extension(XpmImageFile.format, ".xpm")
+
+Image.register_mime(XpmImageFile.format, "image/xpm")
diff --git a/.venv/lib/python3.7/site-packages/PIL/__init__.py b/.venv/lib/python3.7/site-packages/PIL/__init__.py
new file mode 100644
index 0000000..45fef24
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/__init__.py
@@ -0,0 +1,79 @@
+"""Pillow (Fork of the Python Imaging Library)
+
+Pillow is the friendly PIL fork by Alex Clark and Contributors.
+    https://github.com/python-pillow/Pillow/
+
+Pillow is forked from PIL 1.1.7.
+
+PIL is the Python Imaging Library by Fredrik Lundh and Contributors.
+Copyright (c) 1999 by Secret Labs AB.
+
+Use PIL.__version__ for this Pillow version.
+
+;-)
+"""
+
+from . import _version
+
+# VERSION was removed in Pillow 6.0.0.
+# PILLOW_VERSION was removed in Pillow 9.0.0.
+# Use __version__ instead.
+__version__ = _version.__version__
+del _version
+
+
+_plugins = [
+    "BlpImagePlugin",
+    "BmpImagePlugin",
+    "BufrStubImagePlugin",
+    "CurImagePlugin",
+    "DcxImagePlugin",
+    "DdsImagePlugin",
+    "EpsImagePlugin",
+    "FitsStubImagePlugin",
+    "FliImagePlugin",
+    "FpxImagePlugin",
+    "FtexImagePlugin",
+    "GbrImagePlugin",
+    "GifImagePlugin",
+    "GribStubImagePlugin",
+    "Hdf5StubImagePlugin",
+    "IcnsImagePlugin",
+    "IcoImagePlugin",
+    "ImImagePlugin",
+    "ImtImagePlugin",
+    "IptcImagePlugin",
+    "JpegImagePlugin",
+    "Jpeg2KImagePlugin",
+    "McIdasImagePlugin",
+    "MicImagePlugin",
+    "MpegImagePlugin",
+    "MpoImagePlugin",
+    "MspImagePlugin",
+    "PalmImagePlugin",
+    "PcdImagePlugin",
+    "PcxImagePlugin",
+    "PdfImagePlugin",
+    "PixarImagePlugin",
+    "PngImagePlugin",
+    "PpmImagePlugin",
+    "PsdImagePlugin",
+    "SgiImagePlugin",
+    "SpiderImagePlugin",
+    "SunImagePlugin",
+    "TgaImagePlugin",
+    "TiffImagePlugin",
+    "WebPImagePlugin",
+    "WmfImagePlugin",
+    "XbmImagePlugin",
+    "XpmImagePlugin",
+    "XVThumbImagePlugin",
+]
+
+
+class UnidentifiedImageError(OSError):
+    """
+    Raised in :py:meth:`PIL.Image.open` if an image cannot be opened and identified.
+    """
+
+    pass
diff --git a/.venv/lib/python3.7/site-packages/PIL/__main__.py b/.venv/lib/python3.7/site-packages/PIL/__main__.py
new file mode 100644
index 0000000..a05323f
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/__main__.py
@@ -0,0 +1,3 @@
+from .features import pilinfo
+
+pilinfo()
diff --git a/.venv/lib/python3.7/site-packages/PIL/_binary.py b/.venv/lib/python3.7/site-packages/PIL/_binary.py
new file mode 100644
index 0000000..a74ee9e
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/_binary.py
@@ -0,0 +1,102 @@
+#
+# The Python Imaging Library.
+# $Id$
+#
+# Binary input/output support routines.
+#
+# Copyright (c) 1997-2003 by Secret Labs AB
+# Copyright (c) 1995-2003 by Fredrik Lundh
+# Copyright (c) 2012 by Brian Crowell
+#
+# See the README file for information on usage and redistribution.
+#
+
+
+"""Binary input/output support routines."""
+
+
+from struct import pack, unpack_from
+
+
+def i8(c):
+    return c if c.__class__ is int else c[0]
+
+
+def o8(i):
+    return bytes((i & 255,))
+
+
+# Input, le = little endian, be = big endian
+def i16le(c, o=0):
+    """
+    Converts a 2-bytes (16 bits) string to an unsigned integer.
+
+    :param c: string containing bytes to convert
+    :param o: offset of bytes to convert in string
+    """
+    return unpack_from("<H", c, o)[0]
+
+
+def si16le(c, o=0):
+    """
+    Converts a 2-bytes (16 bits) string to a signed integer.
+
+    :param c: string containing bytes to convert
+    :param o: offset of bytes to convert in string
+    """
+    return unpack_from("<h", c, o)[0]
+
+
+def si16be(c, o=0):
+    """
+    Converts a 2-bytes (16 bits) string to a signed integer, big endian.
+
+    :param c: string containing bytes to convert
+    :param o: offset of bytes to convert in string
+    """
+    return unpack_from(">h", c, o)[0]
+
+
+def i32le(c, o=0):
+    """
+    Converts a 4-bytes (32 bits) string to an unsigned integer.
+
+    :param c: string containing bytes to convert
+    :param o: offset of bytes to convert in string
+    """
+    return unpack_from("<I", c, o)[0]
+
+
+def si32le(c, o=0):
+    """
+    Converts a 4-bytes (32 bits) string to a signed integer.
+
+    :param c: string containing bytes to convert
+    :param o: offset of bytes to convert in string
+    """
+    return unpack_from("<i", c, o)[0]
+
+
+def i16be(c, o=0):
+    return unpack_from(">H", c, o)[0]
+
+
+def i32be(c, o=0):
+    return unpack_from(">I", c, o)[0]
+
+
+# Output, le = little endian, be = big endian
+def o16le(i):
+    return pack("<H", i)
+
+
+def o32le(i):
+    return pack("<I", i)
+
+
+def o16be(i):
+    return pack(">H", i)
+
+
+def o32be(i):
+    return pack(">I", i)
diff --git a/.venv/lib/python3.7/site-packages/PIL/_tkinter_finder.py b/.venv/lib/python3.7/site-packages/PIL/_tkinter_finder.py
new file mode 100644
index 0000000..ba4d045
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/_tkinter_finder.py
@@ -0,0 +1,20 @@
+""" Find compiled module linking to Tcl / Tk libraries
+"""
+import sys
+import tkinter
+import warnings
+from tkinter import _tkinter as tk
+
+if hasattr(sys, "pypy_find_executable"):
+    TKINTER_LIB = tk.tklib_cffi.__file__
+else:
+    TKINTER_LIB = tk.__file__
+
+tk_version = str(tkinter.TkVersion)
+if tk_version == "8.4":
+    warnings.warn(
+        "Support for Tk/Tcl 8.4 is deprecated and will be removed"
+        " in Pillow 10 (2023-07-01). Please upgrade to Tk/Tcl 8.5 "
+        "or newer.",
+        DeprecationWarning,
+    )
diff --git a/.venv/lib/python3.7/site-packages/PIL/_util.py b/.venv/lib/python3.7/site-packages/PIL/_util.py
new file mode 100644
index 0000000..0c5d389
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/_util.py
@@ -0,0 +1,19 @@
+import os
+from pathlib import Path
+
+
+def isPath(f):
+    return isinstance(f, (bytes, str, Path))
+
+
+# Checks if an object is a string, and that it points to a directory.
+def isDirectory(f):
+    return isPath(f) and os.path.isdir(f)
+
+
+class deferred_error:
+    def __init__(self, ex):
+        self.ex = ex
+
+    def __getattr__(self, elt):
+        raise self.ex
diff --git a/.venv/lib/python3.7/site-packages/PIL/_version.py b/.venv/lib/python3.7/site-packages/PIL/_version.py
new file mode 100644
index 0000000..694841a
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/_version.py
@@ -0,0 +1,2 @@
+# Master version for Pillow
+__version__ = "9.0.1"
diff --git a/.venv/lib/python3.7/site-packages/PIL/features.py b/.venv/lib/python3.7/site-packages/PIL/features.py
new file mode 100644
index 0000000..3838568
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PIL/features.py
@@ -0,0 +1,320 @@
+import collections
+import os
+import sys
+import warnings
+
+import PIL
+
+from . import Image
+
+modules = {
+    "pil": ("PIL._imaging", "PILLOW_VERSION"),
+    "tkinter": ("PIL._tkinter_finder", "tk_version"),
+    "freetype2": ("PIL._imagingft", "freetype2_version"),
+    "littlecms2": ("PIL._imagingcms", "littlecms_version"),
+    "webp": ("PIL._webp", "webpdecoder_version"),
+}
+
+
+def check_module(feature):
+    """
+    Checks if a module is available.
+
+    :param feature: The module to check for.
+    :returns: ``True`` if available, ``False`` otherwise.
+    :raises ValueError: If the module is not defined in this version of Pillow.
+    """
+    if not (feature in modules):
+        raise ValueError(f"Unknown module {feature}")
+
+    module, ver = modules[feature]
+
+    try:
+        __import__(module)
+        return True
+    except ImportError:
+        return False
+
+
+def version_module(feature):
+    """
+    :param feature: The module to check for.
+    :returns:
+        The loaded version number as a string, or ``None`` if unknown or not available.
+    :raises ValueError: If the module is not defined in this version of Pillow.
+    """
+    if not check_module(feature):
+        return None
+
+    module, ver = modules[feature]
+
+    if ver is None:
+        return None
+
+    return getattr(__import__(module, fromlist=[ver]), ver)
+
+
+def get_supported_modules():
+    """
+    :returns: A list of all supported modules.
+    """
+    return [f for f in modules if check_module(f)]
+
+
+codecs = {
+    "jpg": ("jpeg", "jpeglib"),
+    "jpg_2000": ("jpeg2k", "jp2klib"),
+    "zlib": ("zip", "zlib"),
+    "libtiff": ("libtiff", "libtiff"),
+}
+
+
+def check_codec(feature):
+    """
+    Checks if a codec is available.
+
+    :param feature: The codec to check for.
+    :returns: ``True`` if available, ``False`` otherwise.
+    :raises ValueError: If the codec is not defined in this version of Pillow.
+    """
+    if feature not in codecs:
+        raise ValueError(f"Unknown codec {feature}")
+
+    codec, lib = codecs[feature]
+
+    return codec + "_encoder" in dir(Image.core)
+
+
+def version_codec(feature):
+    """
+    :param feature: The codec to check for.
+    :returns:
+        The version number as a string, or ``None`` if not available.
+        Checked at compile time for ``jpg``, run-time otherwise.
+    :raises ValueError: If the codec is not defined in this version of Pillow.
+    """
+    if not check_codec(feature):
+        return None
+
+    codec, lib = codecs[feature]
+
+    version = getattr(Image.core, lib + "_version")
+
+    if feature == "libtiff":
+        return version.split("\n")[0].split("Version ")[1]
+
+    return version
+
+
+def get_supported_codecs():
+    """
+    :returns: A list of all supported codecs.
+    """
+    return [f for f in codecs if check_codec(f)]
+
+
+features = {
+    "webp_anim": ("PIL._webp", "HAVE_WEBPANIM", None),
+    "webp_mux": ("PIL._webp", "HAVE_WEBPMUX", None),
+    "transp_webp": ("PIL._webp", "HAVE_TRANSPARENCY", None),
+    "raqm": ("PIL._imagingft", "HAVE_RAQM", "raqm_version"),
+    "fribidi": ("PIL._imagingft", "HAVE_FRIBIDI", "fribidi_version"),
+    "harfbuzz": ("PIL._imagingft", "HAVE_HARFBUZZ", "harfbuzz_version"),
+    "libjpeg_turbo": ("PIL._imaging", "HAVE_LIBJPEGTURBO", "libjpeg_turbo_version"),
+    "libimagequant": ("PIL._imaging", "HAVE_LIBIMAGEQUANT", "imagequant_version"),
+    "xcb": ("PIL._imaging", "HAVE_XCB", None),
+}
+
+
+def check_feature(feature):
+    """
+    Checks if a feature is available.
+
+    :param feature: The feature to check for.
+    :returns: ``True`` if available, ``False`` if unavailable, ``None`` if unknown.
+    :raises ValueError: If the feature is not defined in this version of Pillow.
+    """
+    if feature not in features:
+        raise ValueError(f"Unknown feature {feature}")
+
+    module, flag, ver = features[feature]
+
+    try:
+        imported_module = __import__(module, fromlist=["PIL"])
+        return getattr(imported_module, flag)
+    except ImportError:
+        return None
+
+
+def version_feature(feature):
+    """
+    :param feature: The feature to check for.
+    :returns: The version number as a string, or ``None`` if not available.
+    :raises ValueError: If the feature is not defined in this version of Pillow.
+    """
+    if not check_feature(feature):
+        return None
+
+    module, flag, ver = features[feature]
+
+    if ver is None:
+        return None
+
+    return getattr(__import__(module, fromlist=[ver]), ver)
+
+
+def get_supported_features():
+    """
+    :returns: A list of all supported features.
+    """
+    return [f for f in features if check_feature(f)]
+
+
+def check(feature):
+    """
+    :param feature: A module, codec, or feature name.
+    :returns:
+        ``True`` if the module, codec, or feature is available,
+        ``False`` or ``None`` otherwise.
+    """
+
+    if feature in modules:
+        return check_module(feature)
+    if feature in codecs:
+        return check_codec(feature)
+    if feature in features:
+        return check_feature(feature)
+    warnings.warn(f"Unknown feature '{feature}'.", stacklevel=2)
+    return False
+
+
+def version(feature):
+    """
+    :param feature:
+        The module, codec, or feature to check for.
+    :returns:
+        The version number as a string, or ``None`` if unknown or not available.
+    """
+    if feature in modules:
+        return version_module(feature)
+    if feature in codecs:
+        return version_codec(feature)
+    if feature in features:
+        return version_feature(feature)
+    return None
+
+
+def get_supported():
+    """
+    :returns: A list of all supported modules, features, and codecs.
+    """
+
+    ret = get_supported_modules()
+    ret.extend(get_supported_features())
+    ret.extend(get_supported_codecs())
+    return ret
+
+
+def pilinfo(out=None, supported_formats=True):
+    """
+    Prints information about this installation of Pillow.
+    This function can be called with ``python3 -m PIL``.
+
+    :param out:
+        The output stream to print to. Defaults to ``sys.stdout`` if ``None``.
+    :param supported_formats:
+        If ``True``, a list of all supported image file formats will be printed.
+    """
+
+    if out is None:
+        out = sys.stdout
+
+    Image.init()
+
+    print("-" * 68, file=out)
+    print(f"Pillow {PIL.__version__}", file=out)
+    py_version = sys.version.splitlines()
+    print(f"Python {py_version[0].strip()}", file=out)
+    for py_version in py_version[1:]:
+        print(f"       {py_version.strip()}", file=out)
+    print("-" * 68, file=out)
+    print(
+        f"Python modules loaded from {os.path.dirname(Image.__file__)}",
+        file=out,
+    )
+    print(
+        f"Binary modules loaded from {os.path.dirname(Image.core.__file__)}",
+        file=out,
+    )
+    print("-" * 68, file=out)
+
+    for name, feature in [
+        ("pil", "PIL CORE"),
+        ("tkinter", "TKINTER"),
+        ("freetype2", "FREETYPE2"),
+        ("littlecms2", "LITTLECMS2"),
+        ("webp", "WEBP"),
+        ("transp_webp", "WEBP Transparency"),
+        ("webp_mux", "WEBPMUX"),
+        ("webp_anim", "WEBP Animation"),
+        ("jpg", "JPEG"),
+        ("jpg_2000", "OPENJPEG (JPEG2000)"),
+        ("zlib", "ZLIB (PNG/ZIP)"),
+        ("libtiff", "LIBTIFF"),
+        ("raqm", "RAQM (Bidirectional Text)"),
+        ("libimagequant", "LIBIMAGEQUANT (Quantization method)"),
+        ("xcb", "XCB (X protocol)"),
+    ]:
+        if check(name):
+            if name == "jpg" and check_feature("libjpeg_turbo"):
+                v = "libjpeg-turbo " + version_feature("libjpeg_turbo")
+            else:
+                v = version(name)
+            if v is not None:
+                version_static = name in ("pil", "jpg")
+                if name == "littlecms2":
+                    # this check is also in src/_imagingcms.c:setup_module()
+                    version_static = tuple(int(x) for x in v.split(".")) < (2, 7)
+                t = "compiled for" if version_static else "loaded"
+                if name == "raqm":
+                    for f in ("fribidi", "harfbuzz"):
+                        v2 = version_feature(f)
+                        if v2 is not None:
+                            v += f", {f} {v2}"
+                print("---", feature, "support ok,", t, v, file=out)
+            else:
+                print("---", feature, "support ok", file=out)
+        else:
+            print("***", feature, "support not installed", file=out)
+    print("-" * 68, file=out)
+
+    if supported_formats:
+        extensions = collections.defaultdict(list)
+        for ext, i in Image.EXTENSION.items():
+            extensions[i].append(ext)
+
+        for i in sorted(Image.ID):
+            line = f"{i}"
+            if i in Image.MIME:
+                line = f"{line} {Image.MIME[i]}"
+            print(line, file=out)
+
+            if i in extensions:
+                print(
+                    "Extensions: {}".format(", ".join(sorted(extensions[i]))), file=out
+                )
+
+            features = []
+            if i in Image.OPEN:
+                features.append("open")
+            if i in Image.SAVE:
+                features.append("save")
+            if i in Image.SAVE_ALL:
+                features.append("save_all")
+            if i in Image.DECODERS:
+                features.append("decode")
+            if i in Image.ENCODERS:
+                features.append("encode")
+
+            print("Features: {}".format(", ".join(features)), file=out)
+            print("-" * 68, file=out)
diff --git a/.venv/lib/python3.7/site-packages/Pillow-9.0.1.dist-info/INSTALLER b/.venv/lib/python3.7/site-packages/Pillow-9.0.1.dist-info/INSTALLER
new file mode 100644
index 0000000..a1b589e
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/Pillow-9.0.1.dist-info/INSTALLER
@@ -0,0 +1 @@
+pip
diff --git a/.venv/lib/python3.7/site-packages/Pillow-9.0.1.dist-info/LICENSE b/.venv/lib/python3.7/site-packages/Pillow-9.0.1.dist-info/LICENSE
new file mode 100644
index 0000000..4cac92a
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/Pillow-9.0.1.dist-info/LICENSE
@@ -0,0 +1,636 @@
+The Python Imaging Library (PIL) is
+
+    Copyright © 1997-2011 by Secret Labs AB
+    Copyright © 1995-2011 by Fredrik Lundh
+
+Pillow is the friendly PIL fork. It is
+
+    Copyright © 2010-2022 by Alex Clark and contributors
+
+Like PIL, Pillow is licensed under the open source HPND License:
+
+By obtaining, using, and/or copying this software and/or its associated
+documentation, you agree that you have read, understood, and will comply
+with the following terms and conditions:
+
+Permission to use, copy, modify, and distribute this software and its
+associated documentation for any purpose and without fee is hereby granted,
+provided that the above copyright notice appears in all copies, and that
+both that copyright notice and this permission notice appear in supporting
+documentation, and that the name of Secret Labs AB or the author not be
+used in advertising or publicity pertaining to distribution of the software
+without specific, written prior permission.
+
+SECRET LABS AB AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS
+SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS.
+IN NO EVENT SHALL SECRET LABS AB OR THE AUTHOR BE LIABLE FOR ANY SPECIAL,
+INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
+LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE
+OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
+PERFORMANCE OF THIS SOFTWARE.
+
+
+----
+
+FREETYPE2
+
+The  FreeType 2  font  engine is  copyrighted  work and  cannot be  used
+legally  without a  software license.   In  order to  make this  project
+usable  to a vast  majority of  developers, we  distribute it  under two
+mutually exclusive open-source licenses.
+
+This means  that *you* must choose  *one* of the  two licenses described
+below, then obey  all its terms and conditions when  using FreeType 2 in
+any of your projects or products.
+
+  - The FreeType License, found in  the file `FTL.TXT', which is similar
+    to the original BSD license *with* an advertising clause that forces
+    you  to  explicitly cite  the  FreeType  project  in your  product's
+    documentation.  All  details are in the license  file.  This license
+    is  suited  to products  which  don't  use  the GNU  General  Public
+    License.
+
+    Note that  this license  is  compatible  to the  GNU General  Public
+    License version 3, but not version 2.
+
+  - The GNU General Public License version 2, found in  `GPLv2.TXT' (any
+    later version can be used  also), for programs which already use the
+    GPL.  Note  that the  FTL is  incompatible  with  GPLv2 due  to  its
+    advertisement clause.
+
+The contributed BDF and PCF drivers  come with a license similar to that
+of the X Window System.  It is compatible to the above two licenses (see
+file src/bdf/README and  src/pcf/README).  The same holds  for the files
+`fthash.c' and  `fthash.h'; their  code was  part of  the BDF  driver in
+earlier FreeType versions.
+
+The gzip module uses the zlib license (see src/gzip/zlib.h) which too is
+compatible to the above two licenses.
+
+The MD5 checksum support (only used for debugging in development builds)
+is in the public domain.
+
+----
+
+HARFBUZZ
+
+HarfBuzz is licensed under the so-called "Old MIT" license.  Details follow.
+For parts of HarfBuzz that are licensed under different licenses see individual
+files names COPYING in subdirectories where applicable.
+
+Copyright © 2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020  Google, Inc.
+Copyright © 2018,2019,2020  Ebrahim Byagowi
+Copyright © 2019,2020  Facebook, Inc. 
+Copyright © 2012  Mozilla Foundation
+Copyright © 2011  Codethink Limited
+Copyright © 2008,2010  Nokia Corporation and/or its subsidiary(-ies)
+Copyright © 2009  Keith Stribley
+Copyright © 2009  Martin Hosken and SIL International
+Copyright © 2007  Chris Wilson
+Copyright © 2006  Behdad Esfahbod
+Copyright © 2005  David Turner
+Copyright © 2004,2007,2008,2009,2010  Red Hat, Inc.
+Copyright © 1998-2004  David Turner and Werner Lemberg
+
+For full copyright notices consult the individual files in the package.
+
+
+Permission is hereby granted, without written agreement and without
+license or royalty fees, to use, copy, modify, and distribute this
+software and its documentation for any purpose, provided that the
+above copyright notice and the following two paragraphs appear in
+all copies of this software.
+
+IN NO EVENT SHALL THE COPYRIGHT HOLDER BE LIABLE TO ANY PARTY FOR
+DIRECT, INDIRECT, SPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES
+ARISING OUT OF THE USE OF THIS SOFTWARE AND ITS DOCUMENTATION, EVEN
+IF THE COPYRIGHT HOLDER HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH
+DAMAGE.
+
+THE COPYRIGHT HOLDER SPECIFICALLY DISCLAIMS ANY WARRANTIES, INCLUDING,
+BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
+FITNESS FOR A PARTICULAR PURPOSE.  THE SOFTWARE PROVIDED HEREUNDER IS
+ON AN "AS IS" BASIS, AND THE COPYRIGHT HOLDER HAS NO OBLIGATION TO
+PROVIDE MAINTENANCE, SUPPORT, UPDATES, ENHANCEMENTS, OR MODIFICATIONS.
+
+
+----
+
+LCMS2
+
+Little CMS
+Copyright (c) 1998-2020 Marti Maria Saguer
+
+Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+
+----
+
+LIBJPEG
+
+1. We don't promise that this software works.  (But if you find any bugs,
+   please let us know!)
+2. You can use this software for whatever you want.  You don't have to pay us.
+3. You may not pretend that you wrote this software.  If you use it in a
+   program, you must acknowledge somewhere in your documentation that
+   you've used the IJG code.
+
+In legalese:
+
+The authors make NO WARRANTY or representation, either express or implied,
+with respect to this software, its quality, accuracy, merchantability, or
+fitness for a particular purpose.  This software is provided "AS IS", and you,
+its user, assume the entire risk as to its quality and accuracy.
+
+This software is copyright (C) 1991-2020, Thomas G. Lane, Guido Vollbeding.
+All Rights Reserved except as specified below.
+
+Permission is hereby granted to use, copy, modify, and distribute this
+software (or portions thereof) for any purpose, without fee, subject to these
+conditions:
+(1) If any part of the source code for this software is distributed, then this
+README file must be included, with this copyright and no-warranty notice
+unaltered; and any additions, deletions, or changes to the original files
+must be clearly indicated in accompanying documentation.
+(2) If only executable code is distributed, then the accompanying
+documentation must state that "this software is based in part on the work of
+the Independent JPEG Group".
+(3) Permission for use of this software is granted only if the user accepts
+full responsibility for any undesirable consequences; the authors accept
+NO LIABILITY for damages of any kind.
+
+These conditions apply to any software derived from or based on the IJG code,
+not just to the unmodified library.  If you use our work, you ought to
+acknowledge us.
+
+Permission is NOT granted for the use of any IJG author's name or company name
+in advertising or publicity relating to this software or products derived from
+it.  This software may be referred to only as "the Independent JPEG Group's
+software".
+
+We specifically permit and encourage the use of this software as the basis of
+commercial products, provided that all warranty or liability claims are
+assumed by the product vendor.
+
+----
+
+LIBLZMA
+
+XZ Utils Licensing
+==================
+
+    Different licenses apply to different files in this package. Here
+    is a rough summary of which licenses apply to which parts of this
+    package (but check the individual files to be sure!):
+
+      - liblzma is in the public domain.
+
+      - xz, xzdec, and lzmadec command line tools are in the public
+        domain unless GNU getopt_long had to be compiled and linked
+        in from the lib directory. The getopt_long code is under
+        GNU LGPLv2.1+.
+
+      - The scripts to grep, diff, and view compressed files have been
+        adapted from gzip. These scripts and their documentation are
+        under GNU GPLv2+.
+
+      - All the documentation in the doc directory and most of the
+        XZ Utils specific documentation files in other directories
+        are in the public domain.
+
+      - Translated messages are in the public domain.
+
+      - The build system contains public domain files, and files that
+        are under GNU GPLv2+ or GNU GPLv3+. None of these files end up
+        in the binaries being built.
+
+      - Test files and test code in the tests directory, and debugging
+        utilities in the debug directory are in the public domain.
+
+      - The extra directory may contain public domain files, and files
+        that are under various free software licenses.
+
+    You can do whatever you want with the files that have been put into
+    the public domain. If you find public domain legally problematic,
+    take the previous sentence as a license grant. If you still find
+    the lack of copyright legally problematic, you have too many
+    lawyers.
+
+    As usual, this software is provided "as is", without any warranty.
+
+    If you copy significant amounts of public domain code from XZ Utils
+    into your project, acknowledging this somewhere in your software is
+    polite (especially if it is proprietary, non-free software), but
+    naturally it is not legally required. Here is an example of a good
+    notice to put into "about box" or into documentation:
+
+        This software includes code from XZ Utils <http://tukaani.org/xz/>.
+
+    The following license texts are included in the following files:
+      - COPYING.LGPLv2.1: GNU Lesser General Public License version 2.1
+      - COPYING.GPLv2: GNU General Public License version 2
+      - COPYING.GPLv3: GNU General Public License version 3
+
+    Note that the toolchain (compiler, linker etc.) may add some code
+    pieces that are copyrighted. Thus, it is possible that e.g. liblzma
+    binary wouldn't actually be in the public domain in its entirety
+    even though it contains no copyrighted code from the XZ Utils source
+    package.
+
+    If you have questions, don't hesitate to ask the author(s) for more
+    information.
+
+----
+
+LIBTIFF
+
+Copyright (c) 1988-1997 Sam Leffler
+Copyright (c) 1991-1997 Silicon Graphics, Inc.
+
+Permission to use, copy, modify, distribute, and sell this software and 
+its documentation for any purpose is hereby granted without fee, provided
+that (i) the above copyright notices and this permission notice appear in
+all copies of the software and related documentation, and (ii) the names of
+Sam Leffler and Silicon Graphics may not be used in any advertising or
+publicity relating to the software without the specific, prior written
+permission of Sam Leffler and Silicon Graphics.
+
+THE SOFTWARE IS PROVIDED "AS-IS" AND WITHOUT WARRANTY OF ANY KIND, 
+EXPRESS, IMPLIED OR OTHERWISE, INCLUDING WITHOUT LIMITATION, ANY 
+WARRANTY OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.  
+
+IN NO EVENT SHALL SAM LEFFLER OR SILICON GRAPHICS BE LIABLE FOR
+ANY SPECIAL, INCIDENTAL, INDIRECT OR CONSEQUENTIAL DAMAGES OF ANY KIND,
+OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
+WHETHER OR NOT ADVISED OF THE POSSIBILITY OF DAMAGE, AND ON ANY THEORY OF 
+LIABILITY, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE 
+OF THIS SOFTWARE.
+
+----
+
+LIBWEBP
+
+Copyright (c) 2010, Google Inc. All rights reserved.
+
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+
+  * Redistributions of source code must retain the above copyright
+    notice, this list of conditions and the following disclaimer.
+
+  * Redistributions in binary form must reproduce the above copyright
+    notice, this list of conditions and the following disclaimer in
+    the documentation and/or other materials provided with the
+    distribution.
+
+  * Neither the name of Google nor the names of its contributors may
+    be used to endorse or promote products derived from this software
+    without specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+----
+
+OPENJPEG
+
+*
+ * The copyright in this software is being made available under the 2-clauses 
+ * BSD License, included below. This software may be subject to other third 
+ * party and contributor rights, including patent rights, and no such rights
+ * are granted under this license.
+ *
+ * Copyright (c) 2002-2014, Universite catholique de Louvain (UCL), Belgium
+ * Copyright (c) 2002-2014, Professor Benoit Macq
+ * Copyright (c) 2003-2014, Antonin Descampe
+ * Copyright (c) 2003-2009, Francois-Olivier Devaux
+ * Copyright (c) 2005, Herve Drolon, FreeImage Team
+ * Copyright (c) 2002-2003, Yannick Verschueren
+ * Copyright (c) 2001-2003, David Janssens
+ * Copyright (c) 2011-2012, Centre National d'Etudes Spatiales (CNES), France 
+ * Copyright (c) 2012, CS Systemes d'Information, France
+ *
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS `AS IS'
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
+ * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+ * POSSIBILITY OF SUCH DAMAGE.
+ */
+
+---
+
+COPYRIGHT NOTICE, DISCLAIMER, and LICENSE
+=========================================
+
+PNG Reference Library License version 2
+---------------------------------------
+
+ * Copyright (c) 1995-2019 The PNG Reference Library Authors.
+ * Copyright (c) 2018-2019 Cosmin Truta.
+ * Copyright (c) 2000-2002, 2004, 2006-2018 Glenn Randers-Pehrson.
+ * Copyright (c) 1996-1997 Andreas Dilger.
+ * Copyright (c) 1995-1996 Guy Eric Schalnat, Group 42, Inc.
+
+The software is supplied "as is", without warranty of any kind,
+express or implied, including, without limitation, the warranties
+of merchantability, fitness for a particular purpose, title, and
+non-infringement.  In no event shall the Copyright owners, or
+anyone distributing the software, be liable for any damages or
+other liability, whether in contract, tort or otherwise, arising
+from, out of, or in connection with the software, or the use or
+other dealings in the software, even if advised of the possibility
+of such damage.
+
+Permission is hereby granted to use, copy, modify, and distribute
+this software, or portions hereof, for any purpose, without fee,
+subject to the following restrictions:
+
+ 1. The origin of this software must not be misrepresented; you
+    must not claim that you wrote the original software.  If you
+    use this software in a product, an acknowledgment in the product
+    documentation would be appreciated, but is not required.
+
+ 2. Altered source versions must be plainly marked as such, and must
+    not be misrepresented as being the original software.
+
+ 3. This Copyright notice may not be removed or altered from any
+    source or altered source distribution.
+
+
+PNG Reference Library License version 1 (for libpng 0.5 through 1.6.35)
+-----------------------------------------------------------------------
+
+libpng versions 1.0.7, July 1, 2000, through 1.6.35, July 15, 2018 are
+Copyright (c) 2000-2002, 2004, 2006-2018 Glenn Randers-Pehrson, are
+derived from libpng-1.0.6, and are distributed according to the same
+disclaimer and license as libpng-1.0.6 with the following individuals
+added to the list of Contributing Authors:
+
+    Simon-Pierre Cadieux
+    Eric S. Raymond
+    Mans Rullgard
+    Cosmin Truta
+    Gilles Vollant
+    James Yu
+    Mandar Sahastrabuddhe
+    Google Inc.
+    Vadim Barkov
+
+and with the following additions to the disclaimer:
+
+    There is no warranty against interference with your enjoyment of
+    the library or against infringement.  There is no warranty that our
+    efforts or the library will fulfill any of your particular purposes
+    or needs.  This library is provided with all faults, and the entire
+    risk of satisfactory quality, performance, accuracy, and effort is
+    with the user.
+
+Some files in the "contrib" directory and some configure-generated
+files that are distributed with libpng have other copyright owners, and
+are released under other open source licenses.
+
+libpng versions 0.97, January 1998, through 1.0.6, March 20, 2000, are
+Copyright (c) 1998-2000 Glenn Randers-Pehrson, are derived from
+libpng-0.96, and are distributed according to the same disclaimer and
+license as libpng-0.96, with the following individuals added to the
+list of Contributing Authors:
+
+    Tom Lane
+    Glenn Randers-Pehrson
+    Willem van Schaik
+
+libpng versions 0.89, June 1996, through 0.96, May 1997, are
+Copyright (c) 1996-1997 Andreas Dilger, are derived from libpng-0.88,
+and are distributed according to the same disclaimer and license as
+libpng-0.88, with the following individuals added to the list of
+Contributing Authors:
+
+    John Bowler
+    Kevin Bracey
+    Sam Bushell
+    Magnus Holmgren
+    Greg Roelofs
+    Tom Tanner
+
+Some files in the "scripts" directory have other copyright owners,
+but are released under this license.
+
+libpng versions 0.5, May 1995, through 0.88, January 1996, are
+Copyright (c) 1995-1996 Guy Eric Schalnat, Group 42, Inc.
+
+For the purposes of this copyright and license, "Contributing Authors"
+is defined as the following set of individuals:
+
+    Andreas Dilger
+    Dave Martindale
+    Guy Eric Schalnat
+    Paul Schmidt
+    Tim Wegner
+
+The PNG Reference Library is supplied "AS IS".  The Contributing
+Authors and Group 42, Inc. disclaim all warranties, expressed or
+implied, including, without limitation, the warranties of
+merchantability and of fitness for any purpose.  The Contributing
+Authors and Group 42, Inc. assume no liability for direct, indirect,
+incidental, special, exemplary, or consequential damages, which may
+result from the use of the PNG Reference Library, even if advised of
+the possibility of such damage.
+
+Permission is hereby granted to use, copy, modify, and distribute this
+source code, or portions hereof, for any purpose, without fee, subject
+to the following restrictions:
+
+ 1. The origin of this source code must not be misrepresented.
+
+ 2. Altered versions must be plainly marked as such and must not
+    be misrepresented as being the original source.
+
+ 3. This Copyright notice may not be removed or altered from any
+    source or altered source distribution.
+
+The Contributing Authors and Group 42, Inc. specifically permit,
+without fee, and encourage the use of this source code as a component
+to supporting the PNG file format in commercial products.  If you use
+this source code in a product, acknowledgment is not required but would
+be appreciated.
+
+----
+
+RAQM
+
+The MIT License (MIT)
+
+Copyright © 2015 Information Technology Authority (ITA) <foss@ita.gov.om>
+Copyright © 2016 Khaled Hosny <khaledhosny@eglug.org>
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
+
+
+----
+
+XAU
+
+Copyright 1988, 1993, 1994, 1998  The Open Group
+
+Permission to use, copy, modify, distribute, and sell this software and its
+documentation for any purpose is hereby granted without fee, provided that
+the above copyright notice appear in all copies and that both that
+copyright notice and this permission notice appear in supporting
+documentation.
+
+The above copyright notice and this permission notice shall be included in
+all copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL THE
+OPEN GROUP BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN
+AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+
+Except as contained in this notice, the name of The Open Group shall not be
+used in advertising or otherwise to promote the sale, use or other dealings
+in this Software without prior written authorization from The Open Group.
+
+----
+
+XCB
+
+Copyright (C) 2001-2006 Bart Massey, Jamey Sharp, and Josh Triplett.
+All Rights Reserved.
+
+Permission is hereby granted, free of charge, to any person
+obtaining a copy of this software and associated
+documentation files (the "Software"), to deal in the
+Software without restriction, including without limitation
+the rights to use, copy, modify, merge, publish, distribute,
+sublicense, and/or sell copies of the Software, and to
+permit persons to whom the Software is furnished to do so,
+subject to the following conditions:
+
+The above copyright notice and this permission notice shall
+be included in all copies or substantial portions of the
+Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY
+KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
+WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR
+PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS
+BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
+IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+OTHER DEALINGS IN THE SOFTWARE.
+
+Except as contained in this notice, the names of the authors
+or their institutions shall not be used in advertising or
+otherwise to promote the sale, use or other dealings in this
+Software without prior written authorization from the
+authors.
+
+----
+
+XDMCP
+
+Copyright 1989, 1998  The Open Group
+
+Permission to use, copy, modify, distribute, and sell this software and its
+documentation for any purpose is hereby granted without fee, provided that
+the above copyright notice appear in all copies and that both that
+copyright notice and this permission notice appear in supporting
+documentation.
+
+The above copyright notice and this permission notice shall be included in
+all copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL THE
+OPEN GROUP BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN
+AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+
+Except as contained in this notice, the name of The Open Group shall not be
+used in advertising or otherwise to promote the sale, use or other dealings
+in this Software without prior written authorization from The Open Group.
+
+Author:  Keith Packard, MIT X Consortium
+
+----
+
+ZLIB
+
+ (C) 1995-2017 Jean-loup Gailly and Mark Adler
+
+  This software is provided 'as-is', without any express or implied
+  warranty.  In no event will the authors be held liable for any damages
+  arising from the use of this software.
+
+  Permission is granted to anyone to use this software for any purpose,
+  including commercial applications, and to alter it and redistribute it
+  freely, subject to the following restrictions:
+
+  1. The origin of this software must not be misrepresented; you must not
+     claim that you wrote the original software. If you use this software
+     in a product, an acknowledgment in the product documentation would be
+     appreciated but is not required.
+  2. Altered source versions must be plainly marked as such, and must not be
+     misrepresented as being the original software.
+  3. This notice may not be removed or altered from any source distribution.
+
+  Jean-loup Gailly        Mark Adler
+  jloup@gzip.org          madler@alumni.caltech.edu
+
+If you use the zlib library in a product, we would appreciate *not* receiving
+lengthy legal documents to sign.  The sources are provided for free but without
+warranty of any kind.  The library has been entirely written by Jean-loup
+Gailly and Mark Adler; it does not include third-party code.
+
+If you redistribute modified sources, we would appreciate that you include in
+the file ChangeLog history information documenting your changes.  Please read
+the FAQ for more information on the distribution of modified source versions.
\ No newline at end of file
diff --git a/.venv/lib/python3.7/site-packages/Pillow-9.0.1.dist-info/METADATA b/.venv/lib/python3.7/site-packages/Pillow-9.0.1.dist-info/METADATA
new file mode 100644
index 0000000..7d90635
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/Pillow-9.0.1.dist-info/METADATA
@@ -0,0 +1,145 @@
+Metadata-Version: 2.1
+Name: Pillow
+Version: 9.0.1
+Summary: Python Imaging Library (Fork)
+Home-page: https://python-pillow.org
+Author: Alex Clark (PIL Fork Author)
+Author-email: aclark@python-pillow.org
+License: HPND
+Project-URL: Documentation, https://pillow.readthedocs.io
+Project-URL: Source, https://github.com/python-pillow/Pillow
+Project-URL: Funding, https://tidelift.com/subscription/pkg/pypi-pillow?utm_source=pypi-pillow&utm_medium=pypi
+Project-URL: Release notes, https://pillow.readthedocs.io/en/stable/releasenotes/index.html
+Project-URL: Changelog, https://github.com/python-pillow/Pillow/blob/main/CHANGES.rst
+Project-URL: Twitter, https://twitter.com/PythonPillow
+Keywords: Imaging
+Platform: UNKNOWN
+Classifier: Development Status :: 6 - Mature
+Classifier: License :: OSI Approved :: Historical Permission Notice and Disclaimer (HPND)
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3 :: Only
+Classifier: Programming Language :: Python :: 3.7
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Python :: Implementation :: CPython
+Classifier: Programming Language :: Python :: Implementation :: PyPy
+Classifier: Topic :: Multimedia :: Graphics
+Classifier: Topic :: Multimedia :: Graphics :: Capture :: Digital Camera
+Classifier: Topic :: Multimedia :: Graphics :: Capture :: Screen Capture
+Classifier: Topic :: Multimedia :: Graphics :: Graphics Conversion
+Classifier: Topic :: Multimedia :: Graphics :: Viewers
+Requires-Python: >=3.7
+Description-Content-Type: text/markdown
+License-File: LICENSE
+
+<p align="center">
+    <img width="248" height="250" src="https://raw.githubusercontent.com/python-pillow/pillow-logo/main/pillow-logo-248x250.png" alt="Pillow logo">
+</p>
+
+# Pillow
+
+## Python Imaging Library (Fork)
+
+Pillow is the friendly PIL fork by [Alex Clark and
+Contributors](https://github.com/python-pillow/Pillow/graphs/contributors).
+PIL is the Python Imaging Library by Fredrik Lundh and Contributors.
+As of 2019, Pillow development is
+[supported by Tidelift](https://tidelift.com/subscription/pkg/pypi-pillow?utm_source=pypi-pillow&utm_medium=readme&utm_campaign=enterprise).
+
+<table>
+    <tr>
+        <th>docs</th>
+        <td>
+            <a href="https://pillow.readthedocs.io/?badge=latest"><img
+                alt="Documentation Status"
+                src="https://readthedocs.org/projects/pillow/badge/?version=latest"></a>
+        </td>
+    </tr>
+    <tr>
+        <th>tests</th>
+        <td>
+            <a href="https://github.com/python-pillow/Pillow/actions?query=workflow%3ALint"><img
+                alt="GitHub Actions build status (Lint)"
+                src="https://github.com/python-pillow/Pillow/workflows/Lint/badge.svg"></a>
+            <a href="https://github.com/python-pillow/Pillow/actions?query=workflow%3ATest"><img
+                alt="GitHub Actions build status (Test Linux and macOS)"
+                src="https://github.com/python-pillow/Pillow/workflows/Test/badge.svg"></a>
+            <a href="https://github.com/python-pillow/Pillow/actions?query=workflow%3A%22Test+Windows%22"><img
+                alt="GitHub Actions build status (Test Windows)"
+                src="https://github.com/python-pillow/Pillow/workflows/Test%20Windows/badge.svg"></a>
+            <a href="https://github.com/python-pillow/Pillow/actions?query=workflow%3A%22Test+Docker%22"><img
+                alt="GitHub Actions build status (Test Docker)"
+                src="https://github.com/python-pillow/Pillow/workflows/Test%20Docker/badge.svg"></a>
+            <a href="https://ci.appveyor.com/project/python-pillow/Pillow"><img
+                alt="AppVeyor CI build status (Windows)"
+                src="https://img.shields.io/appveyor/build/python-pillow/Pillow/main.svg?label=Windows%20build"></a>
+            <a href="https://github.com/python-pillow/pillow-wheels/actions"><img
+                alt="GitHub Actions wheels build status (Wheels)"
+                src="https://github.com/python-pillow/pillow-wheels/workflows/Wheels/badge.svg"></a>
+            <a href="https://travis-ci.com/github/python-pillow/pillow-wheels"><img
+                alt="Travis CI wheels build status (aarch64)"
+                src="https://img.shields.io/travis/com/python-pillow/pillow-wheels/main.svg?label=aarch64%20wheels"></a>
+            <a href="https://codecov.io/gh/python-pillow/Pillow"><img
+                alt="Code coverage"
+                src="https://codecov.io/gh/python-pillow/Pillow/branch/main/graph/badge.svg"></a>
+            <a href="https://github.com/python-pillow/Pillow/actions/workflows/tidelift.yml"><img
+                alt="Tidelift Align"
+                src="https://github.com/python-pillow/Pillow/actions/workflows/tidelift.yml/badge.svg"></a>
+        </td>
+    </tr>
+    <tr>
+        <th>package</th>
+        <td>
+            <a href="https://zenodo.org/badge/latestdoi/17549/python-pillow/Pillow"><img
+                alt="Zenodo"
+                src="https://zenodo.org/badge/17549/python-pillow/Pillow.svg"></a>
+            <a href="https://tidelift.com/subscription/pkg/pypi-pillow?utm_source=pypi-pillow&utm_medium=badge"><img
+                alt="Tidelift"
+                src="https://tidelift.com/badges/package/pypi/Pillow?style=flat"></a>
+            <a href="https://pypi.org/project/Pillow/"><img
+                alt="Newest PyPI version"
+                src="https://img.shields.io/pypi/v/pillow.svg"></a>
+            <a href="https://pypi.org/project/Pillow/"><img
+                alt="Number of PyPI downloads"
+                src="https://img.shields.io/pypi/dm/pillow.svg"></a>
+        </td>
+    </tr>
+    <tr>
+        <th>social</th>
+        <td>
+            <a href="https://gitter.im/python-pillow/Pillow?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge"><img
+                alt="Join the chat at https://gitter.im/python-pillow/Pillow"
+                src="https://badges.gitter.im/python-pillow/Pillow.svg"></a>
+            <a href="https://twitter.com/PythonPillow"><img
+                alt="Follow on https://twitter.com/PythonPillow"
+                src="https://img.shields.io/badge/tweet-on%20Twitter-00aced.svg"></a>
+        </td>
+    </tr>
+</table>
+
+## Overview
+
+The Python Imaging Library adds image processing capabilities to your Python interpreter.
+
+This library provides extensive file format support, an efficient internal representation, and fairly powerful image processing capabilities.
+
+The core image library is designed for fast access to data stored in a few basic pixel formats. It should provide a solid foundation for a general image processing tool.
+
+## More Information
+
+- [Documentation](https://pillow.readthedocs.io/)
+  - [Installation](https://pillow.readthedocs.io/en/latest/installation.html)
+  - [Handbook](https://pillow.readthedocs.io/en/latest/handbook/index.html)
+- [Contribute](https://github.com/python-pillow/Pillow/blob/main/.github/CONTRIBUTING.md)
+  - [Issues](https://github.com/python-pillow/Pillow/issues)
+  - [Pull requests](https://github.com/python-pillow/Pillow/pulls)
+- [Release notes](https://pillow.readthedocs.io/en/stable/releasenotes/index.html)
+- [Changelog](https://github.com/python-pillow/Pillow/blob/main/CHANGES.rst)
+  - [Pre-fork](https://github.com/python-pillow/Pillow/blob/main/CHANGES.rst#pre-fork)
+
+## Report a Vulnerability
+
+To report a security vulnerability, please follow the procedure described in the [Tidelift security policy](https://tidelift.com/docs/security).
+
+
diff --git a/.venv/lib/python3.7/site-packages/Pillow-9.0.1.dist-info/RECORD b/.venv/lib/python3.7/site-packages/Pillow-9.0.1.dist-info/RECORD
new file mode 100644
index 0000000..222fcd5
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/Pillow-9.0.1.dist-info/RECORD
@@ -0,0 +1,212 @@
+PIL/BdfFontFile.py,sha256=hRnSgFZOIiTgWfJIaRHRQpU4TKVok2E31KJY6sbZPwc,2817
+PIL/BlpImagePlugin.py,sha256=mueMvKLQrS_b082agtFskRnzhCoxuOEyX3VwDm5wzdg,14569
+PIL/BmpImagePlugin.py,sha256=UXKXebUcD_E7Sq5iWiOLn5GdLZy4W6hNFI0Ehib0Yik,14242
+PIL/BufrStubImagePlugin.py,sha256=Zq60GwcqQJTmZJrA9EQq94QvYpNqwYvQzHojh4U7SDw,1520
+PIL/ContainerIO.py,sha256=1U15zUXjWO8uWK-MyCp66Eh7djQEU-oUeCDoBqewNkA,2883
+PIL/CurImagePlugin.py,sha256=er_bI3V1Ezly0QfFJq0fZMlGwrD5izDutwF1FrOwiMA,1679
+PIL/DcxImagePlugin.py,sha256=bfESLTji9GerqI4oYsy5oTFyRMlr2mjSsXzpY9IuLsk,2145
+PIL/DdsImagePlugin.py,sha256=cUSGUNx_sf5UFryyMLrOf1vJQIMx9GwoMfuvxz3Bg1U,7987
+PIL/EpsImagePlugin.py,sha256=mKiRyVh5NcX9MI1ByBzlnSB1u8xx_kX7Q_wcalcZkBY,11918
+PIL/ExifTags.py,sha256=0YRoKyMwPabWOZZgVeLL6mlaGjbZgfF-z8WuUc6Ibb0,9446
+PIL/FitsStubImagePlugin.py,sha256=F9NJsro-OyxKmt9SLBemx5LZaCqFXIejBVbZY9nuUPA,2555
+PIL/FliImagePlugin.py,sha256=pGeC1JI6d5xdYWRhsKz0_3yeFzGII_jYbQhJYNo6n7Y,4260
+PIL/FontFile.py,sha256=LkQcbwUu1C4fokMnbg-ao9ksp2RX-saaPRie-z2rpH4,2765
+PIL/FpxImagePlugin.py,sha256=nKGioxa5C0q9X9qva3t_htRV_3jXQcFkclVxTEaSusk,6658
+PIL/FtexImagePlugin.py,sha256=rHNkZXfhF21i3klylBqo8nJrIm41TxdCLHiv0Zgwbb0,3305
+PIL/GbrImagePlugin.py,sha256=u9kOIdBxYMRrXfXfIwGcz0uyvvxNRCwO3U1xcfa51T4,2794
+PIL/GdImageFile.py,sha256=JFWSUssG1z1r884GQtBbZ3T7uhPF4cDXSuW3ctgf3TU,2465
+PIL/GifImagePlugin.py,sha256=shBwrj_PeD81jWRXriy5AMzWcRtg6zCtb-wnFBNhgg4,32608
+PIL/GimpGradientFile.py,sha256=G0ClRmjRHIJoU0nmG-P-tgehLHZip5i0rY4-5pjJ7bc,3353
+PIL/GimpPaletteFile.py,sha256=_wWvNmB40AfQ1M5sTxoYYXOMApWQji7rrubqZhfd1dU,1274
+PIL/GribStubImagePlugin.py,sha256=sSBrTisTcunuC0WcSQ4_55nV6uFvLCQ0JLSd62dgURw,1515
+PIL/Hdf5StubImagePlugin.py,sha256=zjtFPZIcVkWXvYRPnHow6XA9kElEi772w7PFSuEqmq4,1517
+PIL/IcnsImagePlugin.py,sha256=BU0OEQwMPJrpKqh9kHUqHjpysnxhhuyaFy7pf2nuMmE,11731
+PIL/IcoImagePlugin.py,sha256=hru3Wu7soWoRl-CGKs7Wv14FbeiHvxv_l5HkSVsnK30,10822
+PIL/ImImagePlugin.py,sha256=RFFyRlFJTVuti-TZ9yWsqP7vJJydgX1MC6mjYwwdw-0,10729
+PIL/Image.py,sha256=q-Z3raXFeWzPX2N_Lwcjvtl4GOA-_e8sWe_fw4lu6u0,121350
+PIL/ImageChops.py,sha256=HOGSnuU4EcCbdeUzEGPm54zewppHWWe12XLyOLLPgCw,7297
+PIL/ImageCms.py,sha256=0-sWLr6M88fhkKypchF3fVxclSb6LNfs1d9pkjOtQMQ,37090
+PIL/ImageColor.py,sha256=2e9xfO08S6afUzoahUIzyMN8RJcQsMz9E92rFnEhfP0,8727
+PIL/ImageDraw.py,sha256=rvMmVCjqAo_PRk41fOuOh3kkXYYTY8KinMvLkQ0RhO8,34710
+PIL/ImageDraw2.py,sha256=oBhpBTZhx3bd4D0s8E2kDjBzgThRkDU_TE_987l501k,5019
+PIL/ImageEnhance.py,sha256=CJnCouiBmxN2fE0xW7m_uMdBqcm-Fp0S3ruHhkygal4,3190
+PIL/ImageFile.py,sha256=6X2txgKhCJu1uiNY19vS0AukcyLoT4Umn_Ydk4IzePg,21075
+PIL/ImageFilter.py,sha256=SBdX7_KqGKFOJxXjv9Uc5gUP1LkvQ-r-2cbiRtcXoeM,16129
+PIL/ImageFont.py,sha256=3oEILxC2preYHdfIZ-SZmyJcAe88afrXalPtAiD8E2E,44858
+PIL/ImageGrab.py,sha256=2o1aA0_vP-KeRJsJtIxYhi61yCK4k_Khh6NHQD7HO2Q,3625
+PIL/ImageMath.py,sha256=4MLOwTkq3hqpurWvjZhFUpeKkuQmUO4rg5yehfCRNQs,7445
+PIL/ImageMode.py,sha256=woBgGcqCT5yTkS5yNWJyst4aaLdSMZsPpPoXDgnqo6M,2075
+PIL/ImageMorph.py,sha256=KL2843wgfLyXPOWEJnTXRvySfbpRrlTqA_0M1j5xuD0,7773
+PIL/ImageOps.py,sha256=J2iW0ryjkJWwXDShZVIqvAezN6x-83PZT1VDlnhvUIc,20292
+PIL/ImagePalette.py,sha256=rOpqcuH5DhJXPEvREna3Dg1N7ZK3TfnXHu5eZyltZTs,7841
+PIL/ImagePath.py,sha256=lVmH1-lCd0SyrFoqyhlstAFW2iJuC14fPcW8iewvxCQ,336
+PIL/ImageQt.py,sha256=hECe1rZpv1teaR5exrP39NbWBKwNGD7X5zoA5id_UJo,6698
+PIL/ImageSequence.py,sha256=3djA7vDH6wafTGbt4e_lPlVhy2TaKfdSrA1XQ4n-Uoc,1850
+PIL/ImageShow.py,sha256=bQlsO-nQR8V31ohHOrqrtK-Wgki24eujSLQC6O5jv0M,7933
+PIL/ImageStat.py,sha256=PieQi44mRHE6jod7NqujwGr6WCntuZuNGmC2z9PaoDY,3901
+PIL/ImageTk.py,sha256=rLPqAnLH61y2XRHgRPUdesYLQqnDQ__LeRK66KL_fPQ,9324
+PIL/ImageTransform.py,sha256=V2l6tsjmymMIF7HQBMI21UPn4mlicarrm4NF3Kazvio,2843
+PIL/ImageWin.py,sha256=1MQBJS7tVrQzI9jN0nmeNeFpIaq8fXra9kQocHkiFxM,7191
+PIL/ImtImagePlugin.py,sha256=cn60lqUVnK2oh_sPqPBORr_rZ4zuF_6FU0V96IAh8Ww,2203
+PIL/IptcImagePlugin.py,sha256=-RZBUUodHcF5wLKanW1MxJj7cbLOpx5LvXqm0vDM22U,5714
+PIL/Jpeg2KImagePlugin.py,sha256=fC5qVN7kGz9awyF8P0EEI5XFVOPJDUdJgu3uVWhDLRk,10386
+PIL/JpegImagePlugin.py,sha256=OYXoV5w1A-l5wM8PLunU_7uzKd2gqmV4S6yvPACmS2U,28459
+PIL/JpegPresets.py,sha256=6nVnX_H8eA8ZO7AOVvkUx8gEN6QfI8zKnV6od16XgWE,12347
+PIL/McIdasImagePlugin.py,sha256=LrP5nA7l8IQG3WhlMI0Xs8fGXY_uf6IDmzNCERl3tGw,1754
+PIL/MicImagePlugin.py,sha256=Eh94vjTurXYkmm27hhooyNm9NkWWyVxP8Nq4thNLV6Y,2607
+PIL/MpegImagePlugin.py,sha256=n16Zgdy8Hcfke16lQwZWs53PZq4BA_OxPCMPDkW62nw,1803
+PIL/MpoImagePlugin.py,sha256=2C07_0-G0XepZnJRNSAKp3Os8t_qo32N2WquMomXR9I,4399
+PIL/MspImagePlugin.py,sha256=RdQb1e5-KDWdWy-3MUhchTlxf9TPgyw2axONt_vWRUE,5526
+PIL/PSDraw.py,sha256=xmJ6GVUvDm1SC3QuUpYdeNfGu9lYBLX1ndCt96tObcc,6719
+PIL/PaletteFile.py,sha256=s3KtsDuY5S04MKDyiXK3iIbiOGzV9PvCDUpOQHI7yqc,1106
+PIL/PalmImagePlugin.py,sha256=lTVwwSPFrQ-IPFGU8_gRCMZ1Lb73cuVhQ-nkx1Q0oqc,9108
+PIL/PcdImagePlugin.py,sha256=cnBm_xKcpLGT6hZ8QKai9Up0gZERMxZwhDXl1hQtBm0,1476
+PIL/PcfFontFile.py,sha256=njhgblsjSVcITVz1DpWdEligmJgPMh5nTk_zDDWWTik,6348
+PIL/PcxImagePlugin.py,sha256=J-Pm2QBt5Hi4ObPeXDnc87X7nl1hbtTGqy4sTov6tug,5864
+PIL/PdfImagePlugin.py,sha256=NMho8n6d2JOv-dxcrLYVGJ-RSStZaNakTadObA8fDSg,7336
+PIL/PdfParser.py,sha256=veVDRlSK7c0hnqfa2tBeB2evU3Z5LnGum_QCE3YAjAk,34561
+PIL/PixarImagePlugin.py,sha256=5MMcrrShVr511QKevK1ziKyJn0WllokWQxBhs8NWttY,1631
+PIL/PngImagePlugin.py,sha256=m3s82KcpJ_awnsp4GKrFQd2-7zy6nq7SzUsdGTntBwU,44148
+PIL/PpmImagePlugin.py,sha256=UNwCp3h7psEK8i0p3P93VVXUBz9_8tUVzUWsITux6HQ,4447
+PIL/PsdImagePlugin.py,sha256=tSkfdEw---66vlBu4OA9y7zsQ5y4gIIThhyFi6orT0o,8072
+PIL/PyAccess.py,sha256=SaGs2ZE4kjh-dybpAA5_Og4wuhA6d0LTPKK8t2aHffY,9607
+PIL/SgiImagePlugin.py,sha256=mqpi0G4aiKzWmJHk22WKZ0oGqsglcTNgDfp4H8S-GCM,6097
+PIL/SpiderImagePlugin.py,sha256=gJI4peH7axhNNW37An9ixeFFAYooHh4DZSYPotXnQfo,9535
+PIL/SunImagePlugin.py,sha256=bnjnVFRjvApCH1QC1F9HeynoCe5AZk3wa1tOhPvHzKU,4282
+PIL/TarIO.py,sha256=E_pjAxk9wHezXUuR_99liySBXfJoL2wjzdNDf0g1hTo,1440
+PIL/TgaImagePlugin.py,sha256=xA5JQ1TtHI5NE_4hD7gsIWOntMyFKqWtYP63cvYrwQY,6475
+PIL/TiffImagePlugin.py,sha256=gpVci4s4YtDaou-FxprRGaKLpdq8HJdln1jt33WgxV4,72873
+PIL/TiffTags.py,sha256=s9sOrIxxDdZSgi06YdalbZOn_p8V1Gh5V2TZg3B4DEg,15286
+PIL/WalImageFile.py,sha256=jJNdRLIjbEsPkpkIdY2n6WlStDz1ttVQS7y3DJE7qTU,5546
+PIL/WebPImagePlugin.py,sha256=VkCNYJRoJd8wXT4JG31CF4crjjPfuoOvDH81o4vqJ1w,10830
+PIL/WmfImagePlugin.py,sha256=2dDhAUW8-uebXmBJbI8TDJapK49ocUros1hbUUDlmO8,4639
+PIL/XVThumbImagePlugin.py,sha256=zmZ8Z4B8Kr6NOdUqSipW9_X5mKiLBLs-wxvPRRg1l0M,1940
+PIL/XbmImagePlugin.py,sha256=oIEt_uqwKKU6lLS_IVFwEjotwE1FI4_IHUnx_6Ul_gk,2430
+PIL/XpmImagePlugin.py,sha256=1EBt-g678p0A0NXOkxq7sGM8dymneDMHHQmwJzAbrlw,3062
+PIL/__init__.py,sha256=Alqybme-dfSTTkYxohVlm0MSm6xDNlglsGvmf6IWC-g,1740
+PIL/__main__.py,sha256=axR7PO-HtXp-o0rBhKIxs0wark0rBfaDIhAIWqtWUo4,41
+PIL/__pycache__/BdfFontFile.cpython-37.pyc,,
+PIL/__pycache__/BlpImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/BmpImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/BufrStubImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/ContainerIO.cpython-37.pyc,,
+PIL/__pycache__/CurImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/DcxImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/DdsImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/EpsImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/ExifTags.cpython-37.pyc,,
+PIL/__pycache__/FitsStubImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/FliImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/FontFile.cpython-37.pyc,,
+PIL/__pycache__/FpxImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/FtexImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/GbrImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/GdImageFile.cpython-37.pyc,,
+PIL/__pycache__/GifImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/GimpGradientFile.cpython-37.pyc,,
+PIL/__pycache__/GimpPaletteFile.cpython-37.pyc,,
+PIL/__pycache__/GribStubImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/Hdf5StubImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/IcnsImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/IcoImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/ImImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/Image.cpython-37.pyc,,
+PIL/__pycache__/ImageChops.cpython-37.pyc,,
+PIL/__pycache__/ImageCms.cpython-37.pyc,,
+PIL/__pycache__/ImageColor.cpython-37.pyc,,
+PIL/__pycache__/ImageDraw.cpython-37.pyc,,
+PIL/__pycache__/ImageDraw2.cpython-37.pyc,,
+PIL/__pycache__/ImageEnhance.cpython-37.pyc,,
+PIL/__pycache__/ImageFile.cpython-37.pyc,,
+PIL/__pycache__/ImageFilter.cpython-37.pyc,,
+PIL/__pycache__/ImageFont.cpython-37.pyc,,
+PIL/__pycache__/ImageGrab.cpython-37.pyc,,
+PIL/__pycache__/ImageMath.cpython-37.pyc,,
+PIL/__pycache__/ImageMode.cpython-37.pyc,,
+PIL/__pycache__/ImageMorph.cpython-37.pyc,,
+PIL/__pycache__/ImageOps.cpython-37.pyc,,
+PIL/__pycache__/ImagePalette.cpython-37.pyc,,
+PIL/__pycache__/ImagePath.cpython-37.pyc,,
+PIL/__pycache__/ImageQt.cpython-37.pyc,,
+PIL/__pycache__/ImageSequence.cpython-37.pyc,,
+PIL/__pycache__/ImageShow.cpython-37.pyc,,
+PIL/__pycache__/ImageStat.cpython-37.pyc,,
+PIL/__pycache__/ImageTk.cpython-37.pyc,,
+PIL/__pycache__/ImageTransform.cpython-37.pyc,,
+PIL/__pycache__/ImageWin.cpython-37.pyc,,
+PIL/__pycache__/ImtImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/IptcImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/Jpeg2KImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/JpegImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/JpegPresets.cpython-37.pyc,,
+PIL/__pycache__/McIdasImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/MicImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/MpegImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/MpoImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/MspImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/PSDraw.cpython-37.pyc,,
+PIL/__pycache__/PaletteFile.cpython-37.pyc,,
+PIL/__pycache__/PalmImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/PcdImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/PcfFontFile.cpython-37.pyc,,
+PIL/__pycache__/PcxImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/PdfImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/PdfParser.cpython-37.pyc,,
+PIL/__pycache__/PixarImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/PngImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/PpmImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/PsdImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/PyAccess.cpython-37.pyc,,
+PIL/__pycache__/SgiImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/SpiderImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/SunImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/TarIO.cpython-37.pyc,,
+PIL/__pycache__/TgaImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/TiffImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/TiffTags.cpython-37.pyc,,
+PIL/__pycache__/WalImageFile.cpython-37.pyc,,
+PIL/__pycache__/WebPImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/WmfImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/XVThumbImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/XbmImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/XpmImagePlugin.cpython-37.pyc,,
+PIL/__pycache__/__init__.cpython-37.pyc,,
+PIL/__pycache__/__main__.cpython-37.pyc,,
+PIL/__pycache__/_binary.cpython-37.pyc,,
+PIL/__pycache__/_tkinter_finder.cpython-37.pyc,,
+PIL/__pycache__/_util.cpython-37.pyc,,
+PIL/__pycache__/_version.cpython-37.pyc,,
+PIL/__pycache__/features.cpython-37.pyc,,
+PIL/_binary.py,sha256=E5qhxNJ7hhbEoqu0mODOXHT8z-FDRShXG3jTJhsDdas,2043
+PIL/_imaging.cpython-37m-x86_64-linux-gnu.so,sha256=c0ChyXCEz8OfGai0u19_bTEDIsd3GPgW0mBGSRbEjxY,3094712
+PIL/_imagingcms.cpython-37m-x86_64-linux-gnu.so,sha256=1oYoPS7dkEiVew9bseimHhFZ9A5m1dvk7B9WJ4T1c2I,141320
+PIL/_imagingft.cpython-37m-x86_64-linux-gnu.so,sha256=qjjBbognftR8C3OGoYELT7ZGU2MbsMLjDkFgAKSUUgM,224248
+PIL/_imagingmath.cpython-37m-x86_64-linux-gnu.so,sha256=FlbgaAwy176jmr3Q3JyvDpLyTht1LMC2P1tY8NCz4JQ,140128
+PIL/_imagingmorph.cpython-37m-x86_64-linux-gnu.so,sha256=IUNndm8TXQbMF6Q3_TZoH9e4rmTp2hvynji84x4K_rI,38920
+PIL/_imagingtk.cpython-37m-x86_64-linux-gnu.so,sha256=HdkWyZkFjXpyOaViWMlqyb8-RA3r1qI9_oQY0GTPk74,47960
+PIL/_tkinter_finder.py,sha256=_L2ahIbgqI01JYSg7w-YYH7FrCru-vzqpTtI0XdH5AA,525
+PIL/_util.py,sha256=pbjX5KY1W2oZyYVC4TE9ai2PfrJZrAsO5hAnz_JMees,359
+PIL/_version.py,sha256=o_EGuzTLU6FJDPDhJ9OEpun9EXJ5SbNskcQ9ZPoShbo,50
+PIL/_webp.cpython-37m-x86_64-linux-gnu.so,sha256=TzBi3FSsNuXjJKCNRj_IQKHVV0LdLu_PW4TZqqwDP_M,107224
+PIL/features.py,sha256=j2LT6v78cHWbR8z8OVaAGIbJWI-Bs62pfiB1i1fminM,9387
+Pillow-9.0.1.dist-info/INSTALLER,sha256=zuuue4knoyJ-UwPPXg8fezS7VCrXJQrAP7zeNuwvFQg,4
+Pillow-9.0.1.dist-info/LICENSE,sha256=YJxFpXSmibpABP8KRpkP5NOqcbiIMg2xx1087M2UNqA,27652
+Pillow-9.0.1.dist-info/METADATA,sha256=G1RYIktHMg8oMhOzhHhib27XSBP8ixDXi690eO6gGmQ,7630
+Pillow-9.0.1.dist-info/RECORD,,
+Pillow-9.0.1.dist-info/WHEEL,sha256=FGGRUrvefXOiAJfyJCZAiu4TpTMkXB_CzdEp3x2T96E,150
+Pillow-9.0.1.dist-info/top_level.txt,sha256=riZqrk-hyZqh5f1Z0Zwii3dKfxEsByhu9cU9IODF-NY,4
+Pillow-9.0.1.dist-info/zip-safe,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
+Pillow.libs/libXau-00ec42fe.so.6.0.0,sha256=d75mSMNgdE9Ubbyh6DWZcVKSq3R4m8pD6eltRC2w49o,17048
+Pillow.libs/libfreetype-a029e222.so.6.18.1,sha256=jergcSWdtvQzK3HXUw-lfzy_TJ0_Vk6UxMpuBolf_T8,1385640
+Pillow.libs/libharfbuzz-851aa43c.so.0.30200.0,sha256=r_IR9xZNMVnn7v-Zpo9oAgzzvqtHhb9Hpdsk1a5QHbU,4971560
+Pillow.libs/libjpeg-62ed1500.so.62.3.0,sha256=WA7VaTdamu6brgAI9AccNQPAfPKI4EnHEfaIRfMIXp8,691368
+Pillow.libs/liblcms2-5ee890d7.so.2.0.13,sha256=gmSsSWUBGmVpDQT0rrI8g6T7w4N5TOMkpsbMCvOAUQg,494256
+Pillow.libs/liblzma-d540a118.so.5.2.5,sha256=JbIyQEIYTjuWokwsiGf-sItr6eJBCFWYtfeWpZJ9o64,220808
+Pillow.libs/libopenjp2-430a98fc.so.2.4.0,sha256=xYk9Bl7aTIe1OD9RO8v-2bE4chHpieehUC-zlKPyW0Q,532568
+Pillow.libs/libpng16-213e245f.so.16.37.0,sha256=VG5oYdhMJaFXlX2G7wDk7Ig4m0gQ5BLTjskGjZraGK4,283968
+Pillow.libs/libtiff-8e99fb9e.so.5.7.0,sha256=o2i7_rSi24cXT7E9PdUXLDe-l4QMepL7EpJij-6lpwI,689944
+Pillow.libs/libwebp-8efe125f.so.7.1.3,sha256=C5OMn2tSEFZGyXnwJTTEiiov5ZHOPIRMuDO3OFzh7XM,645808
+Pillow.libs/libwebpdemux-016472e8.so.2.0.9,sha256=TaU1aMJ_RfkUIBWim90HFgxKxmTnfDJ_pXaJHOGWxdc,29456
+Pillow.libs/libwebpmux-5c00cf3e.so.3.0.8,sha256=duMtYlNBckRPEgL7KeY2amcf3w9Cc1pVaHDYgAf4bJw,54456
+Pillow.libs/libxcb-1122e22b.so.1.1.0,sha256=Ghohd8ctbBf5_jE5i6MExypVbwyX-uv1QjLvW_ADCHQ,243216
+Pillow.libs/libz-dd453c56.so.1.2.11,sha256=nYOJa1r68aU19J0jCVgalS9ypvHhC606cwm05SBt3rU,129328
diff --git a/.venv/lib/python3.7/site-packages/Pillow-9.0.1.dist-info/WHEEL b/.venv/lib/python3.7/site-packages/Pillow-9.0.1.dist-info/WHEEL
new file mode 100644
index 0000000..3811098
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/Pillow-9.0.1.dist-info/WHEEL
@@ -0,0 +1,6 @@
+Wheel-Version: 1.0
+Generator: bdist_wheel (0.37.1)
+Root-Is-Purelib: false
+Tag: cp37-cp37m-manylinux_2_17_x86_64
+Tag: cp37-cp37m-manylinux2014_x86_64
+
diff --git a/.venv/lib/python3.7/site-packages/Pillow-9.0.1.dist-info/top_level.txt b/.venv/lib/python3.7/site-packages/Pillow-9.0.1.dist-info/top_level.txt
new file mode 100644
index 0000000..b338169
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/Pillow-9.0.1.dist-info/top_level.txt
@@ -0,0 +1 @@
+PIL
diff --git a/.venv/lib/python3.7/site-packages/Pillow-9.0.1.dist-info/zip-safe b/.venv/lib/python3.7/site-packages/Pillow-9.0.1.dist-info/zip-safe
new file mode 100644
index 0000000..8b13789
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/Pillow-9.0.1.dist-info/zip-safe
@@ -0,0 +1 @@
+
diff --git a/.venv/lib/python3.7/site-packages/PyYAML-6.0.dist-info/INSTALLER b/.venv/lib/python3.7/site-packages/PyYAML-6.0.dist-info/INSTALLER
new file mode 100644
index 0000000..a1b589e
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PyYAML-6.0.dist-info/INSTALLER
@@ -0,0 +1 @@
+pip
diff --git a/.venv/lib/python3.7/site-packages/PyYAML-6.0.dist-info/LICENSE b/.venv/lib/python3.7/site-packages/PyYAML-6.0.dist-info/LICENSE
new file mode 100644
index 0000000..2f1b8e1
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PyYAML-6.0.dist-info/LICENSE
@@ -0,0 +1,20 @@
+Copyright (c) 2017-2021 Ingy döt Net
+Copyright (c) 2006-2016 Kirill Simonov
+
+Permission is hereby granted, free of charge, to any person obtaining a copy of
+this software and associated documentation files (the "Software"), to deal in
+the Software without restriction, including without limitation the rights to
+use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+of the Software, and to permit persons to whom the Software is furnished to do
+so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
diff --git a/.venv/lib/python3.7/site-packages/PyYAML-6.0.dist-info/METADATA b/.venv/lib/python3.7/site-packages/PyYAML-6.0.dist-info/METADATA
new file mode 100644
index 0000000..9a91076
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PyYAML-6.0.dist-info/METADATA
@@ -0,0 +1,46 @@
+Metadata-Version: 2.1
+Name: PyYAML
+Version: 6.0
+Summary: YAML parser and emitter for Python
+Home-page: https://pyyaml.org/
+Author: Kirill Simonov
+Author-email: xi@resolvent.net
+License: MIT
+Download-URL: https://pypi.org/project/PyYAML/
+Project-URL: Bug Tracker, https://github.com/yaml/pyyaml/issues
+Project-URL: CI, https://github.com/yaml/pyyaml/actions
+Project-URL: Documentation, https://pyyaml.org/wiki/PyYAMLDocumentation
+Project-URL: Mailing lists, http://lists.sourceforge.net/lists/listinfo/yaml-core
+Project-URL: Source Code, https://github.com/yaml/pyyaml
+Platform: Any
+Classifier: Development Status :: 5 - Production/Stable
+Classifier: Intended Audience :: Developers
+Classifier: License :: OSI Approved :: MIT License
+Classifier: Operating System :: OS Independent
+Classifier: Programming Language :: Cython
+Classifier: Programming Language :: Python
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.6
+Classifier: Programming Language :: Python :: 3.7
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Python :: Implementation :: CPython
+Classifier: Programming Language :: Python :: Implementation :: PyPy
+Classifier: Topic :: Software Development :: Libraries :: Python Modules
+Classifier: Topic :: Text Processing :: Markup
+Requires-Python: >=3.6
+License-File: LICENSE
+
+YAML is a data serialization format designed for human readability
+and interaction with scripting languages.  PyYAML is a YAML parser
+and emitter for Python.
+
+PyYAML features a complete YAML 1.1 parser, Unicode support, pickle
+support, capable extension API, and sensible error messages.  PyYAML
+supports standard YAML tags and provides Python-specific tags that
+allow to represent an arbitrary Python object.
+
+PyYAML is applicable for a broad range of tasks from complex
+configuration files to object serialization and persistence.
+
diff --git a/.venv/lib/python3.7/site-packages/PyYAML-6.0.dist-info/RECORD b/.venv/lib/python3.7/site-packages/PyYAML-6.0.dist-info/RECORD
new file mode 100644
index 0000000..886f6e7
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PyYAML-6.0.dist-info/RECORD
@@ -0,0 +1,43 @@
+PyYAML-6.0.dist-info/INSTALLER,sha256=zuuue4knoyJ-UwPPXg8fezS7VCrXJQrAP7zeNuwvFQg,4
+PyYAML-6.0.dist-info/LICENSE,sha256=jTko-dxEkP1jVwfLiOsmvXZBAqcoKVQwfT5RZ6V36KQ,1101
+PyYAML-6.0.dist-info/METADATA,sha256=QmHx9kGp_0yezQCXYaft4eEFeJ6W4oyFfYwHDLP1kdg,2006
+PyYAML-6.0.dist-info/RECORD,,
+PyYAML-6.0.dist-info/WHEEL,sha256=kvyGvy5bO3fspZ-7qhg8sVOH8B-z0uw-ppjLYSm8gPI,221
+PyYAML-6.0.dist-info/top_level.txt,sha256=rpj0IVMTisAjh_1vG3Ccf9v5jpCQwAz6cD1IVU5ZdhQ,11
+_yaml/__init__.py,sha256=04Ae_5osxahpJHa3XBZUAf4wi6XX32gR8D6X6p64GEA,1402
+_yaml/__pycache__/__init__.cpython-37.pyc,,
+yaml/__init__.py,sha256=NDS7S8XgA72-hY6LRmGzUWTPvzGzjWVrWk-OGA-77AA,12309
+yaml/__pycache__/__init__.cpython-37.pyc,,
+yaml/__pycache__/composer.cpython-37.pyc,,
+yaml/__pycache__/constructor.cpython-37.pyc,,
+yaml/__pycache__/cyaml.cpython-37.pyc,,
+yaml/__pycache__/dumper.cpython-37.pyc,,
+yaml/__pycache__/emitter.cpython-37.pyc,,
+yaml/__pycache__/error.cpython-37.pyc,,
+yaml/__pycache__/events.cpython-37.pyc,,
+yaml/__pycache__/loader.cpython-37.pyc,,
+yaml/__pycache__/nodes.cpython-37.pyc,,
+yaml/__pycache__/parser.cpython-37.pyc,,
+yaml/__pycache__/reader.cpython-37.pyc,,
+yaml/__pycache__/representer.cpython-37.pyc,,
+yaml/__pycache__/resolver.cpython-37.pyc,,
+yaml/__pycache__/scanner.cpython-37.pyc,,
+yaml/__pycache__/serializer.cpython-37.pyc,,
+yaml/__pycache__/tokens.cpython-37.pyc,,
+yaml/_yaml.cpython-37m-x86_64-linux-gnu.so,sha256=k1iT9TOn30MYZDn6aavdl1xb_aD2h68g4X-cTVF2COs,1832344
+yaml/composer.py,sha256=_Ko30Wr6eDWUeUpauUGT3Lcg9QPBnOPVlTnIMRGJ9FM,4883
+yaml/constructor.py,sha256=kNgkfaeLUkwQYY_Q6Ff1Tz2XVw_pG1xVE9Ak7z-viLA,28639
+yaml/cyaml.py,sha256=6ZrAG9fAYvdVe2FK_w0hmXoG7ZYsoYUwapG8CiC72H0,3851
+yaml/dumper.py,sha256=PLctZlYwZLp7XmeUdwRuv4nYOZ2UBnDIUy8-lKfLF-o,2837
+yaml/emitter.py,sha256=jghtaU7eFwg31bG0B7RZea_29Adi9CKmXq_QjgQpCkQ,43006
+yaml/error.py,sha256=Ah9z-toHJUbE9j-M8YpxgSRM5CgLCcwVzJgLLRF2Fxo,2533
+yaml/events.py,sha256=50_TksgQiE4up-lKo_V-nBy-tAIxkIPQxY5qDhKCeHw,2445
+yaml/loader.py,sha256=UVa-zIqmkFSCIYq_PgSGm4NSJttHY2Rf_zQ4_b1fHN0,2061
+yaml/nodes.py,sha256=gPKNj8pKCdh2d4gr3gIYINnPOaOxGhJAUiYhGRnPE84,1440
+yaml/parser.py,sha256=ilWp5vvgoHFGzvOZDItFoGjD6D42nhlZrZyjAwa0oJo,25495
+yaml/reader.py,sha256=0dmzirOiDG4Xo41RnuQS7K9rkY3xjHiVasfDMNTqCNw,6794
+yaml/representer.py,sha256=IuWP-cAW9sHKEnS0gCqSa894k1Bg4cgTxaDwIcbRQ-Y,14190
+yaml/resolver.py,sha256=9L-VYfm4mWHxUD1Vg4X7rjDRK_7VZd6b92wzq7Y2IKY,9004
+yaml/scanner.py,sha256=YEM3iLZSaQwXcQRg2l2R4MdT0zGP2F9eHkKGKnHyWQY,51279
+yaml/serializer.py,sha256=ChuFgmhU01hj4xgI8GaKv6vfM2Bujwa9i7d2FAHj7cA,4165
+yaml/tokens.py,sha256=lTQIzSVw8Mg9wv459-TjiOQe6wVziqaRlqX2_89rp54,2573
diff --git a/.venv/lib/python3.7/site-packages/PyYAML-6.0.dist-info/WHEEL b/.venv/lib/python3.7/site-packages/PyYAML-6.0.dist-info/WHEEL
new file mode 100644
index 0000000..266135b
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PyYAML-6.0.dist-info/WHEEL
@@ -0,0 +1,8 @@
+Wheel-Version: 1.0
+Generator: bdist_wheel (0.37.0)
+Root-Is-Purelib: false
+Tag: cp37-cp37m-manylinux_2_5_x86_64
+Tag: cp37-cp37m-manylinux1_x86_64
+Tag: cp37-cp37m-manylinux_2_12_x86_64
+Tag: cp37-cp37m-manylinux2010_x86_64
+
diff --git a/.venv/lib/python3.7/site-packages/PyYAML-6.0.dist-info/top_level.txt b/.venv/lib/python3.7/site-packages/PyYAML-6.0.dist-info/top_level.txt
new file mode 100644
index 0000000..e6475e9
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/PyYAML-6.0.dist-info/top_level.txt
@@ -0,0 +1,2 @@
+_yaml
+yaml
diff --git a/.venv/lib/python3.7/site-packages/_yaml/__init__.py b/.venv/lib/python3.7/site-packages/_yaml/__init__.py
new file mode 100644
index 0000000..7baa8c4
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/_yaml/__init__.py
@@ -0,0 +1,33 @@
+# This is a stub package designed to roughly emulate the _yaml
+# extension module, which previously existed as a standalone module
+# and has been moved into the `yaml` package namespace.
+# It does not perfectly mimic its old counterpart, but should get
+# close enough for anyone who's relying on it even when they shouldn't.
+import yaml
+
+# in some circumstances, the yaml module we imoprted may be from a different version, so we need
+# to tread carefully when poking at it here (it may not have the attributes we expect)
+if not getattr(yaml, '__with_libyaml__', False):
+    from sys import version_info
+
+    exc = ModuleNotFoundError if version_info >= (3, 6) else ImportError
+    raise exc("No module named '_yaml'")
+else:
+    from yaml._yaml import *
+    import warnings
+    warnings.warn(
+        'The _yaml extension module is now located at yaml._yaml'
+        ' and its location is subject to change.  To use the'
+        ' LibYAML-based parser and emitter, import from `yaml`:'
+        ' `from yaml import CLoader as Loader, CDumper as Dumper`.',
+        DeprecationWarning
+    )
+    del warnings
+    # Don't `del yaml` here because yaml is actually an existing
+    # namespace member of _yaml.
+
+__name__ = '_yaml'
+# If the module is top-level (i.e. not a part of any specific package)
+# then the attribute should be set to ''.
+# https://docs.python.org/3.8/library/types.html
+__package__ = ''
diff --git a/.venv/lib/python3.7/site-packages/caffe2/__init__.py b/.venv/lib/python3.7/site-packages/caffe2/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/__init__.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/aten/__init__.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/aten/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/aten/aten_test.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/aten/aten_test.py
new file mode 100644
index 0000000..4a025c3
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/aten/aten_test.py
@@ -0,0 +1,136 @@
+
+
+
+
+
+from caffe2.python import core, dyndep
+from hypothesis import given
+
+import caffe2.python.hypothesis_test_util as hu
+import hypothesis.strategies as st
+import numpy as np
+
+
+class TestATen(hu.HypothesisTestCase):
+
+    @given(inputs=hu.tensors(n=2), **hu.gcs)
+    def test_add(self, inputs, gc, dc):
+        op = core.CreateOperator(
+            "ATen",
+            ["X", "Y"],
+            ["Z"],
+            operator="add")
+
+        def ref(X, Y):
+            return [X + Y]
+        self.assertReferenceChecks(gc, op, inputs, ref)
+
+    @given(inputs=hu.tensors(n=2, dtype=np.float16), **hu.gcs_gpu_only)
+    def test_add_half(self, inputs, gc, dc):
+        op = core.CreateOperator(
+            "ATen",
+            ["X", "Y"],
+            ["Z"],
+            operator="add")
+
+        def ref(X, Y):
+            return [X + Y]
+        self.assertReferenceChecks(gc, op, inputs, ref)
+
+    @given(inputs=hu.tensors(n=1), **hu.gcs)
+    def test_pow(self, inputs, gc, dc):
+        op = core.CreateOperator(
+            "ATen",
+            ["S"],
+            ["Z"],
+            operator="pow", exponent=2.0)
+
+        def ref(X):
+            return [np.square(X)]
+
+        self.assertReferenceChecks(gc, op, inputs, ref)
+
+    @given(x=st.integers(min_value=2, max_value=8), **hu.gcs)
+    def test_sort(self, x, gc, dc):
+        inputs = [np.random.permutation(x)]
+        op = core.CreateOperator(
+            "ATen",
+            ["S"],
+            ["Z", "I"],
+            operator="sort")
+
+        def ref(X):
+            return [np.sort(X), np.argsort(X)]
+        self.assertReferenceChecks(gc, op, inputs, ref)
+
+    @given(inputs=hu.tensors(n=1), **hu.gcs)
+    def test_sum(self, inputs, gc, dc):
+        op = core.CreateOperator(
+            "ATen",
+            ["S"],
+            ["Z"],
+            operator="sum")
+
+        def ref(X):
+            return [np.sum(X)]
+
+        self.assertReferenceChecks(gc, op, inputs, ref)
+
+    @given(**hu.gcs)
+    def test_index_uint8(self, gc, dc):
+        # Indexing with uint8 is deprecated, but we need to provide backward compatibility for some old models exported through ONNX
+        op = core.CreateOperator(
+            "ATen",
+            ['self', 'mask'],
+            ["Z"],
+            operator="index")
+
+        def ref(self, mask):
+            return (self[mask.astype(np.bool_)],)
+
+        tensor = np.random.randn(2, 3, 4).astype(np.float32)
+        mask = np.array([[1, 0, 0], [1, 1, 0]]).astype(np.uint8)
+
+        self.assertReferenceChecks(gc, op, [tensor, mask], ref)
+
+    @given(**hu.gcs)
+    def test_index_put(self, gc, dc):
+        op = core.CreateOperator(
+            "ATen",
+            ['self', 'indices', 'values'],
+            ["Z"],
+            operator="index_put")
+
+        def ref(self, indices, values):
+            self[indices] = values
+            return (self,)
+
+        tensor = np.random.randn(3, 3).astype(np.float32)
+        mask = np.array([[True, True, True], [True, False, False], [True, True, False]])
+        values = np.random.randn(6).astype(np.float32)
+
+        self.assertReferenceChecks(gc, op, [tensor, mask, values], ref)
+
+    @given(**hu.gcs)
+    def test_unique(self, gc, dc):
+        op = core.CreateOperator(
+            "ATen",
+            ['self'],
+            ["output"],
+            sorted=True,
+            return_inverse=True,
+            # return_counts=False,
+            operator="_unique")
+
+        def ref(self):
+            index, _ = np.unique(self, return_index=False, return_inverse=True, return_counts=False)
+            return (index,)
+
+        tensor = np.array([1, 2, 6, 4, 2, 3, 2])
+        print(ref(tensor))
+        self.assertReferenceChecks(gc, op, [tensor], ref)
+
+
+if __name__ == "__main__":
+    import unittest
+    unittest.main()
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/aten/docs/__init__.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/aten/docs/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/aten/docs/sample.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/aten/docs/sample.py
new file mode 100644
index 0000000..53ce19b
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/aten/docs/sample.py
@@ -0,0 +1,56 @@
+import tempfile
+
+import numpy as np
+
+from torch import nn
+from torch.autograd import Variable, Function
+import torch.onnx
+
+import onnx
+import caffe2.python.onnx.backend
+
+class MyFunction(Function):
+    @staticmethod
+    def forward(ctx, x, y):
+        return x * x + y
+
+    @staticmethod
+    def symbolic(graph, x, y):
+        x2 = graph.at("mul", x, x)
+        r = graph.at("add", x2, y)
+        # x, y, x2, and r are 'Node' objects
+        # print(r) or print(graph) will print out a textual representation for debugging.
+        # this representation will be converted to ONNX protobufs on export.
+        return r
+
+class MyModule(nn.Module):
+    def forward(self, x, y):
+        # you can combine your ATen ops with standard onnx ones
+        x = nn.ReLU()(x)
+        return MyFunction.apply(x, y)
+
+f = tempfile.NamedTemporaryFile()
+torch.onnx.export(MyModule(),
+                  (Variable(torch.ones(3, 4)), Variable(torch.ones(3, 4))),
+                  f, verbose=True)
+
+# prints the graph for debugging:
+# graph(%input : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu),
+#       %y : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu)):
+#   %2 : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu) = onnx::Relu(%input)
+#   %3 : Tensor = onnx::ATen[operator="mul"](%2, %2)
+#   %4 : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu) = onnx::ATen[operator="add"](%3, %y)
+#   return (%4)
+
+graph = onnx.load(f.name)
+
+a = np.random.randn(3, 4).astype(np.float32)
+b = np.random.randn(3, 4).astype(np.float32)
+
+prepared_backend = caffe2.python.onnx.backend.prepare(graph)
+W = {graph.graph.input[0].name: a, graph.graph.input[1].name: b}
+c2_out = prepared_backend.run(W)[0]
+
+x = np.maximum(a, 0)
+r = x * x + b
+np.testing.assert_array_almost_equal(r, c2_out)
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/aten/gen_op.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/aten/gen_op.py
new file mode 100644
index 0000000..93d4bad
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/aten/gen_op.py
@@ -0,0 +1,325 @@
+#!/bin/env python3
+
+# Copyright (c) 2016-present, Facebook, Inc.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+##############################################################################
+
+import sys
+import yaml
+import argparse
+import os
+from copy import deepcopy
+from typing import Dict, List, Set
+
+parser = argparse.ArgumentParser()
+parser.add_argument("--template_dir", default=".", help="where template.h is")
+parser.add_argument("--yaml_dir", default="aten/src/ATen/ATen",
+                    help="where ATen yaml files are")
+parser.add_argument("--output_prefix", default="", help="")
+parser.add_argument(
+    "--install_dir", default=".", help="where to put generated file")
+parser.add_argument("--aten_root", default="", help="root directory of aten")
+args, _ = parser.parse_known_args()
+
+if args.aten_root:
+    if not os.path.exists(args.aten_root):
+        raise ValueError('aten_root ({}) does not exist'.format(
+            args.aten_root))
+    sys.path.insert(0, os.path.join(args.aten_root, '..'))
+    from tools.codegen.code_template import CodeTemplate as CT
+else:
+    from tools.codegen.code_template import CodeTemplate as CT
+
+OP_TEMPLATE = CT.from_file(
+    os.path.join(args.template_dir, 'aten_op_template.h'))
+
+
+try:
+    # use faster C loader if available
+    from yaml import CSafeLoader as Loader
+except ImportError:
+    from yaml import SafeLoader as Loader  # type: ignore[misc]
+
+
+def write(filename, s):
+    with open(filename, "w") as f:
+        f.write(s)
+
+
+def read(filename):
+    with open(filename, "r") as f:
+        return f.read()
+
+
+def value_has_tensors(v):
+    # Sparse shouldn't appear in public API, seems to be temporary bug
+    return "Tensor" in v['dynamic_type'] and "Sparse" not in v['dynamic_type']
+
+
+def value_is_tensor_type(v):
+    return value_has_tensors(v) and v['dynamic_type'] not in ['at::TensorList', 'const c10::List<c10::optional<at::Tensor>> &']
+
+
+# for each aten type, how do we handle a return value of that type?
+RETURN_MAP = {
+    'at::Tensor': 'assignTo(Output(${offset}),${output});',
+    'at::Scalar': 'assignTo(Output(${offset}),${output}.type(), ${output});',
+    'bool': 'assignToValue<int64_t>(Output(${offset}),${output});',
+    'int64_t': 'assignToValue<int64_t>(Output(${offset}),${output});',
+    '::std::vector<at::Tensor>': 'assignListStartingAt(${offset}, ${output});',
+}
+
+# for each non-Tensor aten argument, how to we read it from caffe2's
+# attribute list. Most of these call runtime functions defined in the
+# template class.
+ARGUMENT_MAP = {
+    'const at::Scalar &': 'at::Scalar ${arg} = readScalarAttribute("${arg}");',
+    'bool': 'bool ${arg} = readAttribute<int64_t>("${arg}");',
+    'int': 'int ${arg} = readAttribute<int64_t>("${arg}");',
+    'double': 'double ${arg} = readAttribute<float>("${arg}");',
+    'int64_t': 'int64_t ${arg} = readAttribute<int64_t>("${arg}");',
+    'at::IntArrayRef': 'auto ${arg} = readIntArrayRef("${arg}");',
+    '::std::array<bool,2>': 'auto ${arg} = readBoolMask<2>("${arg}");',
+    '::std::array<bool,3>': 'auto ${arg} = readBoolMask<3>("${arg}");',
+}
+
+# for BC reasons we want to route some of the functions to different
+# implementations
+SPECIAL_IMPLEMENTATIONS = {
+    'index': 'internal::index_with_uint8_handling',
+}
+
+def expand(o):
+    num_defaults = sum(1 if 'default' in arg else 0 for arg in o['arguments'])
+    results = [o]
+    for i in range(0, num_defaults):
+        # last num_default values should be default
+        assert('default' in o['arguments'][-(i + 1)])
+        v = deepcopy(o)
+        v['arguments'] = v['arguments'][:-(i + 1)]
+        results.append(v)
+    return results
+
+
+# filter the list of declarations removing things we cannot support
+def supports(o, factory_methods):
+    # Ignore all families (!) of functions that have TensorOptions (i.e. tensor factory methods).
+    if o['name'] in factory_methods:
+        if factory_methods[o['name']] == 0:
+            print("Skipping {} because it is a factory method".format(o['name']))
+        factory_methods[o['name']] += 1
+        return False
+
+    # skip all in-place operators for now since aten cannot Resize
+    # caffe2 memory inside an operator
+    if o['inplace']:
+        return False
+
+    # _out variants also work in-place on arguments taken as destinations
+    # we also cannot handle these because aten cannot resize caffe2 Tensors
+    if "_out" in o['name']:
+        return False
+
+    # skip if no return, previously it is 'void'
+    if len(o['returns']) == 0:
+        return False
+
+    # skip return types we cannot handle
+    for ret in o['returns']:
+        if not value_has_tensors(ret) and ret['type'] not in RETURN_MAP:
+            print("Skipping {} Because of Ret: {} ({})".format(
+                  o['name'], ret['type'], ret['dynamic_type']))
+            return False
+
+    # skip arguments we cannot handle
+    for arg in o['arguments']:
+        if not value_has_tensors(arg) and arg['type'] not in ARGUMENT_MAP:
+            print("Skipping {} Because of Arg: {} ({}) ".format(
+                  o['name'], arg['type'], arg['dynamic_type']))
+            return False
+    return True
+
+
+# template for each potential operator.
+# each operator has an integer 'key' associated with it, and
+# a lambda that defines the operator
+# non-tensor attributes are created in ${initialization}
+# and then saved as arguments to the lambda
+# Inputs/Outputs are read inside the lambda
+#
+# each implementation is defined in a separate method annotated with
+# C10_NOINLINE to avoid inlining into the ATenOp constructor, which would
+# trigger pathological compile times.
+IMPLEMENTATION_TEMPLATE = CT("""\
+C10_NOINLINE void implementation_${key}() { // ${name}
+    ${initialization}
+    run_op = [=] {
+        at::AutoDispatchBelowAutograd guard;
+        ${statements}
+        auto the_result = ${invocation};
+        ${assignments}
+        return true;
+    };
+}
+""")
+
+CASE_TEMPLATE = CT("""\
+case ${key}: // ${name}
+  implementation_${key}();
+  break;
+""")
+
+ASSIGN_CHECK_SIZE_TEMPLATE = CT("""\
+  if(OutputSize() > ${offset}) {${assignment}}
+""")
+
+
+def get_output(o, i):
+    if len(o['returns']) == 1:
+        return 'the_result'
+    else:
+        return '::std::get<{}>(the_result)'.format(i)
+
+
+def attribute_names(o):
+    return sorted([a['name'] for a in o['arguments'] if not value_has_tensors(a)])
+
+
+def required_attribute_names(o):
+    return sorted([a['name'] for a in o['arguments'] if not value_has_tensors(a) and 'default' not in a])
+
+
+def self_as_first_argument(arguments):
+    return ([a for a in arguments if a['name'] == 'self'] +
+            [a for a in arguments if a['name'] != 'self'])
+
+
+def get_num_inputs(o):
+    args = 0
+    for a in o['arguments']:
+        if a['type'] in ['at::TensorList', 'const c10::List<c10::optional<at::Tensor>> &']:
+            return '*'
+        elif value_has_tensors(a):
+            args += 1
+    return str(args)
+
+
+def find_factory_methods(decls):
+    factory_methods = {}
+    for o in decls:
+        if any(arg['dynamic_type'] == 'at::TensorOptions' for arg in o['arguments']):
+            factory_methods[o['name']] = 0
+    return factory_methods
+
+
+def emit_assignments(o, env):
+    for i, r in enumerate(o['returns']):
+        t = RETURN_MAP[r['type'] if not value_is_tensor_type(r) else 'at::Tensor']
+        assignment = CT(t).substitute(env, offset=i, output=get_output(o, i))
+        check_size_assignment = ASSIGN_CHECK_SIZE_TEMPLATE.substitute(env, offset=i, assignment=assignment)
+
+        env['assignments'].append(check_size_assignment)
+
+
+if __name__ == '__main__':
+    decls = yaml.load(read(os.path.join(args.yaml_dir, 'Declarations.yaml')), Loader=Loader)
+    factory_methods = find_factory_methods(decls)
+    filtered = [expanded for o in decls for expanded in expand(o) if supports(expanded, factory_methods)]
+    top_env: Dict[str, List] = {
+        'mappings': [],
+        'implementations': [],
+        'cases': [],
+    }
+    seen: Set[str] = set()
+    key = 0
+    for o in filtered:
+        # [DESCRIPTORS]
+        # each option is associated with a descriptor string that is used
+        # to figure out which version of an op is being used:
+        # The format is:
+        #     opname-num_inputs-attribute_1-attribute2
+        # Example:
+        #  lerp-2-weight
+        #  the operator lerp takes 2 arguments and has the attribute weight
+        attr_names = attribute_names(o)
+        num_inputs = get_num_inputs(o)
+        descriptor = '-'.join([o['name']] + attr_names + [num_inputs])
+        if descriptor in seen:
+            continue
+        seen.add(descriptor)
+
+        # map from descriptor string to the integer key in the switch statements
+        # that initializes the operators
+        top_env['mappings'].append('{{ "{}", {} }},'.format(descriptor, key))
+        env = {
+            'name': o['name'],
+            'statements': [],
+            'arguments': [],
+            'assignments': [],
+            'initialization': [],
+            'key': str(key),
+        }
+
+        if 'namespace' not in o['method_of'] and 'Tensor' not in o['method_of']:
+            # methods on type like 'ones' or 'zeros' always take a
+            # string attribute that is translated into the at::Type object
+            # e.g. "Float" is at::kFloat
+            assert('Type' in o['method_of'])
+
+        static_tensor_inputs = sum(arg['type'] not in ['at::TensorList', 'const c10::List<c10::optional<at::Tensor>> &'] and value_is_tensor_type(arg) for arg in o['arguments'])
+        has_tensorlist = any(arg['type'] in ['at::TensorList', 'const c10::List<c10::optional<at::Tensor>> &'] for arg in o['arguments'])
+        if has_tensorlist:
+            tensorlist_idx = [i for i, arg in enumerate(o['arguments']) if arg['type'] in ['at::TensorList', 'const c10::List<c10::optional<at::Tensor>> &']][0]
+
+        real_inputs = 0
+        for i, arg in enumerate(o['arguments']):
+            env['arguments'].append(arg['name'])
+            # Pretend the flat argument list is a stack where the end is the top.
+            view_length = 'InputSize()' if has_tensorlist and i < tensorlist_idx else static_tensor_inputs
+            if arg['type'] == 'at::TensorList':
+                # NOTE: do not advance real_inputs here. After this we will
+                # switch to indexing the "stack" from the end
+                env['statements'].append(
+                    'auto {} = peekSlice({}, InputSize() - {}, InputSize());'
+                    .format(arg['name'], real_inputs, static_tensor_inputs))
+            elif arg['type'] == 'const c10::List<c10::optional<at::Tensor>> &':
+                # NOTE: do not advance real_inputs here. After this we will
+                # switch to indexing the "stack" from the end
+                env['statements'].append(
+                    'auto {} = peekSliceOptionals({}, InputSize() - {}, InputSize());'
+                    .format(arg['name'], real_inputs, static_tensor_inputs))
+            elif value_is_tensor_type(arg):
+                # load tensor inputs from Caffe2
+                env['statements'].append(
+                    'auto {} = peek({}, {});'.format(arg['name'], real_inputs, view_length))
+                real_inputs += 1
+            else:
+                init = CT(ARGUMENT_MAP[arg['type']]).substitute(env, arg=arg['name'])
+                env['initialization'].append(init)
+
+        emit_assignments(o, env)
+
+        if o['name'] in SPECIAL_IMPLEMENTATIONS:
+            env['invocation'] = "{}({})".format(SPECIAL_IMPLEMENTATIONS[o['name']], ','.join(env['arguments']))
+        elif 'namespace' in o['method_of']:
+            env['invocation'] = CT("at::${name}(${arguments})").substitute(env)
+        else:
+            assert('Tensor' in o['method_of'])
+            env['invocation'] = "self.{}({})".format(
+                o['name'], ', '.join(env['arguments'][1:]))
+
+        top_env['implementations'].append(IMPLEMENTATION_TEMPLATE.substitute(env))
+        top_env['cases'].append(CASE_TEMPLATE.substitute(env))
+        key += 1
+    write(os.path.join(args.install_dir, args.output_prefix + "aten_op.h"), OP_TEMPLATE.substitute(top_env))
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/gloo/__init__.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/gloo/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/gloo/gloo_test.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/gloo/gloo_test.py
new file mode 100644
index 0000000..1bc1bf1
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/gloo/gloo_test.py
@@ -0,0 +1,706 @@
+#!/usr/bin/env python3
+
+
+
+
+
+
+from hypothesis import given, settings
+import hypothesis.strategies as st
+from multiprocessing import Process, Queue
+
+import numpy as np
+import os
+import pickle
+import tempfile
+import shutil
+
+from caffe2.python import core, workspace, dyndep
+import caffe2.python.hypothesis_test_util as hu
+from gloo.python import IoError
+
+dyndep.InitOpsLibrary("@/caffe2/caffe2/distributed:file_store_handler_ops")
+dyndep.InitOpsLibrary("@/caffe2/caffe2/distributed:redis_store_handler_ops")
+dyndep.InitOpsLibrary("@/caffe2/caffe2/distributed:store_ops")
+dyndep.InitOpsLibrary("@/caffe2/caffe2/contrib/gloo:gloo_ops")
+dyndep.InitOpsLibrary("@/caffe2/caffe2/contrib/gloo:gloo_ops_gpu")
+
+op_engine = 'GLOO'
+
+class TemporaryDirectory:
+    def __enter__(self):
+        self.tmpdir = tempfile.mkdtemp()
+        return self.tmpdir
+
+    def __exit__(self, type, value, traceback):
+        shutil.rmtree(self.tmpdir)
+
+
+class TestCase(hu.HypothesisTestCase):
+    test_counter = 0
+    sync_counter = 0
+
+    def run_test_locally(self, fn, device_option=None, **kwargs):
+        # Queue for assertion errors on subprocesses
+        queue = Queue()
+
+        # Capture any exception thrown by the subprocess
+        def run_fn(*args, **kwargs):
+            try:
+                with core.DeviceScope(device_option):
+                    fn(*args, **kwargs)
+                    workspace.ResetWorkspace()
+                    queue.put(True)
+            except Exception as ex:
+                queue.put(ex)
+
+        # Start N processes in the background
+        procs = []
+        for i in range(kwargs['comm_size']):
+            kwargs['comm_rank'] = i
+            proc = Process(
+                target=run_fn,
+                kwargs=kwargs)
+            proc.start()
+            procs.append(proc)
+
+        # Test complete, join background processes
+        while len(procs) > 0:
+            proc = procs.pop(0)
+            while proc.is_alive():
+                proc.join(10)
+
+            # Raise exception if we find any. Otherwise each worker
+            # should put a True into the queue
+            # Note that the following is executed ALSO after
+            # the last process was joined, so if ANY exception
+            # was raised, it will be re-raised here.
+            self.assertFalse(queue.empty(), "Job failed without a result")
+            o = queue.get()
+            if isinstance(o, Exception):
+                raise o
+            else:
+                self.assertTrue(o)
+
+    def run_test_distributed(self, fn, device_option=None, **kwargs):
+        comm_rank = os.getenv('COMM_RANK')
+        self.assertIsNotNone(comm_rank)
+        comm_size = os.getenv('COMM_SIZE')
+        self.assertIsNotNone(comm_size)
+        kwargs['comm_rank'] = int(comm_rank)
+        kwargs['comm_size'] = int(comm_size)
+        with core.DeviceScope(device_option):
+            fn(**kwargs)
+            workspace.ResetWorkspace()
+
+    def create_common_world(self, comm_rank, comm_size, tmpdir=None, existing_cw=None):
+        store_handler = "store_handler"
+
+        # If REDIS_HOST is set, use RedisStoreHandler for rendezvous.
+        if existing_cw is None:
+            redis_host = os.getenv("REDIS_HOST")
+            redis_port = int(os.getenv("REDIS_PORT", 6379))
+            if redis_host is not None:
+                workspace.RunOperatorOnce(
+                    core.CreateOperator(
+                        "RedisStoreHandlerCreate",
+                        [],
+                        [store_handler],
+                        prefix=str(TestCase.test_counter) + "/",
+                        host=redis_host,
+                        port=redis_port))
+            else:
+                workspace.RunOperatorOnce(
+                    core.CreateOperator(
+                        "FileStoreHandlerCreate",
+                        [],
+                        [store_handler],
+                        path=tmpdir))
+            common_world = "common_world"
+        else:
+            common_world = str(existing_cw) + ".forked"
+
+        if existing_cw is not None:
+            workspace.RunOperatorOnce(
+                core.CreateOperator(
+                    "CloneCommonWorld",
+                    [existing_cw],
+                    [common_world],
+                    sync=True,
+                    engine=op_engine))
+        else:
+            workspace.RunOperatorOnce(
+                core.CreateOperator(
+                    "CreateCommonWorld",
+                    [store_handler],
+                    [common_world],
+                    size=comm_size,
+                    rank=comm_rank,
+                    sync=True,
+                    engine=op_engine))
+        return (store_handler, common_world)
+
+    def synchronize(self, store_handler, value, comm_rank=None):
+        TestCase.sync_counter += 1
+        blob = "sync_{}".format(TestCase.sync_counter)
+        if comm_rank == 0:
+            workspace.FeedBlob(blob, pickle.dumps(value))
+            workspace.RunOperatorOnce(
+                core.CreateOperator(
+                    "StoreSet",
+                    [store_handler, blob],
+                    []))
+        else:
+            workspace.RunOperatorOnce(
+                core.CreateOperator(
+                    "StoreGet",
+                    [store_handler],
+                    [blob]))
+        return pickle.loads(workspace.FetchBlob(blob))
+
+    def _test_broadcast(self,
+                        comm_rank=None,
+                        comm_size=None,
+                        blob_size=None,
+                        num_blobs=None,
+                        tmpdir=None,
+                        use_float16=False,
+                        ):
+        store_handler, common_world = self.create_common_world(
+            comm_rank=comm_rank,
+            comm_size=comm_size,
+            tmpdir=tmpdir)
+
+        blob_size = self.synchronize(
+            store_handler,
+            blob_size,
+            comm_rank=comm_rank)
+
+        num_blobs = self.synchronize(
+            store_handler,
+            num_blobs,
+            comm_rank=comm_rank)
+
+        for i in range(comm_size):
+            blobs = []
+            for j in range(num_blobs):
+                blob = "blob_{}".format(j)
+                offset = (comm_rank * num_blobs) + j
+                value = np.full(blob_size, offset,
+                                np.float16 if use_float16 else np.float32)
+                workspace.FeedBlob(blob, value)
+                blobs.append(blob)
+
+            net = core.Net("broadcast")
+            net.Broadcast(
+                [common_world] + blobs,
+                blobs,
+                root=i,
+                engine=op_engine)
+
+            workspace.CreateNet(net)
+            workspace.RunNet(net.Name())
+
+            for j in range(num_blobs):
+                np.testing.assert_array_equal(
+                    workspace.FetchBlob(blobs[j]),
+                    i * num_blobs)
+
+            # Run the net a few more times to check the operator
+            # works not just the first time it's called
+            for _tmp in range(4):
+                workspace.RunNet(net.Name())
+
+    @given(comm_size=st.integers(min_value=2, max_value=8),
+           blob_size=st.integers(min_value=int(1e3), max_value=int(1e6)),
+           num_blobs=st.integers(min_value=1, max_value=4),
+           device_option=st.sampled_from([hu.cpu_do]),
+           use_float16=st.booleans())
+    @settings(deadline=10000)
+    def test_broadcast(self, comm_size, blob_size, num_blobs, device_option,
+                       use_float16):
+        TestCase.test_counter += 1
+        if os.getenv('COMM_RANK') is not None:
+            self.run_test_distributed(
+                self._test_broadcast,
+                blob_size=blob_size,
+                num_blobs=num_blobs,
+                use_float16=use_float16,
+                device_option=device_option)
+        else:
+            with TemporaryDirectory() as tmpdir:
+                self.run_test_locally(
+                    self._test_broadcast,
+                    comm_size=comm_size,
+                    blob_size=blob_size,
+                    num_blobs=num_blobs,
+                    device_option=device_option,
+                    tmpdir=tmpdir,
+                    use_float16=use_float16)
+
+    def _test_allreduce(self,
+                        comm_rank=None,
+                        comm_size=None,
+                        blob_size=None,
+                        num_blobs=None,
+                        tmpdir=None,
+                        use_float16=False
+                        ):
+        store_handler, common_world = self.create_common_world(
+            comm_rank=comm_rank,
+            comm_size=comm_size,
+            tmpdir=tmpdir)
+
+        blob_size = self.synchronize(
+            store_handler,
+            blob_size,
+            comm_rank=comm_rank)
+
+        num_blobs = self.synchronize(
+            store_handler,
+            num_blobs,
+            comm_rank=comm_rank)
+
+        blobs = []
+        for i in range(num_blobs):
+            blob = "blob_{}".format(i)
+            value = np.full(blob_size, (comm_rank * num_blobs) + i,
+                            np.float16 if use_float16 else np.float32)
+            workspace.FeedBlob(blob, value)
+            blobs.append(blob)
+
+        net = core.Net("allreduce")
+        net.Allreduce(
+            [common_world] + blobs,
+            blobs,
+            engine=op_engine)
+
+        workspace.CreateNet(net)
+        workspace.RunNet(net.Name())
+
+        for i in range(num_blobs):
+            np.testing.assert_array_equal(
+                workspace.FetchBlob(blobs[i]),
+                (num_blobs * comm_size) * (num_blobs * comm_size - 1) / 2)
+
+        # Run the net a few more times to check the operator
+        # works not just the first time it's called
+        for _tmp in range(4):
+            workspace.RunNet(net.Name())
+
+    def _test_allreduce_multicw(self,
+                                comm_rank=None,
+                                comm_size=None,
+                                tmpdir=None
+                                ):
+        _store_handler, common_world = self.create_common_world(
+            comm_rank=comm_rank,
+            comm_size=comm_size,
+            tmpdir=tmpdir)
+
+        _, common_world2 = self.create_common_world(
+            comm_rank=comm_rank,
+            comm_size=comm_size,
+            tmpdir=tmpdir,
+            existing_cw=common_world)
+
+        blob_size = int(1e4)
+        num_blobs = 4
+
+        for cw in [common_world, common_world2]:
+            blobs = []
+            for i in range(num_blobs):
+                blob = "blob_{}".format(i)
+                value = np.full(blob_size, (comm_rank * num_blobs) + i, np.float32)
+                workspace.FeedBlob(blob, value)
+                blobs.append(blob)
+
+            net = core.Net("allreduce_multicw")
+            net.Allreduce(
+                [cw] + blobs,
+                blobs,
+                engine=op_engine)
+
+            workspace.RunNetOnce(net)
+            for i in range(num_blobs):
+                np.testing.assert_array_equal(
+                    workspace.FetchBlob(blobs[i]),
+                    (num_blobs * comm_size) * (num_blobs * comm_size - 1) / 2)
+
+    @given(comm_size=st.integers(min_value=2, max_value=8),
+           blob_size=st.integers(min_value=int(1e3), max_value=int(1e6)),
+           num_blobs=st.integers(min_value=1, max_value=4),
+           device_option=st.sampled_from([hu.cpu_do]),
+           use_float16=st.booleans())
+    @settings(deadline=10000)
+    def test_allreduce(self, comm_size, blob_size, num_blobs, device_option,
+                       use_float16):
+        TestCase.test_counter += 1
+        if os.getenv('COMM_RANK') is not None:
+            self.run_test_distributed(
+                self._test_allreduce,
+                blob_size=blob_size,
+                num_blobs=num_blobs,
+                use_float16=use_float16,
+                device_option=device_option)
+        else:
+            with TemporaryDirectory() as tmpdir:
+                self.run_test_locally(
+                    self._test_allreduce,
+                    comm_size=comm_size,
+                    blob_size=blob_size,
+                    num_blobs=num_blobs,
+                    device_option=device_option,
+                    tmpdir=tmpdir,
+                    use_float16=use_float16)
+
+    def _test_reduce_scatter(self,
+                             comm_rank=None,
+                             comm_size=None,
+                             blob_size=None,
+                             num_blobs=None,
+                             tmpdir=None,
+                             use_float16=False
+                             ):
+        store_handler, common_world = self.create_common_world(
+            comm_rank=comm_rank,
+            comm_size=comm_size,
+            tmpdir=tmpdir)
+
+        blob_size = self.synchronize(
+            store_handler,
+            blob_size,
+            comm_rank=comm_rank)
+
+        num_blobs = self.synchronize(
+            store_handler,
+            num_blobs,
+            comm_rank=comm_rank)
+
+        blobs = []
+        for i in range(num_blobs):
+            blob = "blob_{}".format(i)
+            value = np.full(blob_size, (comm_rank * num_blobs) + i,
+                            np.float16 if use_float16 else np.float32)
+            workspace.FeedBlob(blob, value)
+            blobs.append(blob)
+
+        # Specify distribution among ranks i.e. number of elements
+        # scattered/distributed to each process.
+        recv_counts = np.zeros(comm_size, dtype=np.int32)
+        remaining = blob_size
+        chunk_size = (blob_size + comm_size - 1) / comm_size
+        for i in range(comm_size):
+            recv_counts[i] = min(chunk_size, remaining)
+            remaining = remaining - chunk_size if remaining > chunk_size else 0
+        recv_counts_blob = "recvCounts"
+        workspace.FeedBlob(recv_counts_blob, recv_counts)
+        blobs.append(recv_counts_blob)
+
+        net = core.Net("reduce_scatter")
+        net.ReduceScatter(
+            [common_world] + blobs,
+            blobs,
+            engine=op_engine)
+
+        workspace.CreateNet(net)
+        workspace.RunNet(net.Name())
+
+        for i in range(num_blobs):
+            np.testing.assert_array_equal(
+                np.resize(workspace.FetchBlob(blobs[i]), recv_counts[comm_rank]),
+                (num_blobs * comm_size) * (num_blobs * comm_size - 1) / 2)
+
+        # Run the net a few more times to check the operator
+        # works not just the first time it's called
+        for _tmp in range(4):
+            workspace.RunNet(net.Name())
+
+    @given(comm_size=st.integers(min_value=2, max_value=8),
+           blob_size=st.integers(min_value=int(1e3), max_value=int(1e6)),
+           num_blobs=st.integers(min_value=1, max_value=4),
+           device_option=st.sampled_from([hu.cpu_do]),
+           use_float16=st.booleans())
+    @settings(deadline=10000)
+    def test_reduce_scatter(self, comm_size, blob_size, num_blobs,
+                            device_option, use_float16):
+        TestCase.test_counter += 1
+        if os.getenv('COMM_RANK') is not None:
+            self.run_test_distributed(
+                self._test_reduce_scatter,
+                blob_size=blob_size,
+                num_blobs=num_blobs,
+                use_float16=use_float16,
+                device_option=device_option)
+        else:
+            with TemporaryDirectory() as tmpdir:
+                self.run_test_locally(
+                    self._test_reduce_scatter,
+                    comm_size=comm_size,
+                    blob_size=blob_size,
+                    num_blobs=num_blobs,
+                    device_option=device_option,
+                    tmpdir=tmpdir,
+                    use_float16=use_float16)
+
+    def _test_allgather(self,
+                        comm_rank=None,
+                        comm_size=None,
+                        blob_size=None,
+                        num_blobs=None,
+                        tmpdir=None,
+                        use_float16=False
+                        ):
+        store_handler, common_world = self.create_common_world(
+            comm_rank=comm_rank,
+            comm_size=comm_size,
+            tmpdir=tmpdir)
+
+        blob_size = self.synchronize(
+            store_handler,
+            blob_size,
+            comm_rank=comm_rank)
+
+        num_blobs = self.synchronize(
+            store_handler,
+            num_blobs,
+            comm_rank=comm_rank)
+
+        blobs = []
+        for i in range(num_blobs):
+            blob = "blob_{}".format(i)
+            value = np.full(blob_size, (comm_rank * num_blobs) + i,
+                            np.float16 if use_float16 else np.float32)
+            workspace.FeedBlob(blob, value)
+            blobs.append(blob)
+
+        net = core.Net("allgather")
+        net.Allgather(
+            [common_world] + blobs,
+            ["Gathered"],
+            engine=op_engine)
+
+        workspace.CreateNet(net)
+        workspace.RunNet(net.Name())
+        # create expected output
+        expected_output = np.array([])
+        for i in range(comm_size):
+            for j in range(num_blobs):
+                value = np.full(blob_size, (i * num_blobs) + j,
+                                np.float16 if use_float16 else np.float32)
+                expected_output = np.concatenate((expected_output, value))
+        np.testing.assert_array_equal(
+            workspace.FetchBlob("Gathered"), expected_output)
+
+        # Run the net a few more times to check the operator
+        # works not just the first time it's called
+        for _tmp in range(4):
+            workspace.RunNet(net.Name())
+
+    @given(comm_size=st.integers(min_value=2, max_value=8),
+           blob_size=st.integers(min_value=int(1e3), max_value=int(1e6)),
+           num_blobs=st.integers(min_value=1, max_value=4),
+           device_option=st.sampled_from([hu.cpu_do]),
+           use_float16=st.booleans())
+    @settings(max_examples=10, deadline=None)
+    def test_allgather(self, comm_size, blob_size, num_blobs, device_option,
+                       use_float16):
+        TestCase.test_counter += 1
+        if os.getenv('COMM_RANK') is not None:
+            self.run_test_distributed(
+                self._test_allgather,
+                blob_size=blob_size,
+                num_blobs=num_blobs,
+                use_float16=use_float16,
+                device_option=device_option)
+        else:
+            with TemporaryDirectory() as tmpdir:
+                self.run_test_locally(
+                    self._test_allgather,
+                    comm_size=comm_size,
+                    blob_size=blob_size,
+                    num_blobs=num_blobs,
+                    device_option=device_option,
+                    tmpdir=tmpdir,
+                    use_float16=use_float16)
+
+    @given(device_option=st.sampled_from([hu.cpu_do]))
+    @settings(deadline=10000)
+    def test_forked_cw(self, device_option):
+        TestCase.test_counter += 1
+        if os.getenv('COMM_RANK') is not None:
+            self.run_test_distributed(
+                self._test_allreduce_multicw,
+                device_option=device_option)
+        else:
+            # Note: this test exercises the path where we fork a common world.
+            # We therefore don't need a comm size larger than 2. It used to be
+            # run with comm_size=8, which causes flaky results in a stress run.
+            # The flakiness was caused by too many listening sockets being
+            # created by Gloo context initialization (8 processes times
+            # 7 sockets times 20-way concurrency, plus TIME_WAIT).
+            with TemporaryDirectory() as tmpdir:
+                self.run_test_locally(
+                    self._test_allreduce_multicw,
+                    comm_size=2,
+                    device_option=device_option,
+                    tmpdir=tmpdir)
+
+    def _test_barrier(
+        self,
+        comm_rank=None,
+        comm_size=None,
+        tmpdir=None,
+    ):
+        store_handler, common_world = self.create_common_world(
+            comm_rank=comm_rank, comm_size=comm_size, tmpdir=tmpdir
+        )
+
+        net = core.Net("barrier")
+        net.Barrier(
+            [common_world],
+            [],
+            engine=op_engine)
+
+        workspace.CreateNet(net)
+        workspace.RunNet(net.Name())
+
+        # Run the net a few more times to check the operator
+        # works not just the first time it's called
+        for _tmp in range(4):
+            workspace.RunNet(net.Name())
+
+    @given(comm_size=st.integers(min_value=2, max_value=8),
+           device_option=st.sampled_from([hu.cpu_do]))
+    @settings(deadline=10000)
+    def test_barrier(self, comm_size, device_option):
+        TestCase.test_counter += 1
+        if os.getenv('COMM_RANK') is not None:
+            self.run_test_distributed(
+                self._test_barrier,
+                device_option=device_option)
+        else:
+            with TemporaryDirectory() as tmpdir:
+                self.run_test_locally(
+                    self._test_barrier,
+                    comm_size=comm_size,
+                    device_option=device_option,
+                    tmpdir=tmpdir)
+
+    def _test_close_connection(
+        self,
+        comm_rank=None,
+        comm_size=None,
+        tmpdir=None,
+    ):
+        '''
+        One node calls close connection, others wait it on barrier.
+        Test will check that all will exit eventually.
+        '''
+        # Caffe's for closers only:
+        # https://www.youtube.com/watch?v=QMFwFgG9NE8
+        closer = comm_rank == comm_size // 2,
+
+        store_handler, common_world = self.create_common_world(
+            comm_rank=comm_rank, comm_size=comm_size, tmpdir=tmpdir
+        )
+
+        net = core.Net("barrier_or_close")
+        if not closer:
+            net.Barrier(
+                [common_world],
+                [],
+                engine=op_engine)
+        else:
+            net.DestroyCommonWorld(
+                [common_world], [common_world], engine=op_engine)
+            # Sleep a bit to ensure others start the barrier
+            import time
+            time.sleep(0.1)
+
+        workspace.CreateNet(net)
+        workspace.RunNet(net.Name())
+
+    @given(comm_size=st.integers(min_value=2, max_value=8),
+           device_option=st.sampled_from([hu.cpu_do]))
+    @settings(deadline=10000)
+    def test_close_connection(self, comm_size, device_option):
+        import time
+        start_time = time.time()
+        TestCase.test_counter += 1
+        if os.getenv('COMM_RANK') is not None:
+            self.run_test_distributed(
+                self._test_close_connection,
+                device_option=device_option)
+        else:
+            with TemporaryDirectory() as tmpdir:
+                self.run_test_locally(
+                    self._test_close_connection,
+                    comm_size=comm_size,
+                    device_option=device_option,
+                    tmpdir=tmpdir)
+        # Check that test finishes quickly because connections get closed.
+        # This assert used to check that the end to end runtime was less
+        # than 2 seconds, but this may not always be the case if there
+        # is significant overhead in starting processes. Ideally, this
+        # assert is replaced by one that doesn't depend on time but rather
+        # checks the success/failure status of the barrier that is run.
+        self.assertLess(time.time() - start_time, 20.0)
+
+    def _test_io_error(
+        self,
+        comm_rank=None,
+        comm_size=None,
+        tmpdir=None,
+    ):
+        '''
+        Only one node will participate in allreduce, resulting in an IoError
+        '''
+        store_handler, common_world = self.create_common_world(
+            comm_rank=comm_rank,
+            comm_size=comm_size,
+            tmpdir=tmpdir)
+
+        if comm_rank == 0:
+            blob_size = 1000
+            num_blobs = 1
+
+            blobs = []
+            for i in range(num_blobs):
+                blob = "blob_{}".format(i)
+                value = np.full(
+                    blob_size, (comm_rank * num_blobs) + i, np.float32
+                )
+                workspace.FeedBlob(blob, value)
+                blobs.append(blob)
+
+            net = core.Net("allreduce")
+            net.Allreduce(
+                [common_world] + blobs,
+                blobs,
+                engine=op_engine)
+
+            workspace.CreateNet(net)
+            workspace.RunNet(net.Name())
+
+    @given(comm_size=st.integers(min_value=2, max_value=8),
+           device_option=st.sampled_from([hu.cpu_do]))
+    @settings(deadline=10000)
+    def test_io_error(self, comm_size, device_option):
+        TestCase.test_counter += 1
+        with self.assertRaises(IoError):
+            if os.getenv('COMM_RANK') is not None:
+                self.run_test_distributed(
+                    self._test_io_error,
+                    device_option=device_option)
+            else:
+                with TemporaryDirectory() as tmpdir:
+                    self.run_test_locally(
+                        self._test_io_error,
+                        comm_size=comm_size,
+                        device_option=device_option,
+                        tmpdir=tmpdir)
+
+if __name__ == "__main__":
+    import unittest
+    unittest.main()
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/nccl/__init__.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/nccl/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/nccl/nccl_ops_test.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/nccl/nccl_ops_test.py
new file mode 100644
index 0000000..2d4e9b5
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/nccl/nccl_ops_test.py
@@ -0,0 +1,192 @@
+
+
+
+
+
+import unittest
+import hypothesis.strategies as st
+from hypothesis import given, assume
+import numpy as np
+import time
+import os
+from caffe2.proto import caffe2_pb2
+from caffe2.python import core, workspace, muji, dyndep
+import caffe2.python.hypothesis_test_util as hu
+
+np.random.seed(1)
+
+dyndep.InitOpsLibrary('@/caffe2/caffe2/contrib/nccl:nccl_ops')
+
+
+def gpu_device(i):
+    device_option = caffe2_pb2.DeviceOption()
+    device_option.device_type = workspace.GpuDeviceType
+    device_option.device_id = i
+    return device_option
+
+
+def benchmark(ws, net, warmups=5, iters=100):
+    for _ in range(warmups):
+        ws.run(net)
+    plan = core.Plan("plan")
+    plan.AddStep(core.ExecutionStep("test-step", net, iters))
+    before = time.time()
+    ws.run(plan)
+    after = time.time()
+    print("Timing network, time taken per-iteration: {:.6f}ms".format((
+        after - before) / float(iters) * 1000.0))
+    return after - before
+
+
+@unittest.skipIf(not workspace.has_cuda_support, "NCCL only on CUDA GPU")
+class NCCLOpsTest(hu.HypothesisTestCase):
+    @given(n=st.integers(min_value=2, max_value=workspace.NumGpuDevices()),
+           m=st.integers(min_value=1, max_value=1000),
+           in_place=st.booleans())
+    def test_nccl_allreduce(self, n, m, in_place):
+        xs = [np.random.randn(m).astype(np.float32) for i in range(n)]
+        inputs = [str("x_{}".format(i)) for i in range(n)]
+        prefix = "" if in_place else "o"
+        outputs = [str("{}x_{}".format(prefix, i)) for i in range(n)]
+        op = core.CreateOperator("NCCLAllreduce", inputs, outputs)
+        input_device_options = {n: gpu_device(i) for i, n in enumerate(inputs)}
+
+        def allreduce(*args):
+            assert len(args) == n
+            output = np.sum(args, axis=0)
+            return [output for _ in range(n)]
+
+        outputs = self.assertReferenceChecks(
+            hu.gpu_do, op, [xs[i] for i, _ in enumerate(inputs)],
+            allreduce, input_device_options)
+        for output in outputs:
+            np.testing.assert_array_equal(outputs[0], output)
+            self.assertEqual(outputs[0].tobytes(), output.tobytes())
+
+    @given(n=st.integers(min_value=2, max_value=workspace.NumGpuDevices()),
+           m=st.integers(min_value=1, max_value=1000),
+           root=st.integers(min_value=0,
+                            max_value=workspace.NumGpuDevices() - 1))
+    def test_nccl_broadcast(self, n, m, root):
+        assume(root < n)
+        xs = [np.random.randn(m).astype(np.float32) for i in range(n)]
+        inputs = [str("x_{}".format(i)) for i in range(n)]
+        op = core.CreateOperator("NCCLBroadcast", inputs, inputs, root=root)
+        input_device_options = {n: gpu_device(i) for i, n in enumerate(inputs)}
+
+        def broadcast(*args):
+            assert len(args) == n
+            return [args[root] for _ in range(n)]
+
+        self.assertReferenceChecks(
+            hu.gpu_do, op, [xs[i] for i, _ in enumerate(inputs)],
+            broadcast, input_device_options)
+
+    @given(n=st.integers(min_value=2, max_value=workspace.NumGpuDevices()),
+           m=st.integers(min_value=1, max_value=1000),
+           # NCCL Reduce seems to deadlock for non-zero roots.
+           root=st.integers(min_value=0, max_value=0),
+           in_place=st.booleans())
+    def test_nccl_reduce(self, n, m, root, in_place):
+        assume(in_place is False or root == 0)
+        xs = [np.random.randn(m).astype(np.float32) for i in range(n)]
+        inputs = [str("x_{}".format(i)) for i in range(n)]
+        op = core.CreateOperator(
+            "NCCLReduce", inputs,
+            inputs[root] if in_place else b"o", root=root)
+        input_device_options = {n: gpu_device(i) for i, n in enumerate(inputs)}
+
+        def reduce(*args):
+            assert len(args) == n
+            return [np.sum(args, axis=0)]
+
+        self.assertReferenceChecks(
+            hu.gpu_do, op, [xs[i] for i, _ in enumerate(inputs)],
+            reduce, input_device_options)
+
+    @given(n=st.integers(min_value=2, max_value=workspace.NumGpuDevices()),
+           m=st.integers(min_value=1, max_value=1000))
+    def test_nccl_allgather(self, n, m):
+        xs = [np.random.randn(m).astype(np.float32) for i in range(n)]
+        inputs = [str("x_{}".format(i)) for i in range(n)]
+        outputs = [str("o_{}".format(i)) for i in range(n)]
+        op = core.CreateOperator("NCCLAllGather", inputs, outputs)
+        input_device_options = {n: gpu_device(i) for i, n in enumerate(inputs)}
+
+        def allgather(*args):
+            assert len(args) == n
+            return [np.stack(args, axis=0) for _ in range(n)]
+
+        outputs = self.assertReferenceChecks(
+            hu.gpu_do, op, [xs[i] for i, _ in enumerate(inputs)],
+            allgather, input_device_options)
+        for output in outputs:
+            np.testing.assert_array_equal(outputs[0], output)
+            self.assertEqual(outputs[0].tobytes(), output.tobytes())
+
+    @given(n=st.integers(min_value=2, max_value=workspace.NumGpuDevices()),
+           m=st.integers(min_value=1, max_value=1000))
+    def test_nccl_reduce_scatter(self, n, m):
+        xs = [np.random.randn(n, m).astype(np.float32) for i in range(n)]
+        inputs = [str("x_{}".format(i)) for i in range(n)]
+        outputs = [str("o_{}".format(i)) for i in range(n)]
+        op = core.CreateOperator("NCCLReduceScatter", inputs, outputs)
+        input_device_options = {n: gpu_device(i) for i, n in enumerate(inputs)}
+
+        def reduce_scatter(*args):
+            assert len(args) == n
+            reduced = sum(args)
+            assert len(reduced.shape) > 1
+            ref = [reduced[i, :] for i in range(n)]
+            return ref
+
+        self.assertReferenceChecks(
+            hu.gpu_do, op, [xs[i] for i, _ in enumerate(inputs)],
+            reduce_scatter, input_device_options)
+
+    @given(n=st.integers(min_value=2, max_value=workspace.NumGpuDevices()),
+           m=st.integers(min_value=100000, max_value=100000),
+           iters=st.integers(min_value=1, max_value=100),
+           net_type=st.sampled_from(["dag", "async_dag", "simple"]))
+    def _test_nccl_sync(self, n, m, iters, net_type):
+        inputs = [str("x_{}".format(i)) for i in range(n)]
+        extra_inputs = [str("xe_{}".format(i)) for i in range(n)]
+        net = core.Net("asdf")
+        net.Proto().type = net_type
+        net.Proto().num_workers = n
+        for i in range(n):
+            net.ConstantFill([], inputs[i], shape=[m], value=0.0,
+                             device_option=gpu_device(i))
+            net.ConstantFill([], extra_inputs[i], shape=[m], value=1.0,
+                             device_option=gpu_device(i))
+            for _ in range(iters):
+                net.Sum([inputs[i], extra_inputs[i]], [inputs[i]],
+                        device_option=gpu_device(i))
+        net.NCCLReduce(inputs, [inputs[0]], device_option=gpu_device(0))
+        self.ws.run(net)
+        np.testing.assert_array_equal(
+            self.ws.blobs[inputs[0]].fetch(),
+            np.full(shape=(m,), fill_value=iters * n, dtype=np.float32))
+
+    @unittest.skipIf(not os.environ.get("CAFFE2_BENCHMARK"), "Benchmark")
+    def test_timings(self):
+        for n in range(2, workspace.NumGpuDevices()):
+            for in_place in [False, True]:
+                xs = [np.random.randn(1e7).astype(np.float32)
+                      for i in range(n)]
+                inputs = [str("x_{}".format(i)) for i in range(n)]
+                prefix = "" if in_place else "o"
+                outputs = [str("{}x_{}".format(prefix, i)) for i in range(n)]
+
+                net = core.Net("test")
+                net.NCCLAllreduce(inputs, outputs)
+                net.RunAllOnGPU()
+                for i in range(n):
+                    self.ws.create_blob(inputs[i]).feed(xs[i], gpu_device(i))
+                self.ws.run(net)
+                net_time = benchmark(self.ws, net)
+                vanilla = core.Net("vanilla")
+                muji.Allreduce(vanilla, inputs)
+                vanilla_time = benchmark(self.ws, vanilla)
+                print("Speedup for NCCL: {:.2f}".format(
+                    vanilla_time / net_time))
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/nnpack/__init__.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/nnpack/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/nnpack/nnpack_ops_test.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/nnpack/nnpack_ops_test.py
new file mode 100644
index 0000000..4bedf0e
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/nnpack/nnpack_ops_test.py
@@ -0,0 +1,237 @@
+
+
+
+
+
+import unittest
+import hypothesis.strategies as st
+from hypothesis import given, assume, settings
+import numpy as np
+import time
+import os
+from caffe2.python import core, dyndep
+import caffe2.python.hypothesis_test_util as hu
+
+
+dyndep.InitOpsLibrary("@/caffe2/caffe2/contrib/nnpack:nnpack_ops")
+
+np.random.seed(1)
+
+
+def benchmark(ws, net, warmups=5, iters=100):
+    for _ in range(warmups):
+        ws.run(net)
+    plan = core.Plan("plan")
+    plan.AddStep(core.ExecutionStep("test-step", net, iters))
+    before = time.time()
+    ws.run(plan)
+    after = time.time()
+    print("Timing network, time taken per-iteration: {:.6f}ms".format((
+        after - before) / float(iters) * 1000.0))
+    return after - before
+
+
+def has_avx2():
+    import subprocess
+    try:
+        subprocess.check_output(["grep", "avx2", "/proc/cpuinfo"])
+        return True
+    except subprocess.CalledProcessError:
+        # grep exits with rc 1 on no matches
+        return False
+
+
+@unittest.skipIf(not has_avx2(), "NNPACK requires AVX2")
+class NNPackOpsTest(hu.HypothesisTestCase):
+    @given(stride=st.integers(1, 3),
+           pad=st.integers(0, 2),
+           kernel=st.integers(3, 5),
+           size=st.integers(5, 10),
+           input_channels=st.integers(1, 8),
+           batch_size=st.integers(1, 5),
+           groups=st.integers(1, 2))
+    def test_convolution_correctness(self, stride, pad, kernel, size,
+                                     input_channels,
+                                     batch_size, groups):
+        input_channels *= groups
+        output_channels = int(input_channels / groups)
+        assume(input_channels % groups == 0)
+        assume(output_channels % groups == 0)
+        assume(output_channels == input_channels / groups)
+        assume(stride <= kernel)
+        if stride != 1:
+            assume(batch_size == 1)
+
+        X = np.random.rand(
+            batch_size, input_channels, size, size).astype(np.float32) - 0.5
+        w = np.random.rand(
+            input_channels, output_channels, kernel, kernel).astype(np.float32)\
+            - 0.5
+        b = np.random.rand(output_channels).astype(np.float32) - 0.5
+        order = "NCHW"
+        outputs = {}
+        for engine in ["", "NNPACK"]:
+            op = core.CreateOperator(
+                "Conv",
+                ["X", "w", "b"],
+                ["Y"],
+                stride=stride,
+                kernel=kernel,
+                pad=pad,
+                order=order,
+                kts="TUPLE",
+                engine=engine,
+                group=groups,
+            )
+            self.ws.create_blob("X").feed(X)
+            self.ws.create_blob("w").feed(w)
+            self.ws.create_blob("b").feed(b)
+            self.ws.run(op)
+            outputs[engine] = self.ws.blobs["Y"].fetch()
+        np.testing.assert_allclose(
+            outputs[""],
+            outputs["NNPACK"],
+            atol=1e-4,
+            rtol=1e-4)
+
+    @given(size=st.sampled_from([6, 8]),
+           input_channels=st.integers(1, 8),
+           batch_size=st.integers(1, 5))
+    def test_max_pool_correctness(self, size, input_channels, batch_size):
+        X = np.random.rand(
+            batch_size, input_channels, size, size).astype(np.float32) - 0.5
+        order = "NCHW"
+        outputs = {}
+        # only 2 * 2 stride and 2 * 2 pool is supported in NNPack now
+        stride = 2
+        kernel = 2
+        # The pooling strategy of NNPack is different from caffe2 pooling
+        pad = 0
+        for engine in ["", "NNPACK"]:
+            op = core.CreateOperator(
+                "MaxPool",
+                ["X"],
+                ["Y"],
+                stride=stride,
+                kernel=kernel,
+                pad=pad,
+                order=order,
+                engine=engine,
+            )
+            self.ws.create_blob("X").feed(X)
+            self.ws.run(op)
+            outputs[engine] = self.ws.blobs["Y"].fetch()
+        np.testing.assert_allclose(
+            outputs[""],
+            outputs["NNPACK"],
+            atol=1e-4,
+            rtol=1e-4)
+
+    @given(size=st.sampled_from([6, 8]),
+           input_channels=st.integers(1, 8),
+           batch_size=st.integers(1, 5))
+    def test_relu_correctness(self, size, input_channels, batch_size):
+        X = np.random.rand(
+            batch_size, input_channels, size, size).astype(np.float32) - 0.5
+        outputs = {}
+        for engine in ["", "NNPACK"]:
+            op = core.CreateOperator(
+                "Relu",
+                ["X"],
+                ["Y"],
+                engine=engine,
+            )
+            self.ws.create_blob("X").feed(X)
+            self.ws.run(op)
+            outputs[engine] = self.ws.blobs["Y"].fetch()
+        np.testing.assert_allclose(
+            outputs[""],
+            outputs["NNPACK"],
+            atol=1e-4,
+            rtol=1e-4)
+
+    @given(size=st.sampled_from([6, 8]),
+           input_channels=st.integers(1, 8),
+           batch_size=st.integers(1, 5),
+           alpha=st.floats(0, 1))
+    def test_leaky_relu_correctness(self, size, input_channels, batch_size,
+                                    alpha):
+        X = np.random.rand(
+            batch_size, input_channels, size, size).astype(np.float32) - 0.5
+        outputs = {}
+        for engine in ["", "NNPACK"]:
+            op = core.CreateOperator(
+                "LeakyRelu",
+                ["X"],
+                ["Y"],
+                alpha=alpha,
+                engine=engine,
+            )
+            self.ws.create_blob("X").feed(X)
+            self.ws.run(op)
+            outputs[engine] = self.ws.blobs["Y"].fetch()
+        np.testing.assert_allclose(
+            outputs[""],
+            outputs["NNPACK"],
+            atol=1e-4,
+            rtol=1e-4)
+
+    @settings(deadline=3600)
+    @unittest.skipIf(not os.environ.get("CAFFE2_BENCHMARK"), "Benchmark")
+    @given(stride=st.integers(1, 1),
+           pad=st.integers(0, 2),
+           kernel=st.sampled_from([3, 5, 7]),
+           size=st.integers(30, 90),
+           input_channels=st.sampled_from([3, 64, 256]),
+           output_channels=st.sampled_from([32, 96, 256]),
+           batch_size=st.sampled_from([32, 64, 96, 128]))
+    def test_timings(self, stride, pad, kernel, size,
+                     input_channels, output_channels, batch_size):
+        assume(stride <= kernel)
+        X = np.random.rand(
+            batch_size, input_channels, size, size).astype(np.float32) - 0.5
+        w = np.random.rand(output_channels, input_channels,
+                           kernel, kernel).astype(np.float32) - 0.5
+        b = np.random.rand(output_channels).astype(np.float32) - 0.5
+        order = "NCHW"
+        times = {}
+        for engine in ["", "NNPACK"]:
+            net = core.Net(engine + "_test")
+            net.Conv(
+                ["X", "W", "b"], "Y",
+                order=order,
+                kernel=kernel,
+                stride=stride,
+                pad=pad,
+                kts="TUPLE",
+                engine=engine,
+            )
+            self.ws.create_blob("X").feed(X)
+            self.ws.create_blob("W").feed(w)
+            self.ws.create_blob("b").feed(b)
+            self.ws.run(net)
+            times[engine] = benchmark(self.ws, net)
+        print("Speedup for NNPACK: {:.2f}".format(
+            times[""] / times["NNPACK"]))
+
+    @settings(deadline=3600)
+    @unittest.skipIf(not os.environ.get("CAFFE2_BENCHMARK"), "Benchmark")
+    @given(size=st.integers(30, 90),
+           input_channels=st.sampled_from([3, 64, 256]),
+           batch_size=st.sampled_from([32, 64, 96, 128]))
+    def test_relu_timings(self, size, input_channels, batch_size):
+        X = np.random.rand(
+            batch_size, input_channels, size, size).astype(np.float32) - 0.5
+        times = {}
+        for engine in ["", "NNPACK"]:
+            net = core.Net(engine + "_test")
+            net.Relu(
+                ["X"],
+                ["Y"],
+                engine=engine,
+            )
+            self.ws.create_blob("X").feed(X)
+            self.ws.run(net)
+            times[engine] = benchmark(self.ws, net)
+        print("Speedup for NNPACK: {:.2f}".format(
+            times[""] / times["NNPACK"]))
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/AnyExp.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/AnyExp.py
new file mode 100644
index 0000000..b8e2f8b
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/AnyExp.py
@@ -0,0 +1,491 @@
+
+
+
+
+
+from abc import abstractmethod
+
+from caffe2.python import workspace
+from caffe2.python import timeout_guard
+from caffe2.python import data_parallel_model
+from . import checkpoint as checkpoint
+
+from . import ModuleRegister as ModuleRegister
+from . import module_map as module_map
+
+# instantiate logger outside of distributed operators may trigger error
+# logger need to be created in each idividual operator instead.
+import os
+import inspect
+import time
+import logging
+logging.basicConfig()
+log = logging.getLogger("AnyExp")
+log.setLevel(logging.DEBUG)
+
+
+def initOpts(opts):
+
+    workspace.GlobalInit(
+        ['caffe2', '--caffe2_log_level=2', '--caffe2_gpu_memory_tracking=0'])
+
+    assert (opts['distributed']['num_gpus'] > 0 or
+            opts['distributed']['num_cpus'] > 0),\
+        "Need to specify num_gpus or num_cpus to decide which device to use."
+
+    trainWithCPU = (opts['distributed']['num_gpus'] == 0)
+    num_xpus = opts['distributed']['num_cpus'] if \
+        trainWithCPU else opts['distributed']['num_gpus']
+    first_xpu = opts['distributed']['first_cpu_id'] if \
+        trainWithCPU else opts['distributed']['first_gpu_id']
+    opts['distributed']['device'] = 'cpu' if trainWithCPU else 'gpu'
+
+    opts['model_param']['combine_spatial_bn'] =\
+        trainWithCPU and opts['model_param']['combine_spatial_bn']
+
+    opts['distributed']['num_xpus'] = num_xpus
+    opts['distributed']['first_xpu_id'] = first_xpu
+    opts['temp_var'] = {}
+    opts['temp_var']['metrics_output'] = {}
+
+    return opts
+
+
+def initDefaultModuleMap():
+    registerModuleMap(module_map)
+
+
+def registerModuleMap(module_map):
+    ModuleRegister.registerModuleMap(module_map)
+
+
+def aquireDatasets(opts):
+    myAquireDataModule = ModuleRegister.getModule(opts['input']['input_name_py'])
+    return myAquireDataModule.get_input_dataset(opts)
+
+
+def createTrainerClass(opts):
+    return ModuleRegister.constructTrainerClass(AnyExpTrainer, opts)
+
+
+def overrideAdditionalMethods(myTrainerClass, opts):
+    return ModuleRegister.overrideAdditionalMethods(myTrainerClass, opts)
+
+
+def initialize_params_from_file(*args, **kwargs):
+    return checkpoint.initialize_params_from_file(*args, **kwargs)
+
+
+class AnyExpTrainer(object):
+
+    def __init__(self, opts):
+        import logging
+        logging.basicConfig()
+        log = logging.getLogger("AnyExp")
+        log.setLevel(logging.DEBUG)
+        self.log = log
+
+        self.opts = opts
+        self.train_dataset = None
+        self.test_dataset = None
+        self.train_df = None
+        self.test_df = None
+
+        self.metrics = {}
+        self.plotsIngredients = []
+
+        self.record_epochs = []
+        self.samples_per_sec = []
+        self.secs_per_train = []
+
+        self.metrics_output = opts['temp_var']['metrics_output']
+
+        first_xpu = opts['distributed']['first_xpu_id']
+        num_xpus = opts['distributed']['num_xpus']
+
+        self.xpus = range(first_xpu, first_xpu + num_xpus)
+
+        self.total_batch_size = \
+            self.opts['epoch_iter']['batch_per_device'] * \
+            self.opts['distributed']['num_xpus'] * \
+            self.opts['distributed']['num_shards']
+        self.epoch_iterations = \
+            self.opts['epoch_iter']['num_train_sample_per_epoch'] // \
+            self.total_batch_size
+
+        if len(opts['input']['datasets']) > 0:
+            self.train_df = opts['input']['datasets'][0]
+            if len(opts['input']['datasets']) == 2:
+                self.test_df = opts['input']['datasets'][1]
+        # at this point, the intance of this class becomes many instances
+        # running on different machines.  Most of their attributes are same,
+        # but the shard_ids are different.
+        self.shard_id = opts['temp_var']['shard_id']
+        self.start_epoch = opts['temp_var']['start_epoch']
+        self.epoch = opts['temp_var']['epoch']
+        self.epochs_to_run = opts['epoch_iter']['num_epochs_per_flow_schedule']
+
+        log.info('opts: {}'.format(str(opts)))
+
+    @abstractmethod
+    def get_input_dataset(self, opts):
+        pass
+
+    @abstractmethod
+    def get_model_input_fun(self):
+        pass
+
+    @abstractmethod
+    def init_model(self):
+        pass
+
+    def init_metrics(self):
+        metrics = self.opts['output']['metrics']
+        for metric in metrics:
+            meterClass = self.getMeterClass(metric['meter_py'])
+            # log.info('metric.meter_kargs {}'.format(metric.meter_kargs))
+            # log.info('type meter_kargs {}'.format(type(metric.meter_kargs)))
+            meterInstance = meterClass(opts=self.opts, **metric['meter_kargs'])
+            self.add_metric(metric['name'], meterInstance, metric['is_train'])
+
+    def getMeterClass(self, meterName):
+        return ModuleRegister.getClassFromModule(meterName, meterName)
+
+    def add_metric(self, name, calculator, is_train):
+        metrics = self.metrics
+        metrics[name] = {}
+        metrics[name]['calculator'] = calculator
+        metrics[name]['is_train'] = is_train
+        metrics[name]['output'] = []
+
+    def extendMetricsOutput(self):
+        metrics_output = self.metrics_output
+        if not metrics_output:
+            metrics_output['epochs'] = self.record_epochs
+            metrics_output['samples_per_sec'] = self.samples_per_sec
+            metrics_output['secs_per_train'] = self.secs_per_train
+            for metric, value in self.metrics.items():
+                metrics_output[metric] = value['output']
+        else:
+            metrics_output['epochs'].extend(self.record_epochs)
+            metrics_output['samples_per_sec'].extend(self.samples_per_sec)
+            metrics_output['secs_per_train'].extend(self.secs_per_train)
+            for metric, value in self.metrics.items():
+                metrics_output[metric].extend(value['output'])
+
+    @abstractmethod
+    def init_plots(self):
+        pass
+
+    def add_plot(self, x, x_title, ys, y_title):
+        plotsIngredients = self.plotsIngredients
+        aPlotIngredients = {}
+        aPlotIngredients['x'] = x
+        aPlotIngredients['x_title'] = x_title
+        aPlotIngredients['ys'] = ys
+        aPlotIngredients['y_title'] = y_title
+        plotsIngredients.append(aPlotIngredients)
+
+    @abstractmethod
+    def init_logs(self):
+        pass
+
+    def list_of_epochs(self):
+        iter_end_point = min(self.opts['epoch_iter']['num_epochs'],
+                             self.epoch +
+                             self.opts['epoch_iter']['num_epochs_per_flow_schedule'])
+        return range(self.epoch, iter_end_point)
+
+    def list_of_epoch_iters(self):
+        return range(0, self.epoch_iterations)
+
+    @abstractmethod
+    def fun_per_epoch_b4RunNet(self, epoch):
+        pass
+
+    @abstractmethod
+    def fun_per_epoch_aftRunNet(self, epoch):
+        pass
+
+    def checkpoint(self, epoch):
+        self.model_path = checkpoint.save_model_params(
+            True, self.train_model, self.gen_checkpoint_path(True, epoch + 1),
+            epoch + 1, self.opts, float('-inf'))
+
+    def gen_checkpoint_path(self, is_checkpoint, epoch):
+        if (is_checkpoint):
+            filename = "model_checkpoint_epoch{}.pkl".format(epoch)
+        else:
+            filename = "model_final.pkl"
+        return self.opts['output']['checkpoint_folder'] + filename
+
+    # @abstractmethod
+    # def gen_checkpoint_path(self, is_checkpoint, epoch):
+    #     pass
+
+    @abstractmethod
+    def fun_per_iter_b4RunNet(self, epoch, epoch_iter):
+        pass
+
+    @abstractmethod
+    def fun_per_iter_aftRunNetB4Test(self, epoch, epoch_iter):
+        pass
+
+    @abstractmethod
+    def fun_per_iter_aftRunNetAftTest(self, epoch, epoch_iter):
+        pass
+
+    @abstractmethod
+    def fun_conclude_operator(self, opts):
+        pass
+
+    def createMetricsPlotsModelsOutputs(self):
+        self.extendMetricsOutput()
+        self.model_output = self.model_path
+
+    @abstractmethod
+    def assembleAllOutputs(self):
+        pass
+
+    @abstractmethod
+    def gen_input_builder_fun(self, model, dataset, is_train):
+        pass
+
+    @abstractmethod
+    def gen_forward_pass_builder_fun(self, model, dataset, is_train):
+        pass
+
+    @abstractmethod
+    def gen_param_update_builder_fun(self, model, dataset, is_train):
+        pass
+
+    @abstractmethod
+    def gen_optimizer_fun(self, model, dataset, is_train):
+        pass
+
+    @abstractmethod
+    def gen_rendezvous_ctx(self, model, dataset, is_train):
+        pass
+
+    @abstractmethod
+    def run_training_net(self):
+        pass
+
+    @abstractmethod
+    def run_testing_net(self):
+        if self.test_model is None:
+            return
+        timeout = 2000.0
+        with timeout_guard.CompleteInTimeOrDie(timeout):
+            workspace.RunNet(self.test_model.net.Proto().name)
+
+    # @abstractmethod
+    def planning_output(self):
+        self.init_metrics()
+        self.init_plots()
+        self.init_logs()
+
+    def prep_data_parallel_models(self):
+        self.prep_a_data_parallel_model(self.train_model,
+                                        self.train_dataset, True)
+        self.prep_a_data_parallel_model(self.test_model,
+                                        self.test_dataset, False)
+
+    def prep_a_data_parallel_model(self, model, dataset, is_train):
+        if model is None:
+            return
+
+        log.info('in prep_a_data_parallel_model')
+
+        param_update = \
+            self.gen_param_update_builder_fun(model, dataset, is_train) \
+            if self.gen_param_update_builder_fun is not None else None
+        log.info('in prep_a_data_parallel_model param_update done ')
+
+        optimizer = \
+            self.gen_optimizer_fun(model, dataset, is_train) \
+            if self.gen_optimizer_fun is not None else None
+        log.info('in prep_a_data_parallel_model optimizer done ')
+
+        max_ops = self.opts['model_param']['max_concurrent_distributed_ops']
+        data_parallel_model.Parallelize(
+            model,
+            input_builder_fun=self.gen_input_builder_fun(model, dataset, is_train),
+            forward_pass_builder_fun=self.gen_forward_pass_builder_fun(
+                model, dataset, is_train),
+            param_update_builder_fun=param_update,
+            optimizer_builder_fun=optimizer,
+            devices=self.xpus,
+            rendezvous=self.gen_rendezvous_ctx(model, dataset, is_train),
+            broadcast_computed_params=False,
+            optimize_gradient_memory=self.opts['model_param']['memonger'],
+            use_nccl=self.opts['model_param']['cuda_nccl'],
+            max_concurrent_distributed_ops=max_ops,
+            cpu_device=(self.opts['distributed']['device'] == 'cpu'),
+            # "shared model" will only keep model parameters for cpu_0 or gpu_0
+            # will cause issue when initialize each gpu_0, gpu_1, gpu_2 ...
+            # shared_model=(self.opts['distributed']['device'] == 'cpu'),
+            combine_spatial_bn=self.opts['model_param']['combine_spatial_bn'],
+        )
+        log.info('in prep_a_data_parallel_model Parallelize done ')
+
+        # log.info("Current blobs in workspace: {}".format(workspace.Blobs()))
+
+        workspace.RunNetOnce(model.param_init_net)
+        log.info('in prep_a_data_parallel_model RunNetOnce done ')
+
+        # for op in model.net.Proto().op:
+        #     log.info('op type engine {} {}'.format(op.type, op.engine))
+
+        log.info('model.net.Proto() {}'.format(model.net.Proto()))
+
+        workspace.CreateNet(model.net)
+
+        # for op in model.net.Proto().op:
+        #     log.info('after CreateNet op type engine {} {}'.
+        #         format(op.type, op.engine))
+
+        log.info('in prep_a_data_parallel_model CreateNet done ')
+
+    def loadCheckpoint(self):
+        opts = self.opts
+        previous_checkpoint = opts['temp_var']['checkpoint_model']
+        pretrained_model = opts['temp_var']['pretrained_model']
+        num_xpus = opts['distributed']['num_xpus']
+        if (previous_checkpoint is not None):
+            if os.path.exists(previous_checkpoint):
+                log.info('Load previous checkpoint:{}'.format(
+                    previous_checkpoint
+                ))
+                start_epoch, prev_checkpointed_lr, _best_metric = \
+                    checkpoint.initialize_params_from_file(
+                        model=self.train_model,
+                        weights_file=previous_checkpoint,
+                        num_xpus=num_xpus,
+                        opts=opts,
+                        broadcast_computed_param=True,
+                        reset_epoch=False,
+                    )
+        elif pretrained_model is not None and os.path.exists(pretrained_model):
+            log.info("Load pretrained model: {}".format(pretrained_model))
+            start_epoch, prev_checkpointed_lr, best_metric = \
+                checkpoint.initialize_params_from_file(
+                    model=self.train_model,
+                    weights_file=pretrained_model,
+                    num_xpus=num_xpus,
+                    opts=opts,
+                    broadcast_computed_param=True,
+                    reset_epoch=opts['model_param']['reset_epoch'],
+                )
+
+        data_parallel_model.FinalizeAfterCheckpoint(self.train_model)
+
+    def buildModelAndTrain(self, opts):
+        log.info('in buildModelAndTrain, trainer_input: {}'.format(str(opts)))
+        log.info("check type self: {}".format(type(self)))
+        log.info("check self dir: {}".format(dir(self)))
+        log.info("check self source: {}".format(self.__dict__))
+        log.info("check self get_input_dataset methods: {}".
+                 format(inspect.getsource(self.get_input_dataset)))
+        log.info("check self gen_input_builder_fun method: {}".
+                 format(inspect.getsource(self.gen_input_builder_fun)))
+        log.info("check self gen_forward_pass_builder_fun method: {}".
+                 format(inspect.getsource(self.gen_forward_pass_builder_fun)))
+        if self.gen_param_update_builder_fun is not None:
+            log.info("check self gen_param_update_builder_fun method: {}".
+                     format(inspect.getsource(self.gen_param_update_builder_fun)))
+        else:
+            log.info("check self gen_optimizer_fun method: {}".
+                     format(inspect.getsource(self.gen_optimizer_fun)))
+        log.info("check self assembleAllOutputs method: {}".
+                 format(inspect.getsource(self.assembleAllOutputs)))
+        log.info("check self prep_data_parallel_models method: {}".
+                 format(inspect.getsource(self.prep_data_parallel_models)))
+
+        self.get_model_input_fun()
+
+        self.init_model()
+
+        self.planning_output()
+
+        self.prep_data_parallel_models()
+
+        self.loadCheckpoint()
+
+        for epoch in self.list_of_epochs():
+
+            log.info("start training epoch {}".format(epoch))
+
+            self.fun_per_epoch_b4RunNet(epoch)
+
+            for epoch_iter in self.list_of_epoch_iters():
+
+                self.iter_start_time = time.time()
+
+                self.fun_per_iter_b4RunNet(epoch, epoch_iter)
+
+                if self.train_model is not None:
+                    self.run_training_net()
+
+                self.fun_per_iter_aftRunNetB4Test(epoch, epoch_iter)
+
+                self.iter_end_time = time.time()
+
+                if (epoch_iter %
+                opts['epoch_iter']['num_train_iteration_per_test'] == 0):
+                    secs_per_train = (self.iter_end_time - self.iter_start_time)
+                    self.secs_per_train.append(secs_per_train)
+
+                    sample_trained = self.total_batch_size
+                    samples_per_sec = sample_trained / secs_per_train
+                    self.samples_per_sec.append(samples_per_sec)
+
+                    self.fract_epoch = (epoch +
+                    float(epoch_iter) / self.epoch_iterations)
+                    self.record_epochs.append(self.fract_epoch)
+
+                    for key in self.metrics:
+                        metric = self.metrics[key]
+                        if not metric['is_train']:
+                            continue
+                        metric['calculator'].Add()
+                        metric['output'].append(metric['calculator'].Compute())
+
+                    self.test_loop_start_time = time.time()
+                    for _test_iter in range(0, opts['epoch_iter']['num_test_iter']):
+                        self.run_testing_net()
+                        for key in self.metrics:
+                            metric = self.metrics[key]
+                            if metric['is_train']:
+                                continue
+                            metric['calculator'].Add()
+                    self.test_loop_end_time = time.time()
+                    self.sec_per_test_loop = \
+                        self.test_loop_end_time - self.test_loop_start_time
+
+                    for metric in self.metrics.values():
+                        if metric['is_train']:
+                            continue
+                        metric['output'].append(metric['calculator'].Compute())
+
+                    logStr = 'epoch:{}/{} iter:{}/{} secs_per_train:{} '.format(
+                        self.fract_epoch, self.opts['epoch_iter']['num_epochs'],
+                        epoch_iter, self.epoch_iterations, secs_per_train)
+                    logStr += 'samples_per_sec:{} loop {} tests takes {} sec'.format(
+                        samples_per_sec, opts['epoch_iter']['num_test_iter'],
+                        self.sec_per_test_loop)
+                    for metric, value in self.metrics.items():
+                        logStr += ' {}:{} '.format(metric, value['output'][-1])
+                    log.info('Iter Stats: {}'.format(logStr))
+
+                self.fun_per_iter_aftRunNetAftTest(epoch, epoch_iter)
+
+            self.checkpoint(epoch)
+
+            self.fun_per_epoch_aftRunNet(epoch)
+
+        self.fun_conclude_operator()
+
+        self.createMetricsPlotsModelsOutputs()
+
+        return self.assembleAllOutputs()
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/AnyExpOnTerm.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/AnyExpOnTerm.py
new file mode 100644
index 0000000..dcfe61f
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/AnyExpOnTerm.py
@@ -0,0 +1,98 @@
+
+
+
+
+
+import argparse
+import json
+import os
+
+import caffe2.contrib.playground.AnyExp as AnyExp
+import caffe2.contrib.playground.checkpoint as checkpoint
+
+import logging
+logging.basicConfig()
+log = logging.getLogger("AnyExpOnTerm")
+log.setLevel(logging.DEBUG)
+
+
+def runShardedTrainLoop(opts, myTrainFun):
+    start_epoch = 0
+    pretrained_model = opts['model_param']['pretrained_model']
+    if pretrained_model != '' and os.path.exists(pretrained_model):
+        # Only want to get start_epoch.
+        start_epoch, prev_checkpointed_lr, best_metric = \
+            checkpoint.initialize_params_from_file(
+                model=None,
+                weights_file=pretrained_model,
+                num_xpus=1,
+                opts=opts,
+                broadcast_computed_param=True,
+                reset_epoch=opts['model_param']['reset_epoch'],
+            )
+    log.info('start epoch: {}'.format(start_epoch))
+    pretrained_model = None if pretrained_model == '' else pretrained_model
+    ret = None
+
+    pretrained_model = ""
+    shard_results = []
+
+    for epoch in range(start_epoch,
+                       opts['epoch_iter']['num_epochs'],
+                       opts['epoch_iter']['num_epochs_per_flow_schedule']):
+        # must support checkpoint or the multiple schedule will always
+        # start from initial state
+        checkpoint_model = None if epoch == start_epoch else ret['model']
+        pretrained_model = None if epoch > start_epoch else pretrained_model
+        shard_results = []
+        # with LexicalContext('epoch{}_gang'.format(epoch),gang_schedule=False):
+        for shard_id in range(opts['distributed']['num_shards']):
+            opts['temp_var']['shard_id'] = shard_id
+            opts['temp_var']['pretrained_model'] = pretrained_model
+            opts['temp_var']['checkpoint_model'] = checkpoint_model
+            opts['temp_var']['epoch'] = epoch
+            opts['temp_var']['start_epoch'] = start_epoch
+            shard_ret = myTrainFun(opts)
+            shard_results.append(shard_ret)
+
+        ret = None
+        # always only take shard_0 return
+        for shard_ret in shard_results:
+            if shard_ret is not None:
+                ret = shard_ret
+                opts['temp_var']['metrics_output'] = ret['metrics']
+                break
+        log.info('ret is: {}'.format(str(ret)))
+
+    return ret
+
+
+def trainFun():
+    def simpleTrainFun(opts):
+        trainerClass = AnyExp.createTrainerClass(opts)
+        trainerClass = AnyExp.overrideAdditionalMethods(trainerClass, opts)
+        trainer = trainerClass(opts)
+        return trainer.buildModelAndTrain(opts)
+    return simpleTrainFun
+
+
+if __name__ == '__main__':
+
+    parser = argparse.ArgumentParser(description='Any Experiment training.')
+    parser.add_argument("--parameters-json", type=json.loads,
+                        help='model options in json format', dest="params")
+
+    args = parser.parse_args()
+    opts = args.params['opts']
+    opts = AnyExp.initOpts(opts)
+    log.info('opts is: {}'.format(str(opts)))
+
+    AnyExp.initDefaultModuleMap()
+
+    opts['input']['datasets'] = AnyExp.aquireDatasets(opts)
+
+    # defined this way so that AnyExp.trainFun(opts) can be replaced with
+    # some other custermized training function.
+    ret = runShardedTrainLoop(opts, trainFun())
+
+    log.info('ret is: {}'.format(str(ret)))
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/ModuleRegister.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/ModuleRegister.py
new file mode 100644
index 0000000..27e0c07
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/ModuleRegister.py
@@ -0,0 +1,120 @@
+
+
+
+
+
+import inspect
+import logging
+logging.basicConfig()
+log = logging.getLogger("ModuleRegister")
+log.setLevel(logging.DEBUG)
+
+MODULE_MAPS = []
+
+
+def registerModuleMap(module_map):
+    MODULE_MAPS.append(module_map)
+    log.info("ModuleRegister get modules from  ModuleMap content: {}".
+             format(inspect.getsource(module_map)))
+
+
+def constructTrainerClass(myTrainerClass, opts):
+
+    log.info("ModuleRegister, myTrainerClass name is {}".
+             format(myTrainerClass.__name__))
+    log.info("ModuleRegister, myTrainerClass type is {}".
+             format(type(myTrainerClass)))
+    log.info("ModuleRegister, myTrainerClass dir is {}".
+             format(dir(myTrainerClass)))
+
+    myInitializeModelModule = getModule(opts['model']['model_name_py'])
+    log.info("ModuleRegister, myInitializeModelModule dir is {}".
+             format(dir(myInitializeModelModule)))
+
+    myTrainerClass.init_model = myInitializeModelModule.init_model
+    myTrainerClass.run_training_net = myInitializeModelModule.run_training_net
+    myTrainerClass.fun_per_iter_b4RunNet = \
+        myInitializeModelModule.fun_per_iter_b4RunNet
+    myTrainerClass.fun_per_epoch_b4RunNet = \
+        myInitializeModelModule.fun_per_epoch_b4RunNet
+
+    myInputModule = getModule(opts['input']['input_name_py'])
+    log.info("ModuleRegister, myInputModule {} dir is {}".
+             format(opts['input']['input_name_py'], myInputModule.__name__))
+
+    # Override input methods of the myTrainerClass class
+    myTrainerClass.get_input_dataset = myInputModule.get_input_dataset
+    myTrainerClass.get_model_input_fun = myInputModule.get_model_input_fun
+    myTrainerClass.gen_input_builder_fun = myInputModule.gen_input_builder_fun
+
+    # myForwardPassModule = GetForwardPassModule(opts)
+    myForwardPassModule = getModule(opts['model']['forward_pass_py'])
+    myTrainerClass.gen_forward_pass_builder_fun = \
+        myForwardPassModule.gen_forward_pass_builder_fun
+
+    myParamUpdateModule = getModule(opts['model']['parameter_update_py'])
+    myTrainerClass.gen_param_update_builder_fun =\
+        myParamUpdateModule.gen_param_update_builder_fun \
+        if myParamUpdateModule is not None else None
+
+    myOptimizerModule = getModule(opts['model']['optimizer_py'])
+    myTrainerClass.gen_optimizer_fun = \
+        myOptimizerModule.gen_optimizer_fun \
+        if myOptimizerModule is not None else None
+
+    myRendezvousModule = getModule(opts['model']['rendezvous_py'])
+    myTrainerClass.gen_rendezvous_ctx = \
+        myRendezvousModule.gen_rendezvous_ctx \
+        if myRendezvousModule is not None else None
+
+    # override output module
+    myOutputModule = getModule(opts['output']['gen_output_py'])
+
+    log.info("ModuleRegister, myOutputModule is {}".
+             format(myOutputModule.__name__))
+    myTrainerClass.fun_conclude_operator = myOutputModule.fun_conclude_operator
+    myTrainerClass.assembleAllOutputs = myOutputModule.assembleAllOutputs
+
+    return myTrainerClass
+
+
+def overrideAdditionalMethods(myTrainerClass, opts):
+    log.info("B4 additional override myTrainerClass source {}".
+        format(inspect.getsource(myTrainerClass)))
+    # override any additional modules
+    myAdditionalOverride = getModule(opts['model']['additional_override_py'])
+    if myAdditionalOverride is not None:
+        for funcName, funcValue in inspect.getmembers(myAdditionalOverride,
+                                                      inspect.isfunction):
+            setattr(myTrainerClass, funcName, funcValue)
+    log.info("Aft additional override myTrainerClass's source {}".
+        format(inspect.getsource(myTrainerClass)))
+    return myTrainerClass
+
+
+def getModule(moduleName):
+    log.info("get module {} from MODULE_MAPS content {}".format(moduleName, str(MODULE_MAPS)))
+    myModule = None
+    for ModuleMap in MODULE_MAPS:
+        log.info("iterate through MODULE_MAPS content {}".
+                 format(str(ModuleMap)))
+        for name, obj in inspect.getmembers(ModuleMap):
+            log.info("iterate through MODULE_MAPS a name {}".format(str(name)))
+            if name == moduleName:
+                log.info("AnyExp get module {} with source:{}".
+                         format(moduleName, inspect.getsource(obj)))
+                myModule = obj
+                return myModule
+    return None
+
+
+def getClassFromModule(moduleName, className):
+    myClass = None
+    for ModuleMap in MODULE_MAPS:
+        for name, obj in inspect.getmembers(ModuleMap):
+            if name == moduleName:
+                log.info("ModuleRegistry from module {} get class {} of source:{}".
+                         format(moduleName, className, inspect.getsource(obj)))
+                myClass = getattr(obj, className)
+                return myClass
+    return None
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/__init__.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/checkpoint.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/checkpoint.py
new file mode 100644
index 0000000..5ea3d2a
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/checkpoint.py
@@ -0,0 +1,174 @@
+
+
+
+
+
+import numpy as np
+import pickle
+from collections import OrderedDict
+
+from caffe2.proto import caffe2_pb2
+
+from caffe2.python import workspace, core, scope
+
+import logging
+logging.basicConfig()
+log = logging.getLogger("AnyExpOnTerm")
+log.setLevel(logging.DEBUG)
+
+
+def initialize_params_from_file(
+        model, weights_file, num_xpus, opts,
+        broadcast_computed_param=False, reset_epoch=False):
+    start_epoch, lr, best_metric = initialize_master_xpu_model_params(
+        model, weights_file, opts, reset_epoch)
+    broadcast_parameters(opts, model, num_xpus, broadcast_computed_param)
+    return start_epoch, lr, best_metric
+
+
+def initialize_master_xpu_model_params(model, weights_file, opts, reset_epoch):
+    log.info("Initializing model params from file: {}".format(weights_file))
+    with open(weights_file, 'r') as fopen:
+        blobs = pickle.load(fopen)
+    if 'blobs' in blobs:
+        blobs = blobs['blobs']
+
+    start_epoch = 0
+    best_metric = float('-inf')
+    if 'epoch' in blobs:
+        log.info('epoch {} is found in model file'.format(blobs['epoch']))
+        if not reset_epoch:
+            start_epoch = blobs['epoch']
+        else:
+            log.info('Reset epoch')
+    else:
+        log.info('no epoch is found in model file')
+    lr = opts['model_param']['base_learning_rate']
+    if 'lr' in blobs:
+        lr = blobs['lr']
+    if 'best_metric' in blobs and not reset_epoch:
+        best_metric = blobs['best_metric']
+
+    if model is not None:
+        log.info('initialize model parameters using weights file: {}'.format(
+            weights_file
+        ))
+        ws_blobs = workspace.Blobs()
+        unscoped_blob_names = OrderedDict()
+        for blob in model.GetAllParams():
+            unscoped_blob_names[unscope_name(str(blob))] = True
+        root_xpu_id = opts['distributed']['first_xpu_id']
+        device = opts['distributed']['device']
+        caffe2_pb2_DEVICE =\
+            caffe2_pb2.CUDA if opts['distributed']['device'] == 'gpu'\
+            else caffe2_pb2.CPU
+        with core.NameScope('{}_{}'.format(device, root_xpu_id)):
+            with core.DeviceScope(core.DeviceOption(caffe2_pb2_DEVICE, 0)):
+                for unscoped_blob_name in unscoped_blob_names.keys():
+                    scoped_blob_name = scoped_name(unscoped_blob_name)
+                    if unscoped_blob_name not in blobs:
+                        log.info('{:s} not found'.format(unscoped_blob_name))
+                        continue
+                    log.info(
+                        '{:s} loaded from weights file into: {:s}'.format(
+                            unscoped_blob_name, scoped_blob_name
+                        )
+                    )
+                    if scoped_blob_name in ws_blobs:
+                        ws_blob = workspace.FetchBlob(scoped_blob_name)
+                        if not ws_blob.shape == blobs[unscoped_blob_name].shape:
+                            log.info(
+                                ('Workspace blob {} with shape {} does '
+                                    'not match weights file shape {}').format(
+                                            unscoped_blob_name, ws_blob.shape,
+                                            blobs[unscoped_blob_name].shape)
+                            )
+                        else:
+                            workspace.FeedBlob(
+                                scoped_blob_name,
+                                blobs[unscoped_blob_name].astype(
+                                    np.float32, copy=False))
+    else:
+        log.info('Skip initializing model parameters from file: {}'.format(
+            weights_file
+        ))
+    log.info('Complete initialize_master_xpu_model_params')
+    return start_epoch, lr, best_metric
+
+
+def broadcast_parameters(opts, model, num_xpus, broadcast_computed_param=False):
+    if num_xpus == 1:
+        log.info("only 1 device. Skip parameter broadcast")
+        return
+    all_params = [model.GetParams()]
+    if broadcast_computed_param:
+        all_params.append(model.GetComputedParams())
+    caffe2_pb2_DEVICE =\
+        caffe2_pb2.CUDA if opts['distributed']['device'] == 'gpu'\
+        else caffe2_pb2.CPU
+    for params in all_params:
+        assert len(params) % num_xpus == 0, \
+            "Current model doesn't match device number when loading checkpoint"
+        params_per_xpu = int(len(params) / num_xpus)
+        for idx in range(params_per_xpu):
+            blobs = [param for param in params[idx::params_per_xpu]]
+            data = workspace.FetchBlob(blobs[0])
+            log.info('Broadcasting {} to'.format(str(blobs[0])))
+            for i, p in enumerate(blobs[1:]):
+                log.info(' |-> {}'.format(str(p)))
+                with core.DeviceScope(core.DeviceOption(caffe2_pb2_DEVICE, i+1)):
+                    workspace.FeedBlob(p, data)
+    log.info("Complete parameter broadcast")
+
+
+def save_model_params(is_checkpoint, model, checkpoint_path, epoch, opts, best_metric):
+    # best_metric=float('-inf')
+    if checkpoint_path is None:
+        return None
+
+    try:
+        save_model_params_blob(
+            model, checkpoint_path, epoch, opts, best_metric
+        )
+    except Exception as e:
+        log.warning('Exception from save_model_params {}'.format(str(e)))
+    return checkpoint_path
+
+
+def save_model_params_blob(model, params_file, epoch, opts, best_metric):
+    # best_metric=float('-inf')
+    log.info("Saving model params...")
+    root_xpu_id = opts['distributed']['first_xpu_id']
+    device = opts['distributed']['device']
+    save_params = [str(param) for param in
+                   model.GetParams('{}_{}'.format(device, root_xpu_id))]
+    save_computed_params = [str(param) for param in
+                            model.GetComputedParams('{}_{}'
+                            .format(device, root_xpu_id))]
+    save_blobs = {}
+    save_blobs['epoch'] = epoch
+    save_blobs['best_metric'] = best_metric
+    save_blobs['lr'] = \
+        workspace.FetchBlob('{}_{}/lr'.format(device, root_xpu_id))
+    for param in save_params + save_computed_params:
+        scoped_blob_name = str(param)
+        unscoped_blob_name = unscope_name(scoped_blob_name)
+        if unscoped_blob_name not in save_blobs:
+            save_blobs[unscoped_blob_name] = workspace.FetchBlob(
+                scoped_blob_name)
+            log.debug(
+                '{:s} -> {:s}'.format(scoped_blob_name, unscoped_blob_name))
+    log.info('to weights file {}'.format(params_file))
+    try:
+        with open(params_file, 'w') as fwrite:
+            pickle.dump(dict(blobs=save_blobs), fwrite, pickle.HIGHEST_PROTOCOL)
+    except IOError as e:
+        log.error('I/O error({0}): {1}'.format(e.errno, e.strerror))
+
+
+def unscope_name(blob_name):
+    return blob_name[blob_name.rfind(scope._NAMESCOPE_SEPARATOR) + 1:]
+
+
+def scoped_name(blob_name):
+    return scope.CurrentNameScope() + blob_name
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/compute_loss.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/compute_loss.py
new file mode 100644
index 0000000..2965ff3
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/compute_loss.py
@@ -0,0 +1,35 @@
+
+
+
+
+
+import caffe2.contrib.playground.meter as Meter
+from caffe2.python import workspace
+
+
+class ComputeLoss(Meter.Meter):
+    def __init__(self, opts=None, blob_name=''):
+        self.blob_name = blob_name
+        self.opts = opts
+        self.iter = 0
+        self.value = 0
+
+    def Reset(self):
+        self.iter = 0
+        self.value = 0
+
+    def Add(self):
+        """Average values of a blob on each gpu"""
+        value = 0
+        for idx in range(self.opts['distributed']['first_xpu_id'],
+                         self.opts['distributed']['first_xpu_id'] +
+                         self.opts['distributed']['num_xpus']):
+            value += workspace.FetchBlob('{}_{}/{}'.
+                format(self.opts['distributed']['device'], idx, self.blob_name))
+        self.value += value
+        self.iter += 1
+
+    def Compute(self):
+        result = self.opts['distributed']['num_shards'] * self.value / self.iter
+        self.Reset()
+        return result
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/compute_topk_accuracy.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/compute_topk_accuracy.py
new file mode 100644
index 0000000..e2f1482
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/compute_topk_accuracy.py
@@ -0,0 +1,59 @@
+
+
+
+
+
+import caffe2.contrib.playground.meter as Meter
+from caffe2.python import workspace
+import numpy as np
+
+
+class ComputeTopKAccuracy(Meter.Meter):
+    # Python default arguments are evaluated once when the function is
+    # defined, not each time the function is called
+    # This means that if you use a mutable default argument and mutate it,
+    # you will and have mutated that object for
+    # all future calls to the function as well.
+    # def __init__(self, blob_name=['softmax', 'label'], opts=None, topk=1):
+    def __init__(self, blob_name=None, opts=None, topk=1):
+        if blob_name is None:
+            blob_name = ['softmax', 'label']
+        self.blob_name = blob_name
+        self.opts = opts
+        self.topk = topk
+        self.iter = 0
+        self.value = 0
+
+    def Reset(self):
+        self.iter = 0
+        self.value = 0
+
+    def Add(self):
+        for idx in range(self.opts['distributed']['first_xpu_id'],
+                         self.opts['distributed']['first_xpu_id'] +
+                         self.opts['distributed']['num_xpus']):
+            prefix = '{}_{}/'.format(self.opts['distributed']['device'], idx)
+            softmax = workspace.FetchBlob(prefix + self.blob_name[0])
+            labels = workspace.FetchBlob(prefix + self.blob_name[1])
+            output = np.squeeze(softmax)
+            target = np.squeeze(labels)
+            if len(output.shape) == 1:
+                output = output.reshape((1, output.shape[0]))
+            else:
+                assert len(output.shape) == 2, \
+                    'wrong output size (1D or 2D expected)'
+            assert len(target.shape) == 1, 'wrong target size (1D expected)'
+            assert output.shape[0] == target.shape[0], \
+                'target and output do not match'
+
+            N = output.shape[0]
+            pred = np.argsort(-output, axis=1)[:, :self.topk]
+            correct = pred.astype(target.dtype) == np.repeat(
+                target.reshape((N, 1)), [self.topk], axis=1)
+            self.value += np.sum(correct[:, :self.topk])
+            self.iter += N
+
+    def Compute(self):
+        result = self.value / self.iter
+        self.Reset()
+        return result
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/meter.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/meter.py
new file mode 100644
index 0000000..ed0158b
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/meter.py
@@ -0,0 +1,25 @@
+
+
+
+
+
+from abc import abstractmethod
+
+
+class Meter(object):
+
+    @abstractmethod
+    def __init__(self, **kwargs):
+        pass
+
+    @abstractmethod
+    def Reset(self):
+        pass
+
+    @abstractmethod
+    def Add(self):
+        pass
+
+    @abstractmethod
+    def Compute(self):
+        pass
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/module_map.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/module_map.py
new file mode 100644
index 0000000..8eb1a3a
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/module_map.py
@@ -0,0 +1,49 @@
+
+
+
+
+
+# Input
+import caffe2.contrib.playground.resnetdemo.\
+    gfs_IN1k as gfs_IN1k  # noqa
+
+# model
+import caffe2.contrib.playground.resnetdemo.\
+    IN1k_resnet as IN1k_resnet # noqa
+
+import caffe2.contrib.playground.resnetdemo.\
+    IN1k_resnet_no_test_model as IN1k_resnet_no_test_model # noqa
+
+# Additional override
+import caffe2.contrib.playground.resnetdemo.\
+    override_no_test_model_no_checkpoint as override_no_test_model_no_checkpoint # noqa
+
+# FORWARD_PASS
+import caffe2.contrib.playground.resnetdemo.\
+    caffe2_resnet50_default_forward as caffe2_resnet50_default_forward # noqa
+
+import caffe2.contrib.playground.resnetdemo.\
+    explicit_resnet_forward as explicit_resnet_forward # noqa
+
+# PARAMETER_UPDATE
+import caffe2.contrib.playground.resnetdemo.\
+    caffe2_resnet50_default_param_update as caffe2_resnet50_default_param_update # noqa
+
+import caffe2.contrib.playground.resnetdemo.\
+    explicit_resnet_param_update as explicit_resnet_param_update # noqa
+
+# RENDEZVOUS
+import caffe2.contrib.playground.resnetdemo.\
+    rendezvous_filestore as rendezvous_filestore # noqa
+
+# OUTPUT
+import caffe2.contrib.playground.\
+    output_generator as output_generator # noqa
+
+# METERS
+# for meters, use the class name as your module name in this map
+import caffe2.contrib.playground.\
+    compute_loss as ComputeLoss # noqa
+
+import caffe2.contrib.playground.\
+    compute_topk_accuracy as ComputeTopKAccuracy # noqa
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/output_generator.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/output_generator.py
new file mode 100644
index 0000000..aaa977c
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/output_generator.py
@@ -0,0 +1,20 @@
+
+
+
+
+
+from caffe2.python import timeout_guard
+
+def fun_conclude_operator(self):
+    # Ensure the program exists. This is to "fix" some unknown problems
+    # causing the job sometimes get stuck.
+    timeout_guard.EuthanizeIfNecessary(600.0)
+
+
+def assembleAllOutputs(self):
+    output = {}
+    output['train_model'] = self.train_model
+    output['test_model'] = self.test_model
+    output['model'] = self.model_output
+    output['metrics'] = self.metrics_output
+    return output
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/IN1k_resnet.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/IN1k_resnet.py
new file mode 100644
index 0000000..58085db
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/IN1k_resnet.py
@@ -0,0 +1,57 @@
+
+
+
+
+
+import numpy as np
+
+from caffe2.python import workspace, cnn, core
+from caffe2.python import timeout_guard
+from caffe2.proto import caffe2_pb2
+
+
+def init_model(self):
+    train_model = cnn.CNNModelHelper(
+        order="NCHW",
+        name="resnet",
+        use_cudnn=True,
+        cudnn_exhaustive_search=False
+    )
+    self.train_model = train_model
+
+    test_model = cnn.CNNModelHelper(
+        order="NCHW",
+        name="resnet_test",
+        use_cudnn=True,
+        cudnn_exhaustive_search=False,
+        init_params=False,
+    )
+    self.test_model = test_model
+
+    self.log.info("Model creation completed")
+
+
+def fun_per_epoch_b4RunNet(self, epoch):
+    pass
+
+
+def fun_per_iter_b4RunNet(self, epoch, epoch_iter):
+
+    learning_rate = 0.05
+    for idx in range(self.opts['distributed']['first_xpu_id'],
+                     self.opts['distributed']['first_xpu_id'] +
+                     self.opts['distributed']['num_xpus']):
+        caffe2_pb2_device = caffe2_pb2.CUDA if \
+            self.opts['distributed']['device'] == 'gpu' else \
+            caffe2_pb2.CPU
+        with core.DeviceScope(core.DeviceOption(caffe2_pb2_device, idx)):
+            workspace.FeedBlob(
+                '{}_{}/lr'.format(self.opts['distributed']['device'], idx),
+                np.array(learning_rate, dtype=np.float32)
+            )
+
+
+def run_training_net(self):
+    timeout = 2000.0
+    with timeout_guard.CompleteInTimeOrDie(timeout):
+        workspace.RunNet(self.train_model.net.Proto().name)
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/IN1k_resnet_no_test_model.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/IN1k_resnet_no_test_model.py
new file mode 100644
index 0000000..4800707
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/IN1k_resnet_no_test_model.py
@@ -0,0 +1,62 @@
+
+
+
+
+
+import numpy as np
+
+from caffe2.python import workspace, cnn, core
+from caffe2.python import timeout_guard
+from caffe2.proto import caffe2_pb2
+
+
+def init_model(self):
+    # if cudnn needs to be turned off, several other places
+    # need to be modified:
+    # 1. operators need to be constructed with engine option, like below:
+    #     conv_blob = model.Conv(...engine=engine)
+    # 2. when launch model, opts['model_param']['engine'] = "" instead of "CUDNN"
+    # 2. caffe2_disable_implicit_engine_preference in operator.cc set to true
+    train_model = cnn.CNNModelHelper(
+        order="NCHW",
+        name="resnet",
+        use_cudnn=False,
+        cudnn_exhaustive_search=False,
+    )
+    self.train_model = train_model
+
+    # test_model = cnn.CNNModelHelper(
+    #     order="NCHW",
+    #     name="resnet_test",
+    #     use_cudnn=False,
+    #     cudnn_exhaustive_search=False,
+    #     init_params=False,
+    # )
+    self.test_model = None
+
+    self.log.info("Model creation completed")
+
+
+def fun_per_epoch_b4RunNet(self, epoch):
+    pass
+
+
+def fun_per_iter_b4RunNet(self, epoch, epoch_iter):
+    learning_rate = 0.05
+    for idx in range(self.opts['distributed']['first_xpu_id'],
+                     self.opts['distributed']['first_xpu_id'] +
+                     self.opts['distributed']['num_xpus']):
+        caffe2_pb2_device = caffe2_pb2.CUDA if \
+            self.opts['distributed']['device'] == 'gpu' else \
+            caffe2_pb2.CPU
+        with core.DeviceScope(core.DeviceOption(caffe2_pb2_device, idx)):
+            workspace.FeedBlob(
+                '{}_{}/lr'.format(self.opts['distributed']['device'], idx),
+                np.array(learning_rate, dtype=np.float32)
+            )
+
+
+def run_training_net(self):
+    timeout = 2000.0
+    with timeout_guard.CompleteInTimeOrDie(timeout):
+        workspace.RunNet(self.train_model.net.Proto().name)
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/__init__.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/caffe2_resnet50_default_forward.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/caffe2_resnet50_default_forward.py
new file mode 100644
index 0000000..fa0fedd
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/caffe2_resnet50_default_forward.py
@@ -0,0 +1,26 @@
+
+
+
+
+
+import caffe2.python.models.resnet as resnet
+
+
+def gen_forward_pass_builder_fun(self, model, dataset, is_train):
+    def create_resnet50_model_ops(model, loss_scale):
+        [softmax, loss] = resnet.create_resnet50(
+            model,
+            "data",
+            num_input_channels=3,
+            num_labels=1000,
+            label="label",
+        )
+        model.Accuracy([softmax, "label"], "accuracy")
+
+        my_loss_scale = 1. / self.opts['distributed']['num_xpus'] / \
+            self.opts['distributed']['num_shards']
+
+        loss = model.Scale(loss, scale=my_loss_scale)
+
+        return [loss]
+    return create_resnet50_model_ops
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/caffe2_resnet50_default_param_update.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/caffe2_resnet50_default_param_update.py
new file mode 100644
index 0000000..5697d13
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/caffe2_resnet50_default_param_update.py
@@ -0,0 +1,42 @@
+
+
+
+
+
+
+def gen_param_update_builder_fun(self, model, dataset, is_train):
+    if not is_train:
+        return None
+    else:
+        def add_parameter_update_ops(model):
+            model.AddWeightDecay(1e-4)
+            ITER = model.Iter("ITER")
+            stepsz = int(30 *
+                         self.opts['epoch_iter']['num_train_sample_per_epoch'] /
+                         self.total_batch_size)
+            LR = model.net.LearningRate(
+                [ITER],
+                "lr",
+                base_lr=self.opts['model_param']['base_learning_rate'],
+                policy="step",
+                stepsize=stepsz,
+                gamma=0.1,
+            )
+
+            params = model.GetParams()
+            assert(len(params) > 0)
+            for param in params:
+                param_grad = model.param_to_grad[param]
+                param_momentum = model.param_init_net.ConstantFill(
+                    [param], param + '_momentum', value=0.0
+                )
+
+                # Update param_grad and param_momentum in place
+                model.net.MomentumSGDUpdate(
+                    [param_grad, param_momentum, LR, param],
+                    [param_grad, param_momentum, param],
+                    momentum=0.9,
+                    nesterov=1
+                )
+
+        return add_parameter_update_ops
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/explicit_resnet_forward.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/explicit_resnet_forward.py
new file mode 100644
index 0000000..056ddd8
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/explicit_resnet_forward.py
@@ -0,0 +1,313 @@
+
+
+
+
+
+import logging
+logging.basicConfig()
+log = logging.getLogger("AnyExp")
+log.setLevel(logging.DEBUG)
+
+# For more depths, add the block config here
+BLOCK_CONFIG = {
+    18: (2, 2, 2, 2),
+    34: (3, 4, 6, 3),
+    50: (3, 4, 6, 3),
+    101: (3, 4, 23, 3),
+    152: (3, 8, 36, 3),
+    200: (3, 32, 36, 3),
+    264: (3, 64, 36, 3),
+    284: (3, 32, 64, 3),
+}
+
+
+def gen_forward_pass_builder_fun(self, model, dataset, is_train):
+    split = 'train' if is_train else 'test'
+    opts = self.opts
+
+    def model_creator(model, loss_scale):
+        model, softmax, loss = resnet_imagenet_create_model(
+            model=model,
+            data='data',
+            labels='label',
+            split=split,
+            opts=opts,
+            dataset=dataset,
+        )
+        return [loss]
+    return model_creator
+
+
+def resnet_imagenet_create_model(model, data, labels, split, opts, dataset):
+    model_helper = ResNetModelHelper(model, split, opts)
+    opts_depth = opts['model_param']['num_layer']
+    engine = opts['model_param']['engine']
+    log.info(' | ResNet-{} Imagenet'.format(opts_depth))
+    assert opts_depth in BLOCK_CONFIG.keys(), \
+        'Block config is not defined for specified model depth. Please check.'
+    (n1, n2, n3, n4) = BLOCK_CONFIG[opts_depth]
+
+    num_features = 2048
+    residual_block = model_helper.bottleneck_block
+    if opts_depth in [18, 34]:
+        num_features = 512
+        residual_block = model_helper.basic_block
+
+    num_classes = 1000
+    conv_blob = model.Conv(
+        data, 'conv1', 3, 64, 7, stride=2, pad=3, weight_init=('MSRAFill', {}),
+        bias_init=('ConstantFill', {'value': 0.}), no_bias=0, engine=engine
+    )
+    test_mode = False
+    if split in ['test', 'val']:
+        test_mode = True
+    bn_blob = model.SpatialBN(
+        conv_blob, 'res_conv1_bn', 64,
+        # does not appear to affect test_loss performance
+        # epsilon=1e-3,
+        epsilon=opts['model_param']['bn_epsilon'],
+        # momentum=0.1,
+        momentum=opts['model_param']['bn_momentum'],
+        is_test=test_mode,
+    )
+    relu_blob = model.Relu(bn_blob, bn_blob)
+    max_pool = model.MaxPool(relu_blob, 'pool1', kernel=3, stride=2, pad=1)
+
+    # TODO: This can be further optimized by passing dim_in, dim_out = features,
+    # dim_out = features * 4
+    if opts_depth in [50, 101, 152, 200, 264, 284]:
+        blob_in, dim_in = model_helper.residual_layer(
+            residual_block, max_pool, 64, 256, stride=1, num_blocks=n1,
+            prefix='res2', dim_inner=64
+        )
+        blob_in, dim_in = model_helper.residual_layer(
+            residual_block, blob_in, dim_in, 512, stride=2, num_blocks=n2,
+            prefix='res3', dim_inner=128
+        )
+        blob_in, dim_in = model_helper.residual_layer(
+            residual_block, blob_in, dim_in, 1024, stride=2, num_blocks=n3,
+            prefix='res4', dim_inner=256
+        )
+        blob_in, dim_in = model_helper.residual_layer(
+            residual_block, blob_in, dim_in, 2048, stride=2, num_blocks=n4,
+            prefix='res5', dim_inner=512
+        )
+    elif opts_depth in [18, 34]:
+        blob_in, dim_in = model_helper.residual_layer(
+            residual_block, max_pool, 64, 64, stride=1, num_blocks=n1,
+            prefix='res2',
+        )
+        blob_in, dim_in = model_helper.residual_layer(
+            residual_block, blob_in, dim_in, 128, stride=2, num_blocks=n2,
+            prefix='res3',
+        )
+        blob_in, dim_in = model_helper.residual_layer(
+            residual_block, blob_in, dim_in, 256, stride=2, num_blocks=n3,
+            prefix='res4',
+        )
+        blob_in, dim_in = model_helper.residual_layer(
+            residual_block, blob_in, dim_in, 512, stride=2, num_blocks=n4,
+            prefix='res5',
+        )
+
+    pool_blob = model.AveragePool(blob_in, 'pool5', kernel=7, stride=1)
+
+    loss_scale = 1. / opts['distributed']['num_xpus'] / \
+        opts['distributed']['num_shards']
+
+    loss = None
+
+    fc_blob = model.FC(
+        pool_blob, 'pred', num_features, num_classes,
+        # does not appear to affect test_loss performance
+        # weight_init=('GaussianFill', {'std': opts.fc_init_std}),
+        # bias_init=('ConstantFill', {'value': 0.})
+        weight_init=None,
+        bias_init=None)
+    softmax, loss = model.SoftmaxWithLoss(
+        [fc_blob, labels],
+        ['softmax', 'loss'],
+        scale=loss_scale)
+    model.Accuracy(['softmax', labels], 'accuracy')
+    return model, softmax, loss
+
+
+class ResNetModelHelper():
+
+    def __init__(self, model, split, opts):
+        self.model = model
+        self.split = split
+        self.opts = opts
+        self.engine = opts['model_param']['engine']
+
+
+    # shortcut type B
+    def add_shortcut(self, blob_in, dim_in, dim_out, stride, prefix):
+        if dim_in == dim_out:
+            return blob_in
+        conv_blob = self.model.Conv(
+            blob_in, prefix, dim_in, dim_out, kernel=1,
+            stride=stride,
+            weight_init=("MSRAFill", {}),
+            bias_init=('ConstantFill', {'value': 0.}), no_bias=1, engine=self.engine
+        )
+        test_mode = False
+        if self.split in ['test', 'val']:
+            test_mode = True
+        bn_blob = self.model.SpatialBN(
+            conv_blob, prefix + "_bn", dim_out,
+            # epsilon=1e-3,
+            # momentum=0.1,
+            epsilon=self.opts['model_param']['bn_epsilon'],
+            momentum=self.opts['model_param']['bn_momentum'],
+            is_test=test_mode,
+        )
+        return bn_blob
+
+    def conv_bn(
+        self, blob_in, dim_in, dim_out, kernel, stride, prefix, group=1, pad=1,
+    ):
+        conv_blob = self.model.Conv(
+            blob_in, prefix, dim_in, dim_out, kernel, stride=stride,
+            pad=pad, group=group,
+            weight_init=("MSRAFill", {}),
+            bias_init=('ConstantFill', {'value': 0.}), no_bias=1, engine=self.engine
+        )
+        test_mode = False
+        if self.split in ['test', 'val']:
+            test_mode = True
+        bn_blob = self.model.SpatialBN(
+            conv_blob, prefix + "_bn", dim_out,
+            epsilon=self.opts['model_param']['bn_epsilon'],
+            momentum=self.opts['model_param']['bn_momentum'],
+            is_test=test_mode,
+        )
+        return bn_blob
+
+    def conv_bn_relu(
+        self, blob_in, dim_in, dim_out, kernel, stride, prefix, pad=1, group=1,
+    ):
+        bn_blob = self.conv_bn(
+            blob_in, dim_in, dim_out, kernel, stride, prefix, group=group,
+            pad=pad
+        )
+        return self.model.Relu(bn_blob, bn_blob)
+
+    # 3(a)this block uses multi-way group conv implementation that splits blobs
+    def multiway_bottleneck_block(
+        self, blob_in, dim_in, dim_out, stride, prefix, dim_inner, group
+    ):
+        blob_out = self.conv_bn_relu(
+            blob_in, dim_in, dim_inner, 1, 1, prefix + "_branch2a", pad=0,
+        )
+
+        conv_blob = self.model.GroupConv_Deprecated(
+            blob_out, prefix + "_branch2b", dim_inner, dim_inner, kernel=3,
+            stride=stride, pad=1, group=group, weight_init=("MSRAFill", {}),
+            bias_init=('ConstantFill', {'value': 0.}), no_bias=1, engine=self.engine
+        )
+        test_mode = False
+        if self.split in ['test', 'val']:
+            test_mode = True
+        bn_blob = self.model.SpatialBN(
+            conv_blob, prefix + "_branch2b_bn", dim_out,
+            epsilon=self.opts['model_param']['bn_epsilon'],
+            momentum=self.opts['model_param']['bn_momentum'], is_test=test_mode,
+        )
+        relu_blob = self.model.Relu(bn_blob, bn_blob)
+
+        bn_blob = self.conv_bn(
+            relu_blob, dim_inner, dim_out, 1, 1, prefix + "_branch2c", pad=0
+        )
+        if self.opts['model_param']['custom_bn_init']:
+            self.model.param_init_net.ConstantFill(
+                [bn_blob + '_s'], bn_blob + '_s',
+                value=self.opts['model_param']['bn_init_gamma'])
+
+        sc_blob = self.add_shortcut(
+            blob_in, dim_in, dim_out, stride, prefix=prefix + "_branch1"
+        )
+        sum_blob = self.model.net.Sum([bn_blob, sc_blob], prefix + "_sum")
+        return self.model.Relu(sum_blob, sum_blob)
+
+    # 3(c) this block uses cudnn group conv op
+    def group_bottleneck_block(
+        self, blob_in, dim_in, dim_out, stride, prefix, dim_inner, group
+    ):
+        blob_out = self.conv_bn_relu(
+            blob_in, dim_in, dim_inner, 1, 1, prefix + "_branch2a", pad=0,
+        )
+        blob_out = self.conv_bn_relu(
+            blob_out, dim_inner, dim_inner, 3, stride, prefix + "_branch2b",
+            group=group
+        )
+        bn_blob = self.conv_bn(
+            blob_out, dim_inner, dim_out, 1, 1, prefix + "_branch2c", pad=0
+        )
+        if self.opts['model_param']['custom_bn_init']:
+            self.model.param_init_net.ConstantFill(
+                [bn_blob + '_s'], bn_blob + '_s',
+                value=self.opts['model_param']['bn_init_gamma'])
+
+        sc_blob = self.add_shortcut(
+            blob_in, dim_in, dim_out, stride, prefix=prefix + "_branch1"
+        )
+        sum_blob = self.model.net.Sum([bn_blob, sc_blob], prefix + "_sum")
+        return self.model.Relu(sum_blob, sum_blob)
+
+    # bottleneck residual layer for 50, 101, 152 layer networks
+    def bottleneck_block(
+        self, blob_in, dim_in, dim_out, stride, prefix, dim_inner, group=None
+    ):
+        blob_out = self.conv_bn_relu(
+            blob_in, dim_in, dim_inner, 1, 1, prefix + "_branch2a", pad=0,
+        )
+        blob_out = self.conv_bn_relu(
+            blob_out, dim_inner, dim_inner, 3, stride, prefix + "_branch2b",
+        )
+        bn_blob = self.conv_bn(
+            blob_out, dim_inner, dim_out, 1, 1, prefix + "_branch2c", pad=0
+        )
+        if self.opts['model_param']['custom_bn_init']:
+            self.model.param_init_net.ConstantFill(
+                [bn_blob + '_s'], bn_blob + '_s',
+                value=self.opts['model_param']['bn_init_gamma'])
+
+        sc_blob = self.add_shortcut(
+            blob_in, dim_in, dim_out, stride, prefix=prefix + "_branch1"
+        )
+        sum_blob = self.model.net.Sum([bn_blob, sc_blob], prefix + "_sum")
+        return self.model.Relu(sum_blob, sum_blob)
+
+    # basic layer for the 18 and 34 layer networks and the CIFAR data netwrorks
+    def basic_block(
+        self, blob_in, dim_in, dim_out, stride, prefix, dim_inner=None,
+        group=None,
+    ):
+        blob_out = self.conv_bn_relu(
+            blob_in, dim_in, dim_out, 3, stride, prefix + "_branch2a"
+        )
+        bn_blob = self.conv_bn(
+            blob_out, dim_out, dim_out, 3, 1, prefix + "_branch2b", pad=1
+        )
+        sc_blob = self.add_shortcut(
+            blob_in, dim_in, dim_out, stride, prefix=prefix + "_branch1"
+        )
+        sum_blob = self.model.net.Sum([bn_blob, sc_blob], prefix + "_sum")
+        return self.model.Relu(sum_blob, sum_blob)
+
+    def residual_layer(
+        self, block_fn, blob_in, dim_in, dim_out, stride, num_blocks, prefix,
+        dim_inner=None, group=None
+    ):
+        # prefix is something like: res2, res3, etc.
+        # each res layer has num_blocks stacked
+        for idx in range(num_blocks):
+            block_prefix = "{}_{}".format(prefix, idx)
+            block_stride = 2 if (idx == 0 and stride == 2) else 1
+            blob_in = block_fn(
+                blob_in, dim_in, dim_out, block_stride, block_prefix, dim_inner,
+                group
+            )
+            dim_in = dim_out
+        return blob_in, dim_in
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/explicit_resnet_param_update.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/explicit_resnet_param_update.py
new file mode 100644
index 0000000..5378acd
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/explicit_resnet_param_update.py
@@ -0,0 +1,65 @@
+
+
+
+
+
+from caffe2.python import workspace, core
+from caffe2.proto import caffe2_pb2
+
+
+def gen_param_update_builder_fun(self, model, dataset, is_train):
+    if not is_train:
+        return None
+    else:
+        # from sherlok
+        for idx in range(self.opts['distributed']['first_xpu_id'],
+                         self.opts['distributed']['first_xpu_id'] +
+                         self.opts['distributed']['num_xpus']):
+            with core.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA, idx)):
+                workspace.CreateBlob('{}_{}/lr'.
+                    format(self.opts['distributed']['device'], idx))
+
+        def add_parameter_update_ops(model):
+            model.Iter("ITER")
+            weight_decay = model.param_init_net.ConstantFill(
+                [], 'weight_decay', shape=[1],
+                value=self.opts['model_param']['weight_decay']
+            )
+            weight_decay_bn = model.param_init_net.ConstantFill(
+                [], 'weight_decay_bn', shape=[1],
+                value=self.opts['model_param']['weight_decay_bn']
+            )
+            one = model.param_init_net.ConstantFill(
+                [], "ONE", shape=[1], value=1.0
+            )
+
+            '''
+            Add the momentum-SGD update.
+            '''
+            params = model.GetParams()
+            assert(len(params) > 0)
+
+            for param in params:
+                param_grad = model.param_to_grad[param]
+                param_momentum = model.param_init_net.ConstantFill(
+                    [param], param + '_momentum', value=0.0
+                )
+
+                if '_bn' in str(param):
+                    model.WeightedSum(
+                        [param_grad, one, param, weight_decay_bn], param_grad
+                    )
+                else:
+                    model.WeightedSum(
+                        [param_grad, one, param, weight_decay], param_grad
+                    )
+
+                # Update param_grad and param_momentum in place
+                model.net.MomentumSGDUpdate(
+                    [param_grad, param_momentum, 'lr', param],
+                    [param_grad, param_momentum, param],
+                    momentum=0.9,
+                    nesterov=1
+                )
+
+        return add_parameter_update_ops
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/gfs_IN1k.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/gfs_IN1k.py
new file mode 100644
index 0000000..496ac22
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/gfs_IN1k.py
@@ -0,0 +1,54 @@
+
+
+
+
+
+# # example1 using gfs as input source.
+
+def gen_input_builder_fun(self, model, dataset, is_train):
+    if is_train:
+        input_path = self.opts['input']['train_input_path']
+    else:
+        input_path = self.opts['input']['test_input_path']
+
+    reader = model.CreateDB("reader",
+                            db=input_path,
+                            db_type='lmdb',
+                            shard_id=self.shard_id,
+                            num_shards=self.opts['distributed']['num_shards'],)
+
+    def AddImageInput(model, reader, batch_size, img_size):
+        '''
+        Image input operator that loads data from reader and
+        applies certain transformations to the images.
+        '''
+        data, label = model.ImageInput(
+            reader,
+            ["data", "label"],
+            batch_size=batch_size,
+            use_caffe_datum=True,
+            mean=128.,
+            std=128.,
+            scale=256,
+            crop=img_size,
+            mirror=1,
+            is_test=True
+        )
+        data = model.StopGradient(data, data)
+
+    def add_image_input(model):
+        AddImageInput(
+            model,
+            reader,
+            batch_size=self.opts['epoch_iter']['batch_per_device'],
+            img_size=self.opts['input']['imsize'],
+        )
+    return add_image_input
+
+
+def get_input_dataset(opts):
+    return []
+
+
+def get_model_input_fun(self):
+    pass
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/override_no_test_model_no_checkpoint.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/override_no_test_model_no_checkpoint.py
new file mode 100644
index 0000000..419d6a2
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/override_no_test_model_no_checkpoint.py
@@ -0,0 +1,16 @@
+
+
+
+
+
+def checkpoint(self, epoch):
+    self.model_path = None
+    pass
+
+def prep_data_parallel_models(self):
+    # only do train_model no test needed here
+    self.prep_a_data_parallel_model(self.train_model,
+                                    self.train_dataset, True)
+
+def run_testing_net(self):
+    pass
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/rendezvous_filestore.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/rendezvous_filestore.py
new file mode 100644
index 0000000..0a56d68
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/playground/resnetdemo/rendezvous_filestore.py
@@ -0,0 +1,41 @@
+
+
+
+
+
+from caffe2.python import core, workspace
+from caffe2.python import dyndep
+dyndep.InitOpsLibrary('@/caffe2/caffe2/distributed:file_store_handler_ops')
+
+
+# rendezvous should NOT be unique for each operator.  It should have
+# the same run_id on different operators.  say we have two shards,
+# both shards created rendezvous of run_id "aaa_bbb_epoch_09", and this
+# rendezvous will wait for two shards to join because max_shards is specified
+# to be 2.  If each shard created an rendezvous with different run_id,
+# each of them are waiting for different rendezvous to join, they will
+# never wait for each other and therefore timeout eventually.
+
+def gen_rendezvous_ctx(self, model, dataset, is_train):
+    if self.opts['distributed']['num_shards'] < 2:
+        return None
+    # have issue when try to set this up on more shards
+    workspace.RunOperatorOnce(
+        core.CreateOperator(
+            "FileStoreHandlerCreate", [], ["store_handler"],
+            path="/tmp",
+            prefix="epoch.{}".format(self.epoch),
+        )
+    )
+
+    rendezvous = dict(
+        kv_handler="store_handler",
+        shard_id=self.shard_id,
+        num_shards=self.opts['distributed']['num_shards'],
+        engine="GLOO",
+        # transport=args.distributed_transport,
+        transport="tcp",
+        # interface=interfaces[0],
+        interface=[],
+        exit_nets=None) if is_train else None
+    return rendezvous
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/prof/__init__.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/prof/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/prof/cuda_profile_ops_test.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/prof/cuda_profile_ops_test.py
new file mode 100644
index 0000000..c77b7ae
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/prof/cuda_profile_ops_test.py
@@ -0,0 +1,24 @@
+
+
+
+
+
+import unittest
+from caffe2.proto import caffe2_pb2
+from caffe2.python import core, dyndep, workspace
+
+dyndep.InitOpsLibrary("@/caffe2/caffe2/contrib/prof:cuda_profile_ops")
+
+
+class CudaProfileOpsTest(unittest.TestCase):
+    @unittest.skipIf(workspace.NumCudaDevices() < 1, "Need at least 1 GPU")
+    def test_run(self):
+        net = core.Net("net")
+        net.CudaProfileInitialize([], [], output="/tmp/cuda_profile_test")
+        net.CudaProfileStart([], [])
+        with core.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA, 0)):
+            net.ConstantFill([], ["out"], shape=[1, 3, 244, 244])
+        net.CudaProfileStop([], [])
+
+        workspace.CreateNet(net)
+        workspace.RunNet(net)
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/script/__init__.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/script/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/script/examples/__init__.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/script/examples/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/tensorboard/__init__.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/tensorboard/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/tensorboard/tensorboard.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/tensorboard/tensorboard.py
new file mode 100644
index 0000000..6f5ad18
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/tensorboard/tensorboard.py
@@ -0,0 +1,212 @@
+
+
+
+
+
+import click
+import collections
+import logging
+import numpy as np
+import os
+
+from caffe2.proto import caffe2_pb2
+from caffe2.python import core
+import caffe2.contrib.tensorboard.tensorboard_exporter as tb_exporter
+
+try:
+    # tensorboard>=1.14.0
+    from tensorboard.compat.proto.summary_pb2 import Summary, HistogramProto
+    from tensorboard.compat.proto.event_pb2 import Event
+    from tensorboard.summary.writer.event_file_writer import EventFileWriter as FileWriter
+except ImportError:
+    from tensorflow.core.framework.summary_pb2 import Summary, HistogramProto
+    from tensorflow.core.util.event_pb2 import Event
+    try:
+        # tensorflow>=1.0.0
+        from tensorflow.summary import FileWriter
+    except ImportError:
+        # tensorflow<=0.12.1
+        from tensorflow.train import SummaryWriter as FileWriter
+
+class Config(object):
+    HEIGHT = 600
+    ASPECT_RATIO = 1.6
+
+
+CODE_TEMPLATE = """
+<script>
+  function load() {{
+    document.getElementById("{id}").pbtxt = {data};
+  }}
+</script>
+<link rel="import"
+  href="https://tensorboard.appspot.com/tf-graph-basic.build.html"
+  onload=load()
+>
+<div style="height:{height}px">
+  <tf-graph-basic id="{id}"></tf-graph-basic>
+</div>
+"""
+
+IFRAME_TEMPLATE = """
+<iframe
+  seamless
+  style="width:{width}px;height:{height}px;border:0"
+  srcdoc="{code}">
+</iframe>
+"""
+
+
+def _show_graph(graph_def):
+    import IPython.display
+
+    code = CODE_TEMPLATE.format(
+        data=repr(str(graph_def)),
+        id='graph' + str(np.random.rand()),
+        height=Config.HEIGHT)
+
+    iframe = IFRAME_TEMPLATE.format(
+        code=code.replace('"', '&quot;'),
+        width=Config.HEIGHT * Config.ASPECT_RATIO,
+        height=Config.HEIGHT + 20)
+
+    IPython.display.display(IPython.display.HTML(iframe))
+
+
+def visualize_cnn(cnn, **kwargs):
+    g = tb_exporter.cnn_to_graph_def(cnn, **kwargs)
+    _show_graph(g)
+
+
+def visualize_net(nets, **kwargs):
+    g = tb_exporter.nets_to_graph_def(nets, **kwargs)
+    _show_graph(g)
+
+
+def visualize_ops(ops, **kwargs):
+    g = tb_exporter.ops_to_graph_def(ops, **kwargs)
+    _show_graph(g)
+
+
+@click.group()
+def cli():
+    pass
+
+
+def write_events(tf_dir, events):
+    writer = FileWriter(tf_dir, len(events))
+    for event in events:
+        writer.add_event(event)
+    writer.flush()
+    writer.close()
+
+
+def graph_def_to_event(step, graph_def):
+    return Event(
+        wall_time=step, step=step, graph_def=graph_def.SerializeToString())
+
+
+@cli.command("tensorboard-graphs")
+@click.option("--c2-netdef", type=click.Path(exists=True, dir_okay=False),
+              multiple=True)
+@click.option("--tf-dir", type=click.Path(exists=True))
+def tensorboard_graphs(c2_netdef, tf_dir):
+    log = logging.getLogger(__name__)
+    log.setLevel(logging.INFO)
+
+    def parse_net_def(path):
+        import google.protobuf.text_format  # type: ignore[import]
+        net_def = caffe2_pb2.NetDef()
+        with open(path) as f:
+            google.protobuf.text_format.Merge(f.read(), net_def)
+        return core.Net(net_def)
+
+    graph_defs = [tb_exporter.nets_to_graph_def([parse_net_def(path)])
+                  for path in c2_netdef]
+    events = [graph_def_to_event(i, graph_def)
+              for (i, graph_def) in enumerate(graph_defs, start=1)]
+    write_events(tf_dir, events)
+    log.info("Wrote %s graphs to logdir %s", len(events), tf_dir)
+
+
+@cli.command("tensorboard-events")
+@click.option("--c2-dir", type=click.Path(exists=True, file_okay=False),
+              help="Root directory of the Caffe2 run")
+@click.option("--tf-dir", type=click.Path(writable=True),
+              help="Output path to the logdir used by TensorBoard")
+def tensorboard_events(c2_dir, tf_dir):
+    np.random.seed(1701)
+    log = logging.getLogger(__name__)
+    log.setLevel(logging.INFO)
+    S = collections.namedtuple('S', ['min', 'max', 'mean', 'std'])
+
+    def parse_summary(filename):
+        try:
+            with open(filename) as f:
+                rows = [(float(el) for el in line.split()) for line in f]
+                return [S(*r) for r in rows]
+        except Exception as e:
+            log.exception(e)
+            return None
+
+    def get_named_summaries(root):
+        summaries = [
+            (fname, parse_summary(os.path.join(dirname, fname)))
+            for dirname, _, fnames in os.walk(root)
+            for fname in fnames
+        ]
+        return [(n, s) for (n, s) in summaries if s]
+
+    def inferred_histo(summary, samples=1000):
+        np.random.seed(
+            hash(
+                summary.std + summary.mean + summary.min + summary.max
+            ) % np.iinfo(np.int32).max
+        )
+        samples = np.random.randn(samples) * summary.std + summary.mean
+        samples = np.clip(samples, a_min=summary.min, a_max=summary.max)
+        (hist, edges) = np.histogram(samples)
+        upper_edges = edges[1:]
+        r = HistogramProto(
+            min=summary.min,
+            max=summary.max,
+            num=len(samples),
+            sum=samples.sum(),
+            sum_squares=(samples * samples).sum())
+        r.bucket_limit.extend(upper_edges)
+        r.bucket.extend(hist)
+        return r
+
+    def named_summaries_to_events(named_summaries):
+        names = [n for (n, _) in named_summaries]
+        summaries = [s for (_, s) in named_summaries]
+        summaries = list(zip(*summaries))
+
+        def event(step, values):
+            s = Summary()
+            scalar = [
+                Summary.Value(
+                    tag="{}/{}".format(name, field),
+                    simple_value=v)
+                for name, value in zip(names, values)
+                for field, v in value._asdict().items()]
+            hist = [
+                Summary.Value(
+                    tag="{}/inferred_normal_hist".format(name),
+                    histo=inferred_histo(value))
+                for name, value in zip(names, values)
+            ]
+            s.value.extend(scalar + hist)
+            return Event(wall_time=int(step), step=step, summary=s)
+
+        return [event(step, values)
+                for step, values in enumerate(summaries, start=1)]
+
+    named_summaries = get_named_summaries(c2_dir)
+    events = named_summaries_to_events(named_summaries)
+    write_events(tf_dir, events)
+    log.info("Wrote %s events to logdir %s", len(events), tf_dir)
+
+
+if __name__ == "__main__":
+    cli()
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/tensorboard/tensorboard_exporter.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/tensorboard/tensorboard_exporter.py
new file mode 100644
index 0000000..a9a1651
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/tensorboard/tensorboard_exporter.py
@@ -0,0 +1,344 @@
+
+
+
+
+
+from builtins import bytes
+import copy
+import logging
+import os
+
+from caffe2.proto import caffe2_pb2
+from caffe2.python import core, workspace
+
+try:
+    # tensorboard>=1.14.0
+    from tensorboard.compat.proto import tensor_shape_pb2
+    from tensorboard.compat.proto.node_def_pb2 import NodeDef
+    from tensorboard.compat.proto.graph_pb2 import GraphDef
+except ImportError:
+    from tensorflow.core.framework import tensor_shape_pb2
+    try:
+        # tensorflow>=1.0.0
+        from tensorflow import NodeDef, GraphDef
+    except ImportError:
+        # tensorflow<=0.12.1
+        from tensorflow.core.framework.graph_pb2 import NodeDef, GraphDef
+
+
+def _make_unique_name(seen, name, min_version=0):
+    assert name is not None
+    i = min_version
+    x = '%s_%d' % (name, i) if i else name
+    while x in seen:
+        i += 1
+        x = '%s_%d' % (name, i)
+    seen.add(x)
+    return x
+
+
+def _convert_to_ssa(shapes, track_blob_names, ops):
+    """
+    Convert an operator graph to SSA (i.e. out-of-place).
+
+    I.e. blobs will be renamed so that each blob is produced only once.
+    """
+    ir = core.IR(ops)
+    seen = set()
+    versioned = {}
+    shapes2 = {}
+    track_blob_names2 = {}
+
+    def ssa_name(name, versions):
+        assert name in versions
+        version = versions[name]
+        if (name, version) in versioned:
+            return versioned[(name, version)]
+        # Always setting name2 = `{name}_{version}` would work, but we also try
+        # to avoid a trailing `_0`, so we have to be careful not to introduce
+        # name collisions, such as (foo_1, 0) = foo_1 = (foo, 1).
+        # Note: operator names (if any) will be handled later.
+        name2 = _make_unique_name(seen, name, min_version=version)
+        versioned[(name, version)] = name2
+        # Transfer shape.
+        if name in shapes:
+            shapes2[name2] = shapes[name]
+        if track_blob_names and name in track_blob_names:
+            track_blob_names2[name2] = track_blob_names[name]
+        return name2
+
+    for (op, ssa) in zip(ops, ir.ssa):
+        assert op is ssa.op
+        inputs = list(op.input)
+        outputs = list(op.output)
+        del op.input[:]
+        del op.output[:]
+        op.input.extend(ssa_name(name, ssa.in_versions) for name in inputs)
+        op.output.extend(ssa_name(name, ssa.out_versions) for name in outputs)
+
+    shapes.clear()
+    shapes.update(shapes2)
+    if track_blob_names:
+        track_blob_names.clear()
+        track_blob_names.update(track_blob_names2)
+
+
+def _get_blob_names(ops):
+    names = set()
+    for op in ops:
+        names.update(op.input)
+        names.update(op.output)
+    return {name: name for name in names}
+
+
+def _remap_keys(m, f):
+    m2 = {f(key): value for key, value in m.items()}
+    m.clear()
+    m.update(m2)
+
+
+def _rename_all(shapes, track_blob_names, ops, f):
+    seen = set()
+    renamed = {}
+
+    def g(name):
+        """ Collision-free version of f.
+        """
+        if name is None:
+            return None
+        if name in renamed:
+            return renamed[name]
+        name2 = _make_unique_name(seen, f(name))
+        renamed[name] = name2
+        return name2
+
+    for op in ops:
+        inputs = list(op.input)
+        outputs = list(op.output)
+        del op.input[:]
+        del op.output[:]
+        op.input.extend(g(name) for name in inputs)
+        op.output.extend(g(name) for name in outputs)
+
+    _remap_keys(shapes, g)
+    if track_blob_names:
+        _remap_keys(track_blob_names, g)
+    # Rename all operator names (if any) independently so that the
+    # unique-fication happens only once in _fill_missing_operator_names().
+    seen.clear()
+    renamed.clear()
+    for op in ops:
+        op.name = g(op.name)
+
+
+def _add_gradient_scope(shapes, track_blob_names, ops):
+    """
+    For all operators or blobs with name containing "_grad", add a
+    "GRADIENTS/" scope.
+
+    Note: breaks graph execution since the blob -> gradient mapping is
+    hardcoded.
+    """
+    def f(name):
+        if '_grad' in name:
+            return 'GRADIENTS/{}'.format(name)
+        else:
+            return name
+    _rename_all(shapes, track_blob_names, ops, f)
+
+
+def _replace_colons(shapes, track_blob_names, ops, repl):
+    """
+    `:i` has a special meaning in Tensorflow.
+    """
+    def f(name):
+        return name.replace(':', repl)
+    _rename_all(shapes, track_blob_names, ops, f)
+
+
+def _fill_missing_operator_names(ops):
+    ''' Give missing operators a name.
+
+    We expect C2 operators to be generally unnamed. This gives them a scope
+    (inferred from their outputs) and a name after their type. Duplicates will
+    be postfixed by an index.
+    '''
+    seen = set()
+    for op in ops:
+        # Make sure operator names don't collide with blobs.
+        seen.update(op.input)
+        seen.update(op.output)
+    for op in ops:
+        if op.name:
+            name = op.name
+        elif op.output or op.input:
+            l = [os.path.dirname(name) for name in op.output or op.input]
+            scope = os.path.commonprefix(l)
+            name = os.path.join(scope, op.type)
+        else:
+            name = op.type
+        assert(name)
+        op.name = _make_unique_name(seen, name)
+
+
+def _tf_device(device_option):
+    if not device_option.HasField("device_type"):
+        return ""
+    if device_option.device_type == caffe2_pb2.CPU:
+        return "/cpu:*"
+    if device_option.device_type == caffe2_pb2.CUDA:
+        return "/gpu:{}".format(device_option.device_id)
+    raise Exception("Unhandled device", device_option)
+
+
+def _add_tf_shape(m, ints):
+    sh = tensor_shape_pb2.TensorShapeProto()
+    for i in ints:
+        dim = tensor_shape_pb2.TensorShapeProto.Dim()
+        dim.size = i
+        sh.dim.extend([dim])
+    m['_output_shapes'].list.shape.extend([sh])
+
+
+def _set_tf_attr(m, arg):
+    k = arg.name
+    if k == 'shape' and arg.ints:
+        _add_tf_shape(m, arg.ints)
+        return
+    if arg.HasField("f"):
+        m[k].f = arg.f
+        return
+    if arg.HasField("i"):
+        m[k].i = arg.i
+        return
+    if arg.HasField("s"):
+        m[k].s = (
+            arg.s if isinstance(arg.s, bytes) else str(arg.s).encode('utf-8')
+        )
+        return
+    if arg.floats:
+        m[k].list.f.extend(arg.floats)
+        return
+    if arg.ints:
+        m[k].list.i.extend(arg.ints)
+        return
+    if arg.strings:
+        m[k].list.s.extend(
+            s if isinstance(s, bytes) else str(s).encode('utf-8')
+            for s in arg.strings
+        )
+        return
+    # The value is an empty list.
+    m[k].list.s.extend([])
+
+
+def _operator_to_node(shapes, op):
+    assert op.name, op
+    n = NodeDef()
+    n.name = op.name
+    n.input.extend(op.input)
+    n.op = op.type
+    n.device = _tf_device(op.device_option)
+    if shapes:
+        # Add shapes in order.
+        for output in op.output:
+            if output not in shapes:
+                break
+            _add_tf_shape(n.attr, shapes[output])
+    for arg in op.arg:
+        _set_tf_attr(n.attr, arg)
+    return n
+
+
+def _blob_to_node(producing_ops, shapes, name):
+    assert name
+    n = NodeDef()
+    n.name = name
+    inputs = producing_ops.get(name, [])
+    if inputs:
+        n.op = 'Blob'
+    else:
+        n.op = 'Placeholder'
+    n.input.extend('%s:%d' % (op.name, i) for op, i in inputs)
+    if inputs:
+        device = inputs[0][0].device_option
+        if (all(input[0].device_option == device for input in inputs)):
+            n.device = _tf_device(device)
+    if shapes and name in shapes:
+        _add_tf_shape(n.attr, shapes[name])
+    return n
+
+
+def _operators_to_graph_def(
+    shapes,
+    ops,
+    replace_colons='$',
+    with_ssa=True,
+    with_gradient_scope=True,
+    track_blob_names=None,  # pass an empty array to track blob names
+):
+    if track_blob_names is not None:
+        track_blob_names.clear()
+        track_blob_names.update(_get_blob_names(ops))
+    if replace_colons:
+        _replace_colons(shapes, track_blob_names, ops, replace_colons)
+    if with_ssa:
+        _convert_to_ssa(shapes, track_blob_names, ops)
+    if with_gradient_scope:
+        _add_gradient_scope(shapes, track_blob_names, ops)
+    _fill_missing_operator_names(ops)
+    g = GraphDef()
+    producing_ops = {}
+    blobs = set()
+    for op in ops:
+        g.node.extend([_operator_to_node(shapes, op)])
+        for input_blob in op.input:
+            blobs.add(input_blob)
+        for i, output_blob in enumerate(op.output):
+            blobs.add(output_blob)
+            producing_ops.setdefault(output_blob, []).append((op, i))
+    for blob in blobs:
+        g.node.extend([_blob_to_node(producing_ops, shapes, blob)])
+    return g
+
+
+def _propagate_device_option(net):
+    if not net.HasField("device_option"):
+        return
+    for op in net.op:
+        if not op.HasField("device_option"):
+            op.device_option.CopyFrom(net.device_option)
+
+
+def _try_get_shapes(nets):
+    try:
+        # Note: this will inspect the workspace for better or worse.
+        shapes, _ = workspace.InferShapesAndTypes(nets)
+        return shapes
+    except Exception as e:
+        logging.warning('Failed to compute shapes: %s', e)
+        return {}
+
+
+def nets_to_graph_def(nets, shapes=None, **kwargs):
+    if shapes is None:
+        shapes = _try_get_shapes(nets)
+    nets = [copy.deepcopy(net.Proto()) for net in nets]
+    shapes = copy.deepcopy(shapes)
+    for net in nets:
+        _propagate_device_option(net)
+    return _operators_to_graph_def(
+        shapes,
+        [op for net in nets for op in net.op],
+        **kwargs
+    )
+
+
+def cnn_to_graph_def(cnn, **kwargs):
+    return nets_to_graph_def([cnn.param_init_net, cnn.net], **kwargs)
+
+
+def ops_to_graph_def(ops, shapes=None, **kwargs):
+    ops = copy.deepcopy(ops)
+    shapes = copy.deepcopy(shapes or {})
+    return _operators_to_graph_def(shapes, ops, **kwargs)
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/tensorboard/tensorboard_exporter_test.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/tensorboard/tensorboard_exporter_test.py
new file mode 100644
index 0000000..31ef818
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/tensorboard/tensorboard_exporter_test.py
@@ -0,0 +1,705 @@
+
+
+
+
+
+import unittest
+
+from caffe2.proto import caffe2_pb2
+import caffe2.python.cnn as cnn
+import caffe2.python.core as core
+import caffe2.contrib.tensorboard.tensorboard_exporter as tb
+
+EXPECTED = """
+node {
+  name: "conv1/XavierFill"
+  op: "XavierFill"
+  device: "/gpu:0"
+  attr {
+    key: "_output_shapes"
+    value {
+      list {
+        shape {
+          dim {
+            size: 96
+          }
+          dim {
+            size: 3
+          }
+          dim {
+            size: 11
+          }
+          dim {
+            size: 11
+          }
+        }
+      }
+    }
+  }
+}
+node {
+  name: "conv1/ConstantFill"
+  op: "ConstantFill"
+  device: "/gpu:0"
+  attr {
+    key: "_output_shapes"
+    value {
+      list {
+        shape {
+          dim {
+            size: 96
+          }
+        }
+      }
+    }
+  }
+}
+node {
+  name: "classifier/XavierFill"
+  op: "XavierFill"
+  device: "/gpu:0"
+  attr {
+    key: "_output_shapes"
+    value {
+      list {
+        shape {
+          dim {
+            size: 1000
+          }
+          dim {
+            size: 4096
+          }
+        }
+      }
+    }
+  }
+}
+node {
+  name: "classifier/ConstantFill"
+  op: "ConstantFill"
+  device: "/gpu:0"
+  attr {
+    key: "_output_shapes"
+    value {
+      list {
+        shape {
+          dim {
+            size: 1000
+          }
+        }
+      }
+    }
+  }
+}
+node {
+  name: "ImageInput"
+  op: "ImageInput"
+  input: "db"
+  device: "/gpu:0"
+  attr {
+    key: "cudnn_exhaustive_search"
+    value {
+      i: 0
+    }
+  }
+  attr {
+    key: "is_test"
+    value {
+      i: 0
+    }
+  }
+  attr {
+    key: "use_cudnn"
+    value {
+      i: 1
+    }
+  }
+}
+node {
+  name: "NHWC2NCHW"
+  op: "NHWC2NCHW"
+  input: "data_nhwc"
+  device: "/gpu:0"
+}
+node {
+  name: "conv1/Conv"
+  op: "Conv"
+  input: "data"
+  input: "conv1/conv1_w"
+  input: "conv1/conv1_b"
+  device: "/gpu:0"
+  attr {
+    key: "exhaustive_search"
+    value {
+      i: 0
+    }
+  }
+  attr {
+    key: "kernel"
+    value {
+      i: 11
+    }
+  }
+  attr {
+    key: "order"
+    value {
+      s: "NCHW"
+    }
+  }
+  attr {
+    key: "stride"
+    value {
+      i: 4
+    }
+  }
+}
+node {
+  name: "conv1/Relu"
+  op: "Relu"
+  input: "conv1/conv1"
+  device: "/gpu:0"
+  attr {
+    key: "cudnn_exhaustive_search"
+    value {
+      i: 0
+    }
+  }
+  attr {
+    key: "order"
+    value {
+      s: "NCHW"
+    }
+  }
+}
+node {
+  name: "conv1/MaxPool"
+  op: "MaxPool"
+  input: "conv1/conv1_1"
+  device: "/gpu:0"
+  attr {
+    key: "cudnn_exhaustive_search"
+    value {
+      i: 0
+    }
+  }
+  attr {
+    key: "kernel"
+    value {
+      i: 2
+    }
+  }
+  attr {
+    key: "order"
+    value {
+      s: "NCHW"
+    }
+  }
+  attr {
+    key: "stride"
+    value {
+      i: 2
+    }
+  }
+}
+node {
+  name: "classifier/FC"
+  op: "FC"
+  input: "conv1/pool1"
+  input: "classifier/fc_w"
+  input: "classifier/fc_b"
+  device: "/gpu:0"
+  attr {
+    key: "cudnn_exhaustive_search"
+    value {
+      i: 0
+    }
+  }
+  attr {
+    key: "order"
+    value {
+      s: "NCHW"
+    }
+  }
+  attr {
+    key: "use_cudnn"
+    value {
+      i: 1
+    }
+  }
+}
+node {
+  name: "classifier/Softmax"
+  op: "Softmax"
+  input: "classifier/fc"
+  device: "/gpu:0"
+  attr {
+    key: "cudnn_exhaustive_search"
+    value {
+      i: 0
+    }
+  }
+  attr {
+    key: "order"
+    value {
+      s: "NCHW"
+    }
+  }
+}
+node {
+  name: "classifier/LabelCrossEntropy"
+  op: "LabelCrossEntropy"
+  input: "classifier/pred"
+  input: "label"
+  device: "/gpu:0"
+}
+node {
+  name: "classifier/AveragedLoss"
+  op: "AveragedLoss"
+  input: "classifier/xent"
+  device: "/gpu:0"
+}
+node {
+  name: "GRADIENTS/classifier/ConstantFill"
+  op: "ConstantFill"
+  input: "classifier/loss"
+  device: "/gpu:0"
+  attr {
+    key: "value"
+    value {
+      f: 1.0
+    }
+  }
+}
+node {
+  name: "GRADIENTS/classifier/AveragedLossGradient"
+  op: "AveragedLossGradient"
+  input: "classifier/xent"
+  input: "GRADIENTS/classifier/loss_autogen_grad"
+  device: "/gpu:0"
+}
+node {
+  name: "GRADIENTS/classifier/LabelCrossEntropyGradient"
+  op: "LabelCrossEntropyGradient"
+  input: "classifier/pred"
+  input: "label"
+  input: "GRADIENTS/classifier/xent_grad"
+  device: "/gpu:0"
+}
+node {
+  name: "GRADIENTS/classifier/SoftmaxGradient"
+  op: "SoftmaxGradient"
+  input: "classifier/pred"
+  input: "GRADIENTS/classifier/pred_grad"
+  device: "/gpu:0"
+  attr {
+    key: "cudnn_exhaustive_search"
+    value {
+      i: 0
+    }
+  }
+  attr {
+    key: "order"
+    value {
+      s: "NCHW"
+    }
+  }
+}
+node {
+  name: "GRADIENTS/c/FCGradient"
+  op: "FCGradient"
+  input: "conv1/pool1"
+  input: "classifier/fc_w"
+  input: "GRADIENTS/classifier/fc_grad"
+  device: "/gpu:0"
+  attr {
+    key: "cudnn_exhaustive_search"
+    value {
+      i: 0
+    }
+  }
+  attr {
+    key: "order"
+    value {
+      s: "NCHW"
+    }
+  }
+  attr {
+    key: "use_cudnn"
+    value {
+      i: 1
+    }
+  }
+}
+node {
+  name: "GRADIENTS/conv1/MaxPoolGradient"
+  op: "MaxPoolGradient"
+  input: "conv1/conv1_1"
+  input: "conv1/pool1"
+  input: "GRADIENTS/conv1/pool1_grad"
+  device: "/gpu:0"
+  attr {
+    key: "cudnn_exhaustive_search"
+    value {
+      i: 0
+    }
+  }
+  attr {
+    key: "kernel"
+    value {
+      i: 2
+    }
+  }
+  attr {
+    key: "order"
+    value {
+      s: "NCHW"
+    }
+  }
+  attr {
+    key: "stride"
+    value {
+      i: 2
+    }
+  }
+}
+node {
+  name: "GRADIENTS/conv1/ReluGradient"
+  op: "ReluGradient"
+  input: "conv1/conv1_1"
+  input: "GRADIENTS/conv1/conv1_grad"
+  device: "/gpu:0"
+  attr {
+    key: "cudnn_exhaustive_search"
+    value {
+      i: 0
+    }
+  }
+  attr {
+    key: "order"
+    value {
+      s: "NCHW"
+    }
+  }
+}
+node {
+  name: "GRADIENTS/ConvGradient"
+  op: "ConvGradient"
+  input: "data"
+  input: "conv1/conv1_w"
+  input: "GRADIENTS/conv1/conv1_grad_1"
+  device: "/gpu:0"
+  attr {
+    key: "exhaustive_search"
+    value {
+      i: 0
+    }
+  }
+  attr {
+    key: "kernel"
+    value {
+      i: 11
+    }
+  }
+  attr {
+    key: "order"
+    value {
+      s: "NCHW"
+    }
+  }
+  attr {
+    key: "stride"
+    value {
+      i: 4
+    }
+  }
+}
+node {
+  name: "GRADIENTS/NCHW2NHWC"
+  op: "NCHW2NHWC"
+  input: "GRADIENTS/data_grad"
+  device: "/gpu:0"
+}
+node {
+  name: "conv1/conv1_w"
+  op: "Blob"
+  input: "conv1/XavierFill:0"
+  device: "/gpu:0"
+}
+node {
+  name: "classifier/fc"
+  op: "Blob"
+  input: "classifier/FC:0"
+  device: "/gpu:0"
+}
+node {
+  name: "data_nhwc"
+  op: "Blob"
+  input: "ImageInput:0"
+  device: "/gpu:0"
+}
+node {
+  name: "GRADIENTS/conv1/conv1_b_grad"
+  op: "Blob"
+  input: "GRADIENTS/ConvGradient:1"
+  device: "/gpu:0"
+}
+node {
+  name: "GRADIENTS/classifier/pred_grad"
+  op: "Blob"
+  input: "GRADIENTS/classifier/LabelCrossEntropyGradient:0"
+  device: "/gpu:0"
+}
+node {
+  name: "GRADIENTS/classifier/fc_grad"
+  op: "Blob"
+  input: "GRADIENTS/classifier/SoftmaxGradient:0"
+  device: "/gpu:0"
+}
+node {
+  name: "conv1/conv1_b"
+  op: "Blob"
+  input: "conv1/ConstantFill:0"
+  device: "/gpu:0"
+}
+node {
+  name: "GRADIENTS/classifier/fc_b_grad"
+  op: "Blob"
+  input: "GRADIENTS/c/FCGradient:1"
+  device: "/gpu:0"
+}
+node {
+  name: "GRADIENTS/classifier/fc_w_grad"
+  op: "Blob"
+  input: "GRADIENTS/c/FCGradient:0"
+  device: "/gpu:0"
+}
+node {
+  name: "label"
+  op: "Blob"
+  input: "ImageInput:1"
+  device: "/gpu:0"
+}
+node {
+  name: "GRADIENTS/data_grad"
+  op: "Blob"
+  input: "GRADIENTS/ConvGradient:2"
+  device: "/gpu:0"
+}
+node {
+  name: "classifier/loss"
+  op: "Blob"
+  input: "classifier/AveragedLoss:0"
+  device: "/gpu:0"
+}
+node {
+  name: "conv1/conv1"
+  op: "Blob"
+  input: "conv1/Conv:0"
+  device: "/gpu:0"
+}
+node {
+  name: "GRADIENTS/conv1/conv1_grad"
+  op: "Blob"
+  input: "GRADIENTS/conv1/MaxPoolGradient:0"
+  device: "/gpu:0"
+}
+node {
+  name: "classifier/xent"
+  op: "Blob"
+  input: "classifier/LabelCrossEntropy:0"
+  device: "/gpu:0"
+}
+node {
+  name: "GRADIENTS/classifier/loss_autogen_grad"
+  op: "Blob"
+  input: "GRADIENTS/classifier/ConstantFill:0"
+  device: "/gpu:0"
+}
+node {
+  name: "classifier/fc_w"
+  op: "Blob"
+  input: "classifier/XavierFill:0"
+  device: "/gpu:0"
+}
+node {
+  name: "conv1/conv1_1"
+  op: "Blob"
+  input: "conv1/Relu:0"
+  device: "/gpu:0"
+}
+node {
+  name: "db"
+  op: "Placeholder"
+}
+node {
+  name: "classifier/pred"
+  op: "Blob"
+  input: "classifier/Softmax:0"
+  device: "/gpu:0"
+}
+node {
+  name: "classifier/fc_b"
+  op: "Blob"
+  input: "classifier/ConstantFill:0"
+  device: "/gpu:0"
+}
+node {
+  name: "GRADIENTS/classifier/xent_grad"
+  op: "Blob"
+  input: "GRADIENTS/classifier/AveragedLossGradient:0"
+  device: "/gpu:0"
+}
+node {
+  name: "data"
+  op: "Blob"
+  input: "NHWC2NCHW:0"
+  device: "/gpu:0"
+}
+node {
+  name: "GRADIENTS/conv1/conv1_w_grad"
+  op: "Blob"
+  input: "GRADIENTS/ConvGradient:0"
+  device: "/gpu:0"
+}
+node {
+  name: "GRADIENTS/conv1/conv1_grad_1"
+  op: "Blob"
+  input: "GRADIENTS/conv1/ReluGradient:0"
+  device: "/gpu:0"
+}
+node {
+  name: "GRADIENTS/data_nhwc_grad"
+  op: "Blob"
+  input: "GRADIENTS/NCHW2NHWC:0"
+  device: "/gpu:0"
+}
+node {
+  name: "GRADIENTS/conv1/pool1_grad"
+  op: "Blob"
+  input: "GRADIENTS/c/FCGradient:2"
+  device: "/gpu:0"
+}
+node {
+  name: "conv1/pool1"
+  op: "Blob"
+  input: "conv1/MaxPool:0"
+  device: "/gpu:0"
+}
+"""
+
+
+class TensorboardExporterTest(unittest.TestCase):
+    def test_that_operators_gets_non_colliding_names(self):
+        op = caffe2_pb2.OperatorDef()
+        op.type = 'foo'
+        op.input.extend(['foo'])
+        tb._fill_missing_operator_names([op])
+        self.assertEqual(op.input[0], 'foo')
+        self.assertEqual(op.name, 'foo_1')
+
+    def test_that_replacing_colons_gives_non_colliding_names(self):
+        # .. and update shapes
+        op = caffe2_pb2.OperatorDef()
+        op.name = 'foo:0'
+        op.input.extend(['foo:0', 'foo$0'])
+        shapes = {'foo:0': [1]}
+        track_blob_names = tb._get_blob_names([op])
+        tb._replace_colons(shapes, track_blob_names, [op], '$')
+        self.assertEqual(op.input[0], 'foo$0')
+        self.assertEqual(op.input[1], 'foo$0_1')
+        # Collision but blobs and op names are handled later by
+        # _fill_missing_operator_names.
+        self.assertEqual(op.name, 'foo$0')
+        self.assertEqual(len(shapes), 1)
+        self.assertEqual(shapes['foo$0'], [1])
+        self.assertEqual(len(track_blob_names), 2)
+        self.assertEqual(track_blob_names['foo$0'], 'foo:0')
+        self.assertEqual(track_blob_names['foo$0_1'], 'foo$0')
+
+    def test_that_adding_gradient_scope_does_no_fancy_renaming(self):
+        # because it cannot create collisions
+        op = caffe2_pb2.OperatorDef()
+        op.name = 'foo_grad'
+        op.input.extend(['foo_grad', 'foo_grad_1'])
+        shapes = {'foo_grad': [1]}
+        track_blob_names = tb._get_blob_names([op])
+        tb._add_gradient_scope(shapes, track_blob_names, [op])
+        self.assertEqual(op.input[0], 'GRADIENTS/foo_grad')
+        self.assertEqual(op.input[1], 'GRADIENTS/foo_grad_1')
+        self.assertEqual(op.name, 'GRADIENTS/foo_grad')
+        self.assertEqual(len(shapes), 1)
+        self.assertEqual(shapes['GRADIENTS/foo_grad'], [1])
+        self.assertEqual(len(track_blob_names), 2)
+        self.assertEqual(
+            track_blob_names['GRADIENTS/foo_grad'], 'foo_grad')
+        self.assertEqual(
+            track_blob_names['GRADIENTS/foo_grad_1'], 'foo_grad_1')
+
+    def test_that_auto_ssa_gives_non_colliding_names(self):
+        op1 = caffe2_pb2.OperatorDef()
+        op1.output.extend(['foo'])
+        op2 = caffe2_pb2.OperatorDef()
+        op2.input.extend(['foo'])
+        op2.output.extend(['foo'])
+        op2.output.extend(['foo_1'])
+        shapes = {'foo': [1], 'foo_1': [2]}
+        track_blob_names = tb._get_blob_names([op1, op2])
+        tb._convert_to_ssa(shapes, track_blob_names, [op1, op2])
+        self.assertEqual(op1.output[0], 'foo')
+        self.assertEqual(op2.input[0], 'foo')
+        self.assertEqual(op2.output[0], 'foo_1')
+        # Unfortunate name but we do not parse original `_` for now.
+        self.assertEqual(op2.output[1], 'foo_1_1')
+        self.assertEqual(len(shapes), 3)
+        self.assertEqual(shapes['foo'], [1])
+        self.assertEqual(shapes['foo_1'], [1])
+        self.assertEqual(shapes['foo_1_1'], [2])
+        self.assertEqual(len(track_blob_names), 3)
+        self.assertEqual(track_blob_names['foo'], 'foo')
+        self.assertEqual(track_blob_names['foo_1'], 'foo')
+        self.assertEqual(track_blob_names['foo_1_1'], 'foo_1')
+
+    def test_simple_cnnmodel(self):
+        model = cnn.CNNModelHelper("NCHW", name="overfeat")
+        data, label = model.ImageInput(["db"], ["data", "label"], is_test=0)
+        with core.NameScope("conv1"):
+            conv1 = model.Conv(data, "conv1", 3, 96, 11, stride=4)
+            relu1 = model.Relu(conv1, conv1)
+            pool1 = model.MaxPool(relu1, "pool1", kernel=2, stride=2)
+        with core.NameScope("classifier"):
+            fc = model.FC(pool1, "fc", 4096, 1000)
+            pred = model.Softmax(fc, "pred")
+            xent = model.LabelCrossEntropy([pred, label], "xent")
+            loss = model.AveragedLoss(xent, "loss")
+        model.net.RunAllOnGPU()
+        model.param_init_net.RunAllOnGPU()
+        model.AddGradientOperators([loss], skip=1)
+        track_blob_names = {}
+        graph = tb.cnn_to_graph_def(
+            model,
+            track_blob_names=track_blob_names,
+            shapes={},
+        )
+        self.assertEqual(
+            track_blob_names['GRADIENTS/conv1/conv1_b_grad'],
+            'conv1/conv1_b_grad',
+        )
+        self.maxDiff = None
+        # We can't guarantee the order in which they appear, so we sort
+        # both before we compare them
+        sep = "node {"
+        expected = "\n".join(sorted(
+            sep + "\n  " + part.strip()
+            for part in EXPECTED.strip().split(sep)
+            if part.strip()
+        ))
+        actual = "\n".join(sorted(
+            sep + "\n  " + part.strip()
+            for part in str(graph).strip().split(sep)
+            if part.strip()
+        ))
+        self.assertMultiLineEqual(actual, expected)
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/tensorboard/tensorboard_test.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/tensorboard/tensorboard_test.py
new file mode 100644
index 0000000..8751be1
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/tensorboard/tensorboard_test.py
@@ -0,0 +1,118 @@
+
+
+
+
+
+import click.testing
+import numpy as np
+import os
+import tempfile
+import unittest
+
+from caffe2.python import brew, core, model_helper
+import caffe2.contrib.tensorboard.tensorboard as tb
+import caffe2.contrib.tensorboard.tensorboard_exporter as tb_exporter
+
+try:
+    # tensorboard>=1.14.0
+    from tensorboard.compat.proto.graph_pb2 import GraphDef
+except ImportError:
+    from tensorflow import GraphDef
+
+
+def load_events(filename):
+    try:
+        # tensorboard>=1.14.0
+        from tensorboard.backend.event_processing import event_file_loader
+        loader = event_file_loader.EventFileLoader(filename)
+        return list(loader.Load())
+    except ImportError:
+        import tensorflow as tf
+        return list(tf.train.summary_iterator(filename))
+
+
+class TensorboardTest(unittest.TestCase):
+
+    def test_events(self):
+        runner = click.testing.CliRunner()
+        c2_dir = tempfile.mkdtemp()
+        np.random.seed(1701)
+        n_iters = 2
+        blobs = ["w", "b"]
+        data = np.random.randn(len(blobs), n_iters, 10)
+        for i, blob in enumerate(blobs):
+            with open(os.path.join(c2_dir, blob), "w") as f:
+                for row in data[i]:
+                    stats = [row.min(), row.max(), row.mean(), row.std()]
+                    f.write(" ".join(str(s) for s in stats) + "\n")
+
+        # Test error handling path
+        with open(os.path.join(c2_dir, "not-a-summary"), "w") as f:
+            f.write("not-a-summary")
+
+        tf_dir = tempfile.mkdtemp()
+        result = runner.invoke(
+            tb.cli,
+            ["tensorboard-events", "--c2-dir", c2_dir, "--tf-dir", tf_dir])
+        self.assertEqual(result.exit_code, 0)
+        entries = list(os.walk(tf_dir))
+        self.assertEqual(len(entries), 1)
+        ((d, _, (fname,)),) = entries
+        self.assertEqual(tf_dir, d)
+        events = load_events(os.path.join(tf_dir, fname))
+        self.assertEqual(len(events), n_iters + 1)
+        events = events[1:]
+        self.maxDiff = None
+        self.assertEqual(len(events), 2)
+
+    def test_tensorboard_graphs(self):
+        model = model_helper.ModelHelper(name="overfeat")
+        data, label = brew.image_input(
+            model, ["db"], ["data", "label"], is_test=0
+        )
+        with core.NameScope("conv1"):
+            conv1 = brew.conv(model, data, "conv1", 3, 96, 11, stride=4)
+            relu1 = brew.relu(model, conv1, conv1)
+            pool1 = brew.max_pool(model, relu1, "pool1", kernel=2, stride=2)
+        with core.NameScope("classifier"):
+            fc = brew.fc(model, pool1, "fc", 4096, 1000)
+            pred = brew.softmax(model, fc, "pred")
+            xent = model.LabelCrossEntropy([pred, label], "xent")
+            loss = model.AveragedLoss(xent, "loss")
+        model.AddGradientOperators([loss], skip=1)
+
+        c2_dir = tempfile.mkdtemp()
+        tf_dir = tempfile.mkdtemp()
+
+        with open(os.path.join(c2_dir, "init"), "w") as f:
+            f.write(str(model.param_init_net.Proto()))
+        with open(os.path.join(c2_dir, "net"), "w") as f:
+            f.write(str(model.net.Proto()))
+        runner = click.testing.CliRunner()
+        result = runner.invoke(
+            tb.cli,
+            ["tensorboard-graphs",
+             "--c2-netdef", os.path.join(c2_dir, "init"),
+             "--c2-netdef", os.path.join(c2_dir, "net"),
+             "--tf-dir", tf_dir])
+        self.assertEqual(result.exit_code, 0)
+        entries = list(os.walk(tf_dir))
+        self.assertEqual(len(entries), 1)
+        ((d, _, (fname,)),) = entries
+        self.assertEqual(tf_dir, d)
+        events = load_events(os.path.join(tf_dir, fname))
+        self.assertEqual(len(events), 3)
+        events = events[1:]
+        nets = [model.param_init_net, model.net]
+        for i, (event, net) in enumerate(zip(events, nets), start=1):
+            self.assertEqual(event.step, i)
+            self.assertEqual(event.wall_time, i)
+            g = GraphDef()
+            g.ParseFromString(event.graph_def)
+            self.assertMultiLineEqual(
+                str(g),
+                str(tb_exporter.nets_to_graph_def([net])))
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/warpctc/__init__.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/warpctc/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/.venv/lib/python3.7/site-packages/caffe2/contrib/warpctc/ctc_ops_test.py b/.venv/lib/python3.7/site-packages/caffe2/contrib/warpctc/ctc_ops_test.py
new file mode 100644
index 0000000..013e80a
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/contrib/warpctc/ctc_ops_test.py
@@ -0,0 +1,108 @@
+
+
+
+
+import numpy as np
+from caffe2.proto import caffe2_pb2
+
+from caffe2.python import core, workspace, dyndep, test_util
+
+dyndep.InitOpsLibrary('@/caffe2/caffe2/contrib/warpctc:ctc_ops')
+workspace.GlobalInit(["python"])
+
+
+def softmax(w):
+    maxes = np.amax(w, axis=-1, keepdims=True)
+    e = np.exp(w - maxes)
+    dist = e / np.sum(e, axis=-1, keepdims=True)
+    return dist
+
+
+class CTCOpsTest(test_util.TestCase):
+    def verify_cost(self, device_option, is_test, skip_input_lengths=False):
+        alphabet_size = 5
+        N = 1
+        T = 2
+
+        inputs = np.asarray(
+            [
+                [[0.1, 0.6, 0.1, 0.1, 0.1]],
+                [[0.1, 0.1, 0.6, 0.1, 0.1]],
+            ]
+        ).reshape(T, N, alphabet_size).astype(np.float32)
+
+        labels = np.asarray([1, 2]).astype(np.int32).reshape(T)
+        label_lengths = np.asarray([2]).astype(np.int32).reshape(N)
+        input_lengths = np.asarray([T]).astype(np.int32)
+
+        net = core.Net("test-net")
+        input_blobs = ["inputs", "labels", "label_lengths"]
+        if not skip_input_lengths:
+            input_blobs.append("input_lengths")
+        output_blobs = ["costs", "workspace"] if is_test \
+                else ["inputs_grad_to_be_copied", "costs", "workspace"]
+        net.CTC(input_blobs,
+                output_blobs,
+                is_test=is_test,
+                device_option=device_option)
+        if not is_test:
+            net.AddGradientOperators(["costs"])
+        self.ws.create_blob("inputs").feed(inputs, device_option=device_option)
+        self.ws.create_blob("labels").feed(labels)
+        self.ws.create_blob("label_lengths").feed(label_lengths)
+        if not skip_input_lengths:
+            self.ws.create_blob("input_lengths").feed(input_lengths)
+        self.ws.run(net)
+        probs = softmax(inputs)
+        expected = probs[0, 0, 1] * probs[1, 0, 2]
+        self.assertEqual(self.ws.blobs["costs"].fetch().shape, (N,))
+        self.assertEqual(self.ws.blobs["costs"].fetch().dtype, np.float32)
+        cost = self.ws.blobs["costs"].fetch()[0]
+        print(cost)
+        self.assertAlmostEqual(np.exp(-cost), expected)
+        if not is_test:
+            # Make sure inputs_grad was added by AddGradientOperators and
+            # it is equal to the inputs_grad_to_be_copied blob returned by CTCop
+            assert np.array_equal(
+                self.ws.blobs["inputs_grad"].fetch(),
+                self.ws.blobs["inputs_grad_to_be_copied"].fetch()
+            )
+
+    def test_ctc_cost_cpu(self):
+        self.verify_cost(
+            caffe2_pb2.DeviceOption(device_type=caffe2_pb2.CPU),
+            is_test=False)
+        self.verify_cost(
+            caffe2_pb2.DeviceOption(device_type=caffe2_pb2.CPU),
+            is_test=False, skip_input_lengths=True)
+
+    def test_ctc_cost_gpu(self):
+        self.verify_cost(
+            caffe2_pb2.DeviceOption(device_type=caffe2_pb2.CUDA,
+                                    device_id=0),
+            is_test=False)
+        self.verify_cost(
+            caffe2_pb2.DeviceOption(device_type=caffe2_pb2.CUDA,
+                                    device_id=0),
+            is_test=False,
+            skip_input_lengths=True)
+
+    def test_ctc_forward_only_cpu(self):
+        self.verify_cost(
+            caffe2_pb2.DeviceOption(device_type=caffe2_pb2.CPU),
+            is_test=True)
+        self.verify_cost(
+            caffe2_pb2.DeviceOption(device_type=caffe2_pb2.CPU),
+            is_test=True,
+            skip_input_lengths=True)
+
+    def test_ctc_forward_only_gpu(self):
+        self.verify_cost(
+            caffe2_pb2.DeviceOption(device_type=caffe2_pb2.CUDA,
+                                    device_id=0),
+            is_test=True)
+        self.verify_cost(
+            caffe2_pb2.DeviceOption(device_type=caffe2_pb2.CUDA,
+                                    device_id=0),
+            is_test=True,
+            skip_input_lengths=True)
diff --git a/.venv/lib/python3.7/site-packages/caffe2/core/__init__.py b/.venv/lib/python3.7/site-packages/caffe2/core/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/.venv/lib/python3.7/site-packages/caffe2/core/nomnigraph/__init__.py b/.venv/lib/python3.7/site-packages/caffe2/core/nomnigraph/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/.venv/lib/python3.7/site-packages/caffe2/core/nomnigraph/op_gen.py b/.venv/lib/python3.7/site-packages/caffe2/core/nomnigraph/op_gen.py
new file mode 100644
index 0000000..060bb9b
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/core/nomnigraph/op_gen.py
@@ -0,0 +1,245 @@
+#!/usr/bin/env python3
+
+
+
+
+
+
+import argparse
+from textwrap import dedent
+from subprocess import call
+
+
+def parse_lines(lines):
+    # States
+    EMPTY = 0
+    OP = 1
+    MACRO = 2
+    parse_state = EMPTY
+
+    # Preprocess the macros
+    curr_macro = ""
+    macros = {}
+
+    index = 0
+    while index < len(lines):
+        line = lines[index]
+        if line.lower().startswith("macro"):
+            assert parse_state == EMPTY
+            macro_line = line.split(" ")
+            # Support macros that look like attributes
+            # e.g. macro - CONV_LIKE
+            curr_macro = " ".join(macro_line[1:])
+            assert curr_macro not in macros, 'Macro "{}" defined twice.'.format(
+                curr_macro
+            )
+            macros[curr_macro] = []
+            parse_state = MACRO
+            lines = lines[:index] + lines[index + 1 :]
+            continue
+        elif line.lower().startswith("endmacro"):
+            assert parse_state == MACRO
+            parse_state = EMPTY
+            lines = lines[:index] + lines[index + 1 :]
+            continue
+        elif parse_state == MACRO:
+            macros[curr_macro].append(line)
+            lines = lines[:index] + lines[index + 1 :]
+            continue
+        index += 1
+
+    index = 0
+    while index < len(lines):
+        line = lines[index]
+        if line in macros:
+            lines = lines[:index] + macros[line] + lines[index + 1 :]
+            index += len(macros[line]) - 1
+        index += 1
+
+    # Now parse the file
+    curr_op = ""
+    # dict of the form
+    #  opName : { attributes: [], ... }
+    ops = {}
+    # To preserve parsing order for dependencies (for things like init_from)
+    op_list = []
+
+    for line in lines:
+        if not len(line):
+            continue
+        if line[0] == "-":
+            assert parse_state is OP
+            attr = [_.strip() for _ in line[1:].split(":")]
+            assert attr[0][0].isupper()
+            if len(attr) == 2:  # attribute : type
+                ops[curr_op]["attributes"].append((attr[0], attr[1]))
+            elif len(attr) == 3:  # attribute : type
+                ops[curr_op]["attributes"].append((attr[0], attr[1], attr[2]))
+        else:
+            op = [l.strip() for l in line.split(":")]
+            assert len(op[0].split(" ")) == 1
+            parse_state = OP
+            curr_op = op[0]
+            assert curr_op not in ops
+            ops[curr_op] = {}
+            op_list.append(curr_op)
+            if len(op) > 1:
+                ops[curr_op]["init_from"] = [op[1]]
+            ops[curr_op]["attributes"] = []
+    return ops, op_list
+
+
+def gen_class(op, op_def):
+    attributes = op_def["attributes"]
+    attribute_args = []
+    default_init = "NeuralNetOperator(NNKind::{op})".format(op=op)
+    attribute_init = [default_init]
+    attribute_declarations = []
+    attribute_getters = []
+    attribute_setters = []
+    for attr in attributes:
+        lower_name = attr[0][0].lower() + attr[0][1:]
+        private_name = lower_name + "_"
+        default_arg = "" if len(attr) < 3 else " = {}".format(attr[2])
+        name = attr[0]
+        t = attr[1]
+        attr_arg = "{type} {lower_name}".format(
+            type=t, lower_name=lower_name + default_arg
+        )
+        attr_init = "{private_name}({lower_name})".format(
+            private_name=private_name, lower_name=lower_name)
+        attr_declare = "{type} {private_name};".format(
+            type=t, private_name=private_name)
+        attr_get = dedent(
+            """
+              {type} get{name}() const {{
+                return {private_name};
+              }}
+            """.format(
+                type=t, name=name, private_name=private_name
+            )
+        )
+        attr_set = dedent(
+            """
+              void set{name}({type} {lower_name}) {{
+                {private_name} = {lower_name};
+              }}
+            """.format(
+                type=t, name=name, private_name=private_name, lower_name=lower_name
+            )
+        )
+        attribute_args.append(attr_arg)
+        attribute_init.append(attr_init)
+        attribute_declarations.append(attr_declare)
+        attribute_getters.append(attr_get)
+        attribute_setters.append(attr_set)
+
+    extra_init = ""
+    if "init_from" in op_def:
+        for other_op in op_def["init_from"]:
+            lower_other_op = other_op[0].lower() + other_op[1:]
+            other_init = [default_init]
+            for attr in attributes:
+                lower_name = attr[0][0].lower() + attr[0][1:]
+                private_name = lower_name + "_"
+                other_init.append(
+                    "{private_name}({other_op}.get{name}())".format(
+                        name=attr[0], private_name=private_name, other_op=lower_other_op
+                    )
+                )
+            init = dedent(
+                """
+                  {op}(const {other_op}& {lower_other_op}) :
+                      {other_init} {{}}
+                """.format(
+                    op=op,
+                    other_op=other_op,
+                    lower_other_op=lower_other_op,
+                    other_init=",\n      ".join(other_init),
+                )
+            )
+            extra_init += init
+
+    return dedent(
+        """
+        class {op} : public NeuralNetOperator {{
+         public:
+          {op}({attribute_args}) :
+              {attribute_init} {{}}
+          {extra_init}
+          ~{op}() {{}}
+
+          NOMNIGRAPH_DEFINE_NN_RTTI({op});
+        {getters}{setters}
+         private:
+          {attribute_declarations}
+        }};
+
+        """.format(
+            op=op,
+            extra_init=extra_init,
+            getters="".join(attribute_getters),
+            setters="".join(attribute_setters),
+            attribute_args=",\n".join(attribute_args),
+            attribute_init=",\n".join(attribute_init),
+            attribute_declarations="\n".join(attribute_declarations),
+        )
+    )
+
+
+def gen_classes(ops, op_list):
+    f = ""
+    for op in op_list:
+        f += gen_class(op, ops[op])
+    return f
+
+
+def gen_enum(op_list):
+    return ",\n".join([op for op in op_list]) + "\n"
+
+
+def gen_names(op_list):
+    f = ""
+    for op in op_list:
+        f += dedent(
+            """
+            case NNKind::{name}:
+                return \"{name}\";
+            """.format(
+                name=op
+            )
+        )
+    return f
+
+
+if __name__ == "__main__":
+    parser = argparse.ArgumentParser(description="Generate op files.")
+    parser.add_argument("--install_dir", help="installation directory")
+    parser.add_argument("--source_def", help="ops.def", action="append")
+    args = parser.parse_args()
+    install_dir = args.install_dir
+    sources = args.source_def
+
+    lines = []
+    for source in sources:
+        with open(source, "rb") as f:
+            lines_tmp = f.readlines()
+            lines += [l.strip().decode("utf-8") for l in lines_tmp]
+    ops, op_list = parse_lines(lines)
+
+    with open(install_dir + "/OpClasses.h", "wb") as f:
+        f.write(gen_classes(ops, op_list).encode("utf-8"))
+    with open(install_dir + "/OpNames.h", "wb") as f:
+        f.write(gen_names(op_list).encode("utf-8"))
+    with open(install_dir + "/OpEnum.h", "wb") as f:
+        f.write(gen_enum(op_list).encode("utf-8"))
+
+    try:
+        cmd = ["clang-format", "-i", install_dir + "/OpClasses.h"]
+        call(cmd)
+        cmd = ["clang-format", "-i", install_dir + "/OpNames.h"]
+        call(cmd)
+        cmd = ["clang-format", "-i", install_dir + "/OpEnum.h"]
+        call(cmd)
+    except Exception:
+        pass
diff --git a/.venv/lib/python3.7/site-packages/caffe2/distributed/__init__.py b/.venv/lib/python3.7/site-packages/caffe2/distributed/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/.venv/lib/python3.7/site-packages/caffe2/distributed/file_store_handler_op_test.py b/.venv/lib/python3.7/site-packages/caffe2/distributed/file_store_handler_op_test.py
new file mode 100644
index 0000000..72f8e45
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/distributed/file_store_handler_op_test.py
@@ -0,0 +1,62 @@
+
+
+
+
+
+import errno
+import os
+import tempfile
+import shutil
+
+from caffe2.distributed.python import StoreHandlerTimeoutError
+from caffe2.distributed.store_ops_test_util import StoreOpsTests
+from caffe2.python import core, workspace, dyndep
+from caffe2.python.test_util import TestCase
+
+dyndep.InitOpsLibrary("@/caffe2/caffe2/distributed:file_store_handler_ops")
+dyndep.InitOpsLibrary("@/caffe2/caffe2/distributed:store_ops")
+
+
+class TestFileStoreHandlerOp(TestCase):
+    testCounter = 0
+
+    def setUp(self):
+        super(TestFileStoreHandlerOp, self).setUp()
+        self.tmpdir = tempfile.mkdtemp()
+
+        # Use counter to tell test cases apart
+        TestFileStoreHandlerOp.testCounter += 1
+
+    def tearDown(self):
+        shutil.rmtree(self.tmpdir)
+        super(TestFileStoreHandlerOp, self).tearDown()
+
+    def create_store_handler(self):
+        # Use new path for every test so they are isolated
+        path = self.tmpdir + "/" + str(TestFileStoreHandlerOp.testCounter)
+
+        # Ensure path exists (including counter)
+        try:
+            os.makedirs(path)
+        except OSError as exc:
+            if exc.errno == errno.EEXIST and os.path.isdir(path):
+                pass
+            else:
+                raise
+
+        store_handler = "store_handler"
+        workspace.RunOperatorOnce(
+            core.CreateOperator(
+                "FileStoreHandlerCreate",
+                [],
+                [store_handler],
+                path=path))
+
+        return store_handler
+
+    def test_set_get(self):
+        StoreOpsTests.test_set_get(self.create_store_handler)
+
+    def test_get_timeout(self):
+        with self.assertRaises(StoreHandlerTimeoutError):
+            StoreOpsTests.test_get_timeout(self.create_store_handler)
diff --git a/.venv/lib/python3.7/site-packages/caffe2/distributed/redis_store_handler_op_test.py b/.venv/lib/python3.7/site-packages/caffe2/distributed/redis_store_handler_op_test.py
new file mode 100644
index 0000000..2eb6c9a
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/distributed/redis_store_handler_op_test.py
@@ -0,0 +1,43 @@
+
+
+
+
+
+import os
+import uuid
+
+from caffe2.distributed.python import StoreHandlerTimeoutError
+from caffe2.distributed.store_ops_test_util import StoreOpsTests
+from caffe2.python import core, workspace, dyndep
+from caffe2.python.test_util import TestCase
+
+dyndep.InitOpsLibrary("@/caffe2/caffe2/distributed:redis_store_handler_ops")
+dyndep.InitOpsLibrary("@/caffe2/caffe2/distributed:store_ops")
+
+
+class TestRedisStoreHandlerOp(TestCase):
+    def setUp(self):
+        super(TestRedisStoreHandlerOp, self).setUp()
+        self.uuid = str(uuid.uuid4()) + "/"
+
+    def tearDown(self):
+        super(TestRedisStoreHandlerOp, self).tearDown()
+
+    def create_store_handler(self):
+        store_handler = "store_handler"
+        workspace.RunOperatorOnce(
+            core.CreateOperator(
+                "RedisStoreHandlerCreate",
+                [],
+                [store_handler],
+                prefix=self.uuid,
+                host=os.getenv("REDIS_HOST", "localhost"),
+                port=int(os.getenv("REDIS_PORT", 6379))))
+        return store_handler
+
+    def test_set_get(self):
+        StoreOpsTests.test_set_get(self.create_store_handler)
+
+    def test_get_timeout(self):
+        with self.assertRaises(StoreHandlerTimeoutError):
+            StoreOpsTests.test_get_timeout(self.create_store_handler)
diff --git a/.venv/lib/python3.7/site-packages/caffe2/distributed/store_ops_test_util.py b/.venv/lib/python3.7/site-packages/caffe2/distributed/store_ops_test_util.py
new file mode 100644
index 0000000..05245be
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/distributed/store_ops_test_util.py
@@ -0,0 +1,76 @@
+## @package store_ops_test_util
+# Module caffe2.distributed.store_ops_test_util
+
+
+
+
+
+from multiprocessing import Process, Queue
+
+import numpy as np
+
+from caffe2.python import core, workspace
+
+
+class StoreOpsTests(object):
+    @classmethod
+    def _test_set_get(cls, queue, create_store_handler_fn, index, num_procs):
+        store_handler = create_store_handler_fn()
+        blob = "blob"
+        value = np.full(1, 1, np.float32)
+
+        # Use last process to set blob to make sure other processes
+        # are waiting for the blob before it is set.
+        if index == (num_procs - 1):
+            workspace.FeedBlob(blob, value)
+            workspace.RunOperatorOnce(
+                core.CreateOperator(
+                    "StoreSet",
+                    [store_handler, blob],
+                    [],
+                    blob_name=blob))
+
+        output_blob = "output_blob"
+        workspace.RunOperatorOnce(
+            core.CreateOperator(
+                "StoreGet",
+                [store_handler],
+                [output_blob],
+                blob_name=blob))
+
+        try:
+            np.testing.assert_array_equal(workspace.FetchBlob(output_blob), 1)
+        except AssertionError as err:
+            queue.put(err)
+
+        workspace.ResetWorkspace()
+
+    @classmethod
+    def test_set_get(cls, create_store_handler_fn):
+        # Queue for assertion errors on subprocesses
+        queue = Queue()
+
+        # Start N processes in the background
+        num_procs = 4
+        procs = []
+        for index in range(num_procs):
+            proc = Process(
+                target=cls._test_set_get,
+                args=(queue, create_store_handler_fn, index, num_procs, ))
+            proc.start()
+            procs.append(proc)
+
+        # Test complete, join background processes
+        for proc in procs:
+            proc.join()
+
+        # Raise first error we find, if any
+        if not queue.empty():
+            raise queue.get()
+
+    @classmethod
+    def test_get_timeout(cls, create_store_handler_fn):
+        store_handler = create_store_handler_fn()
+        net = core.Net('get_missing_blob')
+        net.StoreGet([store_handler], 1, blob_name='blob')
+        workspace.RunNetOnce(net)
diff --git a/.venv/lib/python3.7/site-packages/caffe2/experiments/__init__.py b/.venv/lib/python3.7/site-packages/caffe2/experiments/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/.venv/lib/python3.7/site-packages/caffe2/experiments/python/SparseTransformer.py b/.venv/lib/python3.7/site-packages/caffe2/experiments/python/SparseTransformer.py
new file mode 100644
index 0000000..d97f076
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/experiments/python/SparseTransformer.py
@@ -0,0 +1,206 @@
+# Copyright (c) 2016-present, Facebook, Inc.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+##############################################################################
+
+## @package SparseTransformer
+# Module caffe2.experiments.python.SparseTransformer
+
+
+
+
+from caffe2.python import workspace
+import scipy.sparse
+
+
+class NetDefNode():
+
+    def __init__(self, name, optype, p=None, op=None):
+        self.name = name
+        self.optype = optype
+        self.ops = {}
+        self.prev = {}
+        self.insertInput(p)
+        self.visited = False
+        self.op = op
+
+    def insertInput(self, p):
+        """
+        Insert input of this op
+        also maintain the output of previous op
+        p: a node or a list of node
+        """
+        if isinstance(p, list):
+            for i in p:
+                self.prev[i.name] = i
+                i.ops[self.name] = self
+        elif isinstance(p, NetDefNode):
+            self.prev[p.name] = p
+            p.ops[self.name] = self
+
+    def deleteInput(self, p):
+        if isinstance(p, NetDefNode):
+            del self.prev[p.name]
+            del p.ops[self.name]
+
+
+def maskNallocate(weight_name):
+    """
+    Combine mask and weights
+    create wcsr, iw, jw, return their names
+    """
+    w = workspace.FetchBlob(weight_name)
+    w_csr = scipy.sparse.csr_matrix(w)
+    wcsr = w_csr.data
+    iw = w_csr.indptr
+    jw = w_csr.indices
+    workspace.FeedBlob(weight_name + "wcsr", wcsr)
+    workspace.FeedBlob(weight_name + "iw", iw)
+    workspace.FeedBlob(weight_name + "jw", jw)
+    return weight_name + "wcsr", weight_name + "iw", weight_name + "jw"
+
+
+def transFCRelu(cur, id2node, name2id, ops, model):
+    """
+    Add trans before and after this FC_Prune->(Relu)->FC_Prune chain.
+    """
+    # 1. add trans before the start of this chain
+    # assuming that cur is a FC_Prune, and it has only one input
+    pre = cur.prev.itervalues().next()
+    # Create a node /op and insert it.
+    # TODO(wyiming): check whether it is correct here
+    current_blob = model.Transpose(cur.op.input[0], cur.op.input[0] + "_trans")
+#     print model.net.Proto()
+    trans_op = model.net.Proto().op[-1]
+    trans_node = NetDefNode(trans_op.output[0], "Transpose", pre, trans_op)
+    trans_node.visited = True
+    pre_new = trans_node
+
+    # 2. use while loop to visit the chain
+    while True:
+        # breakup with the parent
+        cur.deleteInput(pre)
+        if not (cur.optype == "FC_Prune" or cur.optype == "Relu"):
+            print("Reaching the end of the chain")
+            break
+        if len(cur.ops) > 1:
+            print("A FC/Relu giving more than 1 useful outputs")
+        if cur.optype == "FC_Prune":
+            op = cur.op
+            wcsr, iw, jw = maskNallocate(op.input[1])
+            bias_name = op.input[3]
+            # TODO(wyiming): create a new Op here
+            current_blob = model.FC_Sparse(current_blob,
+                                           cur.op.output[0] + "_Sparse",
+                                           wcsr, iw, jw, bias_name)
+            sps_op = model.net.Proto().op[-1]
+            sps_node = NetDefNode(cur.op.output[0] + "_Sparse",
+                                  "FC_Sparse",
+                                  pre_new, sps_op)
+            sps_node.visited = True
+            pre_new = sps_node
+        if cur.optype == "Relu":
+            op = cur.op
+            current_blob = model.Relu(current_blob, current_blob)
+            rel_op = model.net.Proto().op[-1]
+            rel_node = NetDefNode(str(current_blob), "Relu",
+                                  pre_new, rel_op)
+            rel_node.visited = True
+            pre_new = rel_node
+
+        cur.visited = True
+        pre = cur
+        flag = False
+        for _, temp in cur.ops.iteritems():
+            if temp.optype == "Relu" or temp.optype == "FC_Prune":
+                flag = True
+                cur = temp
+        if not flag:
+            # assume that there is only 1 output that is not PrintOP
+            cur = cur.ops.itervalues().next()
+            cur.deleteInput(pre)
+            print("No FC/RElu children")
+            print(cur.op.type)
+            break
+    # 3. add trans after this chain like 1.
+    current_blob = model.Transpose(current_blob, pre.op.output[0])
+    trans_op = model.net.Proto().op[-1]
+    trans_node = NetDefNode(str(current_blob), "Transpose", pre_new, trans_op)
+    trans_node.visited = True
+    cur.insertInput(trans_node)
+    print(cur.prev)
+    print(trans_node.ops)
+
+
+def Prune2Sparse(cur, id2node, name2id, ops, model):
+    # Assume that FC and Relu takes in only 1 input;
+    # If not raise warning
+    if not cur.visited and cur.optype == "FC_Prune":
+        transFCRelu(cur, id2node, name2id, ops, model)
+
+    cur.visited = True
+    for name, n in cur.ops.iteritems():
+        Prune2Sparse(n, id2node, name2id, ops, model)
+
+
+def net2list(net_root):
+    """
+    Use topological order(BFS) to print the op of a net in a list
+    """
+    bfs_queue = []
+    op_list = []
+    cur = net_root
+    for _, n in cur.ops.iteritems():
+        bfs_queue.append(n)
+    while bfs_queue:
+        node = bfs_queue[0]
+        bfs_queue = bfs_queue[1:]
+        op_list.append(node.op)
+        for _, n in node.ops.iteritems():
+            bfs_queue.append(n)
+
+    return op_list
+
+
+def netbuilder(model):
+    print("Welcome to model checker")
+    proto = model.net.Proto()
+    net_name2id = {}
+    net_id2node = {}
+    net_root = NetDefNode("net_root", "root", None)
+
+    for op_id, op in enumerate(proto.op):
+        if op.type == "Print":
+            continue
+        op_name = '%s/%s (op#%d)' % (op.name, op.type, op_id) \
+                  if op.name else '%s (op#%d)' % (op.type, op_id)
+        # print(op_name)
+        op_node = NetDefNode(op_name, op.type, op=op)
+        net_id2node[op_id] = op_node
+
+        if_has_layer_input = False
+        for input_name in op.input:
+            if input_name not in net_name2id:
+                # assume that un_occured name are non_layers
+                # TODO: write a non-layer checker and log it
+                continue
+            op_node.insertInput(net_id2node[net_name2id[input_name]])
+            if_has_layer_input = True
+
+        if not if_has_layer_input:
+            op_node.insertInput(net_root)
+
+        for output_name in op.output:
+            net_name2id[output_name] = op_id
+
+    return net_root, net_name2id, net_id2node
diff --git a/.venv/lib/python3.7/site-packages/caffe2/experiments/python/__init__.py b/.venv/lib/python3.7/site-packages/caffe2/experiments/python/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/.venv/lib/python3.7/site-packages/caffe2/experiments/python/convnet_benchmarks.py b/.venv/lib/python3.7/site-packages/caffe2/experiments/python/convnet_benchmarks.py
new file mode 100644
index 0000000..ff9b7a2
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/experiments/python/convnet_benchmarks.py
@@ -0,0 +1,699 @@
+# Copyright (c) 2016-present, Facebook, Inc.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+##############################################################################
+
+## @package convnet_benchmarks
+# Module caffe2.experiments.python.convnet_benchmarks
+
+
+
+
+"""
+Benchmark for common convnets.
+
+(NOTE: Numbers below prior with missing parameter=update step, TODO to update)
+
+Speed on Titan X, with 10 warmup steps and 10 main steps and with different
+versions of cudnn, are as follows (time reported below is per-batch time,
+forward / forward+backward):
+
+                    CuDNN V3        CuDNN v4
+                    AlexNet         32.5 / 108.0    27.4 /  90.1
+                    OverFeat       113.0 / 342.3    91.7 / 276.5
+                    Inception      134.5 / 485.8   125.7 / 450.6
+                    VGG (batch 64) 200.8 / 650.0   164.1 / 551.7
+
+Speed on Inception with varied batch sizes and CuDNN v4 is as follows:
+
+Batch Size   Speed per batch     Speed per image
+16             22.8 /  72.7         1.43 / 4.54
+32             38.0 / 127.5         1.19 / 3.98
+64             67.2 / 233.6         1.05 / 3.65
+128            125.7 / 450.6         0.98 / 3.52
+
+Speed on Tesla M40, which 10 warmup steps and 10 main steps and with cudnn
+v4, is as follows:
+
+AlexNet         68.4 / 218.1
+OverFeat       210.5 / 630.3
+Inception      300.2 / 1122.2
+VGG (batch 64) 405.8 / 1327.7
+
+(Note that these numbers involve a "full" backprop, i.e. the gradient
+with respect to the input image is also computed.)
+
+To get the numbers, simply run:
+
+for MODEL in AlexNet OverFeat Inception; do
+PYTHONPATH=../gen:$PYTHONPATH python convnet_benchmarks.py \
+    --batch_size 128 --model $MODEL --forward_only True
+done
+for MODEL in AlexNet OverFeat Inception; do
+PYTHONPATH=../gen:$PYTHONPATH python convnet_benchmarks.py \
+    --batch_size 128 --model $MODEL
+done
+PYTHONPATH=../gen:$PYTHONPATH python convnet_benchmarks.py \
+    --batch_size 64 --model VGGA --forward_only True
+PYTHONPATH=../gen:$PYTHONPATH python convnet_benchmarks.py \
+    --batch_size 64 --model VGGA
+
+for BS in 16 32 64 128; do
+PYTHONPATH=../gen:$PYTHONPATH python convnet_benchmarks.py \
+    --batch_size $BS --model Inception --forward_only True
+PYTHONPATH=../gen:$PYTHONPATH python convnet_benchmarks.py \
+    --batch_size $BS --model Inception
+done
+
+Note that VGG needs to be run at batch 64 due to memory limit on the backward
+pass.
+"""
+
+import argparse
+import time
+
+from caffe2.python import cnn, workspace, core
+
+import caffe2.python.SparseTransformer as SparseTransformer  # type: ignore[import]
+
+
+def MLP(order):
+    model = cnn.CNNModelHelper()
+    d = 256
+    depth = 20
+    width = 3
+    for i in range(depth):
+        for j in range(width):
+            current = "fc_{}_{}".format(i, j) if i > 0 else "data"
+            next_ = "fc_{}_{}".format(i + 1, j)
+            model.FC(
+                current, next_,
+                dim_in=d, dim_out=d,
+                weight_init=model.XavierInit,
+                bias_init=model.XavierInit)
+            model.Sum(["fc_{}_{}".format(depth, j)
+                       for j in range(width)], ["sum"])
+            model.FC("sum", "last",
+                     dim_in=d, dim_out=1000,
+                     weight_init=model.XavierInit,
+                     bias_init=model.XavierInit)
+            xent = model.LabelCrossEntropy(["last", "label"], "xent")
+            model.AveragedLoss(xent, "loss")
+            return model, d
+
+
+def AlexNet(order):
+    model = cnn.CNNModelHelper(order, name="alexnet",
+                               use_cudnn=True, cudnn_exhaustive_search=True)
+    conv1 = model.Conv(
+        "data",
+        "conv1",
+        3,
+        64,
+        11,
+        ('XavierFill', {}),
+        ('ConstantFill', {}),
+        stride=4,
+        pad=2
+    )
+
+    relu1 = model.Relu(conv1, "conv1")
+    pool1 = model.MaxPool(relu1, "pool1", kernel=3, stride=2)
+    conv2 = model.Conv(
+        pool1,
+        "conv2",
+        64,
+        192,
+        5,
+        ('XavierFill', {}),
+        ('ConstantFill', {}),
+        pad=2
+    )
+    relu2 = model.Relu(conv2, "conv2")
+    pool2 = model.MaxPool(relu2, "pool2", kernel=3, stride=2)
+    conv3 = model.Conv(
+        pool2,
+        "conv3",
+        192,
+        384,
+        3,
+        ('XavierFill', {}),
+        ('ConstantFill', {}),
+        pad=1
+    )
+    relu3 = model.Relu(conv3, "conv3")
+    conv4 = model.Conv(
+        relu3,
+        "conv4",
+        384,
+        256,
+        3,
+        ('XavierFill', {}),
+        ('ConstantFill', {}),
+        pad=1
+    )
+    relu4 = model.Relu(conv4, "conv4")
+    conv5 = model.Conv(
+        relu4,
+        "conv5",
+        256,
+        256,
+        3,
+        ('XavierFill', {}),
+        ('ConstantFill', {}),
+        pad=1
+    )
+    relu5 = model.Relu(conv5, "conv5")
+    pool5 = model.MaxPool(relu5, "pool5", kernel=3, stride=2)
+    fc6 = model.FC(
+        pool5, "fc6", 256 * 6 * 6, 4096, ('XavierFill', {}),
+        ('ConstantFill', {})
+    )
+    relu6 = model.Relu(fc6, "fc6")
+    fc7 = model.FC(
+        relu6, "fc7", 4096, 4096, ('XavierFill', {}), ('ConstantFill', {})
+    )
+    relu7 = model.Relu(fc7, "fc7")
+    fc8 = model.FC(
+        relu7, "fc8", 4096, 1000, ('XavierFill', {}), ('ConstantFill', {})
+    )
+    pred = model.Softmax(fc8, "pred")
+    xent = model.LabelCrossEntropy([pred, "label"], "xent")
+    model.AveragedLoss(xent, "loss")
+    return model, 224
+
+
+def OverFeat(order):
+    model = cnn.CNNModelHelper(order, name="overfeat",
+                               use_cudnn=True, cudnn_exhaustive_search=True)
+    conv1 = model.Conv(
+        "data",
+        "conv1",
+        3,
+        96,
+        11,
+        ('XavierFill', {}),
+        ('ConstantFill', {}),
+        stride=4
+    )
+    relu1 = model.Relu(conv1, "conv1")
+    pool1 = model.MaxPool(relu1, "pool1", kernel=2, stride=2)
+    conv2 = model.Conv(
+        pool1, "conv2", 96, 256, 5, ('XavierFill', {}), ('ConstantFill', {})
+    )
+    relu2 = model.Relu(conv2, "conv2")
+    pool2 = model.MaxPool(relu2, "pool2", kernel=2, stride=2)
+    conv3 = model.Conv(
+        pool2,
+        "conv3",
+        256,
+        512,
+        3,
+        ('XavierFill', {}),
+        ('ConstantFill', {}),
+        pad=1
+    )
+    relu3 = model.Relu(conv3, "conv3")
+    conv4 = model.Conv(
+        relu3,
+        "conv4",
+        512,
+        1024,
+        3,
+        ('XavierFill', {}),
+        ('ConstantFill', {}),
+        pad=1
+    )
+    relu4 = model.Relu(conv4, "conv4")
+    conv5 = model.Conv(
+        relu4,
+        "conv5",
+        1024,
+        1024,
+        3,
+        ('XavierFill', {}),
+        ('ConstantFill', {}),
+        pad=1
+    )
+    relu5 = model.Relu(conv5, "conv5")
+    pool5 = model.MaxPool(relu5, "pool5", kernel=2, stride=2)
+    fc6 = model.FC(
+        pool5, "fc6", 1024 * 6 * 6, 3072, ('XavierFill', {}),
+        ('ConstantFill', {})
+    )
+    relu6 = model.Relu(fc6, "fc6")
+    fc7 = model.FC(
+        relu6, "fc7", 3072, 4096, ('XavierFill', {}), ('ConstantFill', {})
+    )
+    relu7 = model.Relu(fc7, "fc7")
+    fc8 = model.FC(
+        relu7, "fc8", 4096, 1000, ('XavierFill', {}), ('ConstantFill', {})
+    )
+    pred = model.Softmax(fc8, "pred")
+    xent = model.LabelCrossEntropy([pred, "label"], "xent")
+    model.AveragedLoss(xent, "loss")
+    return model, 231
+
+
+def VGGA(order):
+    model = cnn.CNNModelHelper(order, name='vgg-a',
+                               use_cudnn=True, cudnn_exhaustive_search=True)
+    conv1 = model.Conv(
+        "data",
+        "conv1",
+        3,
+        64,
+        3,
+        ('XavierFill', {}),
+        ('ConstantFill', {}),
+        pad=1
+    )
+    relu1 = model.Relu(conv1, "conv1")
+    pool1 = model.MaxPool(relu1, "pool1", kernel=2, stride=2)
+    conv2 = model.Conv(
+        pool1,
+        "conv2",
+        64,
+        128,
+        3,
+        ('XavierFill', {}),
+        ('ConstantFill', {}),
+        pad=1
+    )
+    relu2 = model.Relu(conv2, "conv2")
+    pool2 = model.MaxPool(relu2, "pool2", kernel=2, stride=2)
+    conv3 = model.Conv(
+        pool2,
+        "conv3",
+        128,
+        256,
+        3,
+        ('XavierFill', {}),
+        ('ConstantFill', {}),
+        pad=1
+    )
+    relu3 = model.Relu(conv3, "conv3")
+    conv4 = model.Conv(
+        relu3,
+        "conv4",
+        256,
+        256,
+        3,
+        ('XavierFill', {}),
+        ('ConstantFill', {}),
+        pad=1
+    )
+    relu4 = model.Relu(conv4, "conv4")
+    pool4 = model.MaxPool(relu4, "pool4", kernel=2, stride=2)
+    conv5 = model.Conv(
+        pool4,
+        "conv5",
+        256,
+        512,
+        3,
+        ('XavierFill', {}),
+        ('ConstantFill', {}),
+        pad=1
+    )
+    relu5 = model.Relu(conv5, "conv5")
+    conv6 = model.Conv(
+        relu5,
+        "conv6",
+        512,
+        512,
+        3,
+        ('XavierFill', {}),
+        ('ConstantFill', {}),
+        pad=1
+    )
+    relu6 = model.Relu(conv6, "conv6")
+    pool6 = model.MaxPool(relu6, "pool6", kernel=2, stride=2)
+    conv7 = model.Conv(
+        pool6,
+        "conv7",
+        512,
+        512,
+        3,
+        ('XavierFill', {}),
+        ('ConstantFill', {}),
+        pad=1
+    )
+    relu7 = model.Relu(conv7, "conv7")
+    conv8 = model.Conv(
+        relu7,
+        "conv8",
+        512,
+        512,
+        3,
+        ('XavierFill', {}),
+        ('ConstantFill', {}),
+        pad=1
+    )
+    relu8 = model.Relu(conv8, "conv8")
+    pool8 = model.MaxPool(relu8, "pool8", kernel=2, stride=2)
+
+    fcix = model.FC(
+        pool8, "fcix", 512 * 7 * 7, 4096, ('XavierFill', {}),
+        ('ConstantFill', {})
+    )
+    reluix = model.Relu(fcix, "fcix")
+    fcx = model.FC(
+        reluix, "fcx", 4096, 4096, ('XavierFill', {}), ('ConstantFill', {})
+    )
+    relux = model.Relu(fcx, "fcx")
+    fcxi = model.FC(
+        relux, "fcxi", 4096, 1000, ('XavierFill', {}), ('ConstantFill', {})
+    )
+    pred = model.Softmax(fcxi, "pred")
+    xent = model.LabelCrossEntropy([pred, "label"], "xent")
+    model.AveragedLoss(xent, "loss")
+    return model, 231
+
+
+def net_DAG_Builder(model):
+    print("====================================================")
+    print("                 Start Building DAG                 ")
+    print("====================================================")
+    net_root = SparseTransformer.netbuilder(model)
+    return net_root
+
+
+def _InceptionModule(
+    model, input_blob, input_depth, output_name, conv1_depth, conv3_depths,
+    conv5_depths, pool_depth
+):
+    # path 1: 1x1 conv
+    conv1 = model.Conv(
+        input_blob, output_name + ":conv1", input_depth, conv1_depth, 1,
+        ('XavierFill', {}), ('ConstantFill', {})
+    )
+    conv1 = model.Relu(conv1, conv1)
+    # path 2: 1x1 conv + 3x3 conv
+    conv3_reduce = model.Conv(
+        input_blob, output_name +
+        ":conv3_reduce", input_depth, conv3_depths[0],
+        1, ('XavierFill', {}), ('ConstantFill', {})
+    )
+    conv3_reduce = model.Relu(conv3_reduce, conv3_reduce)
+    conv3 = model.Conv(
+        conv3_reduce,
+        output_name + ":conv3",
+        conv3_depths[0],
+        conv3_depths[1],
+        3,
+        ('XavierFill', {}),
+        ('ConstantFill', {}),
+        pad=1
+    )
+    conv3 = model.Relu(conv3, conv3)
+    # path 3: 1x1 conv + 5x5 conv
+    conv5_reduce = model.Conv(
+        input_blob, output_name +
+        ":conv5_reduce", input_depth, conv5_depths[0],
+        1, ('XavierFill', {}), ('ConstantFill', {})
+    )
+    conv5_reduce = model.Relu(conv5_reduce, conv5_reduce)
+    conv5 = model.Conv(
+        conv5_reduce,
+        output_name + ":conv5",
+        conv5_depths[0],
+        conv5_depths[1],
+        5,
+        ('XavierFill', {}),
+        ('ConstantFill', {}),
+        pad=2
+    )
+    conv5 = model.Relu(conv5, conv5)
+    # path 4: pool + 1x1 conv
+    pool = model.MaxPool(
+        input_blob,
+        output_name + ":pool",
+        kernel=3,
+        stride=1,
+        pad=1
+    )
+    pool_proj = model.Conv(
+        pool, output_name + ":pool_proj", input_depth, pool_depth, 1,
+        ('XavierFill', {}), ('ConstantFill', {})
+    )
+    pool_proj = model.Relu(pool_proj, pool_proj)
+    output = model.Concat([conv1, conv3, conv5, pool_proj], output_name)
+    return output
+
+
+def Inception(order):
+    model = cnn.CNNModelHelper(order, name="inception",
+                               use_cudnn=True, cudnn_exhaustive_search=True)
+    conv1 = model.Conv(
+        "data",
+        "conv1",
+        3,
+        64,
+        7,
+        ('XavierFill', {}),
+        ('ConstantFill', {}),
+        stride=2,
+        pad=3
+    )
+    relu1 = model.Relu(conv1, "conv1")
+    pool1 = model.MaxPool(relu1, "pool1", kernel=3, stride=2, pad=1)
+    conv2a = model.Conv(
+        pool1, "conv2a", 64, 64, 1, ('XavierFill', {}), ('ConstantFill', {})
+    )
+    conv2a = model.Relu(conv2a, conv2a)
+    conv2 = model.Conv(
+        conv2a,
+        "conv2",
+        64,
+        192,
+        3,
+        ('XavierFill', {}),
+        ('ConstantFill', {}),
+        pad=1
+    )
+    relu2 = model.Relu(conv2, "conv2")
+    pool2 = model.MaxPool(relu2, "pool2", kernel=3, stride=2, pad=1)
+    # Inception modules
+    inc3 = _InceptionModule(
+        model, pool2, 192, "inc3", 64, [96, 128], [16, 32], 32
+    )
+    inc4 = _InceptionModule(
+        model, inc3, 256, "inc4", 128, [128, 192], [32, 96], 64
+    )
+    pool5 = model.MaxPool(inc4, "pool5", kernel=3, stride=2, pad=1)
+    inc5 = _InceptionModule(
+        model, pool5, 480, "inc5", 192, [96, 208], [16, 48], 64
+    )
+    inc6 = _InceptionModule(
+        model, inc5, 512, "inc6", 160, [112, 224], [24, 64], 64
+    )
+    inc7 = _InceptionModule(
+        model, inc6, 512, "inc7", 128, [128, 256], [24, 64], 64
+    )
+    inc8 = _InceptionModule(
+        model, inc7, 512, "inc8", 112, [144, 288], [32, 64], 64
+    )
+    inc9 = _InceptionModule(
+        model, inc8, 528, "inc9", 256, [160, 320], [32, 128], 128
+    )
+    pool9 = model.MaxPool(inc9, "pool9", kernel=3, stride=2, pad=1)
+    inc10 = _InceptionModule(
+        model, pool9, 832, "inc10", 256, [160, 320], [32, 128], 128
+    )
+    inc11 = _InceptionModule(
+        model, inc10, 832, "inc11", 384, [192, 384], [48, 128], 128
+    )
+    pool11 = model.AveragePool(inc11, "pool11", kernel=7, stride=1)
+    fc = model.FC(
+        pool11, "fc", 1024, 1000, ('XavierFill', {}), ('ConstantFill', {})
+    )
+    # It seems that Soumith's benchmark does not have softmax on top
+    # for Inception. We will add it anyway so we can have a proper
+    # backward pass.
+    pred = model.Softmax(fc, "pred")
+    xent = model.LabelCrossEntropy([pred, "label"], "xent")
+    model.AveragedLoss(xent, "loss")
+    return model, 224
+
+
+def AddInput(model, batch_size, db, db_type):
+    """Adds the data input part."""
+    data_uint8, label = model.TensorProtosDBInput(
+        [], ["data_uint8", "label"], batch_size=batch_size,
+        db=db, db_type=db_type
+    )
+    data = model.Cast(data_uint8, "data_nhwc", to=core.DataType.FLOAT)
+    data = model.NHWC2NCHW(data, "data")
+    data = model.Scale(data, data, scale=float(1. / 256))
+    data = model.StopGradient(data, data)
+    return data, label
+
+
+def AddParameterUpdate(model):
+    """ Simple plain SGD update -- not tuned to actually train the models """
+    ITER = model.Iter("iter")
+    LR = model.LearningRate(
+        ITER, "LR", base_lr=-1e-8, policy="step", stepsize=10000, gamma=0.999)
+    ONE = model.param_init_net.ConstantFill([], "ONE", shape=[1], value=1.0)
+    for param in model.params:
+        param_grad = model.param_to_grad[param]
+        model.WeightedSum([param, ONE, param_grad, LR], param)
+
+
+def Benchmark(model_gen, arg):
+    model, input_size = model_gen(arg.order)
+    model.Proto().type = arg.net_type
+    model.Proto().num_workers = arg.num_workers
+
+    # In order to be able to run everything without feeding more stuff, let's
+    # add the data and label blobs to the parameter initialization net as well.
+
+    if arg.order == "NCHW":
+        input_shape = [arg.batch_size, 3, input_size, input_size]
+    else:
+        input_shape = [arg.batch_size, input_size, input_size, 3]
+        if arg.model == "MLP":
+            input_shape = [arg.batch_size, input_size]
+
+    model.param_init_net.GaussianFill(
+        [],
+        "data",
+        shape=input_shape,
+        mean=0.0,
+        std=1.0
+    )
+    model.param_init_net.UniformIntFill(
+        [],
+        "label",
+        shape=[arg.batch_size, ],
+        min=0,
+        max=999
+    )
+
+    if arg.forward_only:
+        print('{}: running forward only.'.format(arg.model))
+    else:
+        print('{}: running forward-backward.'.format(arg.model))
+        model.AddGradientOperators(["loss"])
+        AddParameterUpdate(model)
+
+        if arg.order == 'NHWC':
+            print(
+                '==WARNING==\n'
+                'NHWC order with CuDNN may not be supported yet, so I might\n'
+                'exit suddenly.'
+            )
+
+    if not arg.cpu:
+        model.param_init_net.RunAllOnGPU()
+        model.net.RunAllOnGPU()
+
+    if arg.dump_model:
+        # Writes out the pbtxt for benchmarks on e.g. Android
+        with open(
+            "{0}_init_batch_{1}.pbtxt".format(arg.model, arg.batch_size), "w"
+        ) as fid:
+            fid.write(str(model.param_init_net.Proto()))
+            with open("{0}.pbtxt".format(arg.model), "w") as fid:
+                fid.write(str(model.net.Proto()))
+
+    workspace.RunNetOnce(model.param_init_net)
+    workspace.CreateNet(model.net)
+    for i in range(arg.warmup_iterations):
+        workspace.RunNet(model.net.Proto().name)
+
+    plan = core.Plan("plan")
+    plan.AddStep(core.ExecutionStep("run", model.net, arg.iterations))
+    start = time.time()
+    workspace.RunPlan(plan)
+    print('Spent: {}'.format((time.time() - start) / arg.iterations))
+    if arg.layer_wise_benchmark:
+        print('Layer-wise benchmark.')
+        workspace.BenchmarkNet(model.net.Proto().name, 1, arg.iterations, True)
+
+
+def GetArgumentParser():
+    parser = argparse.ArgumentParser(description="Caffe2 benchmark.")
+    parser.add_argument(
+        "--batch_size",
+        type=int,
+        default=128,
+        help="The batch size."
+    )
+    parser.add_argument("--model", type=str, help="The model to benchmark.")
+    parser.add_argument(
+        "--order",
+        type=str,
+        default="NCHW",
+        help="The order to evaluate."
+    )
+    parser.add_argument(
+        "--cudnn_ws",
+        type=int,
+        default=-1,
+        help="The cudnn workspace size."
+    )
+    parser.add_argument(
+        "--iterations",
+        type=int,
+        default=10,
+        help="Number of iterations to run the network."
+    )
+    parser.add_argument(
+        "--warmup_iterations",
+        type=int,
+        default=10,
+        help="Number of warm-up iterations before benchmarking."
+    )
+    parser.add_argument(
+        "--forward_only",
+        action='store_true',
+        help="If set, only run the forward pass."
+    )
+    parser.add_argument(
+        "--layer_wise_benchmark",
+        action='store_true',
+        help="If True, run the layer-wise benchmark as well."
+    )
+    parser.add_argument(
+        "--cpu",
+        action='store_true',
+        help="If True, run testing on CPU instead of GPU."
+    )
+    parser.add_argument(
+        "--dump_model",
+        action='store_true',
+        help="If True, dump the model prototxts to disk."
+    )
+    parser.add_argument("--net_type", type=str, default="dag")
+    parser.add_argument("--num_workers", type=int, default=2)
+    return parser
+
+
+if __name__ == '__main__':
+    args = GetArgumentParser().parse_args()
+    if (
+        not args.batch_size or not args.model or not args.order or
+        not args.cudnn_ws
+    ):
+        GetArgumentParser().print_help()
+
+    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])
+    model_map = {
+        'AlexNet': AlexNet,
+        'OverFeat': OverFeat,
+        'VGGA': VGGA,
+        'Inception': Inception,
+        'MLP': MLP,
+    }
+    Benchmark(model_map[args.model], args)
diff --git a/.venv/lib/python3.7/site-packages/caffe2/experiments/python/device_reduce_sum_bench.py b/.venv/lib/python3.7/site-packages/caffe2/experiments/python/device_reduce_sum_bench.py
new file mode 100644
index 0000000..1a795e2
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/experiments/python/device_reduce_sum_bench.py
@@ -0,0 +1,130 @@
+# Copyright (c) 2016-present, Facebook, Inc.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+##############################################################################
+
+## @package device_reduce_sum_bench
+# Module caffe2.experiments.python.device_reduce_sum_bench
+
+
+
+
+
+import argparse
+import itertools
+import logging
+import os
+
+from six import add_metaclass
+import numpy as np
+
+from caffe2.python import workspace, core
+from caffe2.python.hypothesis_test_util import runOpBenchmark, gpu_do
+
+logging.basicConfig()
+logger = logging.getLogger(os.path.basename(__file__))
+logger.setLevel(logging.INFO)
+
+ALL_BENCHMARKS = {}
+
+
+class BenchmarkMeta(type):
+    def __new__(metacls, name, bases, class_dict):
+        cls = type.__new__(metacls, name, bases, class_dict)
+        if name != 'Benchmark':
+            ALL_BENCHMARKS[name] = cls
+        return cls
+
+
+@add_metaclass(BenchmarkMeta)
+class Benchmark(object):
+
+    def __init__(self):
+        self.results = []
+
+    def display(self):
+        print('Results ({}):'.format(type(self).__name__))
+        print('input size                      ms/iter')
+        print('------------------------------  -----------')
+        for size, ms in self.results:
+            print('{!s:<30}  {:.4f}'.format(size, ms))
+
+
+class SumElements(Benchmark):
+    def run(self):
+        op = core.CreateOperator(
+            "SumElements",
+            ["X"],
+            ["y"]
+        )
+
+        for n in itertools.imap(pow, itertools.cycle([10]), range(10)):
+            X = np.random.rand(n).astype(np.float32)
+            logger.info('Running benchmark for n = {}'.format(n))
+            ret = runOpBenchmark(gpu_do, op, inputs=[X])
+            self.results.append((n, ret[1]))
+
+
+class SumSqrElements(Benchmark):
+    def run(self):
+        op = core.CreateOperator(
+            "SumSqrElements",
+            ["X"],
+            ["y"]
+        )
+
+        for n in itertools.imap(pow, itertools.cycle([10]), range(10)):
+            X = np.random.rand(n).astype(np.float32)
+            logger.info('Running benchmark for n = {}'.format(n))
+            ret = runOpBenchmark(gpu_do, op, inputs=[X])
+            self.results.append((n, ret[1]))
+
+
+class SoftMaxWithLoss(Benchmark):
+    def run(self):
+        op = core.CreateOperator(
+            "SoftmaxWithLoss",
+            ["X", "label"],
+            ["probs", "avgloss"],
+        )
+
+        for n in itertools.imap(pow, itertools.cycle([10]), range(8)):
+            for D in itertools.imap(pow, itertools.cycle([10]), range(3)):
+                X = np.random.rand(n, D).astype(np.float32)
+                label = (np.random.rand(n) * D).astype(np.int32)
+                logger.info('Running benchmark for n = {}, D= {}'.format(n, D))
+                ret = runOpBenchmark(gpu_do, op, inputs=[X, label])
+                self.results.append(((n, D), ret[1]))
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(os.path.basename(__file__))
+    parser.add_argument('-b', '--benchmarks', nargs='+',
+                        default=ALL_BENCHMARKS.keys(),
+                        help='benchmarks to run (default: %(default)s))')
+    return parser.parse_args()
+
+
+def main():
+    args = parse_args()
+
+    benchmarks = [ALL_BENCHMARKS[name]() for name in args.benchmarks]
+    for bench in benchmarks:
+        bench.run()
+    for bench in benchmarks:
+        bench.display()
+
+
+if __name__ == '__main__':
+    workspace.GlobalInit(['caffe2', '--caffe2_log_level=2'])
+    main()
diff --git a/.venv/lib/python3.7/site-packages/caffe2/experiments/python/funhash_op_test.py b/.venv/lib/python3.7/site-packages/caffe2/experiments/python/funhash_op_test.py
new file mode 100644
index 0000000..3fc4c8b
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/experiments/python/funhash_op_test.py
@@ -0,0 +1,79 @@
+# Copyright (c) 2016-present, Facebook, Inc.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+##############################################################################
+
+
+
+
+
+
+import numpy as np
+from scipy.sparse import coo_matrix
+
+from hypothesis import given
+import hypothesis.strategies as st
+
+from caffe2.python import core
+import caffe2.python.hypothesis_test_util as hu
+
+
+class TestFunHash(hu.HypothesisTestCase):
+    @given(n_out=st.integers(min_value=5, max_value=20),
+           n_in=st.integers(min_value=10, max_value=20),
+           n_data=st.integers(min_value=2, max_value=8),
+           n_weight=st.integers(min_value=8, max_value=15),
+           n_alpha=st.integers(min_value=3, max_value=8),
+           sparsity=st.floats(min_value=0.1, max_value=1.0),
+           **hu.gcs)
+    def test_funhash(self, n_out, n_in, n_data, n_weight, n_alpha, sparsity,
+                     gc, dc):
+        A = np.random.rand(n_data, n_in)
+        A[A > sparsity] = 0
+        A_coo = coo_matrix(A)
+        val, key, seg = A_coo.data, A_coo.col, A_coo.row
+
+        weight = np.random.rand(n_weight).astype(np.float32)
+        alpha = np.random.rand(n_alpha).astype(np.float32)
+        val = val.astype(np.float32)
+        key = key.astype(np.int64)
+        seg = seg.astype(np.int32)
+
+        op = core.CreateOperator(
+            'FunHash',
+            ['val', 'key', 'seg', 'weight', 'alpha'],
+            ['out'],
+            num_outputs=n_out)
+
+        # Check over multiple devices
+        self.assertDeviceChecks(
+            dc, op, [val, key, seg, weight, alpha], [0])
+        # Gradient check wrt weight
+        self.assertGradientChecks(
+            gc, op, [val, key, seg, weight, alpha], 3, [0])
+        # Gradient check wrt alpha
+        self.assertGradientChecks(
+            gc, op, [val, key, seg, weight, alpha], 4, [0])
+
+        op2 = core.CreateOperator(
+            'FunHash',
+            ['val', 'key', 'seg', 'weight'],
+            ['out'],
+            num_outputs=n_out)
+
+        # Check over multiple devices
+        self.assertDeviceChecks(
+            dc, op2, [val, key, seg, weight], [0])
+        # Gradient check wrt weight
+        self.assertGradientChecks(
+            gc, op2, [val, key, seg, weight], 3, [0])
diff --git a/.venv/lib/python3.7/site-packages/caffe2/experiments/python/net_construct_bench.py b/.venv/lib/python3.7/site-packages/caffe2/experiments/python/net_construct_bench.py
new file mode 100644
index 0000000..ec12517
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/experiments/python/net_construct_bench.py
@@ -0,0 +1,152 @@
+# Copyright (c) 2016-present, Facebook, Inc.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+##############################################################################
+
+## @package net_construct_bench
+# Module caffe2.experiments.python.net_construct_bench
+
+
+
+
+
+import argparse
+import logging
+import time
+
+from caffe2.python import workspace, data_parallel_model
+from caffe2.python import cnn
+
+import caffe2.python.models.resnet as resnet
+
+'''
+Simple benchmark that creates a data-parallel resnet-50 model
+and measures the time.
+'''
+
+
+logging.basicConfig()
+log = logging.getLogger("net_construct_bench")
+log.setLevel(logging.DEBUG)
+
+
+def AddMomentumParameterUpdate(train_model, LR):
+    '''
+    Add the momentum-SGD update.
+    '''
+    params = train_model.GetParams()
+    assert(len(params) > 0)
+    ONE = train_model.param_init_net.ConstantFill(
+        [], "ONE", shape=[1], value=1.0,
+    )
+    NEGONE = train_model.param_init_net.ConstantFill(
+        [], 'NEGONE', shape=[1], value=-1.0,
+    )
+
+    for param in params:
+        param_grad = train_model.param_to_grad[param]
+        param_momentum = train_model.param_init_net.ConstantFill(
+            [param], param + '_momentum', value=0.0
+        )
+
+        # Update param_grad and param_momentum in place
+        train_model.net.MomentumSGD(
+            [param_grad, param_momentum, LR],
+            [param_grad, param_momentum],
+            momentum=0.9,
+            nesterov=1
+        )
+
+        # Update parameters by applying the moment-adjusted gradient
+        train_model.WeightedSum(
+            [param, ONE, param_grad, NEGONE],
+            param
+        )
+
+
+def Create(args):
+    gpus = list(range(args.num_gpus))
+    log.info("Running on gpus: {}".format(gpus))
+
+    # Create CNNModeLhelper object
+    train_model = cnn.CNNModelHelper(
+        order="NCHW",
+        name="resnet50",
+        use_cudnn=True,
+        cudnn_exhaustive_search=False
+    )
+
+    # Model building functions
+    def create_resnet50_model_ops(model, loss_scale):
+        [softmax, loss] = resnet.create_resnet50(
+            model,
+            "data",
+            num_input_channels=3,
+            num_labels=1000,
+            label="label",
+        )
+        model.Accuracy([softmax, "label"], "accuracy")
+        return [loss]
+
+    # SGD
+    def add_parameter_update_ops(model):
+        model.AddWeightDecay(1e-4)
+        ITER = model.Iter("ITER")
+        stepsz = int(30)
+        LR = model.net.LearningRate(
+            [ITER],
+            "LR",
+            base_lr=0.1,
+            policy="step",
+            stepsize=stepsz,
+            gamma=0.1,
+        )
+        AddMomentumParameterUpdate(model, LR)
+
+    def add_image_input(model):
+        pass
+
+    start_time = time.time()
+
+    # Create parallelized model
+    data_parallel_model.Parallelize_GPU(
+        train_model,
+        input_builder_fun=add_image_input,
+        forward_pass_builder_fun=create_resnet50_model_ops,
+        param_update_builder_fun=add_parameter_update_ops,
+        devices=gpus,
+    )
+
+    ct = time.time() - start_time
+    train_model.net._CheckLookupTables()
+
+    log.info("Model create for {} gpus took: {} secs".format(len(gpus), ct))
+
+
+def main():
+    # TODO: use argv
+    parser = argparse.ArgumentParser(
+        description="Caffe2: Benchmark for net construction"
+    )
+    parser.add_argument("--num_gpus", type=int, default=1,
+                        help="Number of GPUs.")
+    args = parser.parse_args()
+
+    Create(args)
+
+
+if __name__ == '__main__':
+    workspace.GlobalInit(['caffe2', '--caffe2_log_level=2'])
+    import cProfile
+
+    cProfile.run('main()', sort="cumulative")
diff --git a/.venv/lib/python3.7/site-packages/caffe2/experiments/python/sparse_funhash_op_test.py b/.venv/lib/python3.7/site-packages/caffe2/experiments/python/sparse_funhash_op_test.py
new file mode 100644
index 0000000..cfc7a0b
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/experiments/python/sparse_funhash_op_test.py
@@ -0,0 +1,73 @@
+# Copyright (c) 2016-present, Facebook, Inc.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+##############################################################################
+
+
+
+
+
+
+import numpy as np
+from scipy.sparse import coo_matrix
+
+from hypothesis import given
+import hypothesis.strategies as st
+
+from caffe2.python import core
+import caffe2.python.hypothesis_test_util as hu
+
+
+class TestFunHash(hu.HypothesisTestCase):
+    @given(n_out=st.integers(min_value=5, max_value=20),
+           n_in=st.integers(min_value=10, max_value=20),
+           n_data=st.integers(min_value=2, max_value=8),
+           n_weight=st.integers(min_value=8, max_value=15),
+           n_alpha=st.integers(min_value=3, max_value=8),
+           sparsity=st.floats(min_value=0.1, max_value=1.0),
+           **hu.gcs)
+    def test_funhash(self, n_out, n_in, n_data, n_weight, n_alpha, sparsity,
+                     gc, dc):
+        A = np.random.rand(n_data, n_in)
+        A[A > sparsity] = 0
+        A_coo = coo_matrix(A)
+        val, key, seg = A_coo.data, A_coo.col, A_coo.row
+
+        weight = np.random.rand(n_weight).astype(np.float32)
+        alpha = np.random.rand(n_alpha).astype(np.float32)
+        val = val.astype(np.float32)
+        key = key.astype(np.int64)
+        seg = seg.astype(np.int32)
+
+        op = core.CreateOperator(
+            'SparseFunHash',
+            ['val', 'key', 'seg', 'weight', 'alpha'],
+            ['out'],
+            num_outputs=n_out)
+
+        # Gradient check wrt weight
+        self.assertGradientChecks(
+            gc, op, [val, key, seg, weight, alpha], 3, [0])
+        # Gradient check wrt alpha
+        self.assertGradientChecks(
+            gc, op, [val, key, seg, weight, alpha], 4, [0])
+
+        op2 = core.CreateOperator(
+            'SparseFunHash',
+            ['val', 'key', 'seg', 'weight'],
+            ['out'],
+            num_outputs=n_out)
+
+        # Gradient check wrt weight
+        self.assertGradientChecks(
+            gc, op2, [val, key, seg, weight], 3, [0])
diff --git a/.venv/lib/python3.7/site-packages/caffe2/experiments/python/sparse_reshape_op_test.py b/.venv/lib/python3.7/site-packages/caffe2/experiments/python/sparse_reshape_op_test.py
new file mode 100644
index 0000000..a22bf56
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/experiments/python/sparse_reshape_op_test.py
@@ -0,0 +1,104 @@
+# Copyright (c) 2016-present, Facebook, Inc.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+##############################################################################
+
+
+
+
+
+
+import numpy as np
+from scipy.sparse import coo_matrix
+
+from caffe2.python import core, workspace
+from caffe2.python.test_util import TestCase
+
+
+def test_reshape(old_shape, new_shape, stride_only=False):
+    blob_in0 = 'col'
+    blob_out0 = 'col_out'
+
+    blob_in1 = 'row'
+    blob_out1 = 'row_out'
+
+    old_shape_for_op = (-1, old_shape[1]) if stride_only else old_shape
+
+    op = core.CreateOperator('SparseMatrixReshape',
+                             [blob_in0, blob_in1],
+                             [blob_out0, blob_out1],
+                             old_shape=old_shape_for_op,
+                             new_shape=new_shape)
+
+    A = np.random.random_sample(old_shape)
+    A[np.random.random_sample(old_shape) > .5] = 0
+    A_coo = coo_matrix(A)
+    old_row, old_col = A_coo.row, A_coo.col
+
+    workspace.FeedBlob(blob_in0, old_col.astype(np.int64))
+    workspace.FeedBlob(blob_in1, old_row.astype(np.int32))
+
+    workspace.RunOperatorOnce(op)
+
+    A_new_coo = coo_matrix(A.reshape(new_shape))
+    new_row, new_col = A_new_coo.row, A_new_coo.col
+
+    col_out = workspace.FetchBlob(blob_out0)
+    row_out = workspace.FetchBlob(blob_out1)
+
+    np.testing.assert_array_equal(col_out, new_col)
+    np.testing.assert_array_equal(row_out, new_row)
+
+
+class TestSparseMatrixReshapeOp(TestCase):
+    def test_basic_reshape(self):
+        test_reshape(old_shape=(3, 4), new_shape=(4, 3))
+
+    def test_missing_dim(self):
+        test_reshape(old_shape=(2, 8), new_shape=(-1, 4))
+
+    def test_stride_only(self):
+        test_reshape(old_shape=(2, 8), new_shape=(-1, 4), stride_only=True)
+
+    def test_sparse_reshape_mm(self):
+        M, N, K = 300, 400, 500
+        A = np.random.rand(M, K).astype(np.float32)
+        A_sparse = A * (np.random.rand(*A.shape) > .5)
+        A_sparse = A_sparse.reshape((K, M))
+        A_coo = coo_matrix(A_sparse)
+        idx0, idx1, a = A_coo.row, A_coo.col, A_coo.data
+        B = np.random.rand(K, N).astype(np.float32)
+
+        workspace.FeedBlob('col', idx1.astype(np.int64))
+        workspace.FeedBlob('row', idx0.astype(np.int32))
+        workspace.FeedBlob('B', B)
+        workspace.FeedBlob('a', a)
+
+        reshape_op = core.CreateOperator(
+            'SparseMatrixReshape',
+            ['col', 'row'],
+            ['new_col', 'new_row'],
+            old_shape=(K, M),
+            new_shape=(M, K))
+
+        mm_op = core.CreateOperator(
+            'SparseUnsortedSegmentWeightedSum',
+            ['B', 'a', 'new_col', 'new_row'],
+            ['Y'])
+
+        workspace.RunOperatorOnce(reshape_op)
+        workspace.RunOperatorOnce(mm_op)
+
+        Y = workspace.FetchBlob('Y')
+        np.testing.assert_allclose(A_sparse.reshape(M, K).dot(B), Y,
+                                   rtol=1e-4)
diff --git a/.venv/lib/python3.7/site-packages/caffe2/experiments/python/tt_contraction_op_test.py b/.venv/lib/python3.7/site-packages/caffe2/experiments/python/tt_contraction_op_test.py
new file mode 100644
index 0000000..1e41e9e
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/experiments/python/tt_contraction_op_test.py
@@ -0,0 +1,63 @@
+# Copyright (c) 2016-present, Facebook, Inc.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+##############################################################################
+
+
+
+
+
+
+import numpy as np
+
+from hypothesis import given
+import hypothesis.strategies as st
+
+from caffe2.python import core, workspace
+import caffe2.python.hypothesis_test_util as hu
+
+
+class TestTTContraction(hu.HypothesisTestCase):
+    @given(D=st.integers(min_value=5, max_value=20),
+           K=st.integers(min_value=5, max_value=20),
+           M=st.integers(min_value=5, max_value=20),
+           N=st.integers(min_value=5, max_value=20),
+           **hu.gcs)
+    def test_tt_contraction(self, D, K, M, N, gc, dc):
+        A = np.random.rand(K, M).astype(np.float32)
+        B = np.random.rand(D, K, N).astype(np.float32)
+
+        workspace.FeedBlob('A', A)
+        workspace.FeedBlob('B', B)
+
+        op = core.CreateOperator(
+            'TTContraction',
+            ['A', 'B'],
+            ['C'],
+            K=K,
+            M=M,
+            N=N)
+        workspace.RunOperatorOnce(op)
+
+        def tt_contraction_ref(A_, B_):
+            return ((A_[:, :, np.newaxis] * B_[:, :, np.newaxis, :])
+                    .sum(axis=1).flatten()),
+
+        # Check against numpy reference
+        self.assertReferenceChecks(gc, op, [A, B], tt_contraction_ref)
+        # Check over multiple devices
+        self.assertDeviceChecks(dc, op, [A, B], [0])
+        # Gradient check wrt A
+        self.assertGradientChecks(gc, op, [A, B], 0, [0])
+        # Gradient check wrt B
+        self.assertGradientChecks(gc, op, [A, B], 1, [0])
diff --git a/.venv/lib/python3.7/site-packages/caffe2/experiments/python/tt_pad_op_test.py b/.venv/lib/python3.7/site-packages/caffe2/experiments/python/tt_pad_op_test.py
new file mode 100644
index 0000000..27d1354
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/experiments/python/tt_pad_op_test.py
@@ -0,0 +1,60 @@
+# Copyright (c) 2016-present, Facebook, Inc.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+##############################################################################
+
+
+
+
+
+
+import numpy as np
+
+from hypothesis import given
+import hypothesis.strategies as st
+
+from caffe2.python import core, workspace
+import caffe2.python.hypothesis_test_util as hu
+
+
+class TestTTPad(hu.HypothesisTestCase):
+    @given(K=st.integers(min_value=2, max_value=10),
+           M=st.integers(min_value=10, max_value=20),
+           N=st.integers(min_value=10, max_value=20),
+           **hu.gcs)
+    def test_tt_pad(self, K, M, N, gc, dc):
+        op = core.CreateOperator(
+            'TTPad',
+            ['A'],
+            ['A', 'dim0'],
+            scale=(K))
+
+        A = np.random.rand(M, N).astype(np.float32)
+        workspace.FeedBlob('A', A)
+        workspace.RunOperatorOnce(op)
+
+        def tt_pad_ref(A_):
+            M_ = A_.shape[0]
+            if M_ % K == 0:
+                new_dim0 = M_
+            else:
+                new_dim0 = (M_ // K + 1) * K
+            return (np.vstack((A_, np.zeros((new_dim0 - M_, A_.shape[1])))),
+                    np.array([A.shape[0]]))
+
+        # Check against numpy reference
+        self.assertReferenceChecks(gc, op, [A], tt_pad_ref)
+        # Check over multiple devices
+        self.assertDeviceChecks(dc, op, [A], [0])
+        # Gradient check wrt A
+        self.assertGradientChecks(gc, op, [A], 0, [0])
diff --git a/.venv/lib/python3.7/site-packages/caffe2/perfkernels/__init__.py b/.venv/lib/python3.7/site-packages/caffe2/perfkernels/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/.venv/lib/python3.7/site-packages/caffe2/perfkernels/hp_emblookup_codegen.py b/.venv/lib/python3.7/site-packages/caffe2/perfkernels/hp_emblookup_codegen.py
new file mode 100644
index 0000000..402f3bb
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/perfkernels/hp_emblookup_codegen.py
@@ -0,0 +1,530 @@
+
+
+import argparse
+import sys
+
+
+sizeof = {"float": 4, "at::Half": 2, "uint8_t": 1}
+
+
+def unroll(uf, IndexType, InType, OutType, use_weights, isa, fused, use_offsets):
+    def compute(regid, InType, use_weights, isa, prefetch):
+        code = []
+
+        if InType == "float":
+            code.append(
+                "        vop%d = _mm256_fmadd_ps(vwgt, _mm256_loadu_ps(ip + (%d)), vop%d);"  # noqa
+                % (regid, regid, regid)
+            )
+        elif InType == "at::Half":
+            code.append(
+                "        vop%d = _mm256_fmadd_ps(\n"
+                "            vwgt,\n"
+                "            _mm256_cvtph_ps(\n"
+                "                _mm_loadu_si128(reinterpret_cast<const __m128i*>(ip + (%d)))),\n"  # noqa
+                "            vop%d);" % (regid, regid, regid)
+            )
+        elif InType == "uint8_t":
+            code.append(
+                "        vop%d = _mm256_fmadd_ps(\n"
+                "            vwgt,\n"
+                "            _mm256_cvtepi32_ps(_mm256_cvtepu8_epi32(\n"
+                "                _mm_loadl_epi64(reinterpret_cast<const __m128i*>(ip + (%d))))),\n"  # noqa
+                "            _mm256_add_ps(vop%d, vbio));" % (regid, regid, regid)
+            )
+        else:
+            assert False
+
+        if prefetch:
+            code.append(
+                "        _mm_prefetch(\n"
+                "            reinterpret_cast<const char*>(&ip_next_T0[%d]), _MM_HINT_T0);"
+                % (regid)
+            )
+        else:
+            code.append(
+                "        // skip unnecessary prefetch of (&ip_next_T0[%d])" % (regid)
+            )
+
+        return code
+
+    code = []
+    code.append("    // unrolling " + str(uf) + " times")
+
+    if use_offsets:
+        code.append(
+            "    for ("
+            + IndexType
+            + " rangeIndex = 0; rangeIndex < output_size; ++rangeIndex) {"
+        )
+    else:
+        code.append(
+            "    for ("
+            + IndexType
+            + " rangeIndex = 0; rangeIndex < output_size; ++rangeIndex) {"
+        )
+
+    code.append("      " + OutType + "* op = &out[rangeIndex * block_size];")
+    for i in range(0, uf):
+        j = 8 * i
+        code.append("      __m256 vop" + str(j) + " = _mm256_setzero_ps();")
+
+    # inner loop
+    if use_offsets:
+        code.append(
+            "      if (dataInd != offsets[rangeIndex] - offsets[0]) {\n"
+            + "        return false;\n"
+            + "      }"
+        )
+        code.append("""\
+      int64_t end_offset = offsets[rangeIndex + 1];
+      int64_t length = end_offset - offsets[rangeIndex];""")
+        code.append(
+            "      for ("
+            + "int64_t"
+            + " start = dataInd; dataInd < end_offset - offsets[0];\n           ++dataInd) {"  # noqa
+        )
+    else:
+        code.append(
+            "      if (dataInd + lengths[rangeIndex] > index_size) {\n"
+            + "        return false;\n"
+            + "      }"
+        )
+        code.append(
+            "      for ("
+            + IndexType
+            + " start = dataInd; dataInd < start + lengths[rangeIndex];\n           ++dataInd) {"  # noqa
+        )
+    code.append("        const " + IndexType + " idx = indices[dataInd];")
+    code.append(
+        "        if (idx < 0 || idx >= data_size) {\n"
+        + "          return false;\n"
+        + "        }"
+    )
+
+    if InType == "uint8_t":
+        code.append("        " + OutType + " wgt = 1.f;")
+        code.append("        " + OutType + " bio;")
+        code.append("        if (weights) {")
+        code.append(
+            "          wgt = weights[IS_WEIGHT_POSITIONAL ? (dataInd - start) : dataInd];"  # noqa
+        )
+        code.append("        }")
+        if fused:
+            code.append(
+                "        const float* scale_bias = reinterpret_cast<const float*>(\n"
+                "            &input[idx * fused_block_size + block_size]);"
+            )
+            code.append("        bio = wgt * scale_bias[1];")
+            code.append("        wgt = wgt * scale_bias[0];")
+        else:
+            code.append("        bio = wgt * scale_bias[2 * idx + 1];")
+            code.append("        wgt = wgt * scale_bias[2 * idx];")
+        code.append("        __m256 vbio = _mm256_set1_ps(bio);")
+    else:
+        code.append("        " + OutType + " wgt = 1.f;")
+        code.append("        if (weights) {")
+        code.append(
+            "          wgt = weights[IS_WEIGHT_POSITIONAL ? (dataInd - start) : dataInd];"  # noqa
+        )
+        code.append("        }")
+    code.append("        __m256 vwgt = _mm256_set1_ps(wgt);")
+
+    code.append("        const {}* ip = &input[idx * fused_block_size];".format(InType))
+    code.append(
+        "        const {} next_T0 = (dataInd < index_size - prefdist_T0)\n"
+        "            ? (dataInd + prefdist_T0)\n            : dataInd;".format(
+            IndexType
+        )
+    )
+    code.append("        const " + IndexType + " idx_pref_T0 = indices[next_T0];")
+    code.append(
+        "        if (idx_pref_T0 < 0 || idx_pref_T0 >= data_size) {\n"
+        + "          return false;\n"
+        + "        }"
+    )
+
+    code.append(
+        "        const {}* ip_next_T0 = "
+        "&input[idx_pref_T0 * fused_block_size];".format(InType)
+    )
+
+    for i in range(0, uf):
+        j = 8 * i
+        cachelinesize = 64
+        byteoffset = sizeof[InType] * j
+        prefetch = (byteoffset % cachelinesize) == 0
+        code.extend(compute(j, InType, use_weights, isa, prefetch))
+    code.append("      }")
+
+    if use_offsets:
+        code.append("      if (!normalize_by_lengths || length == 0) {")
+    else:
+        code.append("      if (!normalize_by_lengths || lengths[rangeIndex] == 0) {")
+    for i in range(0, uf):
+        j = 8 * i
+        code.append("        _mm256_storeu_ps(&op[" + str(j) + "], vop" + str(j) + ");")
+    code.append("      } else {")
+    # inv of length
+    if use_offsets:
+        code.append("        __m256 vlen_inv = _mm256_set1_ps(1.0f / length);")
+    else:
+        code.append("        __m256 vlen_inv = _mm256_set1_ps(1.0f / lengths[rangeIndex]);")
+    for i in range(0, uf):
+        j = 8 * i
+        code.append(
+            "        _mm256_storeu_ps(&op["
+            + str(j)
+            + "], _mm256_mul_ps("
+            + "vop"
+            + str(j)
+            + ", vlen_inv));"
+        )
+    code.append("      }")
+
+    code.append("    }")
+    return code
+
+
+def generic(IndexType, InType, OutType, use_weights, isa, fused, use_offsets):
+    def compute(InType, use_weights, isa):
+        code = []
+        if InType == "float":
+            code.append(
+                "          _mm256_storeu_ps(\n"
+                "              &op[j],\n"
+                "              _mm256_fmadd_ps(\n"
+                "                  vwgt, _mm256_loadu_ps(&ip[j]), _mm256_loadu_ps(&op[j])));"  # noqa
+            )
+        elif InType == "at::Half":
+            code.append(
+                "          _mm256_storeu_ps(\n"
+                "              &op[j],\n"
+                "              _mm256_fmadd_ps(\n"
+                "                  vwgt,\n"
+                "                  _mm256_cvtph_ps(_mm_loadu_si128(\n"
+                "                      reinterpret_cast<const __m128i*>(&ip[j]))),\n"
+                "                  _mm256_loadu_ps(&op[j])));"
+            )
+        elif InType == "uint8_t":
+            code.append(
+                "          _mm256_storeu_ps(\n"
+                "              &op[j],\n"
+                "              _mm256_fmadd_ps(\n"
+                "                  vwgt,\n"
+                "                  _mm256_cvtepi32_ps(_mm256_cvtepu8_epi32(_mm_loadl_epi64(\n"  # noqa
+                "                      reinterpret_cast<const __m128i*>(&ip[j])))),\n"
+                "                  _mm256_add_ps(_mm256_loadu_ps(&op[j]), vbio)));"
+            )
+        else:
+            assert False
+
+        code.append(
+            "          _mm_prefetch(\n"
+            "              reinterpret_cast<const char*>(&ip_next_T0[j]), _MM_HINT_T0);"
+        )
+
+        return code
+
+    code = []
+    if InType == "at::Half":
+        code.append("    alignas(64) at::Half vtmp1[8] = {0};")
+
+
+
+    if use_offsets:
+        code.append(
+            "    for ("
+            + IndexType
+            + " rangeIndex = 0; rangeIndex < output_size; ++rangeIndex) {"
+        )
+    else:
+        code.append(
+            "    for ("
+            + IndexType
+            + " rangeIndex = 0; rangeIndex < output_size; ++rangeIndex) {"
+        )
+
+    code.append("      " + OutType + "* op = &out[rangeIndex * block_size];")
+
+    # initialize to 0
+    code.append("      int64_t j = 0;")
+    code.append("      for (; j + 8 <= block_size; j += 8) {")
+    code.append("        _mm256_storeu_ps(op + j, _mm256_setzero_ps());")
+    code.append("      }")
+    code.append("      for (; j < block_size; j++) {")
+    code.append("        op[j] = 0.0f;")
+    code.append("      }")
+
+    # inner loop
+    if use_offsets:
+        code.append(
+            "      if (dataInd != offsets[rangeIndex] - offsets[0]) {\n"
+            + "        return false;\n"
+            + "      }"
+        )
+        code.append("""\
+      int64_t end_offset = offsets[rangeIndex + 1];
+      int64_t length = end_offset - offsets[rangeIndex];""")
+        code.append(
+            "      for ("
+            + "int64_t"
+            + " start = dataInd; dataInd < end_offset - offsets[0];\n           ++dataInd) {"  # noqa
+        )
+    else:
+        code.append(
+            "      if (dataInd + lengths[rangeIndex] > index_size) {\n"
+            + "        return false;\n"
+            + "      }"
+        )
+        code.append(
+            "      for ("
+            + IndexType
+            + " start = dataInd; dataInd < start + lengths[rangeIndex];\n           ++dataInd) {"  # noqa
+        )
+    code.append("        const " + IndexType + " idx = indices[dataInd];")
+    code.append(
+        "        if (idx < 0 || idx >= data_size) {\n"
+        + "          return false;\n"
+        + "        }"
+    )
+
+    if InType == "uint8_t":
+        code.append("        " + OutType + " wgt = 1.f;")
+        code.append("        " + OutType + " bio;")
+        code.append("        if (weights) {")
+        code.append(
+            "          wgt = weights[IS_WEIGHT_POSITIONAL ? (dataInd - start) : dataInd];"  # noqa
+        )
+        code.append("        }")
+        if fused:
+            code.append(
+                "        const float* scale_bias = reinterpret_cast<const float*>(\n"
+                "            &input[idx * fused_block_size + block_size]);"
+            )
+            code.append("        bio = wgt * scale_bias[1];")
+            code.append("        wgt = wgt * scale_bias[0];")
+        else:
+            code.append("        bio = wgt * scale_bias[2 * idx + 1];")
+            code.append("        wgt = wgt * scale_bias[2 * idx];")
+        code.append("        __m256 vbio = _mm256_set1_ps(bio);")
+    else:
+        code.append("        " + OutType + " wgt = 1.f;")
+        code.append("        if (weights) {")
+        code.append(
+            "          wgt = weights[IS_WEIGHT_POSITIONAL ? (dataInd - start) : dataInd];"  # noqa
+        )
+        code.append("        }")
+    code.append("        __m256 vwgt = _mm256_set1_ps(wgt);")
+
+    code.append("        const {}* ip = &input[idx * fused_block_size];".format(InType))
+    code.append(
+        "        const {} next_T0 = (dataInd < index_size - prefdist_T0)\n"
+        "            ? (dataInd + prefdist_T0)\n            : dataInd;".format(
+            IndexType
+        )
+    )
+    code.append("        const " + IndexType + " idx_pref_T0 = indices[next_T0];")
+    code.append(
+        "        if (idx_pref_T0 < 0 || idx_pref_T0 >= data_size) {\n"
+        + "          return false;\n"
+        + "        }"
+    )
+    code.append(
+        "        const {}* ip_next_T0 = "
+        "&input[idx_pref_T0 * fused_block_size];".format(InType)
+    )
+
+    # compute and store main loop
+    code.append("        j = 0;")
+    code.append("        for (; j + 8 <= block_size; j += 8) {")
+    code.extend(compute(InType, use_weights, isa))
+    code.append("        }")
+    # leftover
+    code.append("        for (; j < block_size; j++) {")
+    if InType == "float":
+        code.append("          op[j] = std::fma(wgt, ip[j], op[j]);")
+    elif InType == "at::Half":
+        code.append("          vtmp1[0] = ip[j];")
+        code.append(
+            "          __m256 vtmp2 =\n"
+            "              _mm256_cvtph_ps(*(reinterpret_cast<const __m128i*>(vtmp1)));"
+        )
+        code.append("          op[j] = std::fma(wgt, ((float*)(&vtmp2))[0], op[j]);")
+    elif InType == "uint8_t":
+        code.append("          op[j] = std::fma(wgt, (float)ip[j], bio + op[j]);")
+    else:
+        assert False
+
+    code.append("        }")
+
+    code.append("      }")
+
+    if use_offsets:
+        code.append("      if (normalize_by_lengths && length) {")
+        code.append("        float len_inv = 1.0f / length;")
+    else:
+        code.append("      if (normalize_by_lengths && lengths[rangeIndex]) {")
+        code.append("        float len_inv = 1.0f / lengths[rangeIndex];")
+    code.append("        __m256 vlen_inv = _mm256_set1_ps(len_inv);")
+    code.append("        j = 0;")
+    code.append("        for (; j + 8 <= block_size; j += 8) {")
+    code.append(
+        "          _mm256_storeu_ps(\n"
+        "              &op[j], _mm256_mul_ps(_mm256_loadu_ps(&op[j]), vlen_inv));"
+    )
+    code.append("        }")
+    code.append("        for (; j < block_size; j++) {")
+    code.append("          op[j] = len_inv * op[j];")
+    code.append("        }")
+
+    code.append("      }")
+
+    code.append("    }")
+    return code
+
+
+# start main code
+parser = argparse.ArgumentParser()
+parser.add_argument("-f", "--filename", help="file name")
+parser.add_argument("--fused", action="store_true")
+parser.add_argument("--use-offsets", action="store_true")
+opts = parser.parse_args()
+if opts.filename:
+    filename = opts.filename
+elif opts.fused:
+    if opts.use_offsets:
+        filename = "embedding_lookup_fused_8bit_rowwise_idx_avx2.cc"
+    else:
+        filename = "embedding_lookup_fused_8bit_rowwise_avx2.cc"
+else:
+    if opts.use_offsets:
+        filename = "embedding_lookup_idx_avx2.cc"
+    else:
+        filename = "embedding_lookup_avx2.cc"
+
+options = [
+    ["int32_t", "int", "float", "float", "float", "float"],
+    ["int64_t", "int64_t", "float", "float", "float", "float"],
+    ["int32_t", "int", "half", "at::Half", "float", "float"],
+    ["int64_t", "int64_t", "half", "at::Half", "float", "float"],
+    ["int32_t", "int", "uint8_t", "uint8_t", "float", "float"],
+    ["int64_t", "int64_t", "uint8_t", "uint8_t", "float", "float"],
+]
+
+code = []
+# includes
+code.append("//// --------------------------")
+code.append("//// ATTENTION:")
+code.append("//// THIS CODE IS AUTOGENERATED")
+code.append("//// BY {}".format(sys.argv[0]))
+code.append("//// DO NOT MODIFY!!!")
+code.append("//// --------------------------\n")
+
+code.append("#include <c10/util/Half.h>")
+code.append("#include <immintrin.h>")
+
+code.append("namespace caffe2 {\n")
+for o in options:
+    [IndexTypeName, IndexType, InTypeName, InType, OutTypeName, OutType] = o
+
+    prefix = "Fused8BitRowwise" if opts.fused else ""
+    code.append("template <bool IS_WEIGHT_POSITIONAL>")
+    if opts.use_offsets:
+        fn_base = "{}EmbeddingLookupIdx_{}_{}_{}".format(
+            prefix, IndexTypeName, InTypeName, OutTypeName
+        )
+    else:
+        fn_base = "{}EmbeddingLookup_{}_{}_{}".format(
+            prefix, IndexTypeName, InTypeName, OutTypeName
+        )
+    suffix = "__avx2_fma"
+    fn = "static bool " + fn_base + suffix
+    code.append(fn + "(")
+
+    args = []
+    args.append("    const int64_t block_size,")
+    args.append("    const int64_t output_size,")
+    args.append("    const int64_t index_size,")
+    args.append("    const int64_t data_size,")
+    args.append("    const " + InType + "* input,")
+    args.append("    const " + IndexType + "* indices,")
+    if opts.use_offsets:
+        args.append("    const " + IndexType + "* offsets,")
+    else:
+        args.append("    const int* lengths,")
+    args.append("    const float* weights,")
+    if not opts.fused:
+        args.append("    const float* scale_bias,")
+    args.append("    bool normalize_by_lengths,")
+    args.append("    " + OutType + "* out) {")
+    code += args
+
+    code.append("  const " + IndexType + " prefdist_T0 = 16;")
+    # block_size is the number of elements and fused_block_size is the size of
+    # an entire row, including scale and bias.
+    offset = (8 // sizeof[InType]) if opts.fused else 0
+    code.append(
+        "  const {} fused_block_size = block_size + {};".format(IndexType, offset)
+    )
+    if opts.use_offsets:
+        code.append("  int64_t dataInd = 0;")
+    else:
+        code.append("  " + IndexType + " dataInd = 0;")
+
+    # code.append("printf(\"calling " + fn + "\\n\");");
+
+    code.append("  if (block_size == 128) {")
+    code += unroll(16, IndexType, InType, OutType, True, "AVX2", opts.fused, opts.use_offsets)
+    code.append("  } else if (block_size == 64) {")
+    code += unroll(8, IndexType, InType, OutType, True, "AVX2", opts.fused, opts.use_offsets)
+    code.append("  } else if (block_size == 32) {")
+    code += unroll(4, IndexType, InType, OutType, True, "AVX2", opts.fused, opts.use_offsets)
+    code.append("  } else if (block_size == 16) {")
+    code += unroll(2, IndexType, InType, OutType, True, "AVX2", opts.fused, opts.use_offsets)
+    code.append("  } else {")
+    code.append("    // generic code")
+    code += generic(IndexType, InType, OutType, True, "AVX2", opts.fused, opts.use_offsets)
+    code.append("  }")
+    code.append("  return dataInd == index_size;")
+
+    code.append("}")
+
+    for is_weight_positional in ["false", "true"]:
+        code.append("bool " + fn_base + "_" + is_weight_positional + suffix + "(")
+        code += args
+        # Resolve the Lint warnings: Limit of 80 characters in one line.
+        extra_space = "\n      "
+        ret_string = "  return " + fn_base + suffix + "<" + is_weight_positional + ">("
+        if len(ret_string) <= 80:
+            code.append(ret_string)
+        else:
+            code.append("  return " + fn_base + suffix + "<" + extra_space + is_weight_positional + ">(")
+        code.append("      block_size,")
+        code.append("      output_size,")
+        code.append("      index_size,")
+        code.append("      data_size,")
+        code.append("      input,")
+        code.append("      indices,")
+        if opts.use_offsets:
+            code.append("      offsets,")
+        else:
+            code.append("      lengths,")
+        code.append("      weights,")
+        if not opts.fused:
+            code.append("      scale_bias,")
+        code.append("      normalize_by_lengths,")
+        code.append("      out);")
+        code.append("}")
+
+    code.append("")
+
+code.append("} // namespace caffe2")
+
+with open(filename, "w") as fout:
+    for c in code:
+        # print(c, file = fout)
+        fout.write(c + "\n")
+
+
+print("Created " + filename)
diff --git a/.venv/lib/python3.7/site-packages/caffe2/proto/__init__.py b/.venv/lib/python3.7/site-packages/caffe2/proto/__init__.py
new file mode 100644
index 0000000..a753f26
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/proto/__init__.py
@@ -0,0 +1,15 @@
+# NOTE: we have to import python protobuf here **before** we load cpp extension.
+# Otherwise it breaks under certain build conditions if cpp implementation of
+# protobuf is used. Presumably there's some registry in protobuf library and
+# python side has to initialize the dictionary first, before static
+# initialization in python extension does so. Otherwise, duplicated protobuf
+# descriptors will be created and it can lead to obscure errors like
+#   "Parameter to MergeFrom() must be instance of same class:
+#    expected caffe2.NetDef got caffe2.NetDef."
+#
+# This has to be done for all python targets, so listing them here
+from caffe2.proto import caffe2_pb2, metanet_pb2, torch_pb2
+try:
+    from caffe2.caffe2.fb.session.proto import session_pb2
+except ImportError:
+    pass
diff --git a/.venv/lib/python3.7/site-packages/caffe2/proto/caffe2_pb2.py b/.venv/lib/python3.7/site-packages/caffe2/proto/caffe2_pb2.py
new file mode 100644
index 0000000..40cda61
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/proto/caffe2_pb2.py
@@ -0,0 +1,1953 @@
+# -*- coding: utf-8 -*-
+# Generated by the protocol buffer compiler.  DO NOT EDIT!
+# source: caffe2/proto/caffe2.proto
+"""Generated protocol buffer code."""
+from google.protobuf.internal import enum_type_wrapper
+from google.protobuf import descriptor as _descriptor
+from google.protobuf import message as _message
+from google.protobuf import reflection as _reflection
+from google.protobuf import symbol_database as _symbol_database
+# @@protoc_insertion_point(imports)
+
+_sym_db = _symbol_database.Default()
+
+
+
+
+DESCRIPTOR = _descriptor.FileDescriptor(
+  name='caffe2/proto/caffe2.proto',
+  package='caffe2',
+  syntax='proto2',
+  serialized_options=None,
+  create_key=_descriptor._internal_create_key,
+  serialized_pb=b'\n\x19\x63\x61\x66\x66\x65\x32/proto/caffe2.proto\x12\x06\x63\x61\x66\x66\x65\x32\"\xa3\x05\n\x0bTensorProto\x12\x0c\n\x04\x64ims\x18\x01 \x03(\x03\x12\x36\n\tdata_type\x18\x02 \x01(\x0e\x32\x1c.caffe2.TensorProto.DataType:\x05\x46LOAT\x12\x16\n\x0b\x64\x61ta_format\x18\x0f \x01(\r:\x01\x30\x12\x16\n\nfloat_data\x18\x03 \x03(\x02\x42\x02\x10\x01\x12\x16\n\nint32_data\x18\x04 \x03(\x05\x42\x02\x10\x01\x12\x11\n\tbyte_data\x18\x05 \x01(\x0c\x12\x13\n\x0bstring_data\x18\x06 \x03(\x0c\x12\x17\n\x0b\x64ouble_data\x18\t \x03(\x01\x42\x02\x10\x01\x12\x16\n\nint64_data\x18\n \x03(\x03\x42\x02\x10\x01\x12\x10\n\x08raw_data\x18\r \x01(\x0c\x12\x0c\n\x04name\x18\x07 \x01(\t\x12+\n\rdevice_detail\x18\x08 \x01(\x0b\x32\x14.caffe2.DeviceOption\x12,\n\x07segment\x18\x0b \x01(\x0b\x32\x1b.caffe2.TensorProto.Segment\x1a%\n\x07Segment\x12\r\n\x05\x62\x65gin\x18\x01 \x02(\x03\x12\x0b\n\x03\x65nd\x18\x02 \x02(\x03\"\xcf\x01\n\x08\x44\x61taType\x12\r\n\tUNDEFINED\x10\x00\x12\t\n\x05\x46LOAT\x10\x01\x12\t\n\x05INT32\x10\x02\x12\x08\n\x04\x42YTE\x10\x03\x12\n\n\x06STRING\x10\x04\x12\x08\n\x04\x42OOL\x10\x05\x12\t\n\x05UINT8\x10\x06\x12\x08\n\x04INT8\x10\x07\x12\n\n\x06UINT16\x10\x08\x12\t\n\x05INT16\x10\t\x12\t\n\x05INT64\x10\n\x12\x0b\n\x07\x46LOAT16\x10\x0c\x12\n\n\x06\x44OUBLE\x10\r\x12\x17\n\x13ZERO_COLLISION_HASH\x10\x0e\x12\x15\n\x11REBATCHING_BUFFER\x10\x0f\"9\n\x13SerializationFormat\x12\x10\n\x0c\x46MT_PROTOBUF\x10\x00\x12\x10\n\x0c\x46MT_BFLOAT16\x10\x01\"\x83\x02\n\x0cQTensorProto\x12\x0c\n\x04\x64ims\x18\x01 \x03(\x03\x12\x11\n\tprecision\x18\x02 \x02(\x05\x12\r\n\x05scale\x18\x03 \x02(\x01\x12\x0c\n\x04\x62ias\x18\x04 \x02(\x01\x12\x11\n\tis_signed\x18\x05 \x02(\x08\x12\x10\n\x04\x64\x61ta\x18\x06 \x03(\x05\x42\x02\x10\x01\x12\x0c\n\x04name\x18\x07 \x01(\t\x12\x36\n\tdata_type\x18\x08 \x01(\x0e\x32\x1c.caffe2.TensorProto.DataType:\x05INT32\x12\x0e\n\x06scales\x18\t \x03(\x01\x12\x0e\n\x06\x62iases\x18\n \x03(\x01\x12\x0c\n\x04\x61xis\x18\x0b \x01(\x05\x12\x1c\n\ris_multiparam\x18\x0c \x01(\x08:\x05\x66\x61lse\"3\n\x0cTensorProtos\x12#\n\x06protos\x18\x01 \x03(\x0b\x32\x13.caffe2.TensorProto\"\x95\x01\n\x0bTensorShape\x12\x0c\n\x04\x64ims\x18\x01 \x03(\x03\x12\x36\n\tdata_type\x18\x02 \x01(\x0e\x32\x1c.caffe2.TensorProto.DataType:\x05\x46LOAT\x12\x14\n\x0cunknown_dims\x18\x03 \x03(\x05\x12\x1c\n\runknown_shape\x18\x04 \x01(\x08:\x05\x66\x61lse\x12\x0c\n\x04name\x18\x05 \x01(\t\"3\n\x0cTensorShapes\x12#\n\x06shapes\x18\x01 \x03(\x0b\x32\x13.caffe2.TensorShape\"\xa8\x02\n\x10TensorBoundShape\x12\"\n\x05shape\x18\x01 \x01(\x0b\x32\x13.caffe2.TensorShape\x12\x32\n\x08\x64im_type\x18\x02 \x03(\x0e\x32 .caffe2.TensorBoundShape.DimType\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x16\n\x0eshape_is_final\x18\x04 \x01(\x08\"\x95\x01\n\x07\x44imType\x12\x0b\n\x07UNKNOWN\x10\x00\x12\x0c\n\x08\x43ONSTANT\x10\x01\x12\t\n\x05\x42\x41TCH\x10\x02\x12\x18\n\x14\x42\x41TCH_OF_FEATURE_MAX\x10\x03\x12 \n\x1c\x42\x41TCH_OF_FEATURE_MAX_DEFAULT\x10\x04\x12\x0f\n\x0b\x46\x45\x41TURE_MAX\x10\x05\x12\x17\n\x13\x46\x45\x41TURE_MAX_DEFAULT\x10\x06\"n\n\x11TensorBoundShapes\x12(\n\x06shapes\x18\x01 \x03(\x0b\x32\x18.caffe2.TensorBoundShape\x12\x16\n\x0emax_batch_size\x18\x02 \x01(\x03\x12\x17\n\x0fmax_feature_len\x18\x03 \x01(\x03\"\x8d\x01\n\tAOTConfig\x12\x16\n\x0emax_batch_size\x18\x01 \x02(\x03\x12\x14\n\x0cmax_seq_size\x18\x02 \x02(\x03\x12\x1a\n\x12in_batch_broadcast\x18\x03 \x02(\x08\x12\x1d\n\x15onnxifi_blacklist_ops\x18\x04 \x01(\t\x12\x17\n\x0fonnxifi_min_ops\x18\x05 \x01(\x05\"\x8f\x02\n\x08\x41rgument\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\t\n\x01\x66\x18\x02 \x01(\x02\x12\t\n\x01i\x18\x03 \x01(\x03\x12\t\n\x01s\x18\x04 \x01(\x0c\x12\x1e\n\x01t\x18\n \x01(\x0b\x32\x13.caffe2.TensorProto\x12\x19\n\x01n\x18\x08 \x01(\x0b\x32\x0e.caffe2.NetDef\x12\x0e\n\x06\x66loats\x18\x05 \x03(\x02\x12\x0c\n\x04ints\x18\x06 \x03(\x03\x12\x0f\n\x07strings\x18\x07 \x03(\x0c\x12$\n\x07tensors\x18\x0b \x03(\x0b\x32\x13.caffe2.TensorProto\x12\x1c\n\x04nets\x18\t \x03(\x0b\x32\x0e.caffe2.NetDef\x12&\n\x08qtensors\x18\x0c \x03(\x0b\x32\x14.caffe2.QTensorProto\"\x8b\x01\n\x0c\x44\x65viceOption\x12\x16\n\x0b\x64\x65vice_type\x18\x01 \x01(\x05:\x01\x30\x12\x11\n\tdevice_id\x18\x02 \x01(\x05\x12\x13\n\x0brandom_seed\x18\x03 \x01(\r\x12\x11\n\tnode_name\x18\x04 \x01(\t\x12\x14\n\x0cnuma_node_id\x18\x05 \x01(\x05\x12\x12\n\nextra_info\x18\x06 \x03(\t\"\x92\x02\n\x0bOperatorDef\x12\r\n\x05input\x18\x01 \x03(\t\x12\x0e\n\x06output\x18\x02 \x03(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x0c\n\x04type\x18\x04 \x01(\t\x12\x1d\n\x03\x61rg\x18\x05 \x03(\x0b\x32\x10.caffe2.Argument\x12+\n\rdevice_option\x18\x06 \x01(\x0b\x32\x14.caffe2.DeviceOption\x12\x0e\n\x06\x65ngine\x18\x07 \x01(\t\x12\x15\n\rcontrol_input\x18\x08 \x03(\t\x12\x1d\n\x0eis_gradient_op\x18\t \x01(\x08:\x05\x66\x61lse\x12\x12\n\ndebug_info\x18\n \x01(\t\x12\x0e\n\x06\x64omain\x18\x0b \x01(\t\x12\x12\n\nop_version\x18\x0c \x01(\x03\")\n\rMapFieldEntry\x12\x0b\n\x03key\x18\x01 \x02(\t\x12\x0b\n\x03val\x18\x02 \x02(\t\"M\n\x0e\x42\x61\x63kendOptions\x12\x14\n\x0c\x62\x61\x63kend_name\x18\x01 \x02(\t\x12%\n\x06option\x18\x02 \x03(\x0b\x32\x15.caffe2.MapFieldEntry\"u\n\rPartitionInfo\x12\x0c\n\x04name\x18\x01 \x02(\t\x12\x11\n\tdevice_id\x18\x02 \x03(\x05\x12\x12\n\nextra_info\x18\x03 \x01(\t\x12/\n\x0f\x62\x61\x63kend_options\x18\x04 \x03(\x0b\x32\x16.caffe2.BackendOptions\"\x86\x02\n\x06NetDef\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x1f\n\x02op\x18\x02 \x03(\x0b\x32\x13.caffe2.OperatorDef\x12\x0c\n\x04type\x18\x03 \x01(\t\x12\x13\n\x0bnum_workers\x18\x04 \x01(\x05\x12+\n\rdevice_option\x18\x05 \x01(\x0b\x32\x14.caffe2.DeviceOption\x12\x1d\n\x03\x61rg\x18\x06 \x03(\x0b\x32\x10.caffe2.Argument\x12\x16\n\x0e\x65xternal_input\x18\x07 \x03(\t\x12\x17\n\x0f\x65xternal_output\x18\x08 \x03(\t\x12-\n\x0epartition_info\x18\t \x03(\x0b\x32\x15.caffe2.PartitionInfo\"\xcf\x02\n\rExecutionStep\x12\x0c\n\x04name\x18\x01 \x01(\t\x12&\n\x07substep\x18\x02 \x03(\x0b\x32\x15.caffe2.ExecutionStep\x12\x0f\n\x07network\x18\x03 \x03(\t\x12\x10\n\x08num_iter\x18\x04 \x01(\x03\x12\x1c\n\x10\x63riteria_network\x18\x05 \x01(\tB\x02\x18\x01\x12\x12\n\nreport_net\x18\x07 \x01(\t\x12\x17\n\x0freport_interval\x18\x08 \x01(\x05\x12\x14\n\x0crun_every_ms\x18\x0b \x01(\x03\x12\x1b\n\x13\x63oncurrent_substeps\x18\x06 \x01(\x08\x12\x18\n\x10should_stop_blob\x18\t \x01(\t\x12\x11\n\tonly_once\x18\n \x01(\x08\x12\x18\n\x10\x63reate_workspace\x18\x0c \x01(\x08\x12 \n\x18num_concurrent_instances\x18\r \x01(\x05\"g\n\x07PlanDef\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x1f\n\x07network\x18\x02 \x03(\x0b\x32\x0e.caffe2.NetDef\x12-\n\x0e\x65xecution_step\x18\x03 \x03(\x0b\x32\x15.caffe2.ExecutionStep\"\xba\x01\n\tBlobProto\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0c\n\x04type\x18\x02 \x01(\t\x12#\n\x06tensor\x18\x03 \x01(\x0b\x32\x13.caffe2.TensorProto\x12\x0f\n\x07\x63ontent\x18\x04 \x01(\x0c\x12%\n\x07qtensor\x18\x05 \x01(\x0b\x32\x14.caffe2.QTensorProto\x12\x1a\n\x12\x63ontent_num_chunks\x18\x06 \x01(\x05\x12\x18\n\x10\x63ontent_chunk_id\x18\x07 \x01(\x05\"K\n\rDBReaderProto\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0e\n\x06source\x18\x02 \x01(\t\x12\x0f\n\x07\x64\x62_type\x18\x03 \x01(\t\x12\x0b\n\x03key\x18\x04 \x01(\t\"\xd5\x01\n\x18\x42lobSerializationOptions\x12\x17\n\x0f\x62lob_name_regex\x18\x01 \x01(\t\x12\x12\n\nchunk_size\x18\x02 \x01(\x03\x12\x42\n\x0c\x66loat_format\x18\x03 \x01(\x0e\x32,.caffe2.BlobSerializationOptions.FloatFormat\"H\n\x0b\x46loatFormat\x12\x11\n\rFLOAT_DEFAULT\x10\x00\x12\x12\n\x0e\x46LOAT_PROTOBUF\x10\x01\x12\x12\n\x0e\x46LOAT_BFLOAT16\x10\x02\"I\n\x14SerializationOptions\x12\x31\n\x07options\x18\x01 \x03(\x0b\x32 .caffe2.BlobSerializationOptions*\xec\x01\n\x0f\x44\x65viceTypeProto\x12\r\n\tPROTO_CPU\x10\x00\x12\x0e\n\nPROTO_CUDA\x10\x01\x12\x10\n\x0cPROTO_MKLDNN\x10\x02\x12\x10\n\x0cPROTO_OPENGL\x10\x03\x12\x10\n\x0cPROTO_OPENCL\x10\x04\x12\x0f\n\x0bPROTO_IDEEP\x10\x05\x12\r\n\tPROTO_HIP\x10\x06\x12\x0e\n\nPROTO_FPGA\x10\x07\x12\r\n\tPROTO_ORT\x10\x08\x12\r\n\tPROTO_XLA\x10\t\x12\r\n\tPROTO_MLC\x10\n\x12\'\n#PROTO_COMPILE_TIME_MAX_DEVICE_TYPES\x10\x0b'
+)
+
+_DEVICETYPEPROTO = _descriptor.EnumDescriptor(
+  name='DeviceTypeProto',
+  full_name='caffe2.DeviceTypeProto',
+  filename=None,
+  file=DESCRIPTOR,
+  create_key=_descriptor._internal_create_key,
+  values=[
+    _descriptor.EnumValueDescriptor(
+      name='PROTO_CPU', index=0, number=0,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='PROTO_CUDA', index=1, number=1,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='PROTO_MKLDNN', index=2, number=2,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='PROTO_OPENGL', index=3, number=3,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='PROTO_OPENCL', index=4, number=4,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='PROTO_IDEEP', index=5, number=5,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='PROTO_HIP', index=6, number=6,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='PROTO_FPGA', index=7, number=7,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='PROTO_ORT', index=8, number=8,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='PROTO_XLA', index=9, number=9,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='PROTO_MLC', index=10, number=10,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='PROTO_COMPILE_TIME_MAX_DEVICE_TYPES', index=11, number=11,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+  ],
+  containing_type=None,
+  serialized_options=None,
+  serialized_start=3990,
+  serialized_end=4226,
+)
+_sym_db.RegisterEnumDescriptor(_DEVICETYPEPROTO)
+
+DeviceTypeProto = enum_type_wrapper.EnumTypeWrapper(_DEVICETYPEPROTO)
+PROTO_CPU = 0
+PROTO_CUDA = 1
+PROTO_MKLDNN = 2
+PROTO_OPENGL = 3
+PROTO_OPENCL = 4
+PROTO_IDEEP = 5
+PROTO_HIP = 6
+PROTO_FPGA = 7
+PROTO_ORT = 8
+PROTO_XLA = 9
+PROTO_MLC = 10
+PROTO_COMPILE_TIME_MAX_DEVICE_TYPES = 11
+
+
+_TENSORPROTO_DATATYPE = _descriptor.EnumDescriptor(
+  name='DataType',
+  full_name='caffe2.TensorProto.DataType',
+  filename=None,
+  file=DESCRIPTOR,
+  create_key=_descriptor._internal_create_key,
+  values=[
+    _descriptor.EnumValueDescriptor(
+      name='UNDEFINED', index=0, number=0,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='FLOAT', index=1, number=1,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='INT32', index=2, number=2,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='BYTE', index=3, number=3,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='STRING', index=4, number=4,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='BOOL', index=5, number=5,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='UINT8', index=6, number=6,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='INT8', index=7, number=7,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='UINT16', index=8, number=8,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='INT16', index=9, number=9,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='INT64', index=10, number=10,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='FLOAT16', index=11, number=12,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='DOUBLE', index=12, number=13,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='ZERO_COLLISION_HASH', index=13, number=14,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='REBATCHING_BUFFER', index=14, number=15,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+  ],
+  containing_type=None,
+  serialized_options=None,
+  serialized_start=447,
+  serialized_end=654,
+)
+_sym_db.RegisterEnumDescriptor(_TENSORPROTO_DATATYPE)
+
+_TENSORPROTO_SERIALIZATIONFORMAT = _descriptor.EnumDescriptor(
+  name='SerializationFormat',
+  full_name='caffe2.TensorProto.SerializationFormat',
+  filename=None,
+  file=DESCRIPTOR,
+  create_key=_descriptor._internal_create_key,
+  values=[
+    _descriptor.EnumValueDescriptor(
+      name='FMT_PROTOBUF', index=0, number=0,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='FMT_BFLOAT16', index=1, number=1,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+  ],
+  containing_type=None,
+  serialized_options=None,
+  serialized_start=656,
+  serialized_end=713,
+)
+_sym_db.RegisterEnumDescriptor(_TENSORPROTO_SERIALIZATIONFORMAT)
+
+_TENSORBOUNDSHAPE_DIMTYPE = _descriptor.EnumDescriptor(
+  name='DimType',
+  full_name='caffe2.TensorBoundShape.DimType',
+  filename=None,
+  file=DESCRIPTOR,
+  create_key=_descriptor._internal_create_key,
+  values=[
+    _descriptor.EnumValueDescriptor(
+      name='UNKNOWN', index=0, number=0,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='CONSTANT', index=1, number=1,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='BATCH', index=2, number=2,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='BATCH_OF_FEATURE_MAX', index=3, number=3,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='BATCH_OF_FEATURE_MAX_DEFAULT', index=4, number=4,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='FEATURE_MAX', index=5, number=5,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='FEATURE_MAX_DEFAULT', index=6, number=6,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+  ],
+  containing_type=None,
+  serialized_options=None,
+  serialized_start=1383,
+  serialized_end=1532,
+)
+_sym_db.RegisterEnumDescriptor(_TENSORBOUNDSHAPE_DIMTYPE)
+
+_BLOBSERIALIZATIONOPTIONS_FLOATFORMAT = _descriptor.EnumDescriptor(
+  name='FloatFormat',
+  full_name='caffe2.BlobSerializationOptions.FloatFormat',
+  filename=None,
+  file=DESCRIPTOR,
+  create_key=_descriptor._internal_create_key,
+  values=[
+    _descriptor.EnumValueDescriptor(
+      name='FLOAT_DEFAULT', index=0, number=0,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='FLOAT_PROTOBUF', index=1, number=1,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+    _descriptor.EnumValueDescriptor(
+      name='FLOAT_BFLOAT16', index=2, number=2,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+  ],
+  containing_type=None,
+  serialized_options=None,
+  serialized_start=3840,
+  serialized_end=3912,
+)
+_sym_db.RegisterEnumDescriptor(_BLOBSERIALIZATIONOPTIONS_FLOATFORMAT)
+
+
+_TENSORPROTO_SEGMENT = _descriptor.Descriptor(
+  name='Segment',
+  full_name='caffe2.TensorProto.Segment',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='begin', full_name='caffe2.TensorProto.Segment.begin', index=0,
+      number=1, type=3, cpp_type=2, label=2,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='end', full_name='caffe2.TensorProto.Segment.end', index=1,
+      number=2, type=3, cpp_type=2, label=2,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=407,
+  serialized_end=444,
+)
+
+_TENSORPROTO = _descriptor.Descriptor(
+  name='TensorProto',
+  full_name='caffe2.TensorProto',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='dims', full_name='caffe2.TensorProto.dims', index=0,
+      number=1, type=3, cpp_type=2, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='data_type', full_name='caffe2.TensorProto.data_type', index=1,
+      number=2, type=14, cpp_type=8, label=1,
+      has_default_value=True, default_value=1,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='data_format', full_name='caffe2.TensorProto.data_format', index=2,
+      number=15, type=13, cpp_type=3, label=1,
+      has_default_value=True, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='float_data', full_name='caffe2.TensorProto.float_data', index=3,
+      number=3, type=2, cpp_type=6, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=b'\020\001', file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='int32_data', full_name='caffe2.TensorProto.int32_data', index=4,
+      number=4, type=5, cpp_type=1, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=b'\020\001', file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='byte_data', full_name='caffe2.TensorProto.byte_data', index=5,
+      number=5, type=12, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"",
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='string_data', full_name='caffe2.TensorProto.string_data', index=6,
+      number=6, type=12, cpp_type=9, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='double_data', full_name='caffe2.TensorProto.double_data', index=7,
+      number=9, type=1, cpp_type=5, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=b'\020\001', file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='int64_data', full_name='caffe2.TensorProto.int64_data', index=8,
+      number=10, type=3, cpp_type=2, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=b'\020\001', file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='raw_data', full_name='caffe2.TensorProto.raw_data', index=9,
+      number=13, type=12, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"",
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='name', full_name='caffe2.TensorProto.name', index=10,
+      number=7, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='device_detail', full_name='caffe2.TensorProto.device_detail', index=11,
+      number=8, type=11, cpp_type=10, label=1,
+      has_default_value=False, default_value=None,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='segment', full_name='caffe2.TensorProto.segment', index=12,
+      number=11, type=11, cpp_type=10, label=1,
+      has_default_value=False, default_value=None,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[_TENSORPROTO_SEGMENT, ],
+  enum_types=[
+    _TENSORPROTO_DATATYPE,
+    _TENSORPROTO_SERIALIZATIONFORMAT,
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=38,
+  serialized_end=713,
+)
+
+
+_QTENSORPROTO = _descriptor.Descriptor(
+  name='QTensorProto',
+  full_name='caffe2.QTensorProto',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='dims', full_name='caffe2.QTensorProto.dims', index=0,
+      number=1, type=3, cpp_type=2, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='precision', full_name='caffe2.QTensorProto.precision', index=1,
+      number=2, type=5, cpp_type=1, label=2,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='scale', full_name='caffe2.QTensorProto.scale', index=2,
+      number=3, type=1, cpp_type=5, label=2,
+      has_default_value=False, default_value=float(0),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='bias', full_name='caffe2.QTensorProto.bias', index=3,
+      number=4, type=1, cpp_type=5, label=2,
+      has_default_value=False, default_value=float(0),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='is_signed', full_name='caffe2.QTensorProto.is_signed', index=4,
+      number=5, type=8, cpp_type=7, label=2,
+      has_default_value=False, default_value=False,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='data', full_name='caffe2.QTensorProto.data', index=5,
+      number=6, type=5, cpp_type=1, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=b'\020\001', file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='name', full_name='caffe2.QTensorProto.name', index=6,
+      number=7, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='data_type', full_name='caffe2.QTensorProto.data_type', index=7,
+      number=8, type=14, cpp_type=8, label=1,
+      has_default_value=True, default_value=2,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='scales', full_name='caffe2.QTensorProto.scales', index=8,
+      number=9, type=1, cpp_type=5, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='biases', full_name='caffe2.QTensorProto.biases', index=9,
+      number=10, type=1, cpp_type=5, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='axis', full_name='caffe2.QTensorProto.axis', index=10,
+      number=11, type=5, cpp_type=1, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='is_multiparam', full_name='caffe2.QTensorProto.is_multiparam', index=11,
+      number=12, type=8, cpp_type=7, label=1,
+      has_default_value=True, default_value=False,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=716,
+  serialized_end=975,
+)
+
+
+_TENSORPROTOS = _descriptor.Descriptor(
+  name='TensorProtos',
+  full_name='caffe2.TensorProtos',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='protos', full_name='caffe2.TensorProtos.protos', index=0,
+      number=1, type=11, cpp_type=10, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=977,
+  serialized_end=1028,
+)
+
+
+_TENSORSHAPE = _descriptor.Descriptor(
+  name='TensorShape',
+  full_name='caffe2.TensorShape',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='dims', full_name='caffe2.TensorShape.dims', index=0,
+      number=1, type=3, cpp_type=2, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='data_type', full_name='caffe2.TensorShape.data_type', index=1,
+      number=2, type=14, cpp_type=8, label=1,
+      has_default_value=True, default_value=1,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='unknown_dims', full_name='caffe2.TensorShape.unknown_dims', index=2,
+      number=3, type=5, cpp_type=1, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='unknown_shape', full_name='caffe2.TensorShape.unknown_shape', index=3,
+      number=4, type=8, cpp_type=7, label=1,
+      has_default_value=True, default_value=False,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='name', full_name='caffe2.TensorShape.name', index=4,
+      number=5, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=1031,
+  serialized_end=1180,
+)
+
+
+_TENSORSHAPES = _descriptor.Descriptor(
+  name='TensorShapes',
+  full_name='caffe2.TensorShapes',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='shapes', full_name='caffe2.TensorShapes.shapes', index=0,
+      number=1, type=11, cpp_type=10, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=1182,
+  serialized_end=1233,
+)
+
+
+_TENSORBOUNDSHAPE = _descriptor.Descriptor(
+  name='TensorBoundShape',
+  full_name='caffe2.TensorBoundShape',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='shape', full_name='caffe2.TensorBoundShape.shape', index=0,
+      number=1, type=11, cpp_type=10, label=1,
+      has_default_value=False, default_value=None,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='dim_type', full_name='caffe2.TensorBoundShape.dim_type', index=1,
+      number=2, type=14, cpp_type=8, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='name', full_name='caffe2.TensorBoundShape.name', index=2,
+      number=3, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='shape_is_final', full_name='caffe2.TensorBoundShape.shape_is_final', index=3,
+      number=4, type=8, cpp_type=7, label=1,
+      has_default_value=False, default_value=False,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+    _TENSORBOUNDSHAPE_DIMTYPE,
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=1236,
+  serialized_end=1532,
+)
+
+
+_TENSORBOUNDSHAPES = _descriptor.Descriptor(
+  name='TensorBoundShapes',
+  full_name='caffe2.TensorBoundShapes',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='shapes', full_name='caffe2.TensorBoundShapes.shapes', index=0,
+      number=1, type=11, cpp_type=10, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='max_batch_size', full_name='caffe2.TensorBoundShapes.max_batch_size', index=1,
+      number=2, type=3, cpp_type=2, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='max_feature_len', full_name='caffe2.TensorBoundShapes.max_feature_len', index=2,
+      number=3, type=3, cpp_type=2, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=1534,
+  serialized_end=1644,
+)
+
+
+_AOTCONFIG = _descriptor.Descriptor(
+  name='AOTConfig',
+  full_name='caffe2.AOTConfig',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='max_batch_size', full_name='caffe2.AOTConfig.max_batch_size', index=0,
+      number=1, type=3, cpp_type=2, label=2,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='max_seq_size', full_name='caffe2.AOTConfig.max_seq_size', index=1,
+      number=2, type=3, cpp_type=2, label=2,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='in_batch_broadcast', full_name='caffe2.AOTConfig.in_batch_broadcast', index=2,
+      number=3, type=8, cpp_type=7, label=2,
+      has_default_value=False, default_value=False,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='onnxifi_blacklist_ops', full_name='caffe2.AOTConfig.onnxifi_blacklist_ops', index=3,
+      number=4, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='onnxifi_min_ops', full_name='caffe2.AOTConfig.onnxifi_min_ops', index=4,
+      number=5, type=5, cpp_type=1, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=1647,
+  serialized_end=1788,
+)
+
+
+_ARGUMENT = _descriptor.Descriptor(
+  name='Argument',
+  full_name='caffe2.Argument',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='name', full_name='caffe2.Argument.name', index=0,
+      number=1, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='f', full_name='caffe2.Argument.f', index=1,
+      number=2, type=2, cpp_type=6, label=1,
+      has_default_value=False, default_value=float(0),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='i', full_name='caffe2.Argument.i', index=2,
+      number=3, type=3, cpp_type=2, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='s', full_name='caffe2.Argument.s', index=3,
+      number=4, type=12, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"",
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='t', full_name='caffe2.Argument.t', index=4,
+      number=10, type=11, cpp_type=10, label=1,
+      has_default_value=False, default_value=None,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='n', full_name='caffe2.Argument.n', index=5,
+      number=8, type=11, cpp_type=10, label=1,
+      has_default_value=False, default_value=None,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='floats', full_name='caffe2.Argument.floats', index=6,
+      number=5, type=2, cpp_type=6, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='ints', full_name='caffe2.Argument.ints', index=7,
+      number=6, type=3, cpp_type=2, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='strings', full_name='caffe2.Argument.strings', index=8,
+      number=7, type=12, cpp_type=9, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='tensors', full_name='caffe2.Argument.tensors', index=9,
+      number=11, type=11, cpp_type=10, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='nets', full_name='caffe2.Argument.nets', index=10,
+      number=9, type=11, cpp_type=10, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='qtensors', full_name='caffe2.Argument.qtensors', index=11,
+      number=12, type=11, cpp_type=10, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=1791,
+  serialized_end=2062,
+)
+
+
+_DEVICEOPTION = _descriptor.Descriptor(
+  name='DeviceOption',
+  full_name='caffe2.DeviceOption',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='device_type', full_name='caffe2.DeviceOption.device_type', index=0,
+      number=1, type=5, cpp_type=1, label=1,
+      has_default_value=True, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='device_id', full_name='caffe2.DeviceOption.device_id', index=1,
+      number=2, type=5, cpp_type=1, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='random_seed', full_name='caffe2.DeviceOption.random_seed', index=2,
+      number=3, type=13, cpp_type=3, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='node_name', full_name='caffe2.DeviceOption.node_name', index=3,
+      number=4, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='numa_node_id', full_name='caffe2.DeviceOption.numa_node_id', index=4,
+      number=5, type=5, cpp_type=1, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='extra_info', full_name='caffe2.DeviceOption.extra_info', index=5,
+      number=6, type=9, cpp_type=9, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=2065,
+  serialized_end=2204,
+)
+
+
+_OPERATORDEF = _descriptor.Descriptor(
+  name='OperatorDef',
+  full_name='caffe2.OperatorDef',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='input', full_name='caffe2.OperatorDef.input', index=0,
+      number=1, type=9, cpp_type=9, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='output', full_name='caffe2.OperatorDef.output', index=1,
+      number=2, type=9, cpp_type=9, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='name', full_name='caffe2.OperatorDef.name', index=2,
+      number=3, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='type', full_name='caffe2.OperatorDef.type', index=3,
+      number=4, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='arg', full_name='caffe2.OperatorDef.arg', index=4,
+      number=5, type=11, cpp_type=10, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='device_option', full_name='caffe2.OperatorDef.device_option', index=5,
+      number=6, type=11, cpp_type=10, label=1,
+      has_default_value=False, default_value=None,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='engine', full_name='caffe2.OperatorDef.engine', index=6,
+      number=7, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='control_input', full_name='caffe2.OperatorDef.control_input', index=7,
+      number=8, type=9, cpp_type=9, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='is_gradient_op', full_name='caffe2.OperatorDef.is_gradient_op', index=8,
+      number=9, type=8, cpp_type=7, label=1,
+      has_default_value=True, default_value=False,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='debug_info', full_name='caffe2.OperatorDef.debug_info', index=9,
+      number=10, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='domain', full_name='caffe2.OperatorDef.domain', index=10,
+      number=11, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='op_version', full_name='caffe2.OperatorDef.op_version', index=11,
+      number=12, type=3, cpp_type=2, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=2207,
+  serialized_end=2481,
+)
+
+
+_MAPFIELDENTRY = _descriptor.Descriptor(
+  name='MapFieldEntry',
+  full_name='caffe2.MapFieldEntry',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='key', full_name='caffe2.MapFieldEntry.key', index=0,
+      number=1, type=9, cpp_type=9, label=2,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='val', full_name='caffe2.MapFieldEntry.val', index=1,
+      number=2, type=9, cpp_type=9, label=2,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=2483,
+  serialized_end=2524,
+)
+
+
+_BACKENDOPTIONS = _descriptor.Descriptor(
+  name='BackendOptions',
+  full_name='caffe2.BackendOptions',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='backend_name', full_name='caffe2.BackendOptions.backend_name', index=0,
+      number=1, type=9, cpp_type=9, label=2,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='option', full_name='caffe2.BackendOptions.option', index=1,
+      number=2, type=11, cpp_type=10, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=2526,
+  serialized_end=2603,
+)
+
+
+_PARTITIONINFO = _descriptor.Descriptor(
+  name='PartitionInfo',
+  full_name='caffe2.PartitionInfo',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='name', full_name='caffe2.PartitionInfo.name', index=0,
+      number=1, type=9, cpp_type=9, label=2,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='device_id', full_name='caffe2.PartitionInfo.device_id', index=1,
+      number=2, type=5, cpp_type=1, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='extra_info', full_name='caffe2.PartitionInfo.extra_info', index=2,
+      number=3, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='backend_options', full_name='caffe2.PartitionInfo.backend_options', index=3,
+      number=4, type=11, cpp_type=10, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=2605,
+  serialized_end=2722,
+)
+
+
+_NETDEF = _descriptor.Descriptor(
+  name='NetDef',
+  full_name='caffe2.NetDef',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='name', full_name='caffe2.NetDef.name', index=0,
+      number=1, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='op', full_name='caffe2.NetDef.op', index=1,
+      number=2, type=11, cpp_type=10, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='type', full_name='caffe2.NetDef.type', index=2,
+      number=3, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='num_workers', full_name='caffe2.NetDef.num_workers', index=3,
+      number=4, type=5, cpp_type=1, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='device_option', full_name='caffe2.NetDef.device_option', index=4,
+      number=5, type=11, cpp_type=10, label=1,
+      has_default_value=False, default_value=None,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='arg', full_name='caffe2.NetDef.arg', index=5,
+      number=6, type=11, cpp_type=10, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='external_input', full_name='caffe2.NetDef.external_input', index=6,
+      number=7, type=9, cpp_type=9, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='external_output', full_name='caffe2.NetDef.external_output', index=7,
+      number=8, type=9, cpp_type=9, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='partition_info', full_name='caffe2.NetDef.partition_info', index=8,
+      number=9, type=11, cpp_type=10, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=2725,
+  serialized_end=2987,
+)
+
+
+_EXECUTIONSTEP = _descriptor.Descriptor(
+  name='ExecutionStep',
+  full_name='caffe2.ExecutionStep',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='name', full_name='caffe2.ExecutionStep.name', index=0,
+      number=1, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='substep', full_name='caffe2.ExecutionStep.substep', index=1,
+      number=2, type=11, cpp_type=10, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='network', full_name='caffe2.ExecutionStep.network', index=2,
+      number=3, type=9, cpp_type=9, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='num_iter', full_name='caffe2.ExecutionStep.num_iter', index=3,
+      number=4, type=3, cpp_type=2, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='criteria_network', full_name='caffe2.ExecutionStep.criteria_network', index=4,
+      number=5, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=b'\030\001', file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='report_net', full_name='caffe2.ExecutionStep.report_net', index=5,
+      number=7, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='report_interval', full_name='caffe2.ExecutionStep.report_interval', index=6,
+      number=8, type=5, cpp_type=1, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='run_every_ms', full_name='caffe2.ExecutionStep.run_every_ms', index=7,
+      number=11, type=3, cpp_type=2, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='concurrent_substeps', full_name='caffe2.ExecutionStep.concurrent_substeps', index=8,
+      number=6, type=8, cpp_type=7, label=1,
+      has_default_value=False, default_value=False,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='should_stop_blob', full_name='caffe2.ExecutionStep.should_stop_blob', index=9,
+      number=9, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='only_once', full_name='caffe2.ExecutionStep.only_once', index=10,
+      number=10, type=8, cpp_type=7, label=1,
+      has_default_value=False, default_value=False,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='create_workspace', full_name='caffe2.ExecutionStep.create_workspace', index=11,
+      number=12, type=8, cpp_type=7, label=1,
+      has_default_value=False, default_value=False,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='num_concurrent_instances', full_name='caffe2.ExecutionStep.num_concurrent_instances', index=12,
+      number=13, type=5, cpp_type=1, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=2990,
+  serialized_end=3325,
+)
+
+
+_PLANDEF = _descriptor.Descriptor(
+  name='PlanDef',
+  full_name='caffe2.PlanDef',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='name', full_name='caffe2.PlanDef.name', index=0,
+      number=1, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='network', full_name='caffe2.PlanDef.network', index=1,
+      number=2, type=11, cpp_type=10, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='execution_step', full_name='caffe2.PlanDef.execution_step', index=2,
+      number=3, type=11, cpp_type=10, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=3327,
+  serialized_end=3430,
+)
+
+
+_BLOBPROTO = _descriptor.Descriptor(
+  name='BlobProto',
+  full_name='caffe2.BlobProto',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='name', full_name='caffe2.BlobProto.name', index=0,
+      number=1, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='type', full_name='caffe2.BlobProto.type', index=1,
+      number=2, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='tensor', full_name='caffe2.BlobProto.tensor', index=2,
+      number=3, type=11, cpp_type=10, label=1,
+      has_default_value=False, default_value=None,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='content', full_name='caffe2.BlobProto.content', index=3,
+      number=4, type=12, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"",
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='qtensor', full_name='caffe2.BlobProto.qtensor', index=4,
+      number=5, type=11, cpp_type=10, label=1,
+      has_default_value=False, default_value=None,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='content_num_chunks', full_name='caffe2.BlobProto.content_num_chunks', index=5,
+      number=6, type=5, cpp_type=1, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='content_chunk_id', full_name='caffe2.BlobProto.content_chunk_id', index=6,
+      number=7, type=5, cpp_type=1, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=3433,
+  serialized_end=3619,
+)
+
+
+_DBREADERPROTO = _descriptor.Descriptor(
+  name='DBReaderProto',
+  full_name='caffe2.DBReaderProto',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='name', full_name='caffe2.DBReaderProto.name', index=0,
+      number=1, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='source', full_name='caffe2.DBReaderProto.source', index=1,
+      number=2, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='db_type', full_name='caffe2.DBReaderProto.db_type', index=2,
+      number=3, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='key', full_name='caffe2.DBReaderProto.key', index=3,
+      number=4, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=3621,
+  serialized_end=3696,
+)
+
+
+_BLOBSERIALIZATIONOPTIONS = _descriptor.Descriptor(
+  name='BlobSerializationOptions',
+  full_name='caffe2.BlobSerializationOptions',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='blob_name_regex', full_name='caffe2.BlobSerializationOptions.blob_name_regex', index=0,
+      number=1, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='chunk_size', full_name='caffe2.BlobSerializationOptions.chunk_size', index=1,
+      number=2, type=3, cpp_type=2, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='float_format', full_name='caffe2.BlobSerializationOptions.float_format', index=2,
+      number=3, type=14, cpp_type=8, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+    _BLOBSERIALIZATIONOPTIONS_FLOATFORMAT,
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=3699,
+  serialized_end=3912,
+)
+
+
+_SERIALIZATIONOPTIONS = _descriptor.Descriptor(
+  name='SerializationOptions',
+  full_name='caffe2.SerializationOptions',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='options', full_name='caffe2.SerializationOptions.options', index=0,
+      number=1, type=11, cpp_type=10, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=3914,
+  serialized_end=3987,
+)
+
+_TENSORPROTO_SEGMENT.containing_type = _TENSORPROTO
+_TENSORPROTO.fields_by_name['data_type'].enum_type = _TENSORPROTO_DATATYPE
+_TENSORPROTO.fields_by_name['device_detail'].message_type = _DEVICEOPTION
+_TENSORPROTO.fields_by_name['segment'].message_type = _TENSORPROTO_SEGMENT
+_TENSORPROTO_DATATYPE.containing_type = _TENSORPROTO
+_TENSORPROTO_SERIALIZATIONFORMAT.containing_type = _TENSORPROTO
+_QTENSORPROTO.fields_by_name['data_type'].enum_type = _TENSORPROTO_DATATYPE
+_TENSORPROTOS.fields_by_name['protos'].message_type = _TENSORPROTO
+_TENSORSHAPE.fields_by_name['data_type'].enum_type = _TENSORPROTO_DATATYPE
+_TENSORSHAPES.fields_by_name['shapes'].message_type = _TENSORSHAPE
+_TENSORBOUNDSHAPE.fields_by_name['shape'].message_type = _TENSORSHAPE
+_TENSORBOUNDSHAPE.fields_by_name['dim_type'].enum_type = _TENSORBOUNDSHAPE_DIMTYPE
+_TENSORBOUNDSHAPE_DIMTYPE.containing_type = _TENSORBOUNDSHAPE
+_TENSORBOUNDSHAPES.fields_by_name['shapes'].message_type = _TENSORBOUNDSHAPE
+_ARGUMENT.fields_by_name['t'].message_type = _TENSORPROTO
+_ARGUMENT.fields_by_name['n'].message_type = _NETDEF
+_ARGUMENT.fields_by_name['tensors'].message_type = _TENSORPROTO
+_ARGUMENT.fields_by_name['nets'].message_type = _NETDEF
+_ARGUMENT.fields_by_name['qtensors'].message_type = _QTENSORPROTO
+_OPERATORDEF.fields_by_name['arg'].message_type = _ARGUMENT
+_OPERATORDEF.fields_by_name['device_option'].message_type = _DEVICEOPTION
+_BACKENDOPTIONS.fields_by_name['option'].message_type = _MAPFIELDENTRY
+_PARTITIONINFO.fields_by_name['backend_options'].message_type = _BACKENDOPTIONS
+_NETDEF.fields_by_name['op'].message_type = _OPERATORDEF
+_NETDEF.fields_by_name['device_option'].message_type = _DEVICEOPTION
+_NETDEF.fields_by_name['arg'].message_type = _ARGUMENT
+_NETDEF.fields_by_name['partition_info'].message_type = _PARTITIONINFO
+_EXECUTIONSTEP.fields_by_name['substep'].message_type = _EXECUTIONSTEP
+_PLANDEF.fields_by_name['network'].message_type = _NETDEF
+_PLANDEF.fields_by_name['execution_step'].message_type = _EXECUTIONSTEP
+_BLOBPROTO.fields_by_name['tensor'].message_type = _TENSORPROTO
+_BLOBPROTO.fields_by_name['qtensor'].message_type = _QTENSORPROTO
+_BLOBSERIALIZATIONOPTIONS.fields_by_name['float_format'].enum_type = _BLOBSERIALIZATIONOPTIONS_FLOATFORMAT
+_BLOBSERIALIZATIONOPTIONS_FLOATFORMAT.containing_type = _BLOBSERIALIZATIONOPTIONS
+_SERIALIZATIONOPTIONS.fields_by_name['options'].message_type = _BLOBSERIALIZATIONOPTIONS
+DESCRIPTOR.message_types_by_name['TensorProto'] = _TENSORPROTO
+DESCRIPTOR.message_types_by_name['QTensorProto'] = _QTENSORPROTO
+DESCRIPTOR.message_types_by_name['TensorProtos'] = _TENSORPROTOS
+DESCRIPTOR.message_types_by_name['TensorShape'] = _TENSORSHAPE
+DESCRIPTOR.message_types_by_name['TensorShapes'] = _TENSORSHAPES
+DESCRIPTOR.message_types_by_name['TensorBoundShape'] = _TENSORBOUNDSHAPE
+DESCRIPTOR.message_types_by_name['TensorBoundShapes'] = _TENSORBOUNDSHAPES
+DESCRIPTOR.message_types_by_name['AOTConfig'] = _AOTCONFIG
+DESCRIPTOR.message_types_by_name['Argument'] = _ARGUMENT
+DESCRIPTOR.message_types_by_name['DeviceOption'] = _DEVICEOPTION
+DESCRIPTOR.message_types_by_name['OperatorDef'] = _OPERATORDEF
+DESCRIPTOR.message_types_by_name['MapFieldEntry'] = _MAPFIELDENTRY
+DESCRIPTOR.message_types_by_name['BackendOptions'] = _BACKENDOPTIONS
+DESCRIPTOR.message_types_by_name['PartitionInfo'] = _PARTITIONINFO
+DESCRIPTOR.message_types_by_name['NetDef'] = _NETDEF
+DESCRIPTOR.message_types_by_name['ExecutionStep'] = _EXECUTIONSTEP
+DESCRIPTOR.message_types_by_name['PlanDef'] = _PLANDEF
+DESCRIPTOR.message_types_by_name['BlobProto'] = _BLOBPROTO
+DESCRIPTOR.message_types_by_name['DBReaderProto'] = _DBREADERPROTO
+DESCRIPTOR.message_types_by_name['BlobSerializationOptions'] = _BLOBSERIALIZATIONOPTIONS
+DESCRIPTOR.message_types_by_name['SerializationOptions'] = _SERIALIZATIONOPTIONS
+DESCRIPTOR.enum_types_by_name['DeviceTypeProto'] = _DEVICETYPEPROTO
+_sym_db.RegisterFileDescriptor(DESCRIPTOR)
+
+TensorProto = _reflection.GeneratedProtocolMessageType('TensorProto', (_message.Message,), {
+
+  'Segment' : _reflection.GeneratedProtocolMessageType('Segment', (_message.Message,), {
+    'DESCRIPTOR' : _TENSORPROTO_SEGMENT,
+    '__module__' : 'caffe2.proto.caffe2_pb2'
+    # @@protoc_insertion_point(class_scope:caffe2.TensorProto.Segment)
+    })
+  ,
+  'DESCRIPTOR' : _TENSORPROTO,
+  '__module__' : 'caffe2.proto.caffe2_pb2'
+  # @@protoc_insertion_point(class_scope:caffe2.TensorProto)
+  })
+_sym_db.RegisterMessage(TensorProto)
+_sym_db.RegisterMessage(TensorProto.Segment)
+
+QTensorProto = _reflection.GeneratedProtocolMessageType('QTensorProto', (_message.Message,), {
+  'DESCRIPTOR' : _QTENSORPROTO,
+  '__module__' : 'caffe2.proto.caffe2_pb2'
+  # @@protoc_insertion_point(class_scope:caffe2.QTensorProto)
+  })
+_sym_db.RegisterMessage(QTensorProto)
+
+TensorProtos = _reflection.GeneratedProtocolMessageType('TensorProtos', (_message.Message,), {
+  'DESCRIPTOR' : _TENSORPROTOS,
+  '__module__' : 'caffe2.proto.caffe2_pb2'
+  # @@protoc_insertion_point(class_scope:caffe2.TensorProtos)
+  })
+_sym_db.RegisterMessage(TensorProtos)
+
+TensorShape = _reflection.GeneratedProtocolMessageType('TensorShape', (_message.Message,), {
+  'DESCRIPTOR' : _TENSORSHAPE,
+  '__module__' : 'caffe2.proto.caffe2_pb2'
+  # @@protoc_insertion_point(class_scope:caffe2.TensorShape)
+  })
+_sym_db.RegisterMessage(TensorShape)
+
+TensorShapes = _reflection.GeneratedProtocolMessageType('TensorShapes', (_message.Message,), {
+  'DESCRIPTOR' : _TENSORSHAPES,
+  '__module__' : 'caffe2.proto.caffe2_pb2'
+  # @@protoc_insertion_point(class_scope:caffe2.TensorShapes)
+  })
+_sym_db.RegisterMessage(TensorShapes)
+
+TensorBoundShape = _reflection.GeneratedProtocolMessageType('TensorBoundShape', (_message.Message,), {
+  'DESCRIPTOR' : _TENSORBOUNDSHAPE,
+  '__module__' : 'caffe2.proto.caffe2_pb2'
+  # @@protoc_insertion_point(class_scope:caffe2.TensorBoundShape)
+  })
+_sym_db.RegisterMessage(TensorBoundShape)
+
+TensorBoundShapes = _reflection.GeneratedProtocolMessageType('TensorBoundShapes', (_message.Message,), {
+  'DESCRIPTOR' : _TENSORBOUNDSHAPES,
+  '__module__' : 'caffe2.proto.caffe2_pb2'
+  # @@protoc_insertion_point(class_scope:caffe2.TensorBoundShapes)
+  })
+_sym_db.RegisterMessage(TensorBoundShapes)
+
+AOTConfig = _reflection.GeneratedProtocolMessageType('AOTConfig', (_message.Message,), {
+  'DESCRIPTOR' : _AOTCONFIG,
+  '__module__' : 'caffe2.proto.caffe2_pb2'
+  # @@protoc_insertion_point(class_scope:caffe2.AOTConfig)
+  })
+_sym_db.RegisterMessage(AOTConfig)
+
+Argument = _reflection.GeneratedProtocolMessageType('Argument', (_message.Message,), {
+  'DESCRIPTOR' : _ARGUMENT,
+  '__module__' : 'caffe2.proto.caffe2_pb2'
+  # @@protoc_insertion_point(class_scope:caffe2.Argument)
+  })
+_sym_db.RegisterMessage(Argument)
+
+DeviceOption = _reflection.GeneratedProtocolMessageType('DeviceOption', (_message.Message,), {
+  'DESCRIPTOR' : _DEVICEOPTION,
+  '__module__' : 'caffe2.proto.caffe2_pb2'
+  # @@protoc_insertion_point(class_scope:caffe2.DeviceOption)
+  })
+_sym_db.RegisterMessage(DeviceOption)
+
+OperatorDef = _reflection.GeneratedProtocolMessageType('OperatorDef', (_message.Message,), {
+  'DESCRIPTOR' : _OPERATORDEF,
+  '__module__' : 'caffe2.proto.caffe2_pb2'
+  # @@protoc_insertion_point(class_scope:caffe2.OperatorDef)
+  })
+_sym_db.RegisterMessage(OperatorDef)
+
+MapFieldEntry = _reflection.GeneratedProtocolMessageType('MapFieldEntry', (_message.Message,), {
+  'DESCRIPTOR' : _MAPFIELDENTRY,
+  '__module__' : 'caffe2.proto.caffe2_pb2'
+  # @@protoc_insertion_point(class_scope:caffe2.MapFieldEntry)
+  })
+_sym_db.RegisterMessage(MapFieldEntry)
+
+BackendOptions = _reflection.GeneratedProtocolMessageType('BackendOptions', (_message.Message,), {
+  'DESCRIPTOR' : _BACKENDOPTIONS,
+  '__module__' : 'caffe2.proto.caffe2_pb2'
+  # @@protoc_insertion_point(class_scope:caffe2.BackendOptions)
+  })
+_sym_db.RegisterMessage(BackendOptions)
+
+PartitionInfo = _reflection.GeneratedProtocolMessageType('PartitionInfo', (_message.Message,), {
+  'DESCRIPTOR' : _PARTITIONINFO,
+  '__module__' : 'caffe2.proto.caffe2_pb2'
+  # @@protoc_insertion_point(class_scope:caffe2.PartitionInfo)
+  })
+_sym_db.RegisterMessage(PartitionInfo)
+
+NetDef = _reflection.GeneratedProtocolMessageType('NetDef', (_message.Message,), {
+  'DESCRIPTOR' : _NETDEF,
+  '__module__' : 'caffe2.proto.caffe2_pb2'
+  # @@protoc_insertion_point(class_scope:caffe2.NetDef)
+  })
+_sym_db.RegisterMessage(NetDef)
+
+ExecutionStep = _reflection.GeneratedProtocolMessageType('ExecutionStep', (_message.Message,), {
+  'DESCRIPTOR' : _EXECUTIONSTEP,
+  '__module__' : 'caffe2.proto.caffe2_pb2'
+  # @@protoc_insertion_point(class_scope:caffe2.ExecutionStep)
+  })
+_sym_db.RegisterMessage(ExecutionStep)
+
+PlanDef = _reflection.GeneratedProtocolMessageType('PlanDef', (_message.Message,), {
+  'DESCRIPTOR' : _PLANDEF,
+  '__module__' : 'caffe2.proto.caffe2_pb2'
+  # @@protoc_insertion_point(class_scope:caffe2.PlanDef)
+  })
+_sym_db.RegisterMessage(PlanDef)
+
+BlobProto = _reflection.GeneratedProtocolMessageType('BlobProto', (_message.Message,), {
+  'DESCRIPTOR' : _BLOBPROTO,
+  '__module__' : 'caffe2.proto.caffe2_pb2'
+  # @@protoc_insertion_point(class_scope:caffe2.BlobProto)
+  })
+_sym_db.RegisterMessage(BlobProto)
+
+DBReaderProto = _reflection.GeneratedProtocolMessageType('DBReaderProto', (_message.Message,), {
+  'DESCRIPTOR' : _DBREADERPROTO,
+  '__module__' : 'caffe2.proto.caffe2_pb2'
+  # @@protoc_insertion_point(class_scope:caffe2.DBReaderProto)
+  })
+_sym_db.RegisterMessage(DBReaderProto)
+
+BlobSerializationOptions = _reflection.GeneratedProtocolMessageType('BlobSerializationOptions', (_message.Message,), {
+  'DESCRIPTOR' : _BLOBSERIALIZATIONOPTIONS,
+  '__module__' : 'caffe2.proto.caffe2_pb2'
+  # @@protoc_insertion_point(class_scope:caffe2.BlobSerializationOptions)
+  })
+_sym_db.RegisterMessage(BlobSerializationOptions)
+
+SerializationOptions = _reflection.GeneratedProtocolMessageType('SerializationOptions', (_message.Message,), {
+  'DESCRIPTOR' : _SERIALIZATIONOPTIONS,
+  '__module__' : 'caffe2.proto.caffe2_pb2'
+  # @@protoc_insertion_point(class_scope:caffe2.SerializationOptions)
+  })
+_sym_db.RegisterMessage(SerializationOptions)
+
+
+_TENSORPROTO.fields_by_name['float_data']._options = None
+_TENSORPROTO.fields_by_name['int32_data']._options = None
+_TENSORPROTO.fields_by_name['double_data']._options = None
+_TENSORPROTO.fields_by_name['int64_data']._options = None
+_QTENSORPROTO.fields_by_name['data']._options = None
+_EXECUTIONSTEP.fields_by_name['criteria_network']._options = None
+# @@protoc_insertion_point(module_scope)
diff --git a/.venv/lib/python3.7/site-packages/caffe2/proto/gen_proto_typestubs_helper.py b/.venv/lib/python3.7/site-packages/caffe2/proto/gen_proto_typestubs_helper.py
new file mode 100644
index 0000000..4ed83f5
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/proto/gen_proto_typestubs_helper.py
@@ -0,0 +1,15 @@
+import ast
+
+with open("../python/__init__.py", "r") as f:
+    tree = ast.parse(f.read())
+
+print("\nDeviceType = int\n")
+print("# These are freedom-patched into caffe2_pb2 in caffe2/proto/__init__.py")
+for stmt in tree.body:
+    if not isinstance(stmt, ast.Assign):
+        continue
+    target = stmt.targets[0]
+    if not isinstance(target, ast.Attribute):
+        continue
+    if isinstance(target.value, ast.Name) and target.value.id == "caffe2_pb2":
+        print(f"{target.attr}: int = DeviceType.PROTO_{target.attr}")
diff --git a/.venv/lib/python3.7/site-packages/caffe2/proto/torch_pb2.py b/.venv/lib/python3.7/site-packages/caffe2/proto/torch_pb2.py
new file mode 100644
index 0000000..8e54c30
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/proto/torch_pb2.py
@@ -0,0 +1,538 @@
+# -*- coding: utf-8 -*-
+# Generated by the protocol buffer compiler.  DO NOT EDIT!
+# source: caffe2/proto/torch.proto
+"""Generated protocol buffer code."""
+from google.protobuf.internal import enum_type_wrapper
+from google.protobuf import descriptor as _descriptor
+from google.protobuf import message as _message
+from google.protobuf import reflection as _reflection
+from google.protobuf import symbol_database as _symbol_database
+# @@protoc_insertion_point(imports)
+
+_sym_db = _symbol_database.Default()
+
+
+from caffe2.proto import caffe2_pb2 as caffe2_dot_proto_dot_caffe2__pb2
+
+
+DESCRIPTOR = _descriptor.FileDescriptor(
+  name='caffe2/proto/torch.proto',
+  package='torch',
+  syntax='proto2',
+  serialized_options=None,
+  create_key=_descriptor._internal_create_key,
+  serialized_pb=b'\n\x18\x63\x61\x66\x66\x65\x32/proto/torch.proto\x12\x05torch\x1a\x19\x63\x61\x66\x66\x65\x32/proto/caffe2.proto\"\x18\n\tRecordRef\x12\x0b\n\x03key\x18\x01 \x01(\t\"\xeb\x01\n\tTensorDef\x12\x0c\n\x04\x64ims\x18\x01 \x03(\x03\x12\x0e\n\x06offset\x18\x02 \x01(\x03\x12\x0f\n\x07strides\x18\x03 \x03(\x03\x12\x15\n\rrequires_grad\x18\x04 \x01(\x08\x12/\n\tdata_type\x18\x05 \x01(\x0e\x32\x1c.caffe2.TensorProto.DataType\x12\x1e\n\x04\x64\x61ta\x18\x06 \x01(\x0b\x32\x10.torch.RecordRef\x12\x0e\n\x06\x64\x65vice\x18\x07 \x01(\t\x12\x14\n\x0cis_quantized\x18\x08 \x01(\x08\x12\r\n\x05scale\x18\t \x01(\x01\x12\x12\n\nzero_point\x18\n \x01(\x03\"6\n\x0c\x41ttributeDef\x12\x0c\n\x04type\x18\x01 \x02(\t\x12\x0c\n\x04name\x18\x02 \x02(\t\x12\n\n\x02id\x18\x03 \x02(\x03\"B\n\x0cParameterDef\x12\x11\n\tis_buffer\x18\x01 \x01(\x08\x12\x11\n\ttensor_id\x18\x02 \x01(\x03\x12\x0c\n\x04name\x18\x03 \x01(\t\"\x95\x03\n\tModuleDef\x12$\n\nsubmodules\x18\x01 \x03(\x0b\x32\x10.torch.ModuleDef\x12+\n\x11torchscript_arena\x18\x02 \x01(\x0b\x32\x10.torch.RecordRef\x12#\n\x0b\x63\x61\x66\x66\x65\x32_nets\x18\x03 \x03(\x0b\x32\x0e.caffe2.NetDef\x12&\n\x0cpickle_arena\x18\x04 \x01(\x0b\x32\x10.torch.RecordRef\x12#\n\tcpp_arena\x18\x05 \x01(\x0b\x32\x10.torch.RecordRef\x12\'\n\nparameters\x18\x06 \x03(\x0b\x32\x13.torch.ParameterDef\x12\x0c\n\x04name\x18\x07 \x01(\t\x12\x10\n\x08optimize\x18\x08 \x01(\x08\x12\'\n\nattributes\x18\t \x03(\x0b\x32\x13.torch.AttributeDef\x12\x1e\n\x16get_state_attribute_id\x18\n \x01(\x03\x12\x31\n\x17torchscript_debug_arena\x18\x0b \x01(\x0b\x32\x10.torch.RecordRef\"5\n\x06LibDef\x12+\n\x11torchscript_arena\x18\x01 \x01(\x0b\x32\x10.torch.RecordRef\"\xa8\x01\n\x08ModelDef\x12\x15\n\rproto_version\x18\x01 \x01(\x03\x12%\n\x0bmain_module\x18\x02 \x01(\x0b\x32\x10.torch.ModuleDef\x12\x15\n\rproducer_name\x18\x03 \x01(\t\x12\x18\n\x10producer_version\x18\x04 \x01(\t\x12!\n\x07tensors\x18\x05 \x03(\x0b\x32\x10.torch.TensorDefJ\x04\x08\t\x10\nR\x04libs*(\n\x0cProtoVersion\x12\x18\n\x14PROTO_VERSION_NEWEST\x10\x06'
+  ,
+  dependencies=[caffe2_dot_proto_dot_caffe2__pb2.DESCRIPTOR,])
+
+_PROTOVERSION = _descriptor.EnumDescriptor(
+  name='ProtoVersion',
+  full_name='torch.ProtoVersion',
+  filename=None,
+  file=DESCRIPTOR,
+  create_key=_descriptor._internal_create_key,
+  values=[
+    _descriptor.EnumValueDescriptor(
+      name='PROTO_VERSION_NEWEST', index=0, number=6,
+      serialized_options=None,
+      type=None,
+      create_key=_descriptor._internal_create_key),
+  ],
+  containing_type=None,
+  serialized_options=None,
+  serialized_start=1084,
+  serialized_end=1124,
+)
+_sym_db.RegisterEnumDescriptor(_PROTOVERSION)
+
+ProtoVersion = enum_type_wrapper.EnumTypeWrapper(_PROTOVERSION)
+PROTO_VERSION_NEWEST = 6
+
+
+
+_RECORDREF = _descriptor.Descriptor(
+  name='RecordRef',
+  full_name='torch.RecordRef',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='key', full_name='torch.RecordRef.key', index=0,
+      number=1, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=62,
+  serialized_end=86,
+)
+
+
+_TENSORDEF = _descriptor.Descriptor(
+  name='TensorDef',
+  full_name='torch.TensorDef',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='dims', full_name='torch.TensorDef.dims', index=0,
+      number=1, type=3, cpp_type=2, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='offset', full_name='torch.TensorDef.offset', index=1,
+      number=2, type=3, cpp_type=2, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='strides', full_name='torch.TensorDef.strides', index=2,
+      number=3, type=3, cpp_type=2, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='requires_grad', full_name='torch.TensorDef.requires_grad', index=3,
+      number=4, type=8, cpp_type=7, label=1,
+      has_default_value=False, default_value=False,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='data_type', full_name='torch.TensorDef.data_type', index=4,
+      number=5, type=14, cpp_type=8, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='data', full_name='torch.TensorDef.data', index=5,
+      number=6, type=11, cpp_type=10, label=1,
+      has_default_value=False, default_value=None,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='device', full_name='torch.TensorDef.device', index=6,
+      number=7, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='is_quantized', full_name='torch.TensorDef.is_quantized', index=7,
+      number=8, type=8, cpp_type=7, label=1,
+      has_default_value=False, default_value=False,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='scale', full_name='torch.TensorDef.scale', index=8,
+      number=9, type=1, cpp_type=5, label=1,
+      has_default_value=False, default_value=float(0),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='zero_point', full_name='torch.TensorDef.zero_point', index=9,
+      number=10, type=3, cpp_type=2, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=89,
+  serialized_end=324,
+)
+
+
+_ATTRIBUTEDEF = _descriptor.Descriptor(
+  name='AttributeDef',
+  full_name='torch.AttributeDef',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='type', full_name='torch.AttributeDef.type', index=0,
+      number=1, type=9, cpp_type=9, label=2,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='name', full_name='torch.AttributeDef.name', index=1,
+      number=2, type=9, cpp_type=9, label=2,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='id', full_name='torch.AttributeDef.id', index=2,
+      number=3, type=3, cpp_type=2, label=2,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=326,
+  serialized_end=380,
+)
+
+
+_PARAMETERDEF = _descriptor.Descriptor(
+  name='ParameterDef',
+  full_name='torch.ParameterDef',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='is_buffer', full_name='torch.ParameterDef.is_buffer', index=0,
+      number=1, type=8, cpp_type=7, label=1,
+      has_default_value=False, default_value=False,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='tensor_id', full_name='torch.ParameterDef.tensor_id', index=1,
+      number=2, type=3, cpp_type=2, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='name', full_name='torch.ParameterDef.name', index=2,
+      number=3, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=382,
+  serialized_end=448,
+)
+
+
+_MODULEDEF = _descriptor.Descriptor(
+  name='ModuleDef',
+  full_name='torch.ModuleDef',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='submodules', full_name='torch.ModuleDef.submodules', index=0,
+      number=1, type=11, cpp_type=10, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='torchscript_arena', full_name='torch.ModuleDef.torchscript_arena', index=1,
+      number=2, type=11, cpp_type=10, label=1,
+      has_default_value=False, default_value=None,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='caffe2_nets', full_name='torch.ModuleDef.caffe2_nets', index=2,
+      number=3, type=11, cpp_type=10, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='pickle_arena', full_name='torch.ModuleDef.pickle_arena', index=3,
+      number=4, type=11, cpp_type=10, label=1,
+      has_default_value=False, default_value=None,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='cpp_arena', full_name='torch.ModuleDef.cpp_arena', index=4,
+      number=5, type=11, cpp_type=10, label=1,
+      has_default_value=False, default_value=None,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='parameters', full_name='torch.ModuleDef.parameters', index=5,
+      number=6, type=11, cpp_type=10, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='name', full_name='torch.ModuleDef.name', index=6,
+      number=7, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='optimize', full_name='torch.ModuleDef.optimize', index=7,
+      number=8, type=8, cpp_type=7, label=1,
+      has_default_value=False, default_value=False,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='attributes', full_name='torch.ModuleDef.attributes', index=8,
+      number=9, type=11, cpp_type=10, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='get_state_attribute_id', full_name='torch.ModuleDef.get_state_attribute_id', index=9,
+      number=10, type=3, cpp_type=2, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='torchscript_debug_arena', full_name='torch.ModuleDef.torchscript_debug_arena', index=10,
+      number=11, type=11, cpp_type=10, label=1,
+      has_default_value=False, default_value=None,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=451,
+  serialized_end=856,
+)
+
+
+_LIBDEF = _descriptor.Descriptor(
+  name='LibDef',
+  full_name='torch.LibDef',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='torchscript_arena', full_name='torch.LibDef.torchscript_arena', index=0,
+      number=1, type=11, cpp_type=10, label=1,
+      has_default_value=False, default_value=None,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=858,
+  serialized_end=911,
+)
+
+
+_MODELDEF = _descriptor.Descriptor(
+  name='ModelDef',
+  full_name='torch.ModelDef',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  create_key=_descriptor._internal_create_key,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='proto_version', full_name='torch.ModelDef.proto_version', index=0,
+      number=1, type=3, cpp_type=2, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='main_module', full_name='torch.ModelDef.main_module', index=1,
+      number=2, type=11, cpp_type=10, label=1,
+      has_default_value=False, default_value=None,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='producer_name', full_name='torch.ModelDef.producer_name', index=2,
+      number=3, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='producer_version', full_name='torch.ModelDef.producer_version', index=3,
+      number=4, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=b"".decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+    _descriptor.FieldDescriptor(
+      name='tensors', full_name='torch.ModelDef.tensors', index=4,
+      number=5, type=11, cpp_type=10, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  serialized_options=None,
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=914,
+  serialized_end=1082,
+)
+
+_TENSORDEF.fields_by_name['data_type'].enum_type = caffe2_dot_proto_dot_caffe2__pb2._TENSORPROTO_DATATYPE
+_TENSORDEF.fields_by_name['data'].message_type = _RECORDREF
+_MODULEDEF.fields_by_name['submodules'].message_type = _MODULEDEF
+_MODULEDEF.fields_by_name['torchscript_arena'].message_type = _RECORDREF
+_MODULEDEF.fields_by_name['caffe2_nets'].message_type = caffe2_dot_proto_dot_caffe2__pb2._NETDEF
+_MODULEDEF.fields_by_name['pickle_arena'].message_type = _RECORDREF
+_MODULEDEF.fields_by_name['cpp_arena'].message_type = _RECORDREF
+_MODULEDEF.fields_by_name['parameters'].message_type = _PARAMETERDEF
+_MODULEDEF.fields_by_name['attributes'].message_type = _ATTRIBUTEDEF
+_MODULEDEF.fields_by_name['torchscript_debug_arena'].message_type = _RECORDREF
+_LIBDEF.fields_by_name['torchscript_arena'].message_type = _RECORDREF
+_MODELDEF.fields_by_name['main_module'].message_type = _MODULEDEF
+_MODELDEF.fields_by_name['tensors'].message_type = _TENSORDEF
+DESCRIPTOR.message_types_by_name['RecordRef'] = _RECORDREF
+DESCRIPTOR.message_types_by_name['TensorDef'] = _TENSORDEF
+DESCRIPTOR.message_types_by_name['AttributeDef'] = _ATTRIBUTEDEF
+DESCRIPTOR.message_types_by_name['ParameterDef'] = _PARAMETERDEF
+DESCRIPTOR.message_types_by_name['ModuleDef'] = _MODULEDEF
+DESCRIPTOR.message_types_by_name['LibDef'] = _LIBDEF
+DESCRIPTOR.message_types_by_name['ModelDef'] = _MODELDEF
+DESCRIPTOR.enum_types_by_name['ProtoVersion'] = _PROTOVERSION
+_sym_db.RegisterFileDescriptor(DESCRIPTOR)
+
+RecordRef = _reflection.GeneratedProtocolMessageType('RecordRef', (_message.Message,), {
+  'DESCRIPTOR' : _RECORDREF,
+  '__module__' : 'caffe2.proto.torch_pb2'
+  # @@protoc_insertion_point(class_scope:torch.RecordRef)
+  })
+_sym_db.RegisterMessage(RecordRef)
+
+TensorDef = _reflection.GeneratedProtocolMessageType('TensorDef', (_message.Message,), {
+  'DESCRIPTOR' : _TENSORDEF,
+  '__module__' : 'caffe2.proto.torch_pb2'
+  # @@protoc_insertion_point(class_scope:torch.TensorDef)
+  })
+_sym_db.RegisterMessage(TensorDef)
+
+AttributeDef = _reflection.GeneratedProtocolMessageType('AttributeDef', (_message.Message,), {
+  'DESCRIPTOR' : _ATTRIBUTEDEF,
+  '__module__' : 'caffe2.proto.torch_pb2'
+  # @@protoc_insertion_point(class_scope:torch.AttributeDef)
+  })
+_sym_db.RegisterMessage(AttributeDef)
+
+ParameterDef = _reflection.GeneratedProtocolMessageType('ParameterDef', (_message.Message,), {
+  'DESCRIPTOR' : _PARAMETERDEF,
+  '__module__' : 'caffe2.proto.torch_pb2'
+  # @@protoc_insertion_point(class_scope:torch.ParameterDef)
+  })
+_sym_db.RegisterMessage(ParameterDef)
+
+ModuleDef = _reflection.GeneratedProtocolMessageType('ModuleDef', (_message.Message,), {
+  'DESCRIPTOR' : _MODULEDEF,
+  '__module__' : 'caffe2.proto.torch_pb2'
+  # @@protoc_insertion_point(class_scope:torch.ModuleDef)
+  })
+_sym_db.RegisterMessage(ModuleDef)
+
+LibDef = _reflection.GeneratedProtocolMessageType('LibDef', (_message.Message,), {
+  'DESCRIPTOR' : _LIBDEF,
+  '__module__' : 'caffe2.proto.torch_pb2'
+  # @@protoc_insertion_point(class_scope:torch.LibDef)
+  })
+_sym_db.RegisterMessage(LibDef)
+
+ModelDef = _reflection.GeneratedProtocolMessageType('ModelDef', (_message.Message,), {
+  'DESCRIPTOR' : _MODELDEF,
+  '__module__' : 'caffe2.proto.torch_pb2'
+  # @@protoc_insertion_point(class_scope:torch.ModelDef)
+  })
+_sym_db.RegisterMessage(ModelDef)
+
+
+# @@protoc_insertion_point(module_scope)
diff --git a/.venv/lib/python3.7/site-packages/caffe2/python/__init__.py b/.venv/lib/python3.7/site-packages/caffe2/python/__init__.py
new file mode 100644
index 0000000..6617a62
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/python/__init__.py
@@ -0,0 +1,87 @@
+
+from caffe2.proto import caffe2_pb2
+import os
+import sys
+# TODO: refactor & remove the following alias
+caffe2_pb2.CPU = caffe2_pb2.PROTO_CPU
+caffe2_pb2.CUDA = caffe2_pb2.PROTO_CUDA
+caffe2_pb2.MKLDNN = caffe2_pb2.PROTO_MKLDNN
+caffe2_pb2.OPENGL = caffe2_pb2.PROTO_OPENGL
+caffe2_pb2.OPENCL = caffe2_pb2.PROTO_OPENCL
+caffe2_pb2.IDEEP = caffe2_pb2.PROTO_IDEEP
+caffe2_pb2.HIP = caffe2_pb2.PROTO_HIP
+caffe2_pb2.COMPILE_TIME_MAX_DEVICE_TYPES = caffe2_pb2.PROTO_COMPILE_TIME_MAX_DEVICE_TYPES
+
+if sys.platform == "win32":
+    is_conda = os.path.exists(os.path.join(sys.prefix, 'conda-meta'))
+    py_dll_path = os.path.join(os.path.dirname(sys.executable), 'Library', 'bin')
+    th_root = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'torch')
+    th_dll_path = os.path.join(th_root, 'lib')
+
+    if not os.path.exists(os.path.join(th_dll_path, 'nvToolsExt64_1.dll')) and \
+            not os.path.exists(os.path.join(py_dll_path, 'nvToolsExt64_1.dll')):
+        nvtoolsext_dll_path = os.path.join(
+            os.getenv('NVTOOLSEXT_PATH', 'C:\\Program Files\\NVIDIA Corporation\\NvToolsExt'), 'bin', 'x64')
+    else:
+        nvtoolsext_dll_path = ''
+
+    import importlib.util
+    import glob
+    spec = importlib.util.spec_from_file_location('torch_version', os.path.join(th_root, 'version.py'))
+    torch_version = importlib.util.module_from_spec(spec)
+    spec.loader.exec_module(torch_version)
+    if torch_version.cuda and len(glob.glob(os.path.join(th_dll_path, 'cudart64*.dll'))) == 0 and \
+            len(glob.glob(os.path.join(py_dll_path, 'cudart64*.dll'))) == 0:
+        cuda_version = torch_version.cuda
+        cuda_version_1 = cuda_version.replace('.', '_')
+        cuda_path_var = 'CUDA_PATH_V' + cuda_version_1
+        default_path = 'C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v' + cuda_version
+        cuda_path = os.path.join(os.getenv(cuda_path_var, default_path), 'bin')
+    else:
+        cuda_path = ''
+
+    import ctypes
+    kernel32 = ctypes.WinDLL('kernel32.dll', use_last_error=True)
+    dll_paths = list(filter(os.path.exists, [th_dll_path, py_dll_path, nvtoolsext_dll_path, cuda_path]))
+    with_load_library_flags = hasattr(kernel32, 'AddDllDirectory')
+    prev_error_mode = kernel32.SetErrorMode(0x0001)
+
+    kernel32.LoadLibraryW.restype = ctypes.c_void_p
+    if with_load_library_flags:
+        kernel32.AddDllDirectory.restype = ctypes.c_void_p
+        kernel32.LoadLibraryExW.restype = ctypes.c_void_p
+
+    for dll_path in dll_paths:
+        if sys.version_info >= (3, 8):
+            os.add_dll_directory(dll_path)
+        elif with_load_library_flags:
+            res = kernel32.AddDllDirectory(dll_path)
+            if res is None:
+                err = ctypes.WinError(ctypes.get_last_error())
+                err.strerror += ' Error adding "{}" to the DLL directories.'.format(dll_path)
+                raise err
+
+    dlls = glob.glob(os.path.join(th_dll_path, '*.dll'))
+    path_patched = False
+    for dll in dlls:
+        is_loaded = False
+        if with_load_library_flags:
+            res = kernel32.LoadLibraryExW(dll, None, 0x00001100)
+            last_error = ctypes.get_last_error()
+            if res is None and last_error != 126:
+                err = ctypes.WinError(last_error)
+                err.strerror += ' Error loading "{}" or one of its dependencies.'.format(dll)
+                raise err
+            elif res is not None:
+                is_loaded = True
+        if not is_loaded:
+            if not path_patched:
+                os.environ['PATH'] = ';'.join(dll_paths + [os.environ['PATH']])
+                path_patched = True
+            res = kernel32.LoadLibraryW(dll)
+            if res is None:
+                err = ctypes.WinError(ctypes.get_last_error())
+                err.strerror += ' Error loading "{}" or one of its dependencies.'.format(dll)
+                raise err
+
+    kernel32.SetErrorMode(prev_error_mode)
diff --git a/.venv/lib/python3.7/site-packages/caffe2/python/_import_c_extension.py b/.venv/lib/python3.7/site-packages/caffe2/python/_import_c_extension.py
new file mode 100644
index 0000000..32b9ec3
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/python/_import_c_extension.py
@@ -0,0 +1,57 @@
+## @package _import_c_extension
+# Module caffe2.python._import_c_extension
+import atexit
+import logging
+import sys
+from caffe2.python import extension_loader
+
+# We will first try to load the gpu-enabled caffe2. If it fails, we will then
+# attempt to load the cpu version. The cpu backend is the minimum required, so
+# if that still fails, we will exit loud.
+with extension_loader.DlopenGuard():
+    has_hip_support = False
+    has_cuda_support = False
+    has_gpu_support = False
+
+    try:
+        from caffe2.python.caffe2_pybind11_state_gpu import *  # noqa
+        if num_cuda_devices():  # noqa
+            has_gpu_support = has_cuda_support = True
+    except ImportError as gpu_e:
+        logging.info('Failed to import cuda module: {}'.format(gpu_e))
+        try:
+            from caffe2.python.caffe2_pybind11_state_hip import *  # noqa
+            # we stop checking whether we have AMD GPU devices on the host,
+            # because we may be constructing a net on a machine without GPU,
+            # and run the net on another one with GPU
+            has_gpu_support = has_hip_support = True
+            logging.info('This caffe2 python run has AMD GPU support!')
+        except ImportError as hip_e:
+            logging.info('Failed to import AMD hip module: {}'.format(hip_e))
+
+            logging.warning(
+                'This caffe2 python run failed to load cuda module:{},'
+                'and AMD hip module:{}.'
+                'Will run in CPU only mode.'.format(gpu_e, hip_e))
+            try:
+                from caffe2.python.caffe2_pybind11_state import *  # noqa
+            except ImportError as cpu_e:
+                logging.critical(
+                    'Cannot load caffe2.python. Error: {0}'.format(str(cpu_e)))
+                sys.exit(1)
+
+# libcaffe2_python contains a global Workspace that we need to properly delete
+# when exiting. Otherwise, cudart will cause segfaults sometimes.
+atexit.register(on_module_exit)  # noqa
+
+
+# Add functionalities for the TensorCPU interface.
+def _TensorCPU_shape(self):
+    return tuple(self._shape)
+
+
+def _TensorCPU_reshape(self, shape):
+    return self._reshape(list(shape))
+
+TensorCPU.shape = property(_TensorCPU_shape)  # noqa
+TensorCPU.reshape = _TensorCPU_reshape  # noqa
diff --git a/.venv/lib/python3.7/site-packages/caffe2/python/allcompare_test.py b/.venv/lib/python3.7/site-packages/caffe2/python/allcompare_test.py
new file mode 100644
index 0000000..8733e6d
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/python/allcompare_test.py
@@ -0,0 +1,87 @@
+#!/usr/bin/env python3
+
+
+
+
+
+
+from hypothesis import given, settings
+import hypothesis.strategies as st
+from multiprocessing import Process
+
+import numpy as np
+import tempfile
+import shutil
+
+import caffe2.python.hypothesis_test_util as hu
+
+op_engine = 'GLOO'
+
+
+class TemporaryDirectory:
+    def __enter__(self):
+        self.tmpdir = tempfile.mkdtemp()
+        return self.tmpdir
+
+    def __exit__(self, type, value, traceback):
+        shutil.rmtree(self.tmpdir)
+
+
+def allcompare_process(filestore_dir, process_id, data, num_procs):
+    from caffe2.python import core, data_parallel_model, workspace, dyndep
+    from caffe2.python.model_helper import ModelHelper
+    from caffe2.proto import caffe2_pb2
+    dyndep.InitOpsLibrary("@/caffe2/caffe2/distributed:file_store_handler_ops")
+
+    workspace.RunOperatorOnce(
+        core.CreateOperator(
+            "FileStoreHandlerCreate", [], ["store_handler"], path=filestore_dir
+        )
+    )
+    rendezvous = dict(
+        kv_handler="store_handler",
+        shard_id=process_id,
+        num_shards=num_procs,
+        engine=op_engine,
+        exit_nets=None
+    )
+
+    model = ModelHelper()
+    model._rendezvous = rendezvous
+
+    workspace.FeedBlob("test_data", data)
+
+    data_parallel_model._RunComparison(
+        model, "test_data", core.DeviceOption(caffe2_pb2.CPU, 0)
+    )
+
+
+class TestAllCompare(hu.HypothesisTestCase):
+    @given(
+        d=st.integers(1, 5), n=st.integers(2, 11), num_procs=st.integers(1, 8)
+    )
+    @settings(deadline=10000)
+    def test_allcompare(self, d, n, num_procs):
+        dims = []
+        for _ in range(d):
+            dims.append(np.random.randint(1, high=n))
+        test_data = np.random.ranf(size=tuple(dims)).astype(np.float32)
+
+        with TemporaryDirectory() as tempdir:
+            processes = []
+            for idx in range(num_procs):
+                process = Process(
+                    target=allcompare_process,
+                    args=(tempdir, idx, test_data, num_procs)
+                )
+                processes.append(process)
+                process.start()
+
+            while len(processes) > 0:
+                process = processes.pop()
+                process.join()
+
+
+if __name__ == "__main__":
+    import unittest
+    unittest.main()
diff --git a/.venv/lib/python3.7/site-packages/caffe2/python/attention.py b/.venv/lib/python3.7/site-packages/caffe2/python/attention.py
new file mode 100644
index 0000000..59f4a5a
--- /dev/null
+++ b/.venv/lib/python3.7/site-packages/caffe2/python/attention.py
@@ -0,0 +1,424 @@
+## @package attention
+# Module caffe2.python.attention
+
+
+
+
+
+from caffe2.python import brew
+
+
+class AttentionType:
+    Regular, Recurrent, Dot, SoftCoverage = tuple(range(4))
+
+
+def s(scope, name):
+    # We have to manually scope due to our internal/external blob
+    # relationships.
+    return "{}/{}".format(str(scope), str(name))
+
+
+# c_i = \sum_j w_{ij}\textbf{s}_j
+def _calc_weighted_context(
+    model,
+    encoder_outputs_transposed,
+    encoder_output_dim,
+    attention_weights_3d,
+    scope,
+):
+    # [batch_size, encoder_output_dim, 1]
+    attention_weighted_encoder_context = brew.batch_mat_mul(
+        model,
+        [encoder_outputs_transposed, attention_weights_3d],
+        s(scope, 'attention_weighted_encoder_context'),
+    )
+    # [batch_size, encoder_output_dim]
+    attention_weighted_encoder_context, _ = model.net.Reshape(
+        attention_weighted_encoder_context,
+        [
+            attention_weighted_encoder_context,
+            s(scope, 'attention_weighted_encoder_context_old_shape'),
+        ],
+        shape=[1, -1, encoder_output_dim],
+    )
+    return attention_weighted_encoder_context
+
+
+# Calculate a softmax over the passed in attention energy logits
+def _calc_attention_weights(
+    model,
+    attention_logits_transposed,
+    scope,
+    encoder_lengths=None,
+):
+    if encoder_lengths is not None:
+        attention_logits_transposed = model.net.SequenceMask(
+            [attention_logits_transposed, encoder_lengths],
+            ['masked_attention_logits'],
+            mode='sequence',
+        )
+
+    # [batch_size, encoder_length, 1]
+    attention_weights_3d = brew.softmax(
+        model,
+        attention_logits_transposed,
+        s(scope, 'attention_weights_3d'),
+        engine='CUDNN',
+        axis=1,
+    )
+    return attention_weights_3d
+
+
+# e_{ij} = \textbf{v}^T tanh \alpha(\textbf{h}_{i-1}, \textbf{s}_j)
+def _calc_attention_logits_from_sum_match(
+    model,
+    decoder_hidden_encoder_outputs_sum,
+    encoder_output_dim,
+    scope,
+):
+    # [encoder_length, batch_size, encoder_output_dim]
+    decoder_hidden_encoder_outputs_sum = model.net.Tanh(
+        decoder_hidden_encoder_outputs_sum,
+        decoder_hidden_encoder_outputs_sum,
+    )
+
+    # [encoder_length, batch_size, 1]
+    attention_logits = brew.fc(
+        model,
+        decoder_hidden_encoder_outputs_sum,
+        s(scope, 'attention_logits'),
+        dim_in=encoder_output_dim,
+        dim_out=1,
+        axis=2,
+        freeze_bias=True,
+    )
+
+    # [batch_size, encoder_length, 1]
+    attention_logits_transposed = brew.transpose(
+        model,
+        attention_logits,
+        s(scope, 'attention_logits_transposed'),
+        axes=[1, 0, 2],
+    )
+    return attention_logits_transposed
+
+
+# \textbf{W}^\alpha used in the context of \alpha_{sum}(a,b)
+def _apply_fc_weight_for_sum_match(
+    model,
+    input,
+    dim_in,
+    dim_out,
+    scope,
+    name,
+):
+    output = brew.fc(
+        model,
+        input,
+        s(scope, name),
+        dim_in=dim_in,
+        dim_out=dim_out,
+        axis=2,
+    )
+    output = model.net.Squeeze(
+        output,
+        output,
+        dims=[0],
+    )
+    return output
+
+
+# Implement RecAtt due to section 4.1 in http://arxiv.org/abs/1601.03317
+def apply_recurrent_attention(
+    model,
+    encoder_output_dim,
+    encoder_outputs_transposed,
+    weighted_encoder_outputs,
+    decoder_hidden_state_t,
+    decoder_hidden_state_dim,
+    attention_weighted_encoder_context_t_prev,
+    scope,
+    encoder_lengths=None,
+):
+    weighted_prev_attention_context = _apply_fc_weight_for_sum_match(
+        model=model,
+        input=attention_weighted_encoder_context_t_prev,
+        dim_in=encoder_output_dim,
+        dim_out=encoder_output_dim,
+        scope=scope,
+        name='weighted_prev_attention_context',
+    )
+
+    weighted_decoder_hidden_state = _apply_fc_weight_for_sum_match(
+        model=model,
+        input=decoder_hidden_state_t,
+        dim_in=decoder_hidden_state_dim,
+        dim_out=encoder_output_dim,
+        scope=scope,
+        name='weighted_decoder_hidden_state',
+    )
+    # [1, batch_size, encoder_output_dim]
+    decoder_hidden_encoder_outputs_sum_tmp = model.net.Add(
+        [
+            weighted_prev_attention_context,
+            weighted_decoder_hidden_state,
+        ],
+        s(scope, 'decoder_hidden_encoder_outputs_sum_tmp'),
+    )
+    # [encoder_length, batch_size, encoder_output_dim]
+    decoder_hidden_encoder_outputs_sum = model.net.Add(
+        [
+            weighted_encoder_outputs,
+            decoder_hidden_encoder_outputs_sum_tmp,
+        ],
+        s(scope, 'decoder_hidden_encoder_outputs_sum'),
+        broadcast=1,
+    )
+    attention_logits_transposed = _calc_attention_logits_from_sum_match(
+        model=model,
+        decoder_hidden_encoder_outputs_sum=decoder_hidden_encoder_outputs_sum,
+        encoder_output_dim=encoder_output_dim,
+        scope=scope,
+    )
+
+    # [batch_size, encoder_length, 1]
+    attention_weights_3d = _calc_attention_weights(
+        model=model,
+        attention_logits_transposed=attention_logits_transposed,
+        scope=scope,
+        encoder_lengths=encoder_lengths,
+    )
+
+    # [batch_size, encoder_output_dim, 1]
+    attention_weighted_encoder_context = _calc_weighted_context(
+        model=model,
+        encoder_outputs_transposed=encoder_outputs_transposed,
+        encoder_output_dim=encoder_output_dim,
+        attention_weights_3d=attention_weights_3d,
+        scope=scope,
+    )
+    return attention_weighted_encoder_context, attention_weights_3d, [
+        decoder_hidden_encoder_outputs_sum,
+    ]
+
+
+def apply_regular_attention(
+    model,
+    encoder_output_dim,
+    encoder_outputs_transposed,
+    weighted_encoder_outputs,
+    decoder_hidden_state_t,
+    decoder_hidden_state_dim,
+    scope,
+    encoder_lengths=None,
+):
+    weighted_decoder_hidden_state = _apply_fc_weight_for_sum_match(
+        model=model,
+        input=decoder_hidden_state_t,
+        dim_in=decoder_hidden_state_dim,
+        dim_out=encoder_output_dim,
+        scope=scope,
+        name='weighted_decoder_hidden_state',
+    )
+
+    # [encoder_length, batch_size, encoder_output_dim]
+    decoder_hidden_encoder_outputs_sum = model.net.Add(
+        [weighted_encoder_outputs, weighted_decoder_hidden_state],
+        s(scope, 'decoder_hidden_encoder_outputs_sum'),
+        broadcast=1,
+        use_grad_hack=1,
+    )
+
+    attention_logits_transposed = _calc_attention_logits_from_sum_match(
+        model=model,
+        decoder_hidden_encoder_outputs_sum=decoder_hidden_encoder_outputs_sum,
+        encoder_output_dim=encoder_output_dim,
+        scope=scope,
+    )
+
+   
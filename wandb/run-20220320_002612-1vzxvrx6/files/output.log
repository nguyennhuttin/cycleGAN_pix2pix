/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
create web directory ./checkpoints/concatCG3rdloss/web...
learning rate 0.0002000 -> 0.0002000
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
(epoch: 1, iters: 100, time: 0.480, data: 1.280) D_A: 0.463 G_A: 0.950 D: 1.289 cycle_A: 5.465 idt_A: 0.000 D_B: 0.586 G_B: 0.708 cycle_B: 1.230 idt_B: 0.000
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
(epoch: 1, iters: 200, time: 0.485, data: 0.004) D_A: 0.219 G_A: 0.658 D: 0.642 cycle_A: 5.864 idt_A: 0.000 D_B: 0.635 G_B: 0.842 cycle_B: 0.804 idt_B: 0.000
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
(epoch: 1, iters: 300, time: 0.487, data: 0.003) D_A: 0.474 G_A: 0.868 D: 1.378 cycle_A: 7.524 idt_A: 0.000 D_B: 0.493 G_B: 0.461 cycle_B: 0.600 idt_B: 0.000
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
model_get_current_visuals: OrderedDict([('real_A', tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.]],
         [[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.]],
         [[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.]],
         ...,
         [[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.]],
         [[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.]],
         [[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.]]]], device='cuda:0')), ('fake_B', tensor([[[[0.9994, 0.9989, 0.9990,  ..., 0.9994, 0.9966, 0.9973],
          [0.9998, 0.9999, 0.9997,  ..., 0.9996, 0.9909, 0.9756],
          [0.9993, 0.9978, 0.9992,  ..., 0.9966, 0.9932, 0.9938],
          ...,
          [0.9937, 0.9990, 0.9958,  ..., 0.9812, 0.9698, 0.9659],
          [0.9962, 0.9915, 0.9969,  ..., 0.9836, 0.9483, 0.9257],
          [0.9800, 0.9978, 0.9950,  ..., 0.9725, 0.8494, 0.9076]],
         [[0.9999, 0.9997, 0.9972,  ..., 0.9992, 0.9968, 0.9893],
          [0.9832, 0.9996, 0.9997,  ..., 0.9948, 0.9955, 0.9851],
          [0.9998, 0.9992, 0.9993,  ..., 0.9984, 0.9874, 0.9818],
          ...,
          [0.9683, 0.9929, 0.9949,  ..., 0.9636, 0.9514, 0.9674],
          [0.9939, 0.9924, 0.9697,  ..., 0.9658, 0.9129, 0.9510],
          [0.9914, 0.9839, 0.9965,  ..., 0.9046, 0.8982, 0.8401]],
         [[0.9998, 0.9999, 1.0000,  ..., 0.9994, 0.9985, 0.9980],
          [0.9997, 0.9986, 0.9999,  ..., 0.9967, 0.9994, 0.9903],
          [0.9988, 0.9999, 0.9995,  ..., 0.9984, 0.9930, 0.9931],
          ...,
          [0.9979, 0.9963, 0.9961,  ..., 0.9671, 0.9676, 0.9809],
          [0.9894, 0.9969, 0.9916,  ..., 0.9791, 0.8697, 0.9571],
          [0.9901, 0.9940, 0.9935,  ..., 0.9664, 0.9823, 0.9320]]]],
       device='cuda:0', grad_fn=<TanhBackward0>)), ('rec_A', tensor([[[[0.9885, 0.9030, 0.8965,  ..., 0.8820, 0.9495, 0.9239],
          [0.9806, 0.9318, 0.9922,  ..., 0.8747, 0.9788, 0.9354],
          [0.9574, 0.9283, 0.9383,  ..., 0.7143, 0.8986, 0.9775],
          ...,
          [0.9731, 0.8851, 0.9684,  ..., 0.8354, 0.8771, 0.8766],
          [0.9641, 0.9555, 0.9256,  ..., 0.9296, 0.8412, 0.9619],
          [0.9822, 0.9528, 0.9777,  ..., 0.8736, 0.9346, 0.9324]],
         [[0.9579, 0.6376, 0.9255,  ..., 0.7458, 0.8565, 0.6311],
          [0.9847, 0.9086, 0.9425,  ..., 0.6605, 0.8951, 0.9635],
          [0.8237, 0.8742, 0.9413,  ..., 0.6704, 0.7756, 0.8051],
          ...,
          [0.9795, 0.9193, 0.7848,  ..., 0.6001, 0.9079, 0.9195],
          [0.6563, 0.8931, 0.8179,  ..., 0.7018, 0.4158, 0.8573],
          [0.8669, 0.9152, 0.9138,  ..., 0.8690, 0.7691, 0.8837]],
         [[0.9884, 0.8020, 0.9906,  ..., 0.8334, 0.9768, 0.8884],
          [0.9660, 0.9494, 0.9267,  ..., 0.9862, 0.8755, 0.9124],
          [0.8904, 0.8640, 0.9765,  ..., 0.9313, 0.9174, 0.7460],
          ...,
          [0.7651, 0.9056, 0.8988,  ..., 0.9622, 0.7509, 0.7291],
          [0.9080, 0.9259, 0.9094,  ..., 0.9086, 0.8580, 0.7713],
          [0.9306, 0.9742, 0.9366,  ..., 0.9859, 0.8128, 0.9432]],
         ...,
         [[0.9838, 0.9049, 0.9810,  ..., 0.8582, 0.8793, 0.9206],
          [0.9795, 0.9531, 0.9859,  ..., 0.9244, 0.9828, 0.9387],
          [0.9872, 0.9840, 0.9826,  ..., 0.9847, 0.9706, 0.9338],
          ...,
          [0.8583, 0.8784, 0.9472,  ..., 0.7553, 0.9278, 0.7862],
          [0.9756, 0.9683, 0.9571,  ..., 0.9496, 0.9222, 0.9032],
          [0.9526, 0.9318, 0.9706,  ..., 0.9322, 0.9238, 0.9226]],
         [[0.7741, 0.9541, 0.8889,  ..., 0.9378, 0.9512, 0.9432],
          [0.8319, 0.9069, 0.8240,  ..., 0.9532, 0.8259, 0.8915],
          [0.9355, 0.8807, 0.9156,  ..., 0.9538, 0.9783, 0.9213],
          ...,
          [0.8911, 0.9236, 0.7922,  ..., 0.8431, 0.8582, 0.8677],
          [0.8760, 0.9374, 0.7214,  ..., 0.9257, 0.9474, 0.8839],
          [0.9244, 0.9797, 0.8824,  ..., 0.9331, 0.6715, 0.9131]],
         [[0.9257, 0.8941, 0.9555,  ..., 0.7835, 0.8909, 0.8310],
          [0.9432, 0.9953, 0.8795,  ..., 0.9803, 0.8571, 0.9807],
          [0.9225, 0.8553, 0.7747,  ..., 0.8477, 0.8692, 0.8535],
          ...,
          [0.9182, 0.9892, 0.9177,  ..., 0.9583, 0.8657, 0.9304],
          [0.9261, 0.7720, 0.8637,  ..., 0.8285, 0.8616, 0.6868],
          [0.9447, 0.9553, 0.7989,  ..., 0.9021, 0.8480, 0.9086]]]],
       device='cuda:0', grad_fn=<TanhBackward0>)), ('real_B', tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.]],
         [[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.]],
         [[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.]]],
        [[[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.]],
         [[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.]],
         [[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.]]],
        [[[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.]],
         [[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.]],
         [[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.]]],
        [[[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.]],
         [[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.]],
         [[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.]]],
        [[[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.]],
         [[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.]],
         [[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.]]]], device='cuda:0')), ('fake_A', tensor([[[[0.9396, 0.6735, 0.7099,  ..., 0.7660, 0.8239, 0.8333],
          [0.9005, 0.8028, 0.9145,  ..., 0.7233, 0.9321, 0.8070],
          [0.8781, 0.6589, 0.9071,  ..., 0.5385, 0.8000, 0.8913],
          ...,
          [0.8644, 0.7975, 0.9018,  ..., 0.7337, 0.8086, 0.7862],
          [0.8575, 0.7929, 0.8379,  ..., 0.8426, 0.7514, 0.8877],
          [0.8981, 0.8693, 0.8956,  ..., 0.7733, 0.8664, 0.8330]],
         [[0.8365, 0.2692, 0.7751,  ..., 0.5456, 0.7011, 0.4227],
          [0.8569, 0.7060, 0.6979,  ..., 0.4918, 0.7242, 0.8768],
          [0.5227, 0.5439, 0.8041,  ..., 0.4136, 0.6127, 0.5870],
          ...,
          [0.9154, 0.7897, 0.6521,  ..., 0.4878, 0.7916, 0.8387],
          [0.5089, 0.7136, 0.6233,  ..., 0.5422, 0.4158, 0.7377],
          [0.6835, 0.7275, 0.7472,  ..., 0.7760, 0.6279, 0.7444]],
         [[0.9004, 0.6180, 0.9510,  ..., 0.7251, 0.8970, 0.7709],
          [0.8305, 0.8249, 0.8102,  ..., 0.9246, 0.8071, 0.7350],
          [0.7813, 0.7561, 0.9438,  ..., 0.8381, 0.8402, 0.6630],
          ...,
          [0.6449, 0.7749, 0.7043,  ..., 0.9054, 0.6000, 0.5963],
          [0.7466, 0.8063, 0.8451,  ..., 0.8043, 0.7850, 0.6146],
          [0.7493, 0.9074, 0.8602,  ..., 0.9555, 0.7016, 0.8754]],
         ...,
         [[0.9255, 0.7313, 0.9210,  ..., 0.7084, 0.7481, 0.8378],
          [0.9036, 0.8521, 0.9248,  ..., 0.7539, 0.9494, 0.8790],
          [0.9276, 0.8789, 0.9279,  ..., 0.9373, 0.9113, 0.8143],
          ...,
          [0.6551, 0.7897, 0.8094,  ..., 0.6710, 0.8110, 0.6604],
          [0.8650, 0.8375, 0.8005,  ..., 0.8315, 0.8228, 0.7986],
          [0.8283, 0.8304, 0.8325,  ..., 0.8426, 0.8398, 0.8445]],
         [[0.4636, 0.8471, 0.8441,  ..., 0.8434, 0.8724, 0.8266],
          [0.5995, 0.8677, 0.6429,  ..., 0.8892, 0.6699, 0.7889],
          [0.8159, 0.7714, 0.8220,  ..., 0.8352, 0.9068, 0.8620],
          ...,
          [0.6975, 0.8453, 0.6124,  ..., 0.7609, 0.7447, 0.8042],
          [0.8109, 0.8299, 0.6157,  ..., 0.7914, 0.8751, 0.7670],
          [0.7615, 0.9133, 0.7931,  ..., 0.8281, 0.5955, 0.8400]],
         [[0.6589, 0.7375, 0.8284,  ..., 0.5692, 0.7567, 0.6717],
          [0.7207, 0.9384, 0.6616,  ..., 0.9403, 0.6738, 0.9192],
          [0.7711, 0.6449, 0.5598,  ..., 0.6941, 0.6836, 0.6984],
          ...,
          [0.7673, 0.9034, 0.8187,  ..., 0.8703, 0.7352, 0.8069],
          [0.7778, 0.6347, 0.7503,  ..., 0.7150, 0.7491, 0.6039],
          [0.8244, 0.8658, 0.7379,  ..., 0.8135, 0.7472, 0.8000]]],
        [[[0.9646, 0.7479, 0.7374,  ..., 0.8041, 0.8722, 0.8704],
          [0.9326, 0.8422, 0.9486,  ..., 0.7793, 0.9544, 0.8550],
          [0.9140, 0.7396, 0.9248,  ..., 0.5817, 0.8431, 0.9318],
          ...,
          [0.9109, 0.8397, 0.9320,  ..., 0.7814, 0.8440, 0.8286],
          [0.9049, 0.8626, 0.8818,  ..., 0.8859, 0.7910, 0.9235],
          [0.9408, 0.9109, 0.9314,  ..., 0.8172, 0.9001, 0.8766]],
         [[0.9008, 0.2465, 0.8412,  ..., 0.6109, 0.7560, 0.4531],
          [0.9050, 0.7824, 0.7800,  ..., 0.5358, 0.7726, 0.9164],
          [0.6029, 0.6209, 0.8609,  ..., 0.5065, 0.6561, 0.6579],
          ...,
          [0.9440, 0.8513, 0.7156,  ..., 0.5379, 0.8401, 0.8826],
          [0.5533, 0.7831, 0.7006,  ..., 0.6050, 0.4374, 0.7932],
          [0.7496, 0.8043, 0.8179,  ..., 0.8227, 0.6815, 0.8061]],
         [[0.9449, 0.6392, 0.9718,  ..., 0.7626, 0.9296, 0.8051],
          [0.8875, 0.8833, 0.8510,  ..., 0.9540, 0.8389, 0.8090],
          [0.8399, 0.7829, 0.9655,  ..., 0.8758, 0.8761, 0.6951],
          ...,
          [0.7084, 0.8285, 0.7767,  ..., 0.9343, 0.6626, 0.6432],
          [0.8059, 0.8463, 0.8813,  ..., 0.8504, 0.8190, 0.6698],
          [0.8206, 0.9402, 0.8999,  ..., 0.9726, 0.7522, 0.9089]],
         ...,
         [[0.9548, 0.7951, 0.9491,  ..., 0.7660, 0.7928, 0.8758],
          [0.9447, 0.8864, 0.9603,  ..., 0.8137, 0.9705, 0.9105],
          [0.9572, 0.9322, 0.9583,  ..., 0.9615, 0.9448, 0.8557],
          ...,
          [0.7400, 0.8372, 0.8698,  ..., 0.7162, 0.8644, 0.7142],
          [0.9137, 0.8889, 0.8630,  ..., 0.8876, 0.8704, 0.8440],
          [0.8853, 0.8798, 0.8990,  ..., 0.8817, 0.8823, 0.8806]],
         [[0.5158, 0.8806, 0.8618,  ..., 0.8802, 0.9028, 0.8731],
          [0.6654, 0.8893, 0.7075,  ..., 0.9216, 0.7306, 0.8376],
          [0.8601, 0.8194, 0.8622,  ..., 0.8890, 0.9359, 0.9003],
          ...,
          [0.7732, 0.8859, 0.6829,  ..., 0.7990, 0.7970, 0.8444],
          [0.8524, 0.8809, 0.6476,  ..., 0.8518, 0.9097, 0.8215],
          [0.8347, 0.9465, 0.8439,  ..., 0.8775, 0.6450, 0.8761]],
         [[0.7573, 0.7922, 0.8831,  ..., 0.6361, 0.8112, 0.7029],
          [0.8057, 0.9651, 0.7159,  ..., 0.9595, 0.7288, 0.9464],
          [0.8419, 0.7214, 0.6588,  ..., 0.7513, 0.7427, 0.7581],
          ...,
          [0.8246, 0.9488, 0.8662,  ..., 0.9153, 0.7953, 0.8624],
          [0.8468, 0.6972, 0.7924,  ..., 0.7646, 0.7922, 0.6465],
          [0.8841, 0.9081, 0.7781,  ..., 0.8521, 0.7965, 0.8509]]],
        [[[0.9210, 0.6836, 0.7005,  ..., 0.7386, 0.8038, 0.7944],
          [0.8865, 0.7891, 0.9079,  ..., 0.7010, 0.9082, 0.7857],
          [0.8505, 0.6794, 0.8766,  ..., 0.5381, 0.7644, 0.8597],
          ...,
          [0.8438, 0.7580, 0.8790,  ..., 0.6883, 0.7689, 0.7406],
          [0.8185, 0.7714, 0.8102,  ..., 0.8072, 0.7067, 0.8519],
          [0.8736, 0.8452, 0.8767,  ..., 0.7277, 0.8323, 0.7908]],
         [[0.8208, 0.4069, 0.7438,  ..., 0.5482, 0.6450, 0.4297],
          [0.8562, 0.6952, 0.7199,  ..., 0.4654, 0.7176, 0.8461],
          [0.5347, 0.6099, 0.7787,  ..., 0.4454, 0.5625, 0.5834],
          ...,
          [0.8968, 0.7503, 0.6171,  ..., 0.4660, 0.7382, 0.7950],
          [0.4773, 0.6894, 0.5953,  ..., 0.4994, 0.3726, 0.6923],
          [0.6405, 0.7119, 0.7403,  ..., 0.7273, 0.5769, 0.6950]],
         [[0.8939, 0.6216, 0.9386,  ..., 0.6956, 0.8683, 0.7411],
          [0.8099, 0.8032, 0.7767,  ..., 0.9024, 0.7587, 0.7023],
          [0.7305, 0.7415, 0.9195,  ..., 0.8182, 0.7944, 0.6292],
          ...,
          [0.5936, 0.7401, 0.6720,  ..., 0.8735, 0.5648, 0.5601],
          [0.7082, 0.7720, 0.8130,  ..., 0.7631, 0.7384, 0.5778],
          [0.6978, 0.8835, 0.8251,  ..., 0.9332, 0.6521, 0.8374]],
         ...,
         [[0.9052, 0.7062, 0.8851,  ..., 0.6454, 0.6791, 0.7978],
          [0.8768, 0.8238, 0.9159,  ..., 0.7263, 0.9271, 0.8415],
          [0.9050, 0.8719, 0.9002,  ..., 0.9134, 0.8701, 0.7795],
          ...,
          [0.6224, 0.7454, 0.7726,  ..., 0.6374, 0.7638, 0.6150],
          [0.8310, 0.8085, 0.7633,  ..., 0.7911, 0.7809, 0.7614],
          [0.8108, 0.7970, 0.8124,  ..., 0.8032, 0.8002, 0.8041]],
         [[0.4399, 0.8128, 0.7971,  ..., 0.7847, 0.8466, 0.8066],
          [0.5455, 0.8317, 0.6453,  ..., 0.8497, 0.6231, 0.7461],
          [0.7554, 0.7188, 0.7715,  ..., 0.8068, 0.8813, 0.8266],
          ...,
          [0.6637, 0.8145, 0.5829,  ..., 0.7207, 0.7007, 0.7599],
          [0.7633, 0.7999, 0.5526,  ..., 0.7525, 0.8398, 0.7263],
          [0.7268, 0.8790, 0.7577,  ..., 0.7862, 0.5577, 0.8019]],
         [[0.6976, 0.7199, 0.8039,  ..., 0.5660, 0.7174, 0.6564],
          [0.7539, 0.9322, 0.6893,  ..., 0.9105, 0.6434, 0.8972],
          [0.7268, 0.6021, 0.5064,  ..., 0.6450, 0.6306, 0.6573],
          ...,
          [0.7231, 0.8876, 0.7700,  ..., 0.8308, 0.6850, 0.7677],
          [0.7313, 0.5830, 0.7010,  ..., 0.6696, 0.7076, 0.5647],
          [0.7958, 0.8398, 0.7075,  ..., 0.7763, 0.6982, 0.7539]]],
        [[[0.9193, 0.6812, 0.7051,  ..., 0.7367, 0.8023, 0.7934],
          [0.8853, 0.7879, 0.9077,  ..., 0.7011, 0.9066, 0.7839],
          [0.8477, 0.6763, 0.8759,  ..., 0.5344, 0.7606, 0.8590],
          ...,
          [0.8436, 0.7589, 0.8779,  ..., 0.6875, 0.7679, 0.7407],
          [0.8187, 0.7732, 0.8095,  ..., 0.8065, 0.7061, 0.8517],
          [0.8702, 0.8445, 0.8755,  ..., 0.7273, 0.8314, 0.7895]],
         [[0.8209, 0.3982, 0.7441,  ..., 0.5458, 0.6466, 0.4289],
          [0.8560, 0.6930, 0.7196,  ..., 0.4592, 0.7178, 0.8459],
          [0.5290, 0.6074, 0.7746,  ..., 0.4442, 0.5631, 0.5790],
          ...,
          [0.8946, 0.7483, 0.6172,  ..., 0.4638, 0.7382, 0.7941],
          [0.4770, 0.6861, 0.5945,  ..., 0.4988, 0.3727, 0.6929],
          [0.6384, 0.7083, 0.7377,  ..., 0.7260, 0.5778, 0.6941]],
         [[0.8934, 0.6156, 0.9374,  ..., 0.6948, 0.8670, 0.7406],
          [0.8039, 0.8029, 0.7725,  ..., 0.9023, 0.7582, 0.7017],
          [0.7293, 0.7405, 0.9193,  ..., 0.8183, 0.7942, 0.6291],
          ...,
          [0.5913, 0.7403, 0.6695,  ..., 0.8726, 0.5643, 0.5582],
          [0.7097, 0.7686, 0.8108,  ..., 0.7618, 0.7372, 0.5771],
          [0.6977, 0.8820, 0.8231,  ..., 0.9329, 0.6513, 0.8365]],
         ...,
         [[0.9043, 0.6972, 0.8844,  ..., 0.6415, 0.6768, 0.7942],
          [0.8733, 0.8204, 0.9130,  ..., 0.7238, 0.9259, 0.8386],
          [0.9036, 0.8682, 0.8985,  ..., 0.9125, 0.8698, 0.7781],
          ...,
          [0.6184, 0.7405, 0.7698,  ..., 0.6348, 0.7619, 0.6127],
          [0.8294, 0.8048, 0.7620,  ..., 0.7899, 0.7796, 0.7595],
          [0.8054, 0.7954, 0.8058,  ..., 0.8015, 0.7998, 0.8034]],
         [[0.4494, 0.8173, 0.7985,  ..., 0.7845, 0.8471, 0.8072],
          [0.5423, 0.8372, 0.6409,  ..., 0.8505, 0.6238, 0.7449],
          [0.7560, 0.7194, 0.7707,  ..., 0.8049, 0.8799, 0.8238],
          ...,
          [0.6599, 0.8135, 0.5810,  ..., 0.7205, 0.7003, 0.7590],
          [0.7628, 0.8003, 0.5528,  ..., 0.7520, 0.8382, 0.7259],
          [0.7234, 0.8776, 0.7548,  ..., 0.7855, 0.5571, 0.8011]],
         [[0.6960, 0.7223, 0.7976,  ..., 0.5617, 0.7142, 0.6582],
          [0.7505, 0.9295, 0.6853,  ..., 0.9095, 0.6441, 0.8964],
          [0.7200, 0.5967, 0.5090,  ..., 0.6406, 0.6285, 0.6566],
          ...,
          [0.7208, 0.8856, 0.7685,  ..., 0.8301, 0.6845, 0.7666],
          [0.7291, 0.5818, 0.6979,  ..., 0.6694, 0.7065, 0.5633],
          [0.7936, 0.8369, 0.7079,  ..., 0.7755, 0.6973, 0.7533]]],
        [[[0.9575, 0.6981, 0.7244,  ..., 0.7932, 0.8518, 0.8584],
          [0.9217, 0.8273, 0.9357,  ..., 0.7566, 0.9487, 0.8371],
          [0.9051, 0.6850, 0.9245,  ..., 0.5510, 0.8306, 0.9165],
          ...,
          [0.8863, 0.8256, 0.9185,  ..., 0.7669, 0.8345, 0.8153],
          [0.8867, 0.8288, 0.8676,  ..., 0.8686, 0.7821, 0.9116],
          [0.9236, 0.8929, 0.9191,  ..., 0.8040, 0.8888, 0.8605]],
         [[0.8747, 0.2381, 0.8123,  ..., 0.5720, 0.7381, 0.4567],
          [0.8815, 0.7546, 0.7392,  ..., 0.5093, 0.7484, 0.9024],
          [0.5597, 0.5654, 0.8416,  ..., 0.4504, 0.6473, 0.6262],
          ...,
          [0.9339, 0.8258, 0.6857,  ..., 0.5140, 0.8257, 0.8695],
          [0.5445, 0.7571, 0.6757,  ..., 0.5847, 0.4427, 0.7750],
          [0.7204, 0.7703, 0.7818,  ..., 0.8091, 0.6664, 0.7857]],
         [[0.9238, 0.6322, 0.9659,  ..., 0.7513, 0.9182, 0.8001],
          [0.8717, 0.8555, 0.8382,  ..., 0.9424, 0.8320, 0.7699],
          [0.8255, 0.7740, 0.9583,  ..., 0.8618, 0.8684, 0.6935],
          ...,
          [0.6963, 0.8069, 0.7464,  ..., 0.9250, 0.6375, 0.6275],
          [0.7781, 0.8338, 0.8677,  ..., 0.8327, 0.8125, 0.6458],
          [0.7965, 0.9257, 0.8873,  ..., 0.9676, 0.7380, 0.8993]],
         ...,
         [[0.9433, 0.7821, 0.9387,  ..., 0.7527, 0.7772, 0.8653],
          [0.9257, 0.8757, 0.9436,  ..., 0.7787, 0.9618, 0.8980],
          [0.9456, 0.9107, 0.9484,  ..., 0.9543, 0.9321, 0.8407],
          ...,
          [0.6947, 0.8207, 0.8428,  ..., 0.6953, 0.8430, 0.6939],
          [0.8948, 0.8690, 0.8357,  ..., 0.8634, 0.8501, 0.8239],
          [0.8554, 0.8584, 0.8676,  ..., 0.8653, 0.8674, 0.8690]],
         [[0.4782, 0.8748, 0.8611,  ..., 0.8712, 0.8919, 0.8560],
          [0.6479, 0.8872, 0.6668,  ..., 0.9090, 0.7058, 0.8203],
          [0.8489, 0.8144, 0.8565,  ..., 0.8726, 0.9281, 0.8891],
          ...,
          [0.7458, 0.8739, 0.6487,  ..., 0.7866, 0.7767, 0.8326],
          [0.8309, 0.8581, 0.6403,  ..., 0.8237, 0.8983, 0.8007],
          [0.7981, 0.9330, 0.8201,  ..., 0.8568, 0.6206, 0.8658]],
         [[0.7046, 0.7670, 0.8649,  ..., 0.6079, 0.7910, 0.6872],
          [0.7626, 0.9543, 0.6825,  ..., 0.9557, 0.7032, 0.9372],
          [0.8187, 0.7042, 0.6262,  ..., 0.7324, 0.7267, 0.7378],
          ...,
          [0.7990, 0.9293, 0.8505,  ..., 0.8978, 0.7736, 0.8393],
          [0.8224, 0.6637, 0.7821,  ..., 0.7497, 0.7765, 0.6304],
          [0.8576, 0.8896, 0.7615,  ..., 0.8381, 0.7786, 0.8338]]]],
       device='cuda:0', grad_fn=<TanhBackward0>)), ('rec_B', tensor([[[[0.9997, 0.9990, 0.9993,  ..., 0.9922, 0.9876, 0.9911],
          [0.9997, 0.9991, 0.9996,  ..., 0.9953, 0.9861, 0.9509],
          [0.9992, 0.9996, 0.9979,  ..., 0.9926, 0.9643, 0.9903],
          ...,
          [0.9954, 0.9976, 0.9984,  ..., 0.9451, 0.9620, 0.9329],
          [0.9944, 0.9901, 0.9901,  ..., 0.9527, 0.9285, 0.9161],
          [0.9891, 0.9946, 0.9931,  ..., 0.9695, 0.8801, 0.7221]],
         [[0.9993, 0.9988, 0.9996,  ..., 0.9919, 0.9833, 0.9356],
          [0.9984, 0.9994, 0.9996,  ..., 0.9905, 0.9901, 0.9477],
          [0.9993, 0.9988, 0.9996,  ..., 0.9951, 0.9818, 0.9415],
          ...,
          [0.9859, 0.9923, 0.9938,  ..., 0.9464, 0.9393, 0.9119],
          [0.9633, 0.9847, 0.9859,  ..., 0.9209, 0.8732, 0.7676],
          [0.9443, 0.9819, 0.9688,  ..., 0.9266, 0.8228, 0.7648]],
         [[0.9942, 0.9995, 0.9988,  ..., 0.9960, 0.9876, 0.9834],
          [0.9996, 0.9997, 0.9995,  ..., 0.9864, 0.9911, 0.9588],
          [0.9995, 0.9985, 0.9996,  ..., 0.9823, 0.9874, 0.9792],
          ...,
          [0.9984, 0.9983, 0.9979,  ..., 0.9442, 0.9430, 0.9395],
          [0.9888, 0.9958, 0.9529,  ..., 0.9616, 0.9194, 0.9603],
          [0.9829, 0.9855, 0.9824,  ..., 0.9103, 0.9138, 0.8797]]],
        [[[0.9992, 0.9993, 0.9989,  ..., 0.9959, 0.9894, 0.9948],
          [0.9998, 0.9996, 0.9998,  ..., 0.9979, 0.9856, 0.9554],
          [0.9996, 0.9996, 0.9983,  ..., 0.9943, 0.9800, 0.9890],
          ...,
          [0.9933, 0.9977, 0.9974,  ..., 0.9663, 0.9513, 0.9356],
          [0.9940, 0.9909, 0.9912,  ..., 0.9612, 0.9298, 0.9265],
          [0.9822, 0.9962, 0.9913,  ..., 0.9685, 0.8297, 0.7785]],
         [[0.9997, 0.9996, 0.9991,  ..., 0.9965, 0.9893, 0.9609],
          [0.9965, 0.9995, 0.9998,  ..., 0.9920, 0.9933, 0.9490],
          [0.9995, 0.9994, 0.9997,  ..., 0.9963, 0.9844, 0.9349],
          ...,
          [0.9750, 0.9936, 0.9952,  ..., 0.9487, 0.9388, 0.9257],
          [0.9825, 0.9842, 0.9777,  ..., 0.9337, 0.8756, 0.8168],
          [0.9700, 0.9755, 0.9895,  ..., 0.9131, 0.8477, 0.7602]],
         [[0.9975, 0.9998, 0.9994,  ..., 0.9980, 0.9939, 0.9899],
          [0.9998, 0.9995, 0.9998,  ..., 0.9892, 0.9950, 0.9728],
          [0.9994, 0.9993, 0.9996,  ..., 0.9921, 0.9905, 0.9812],
          ...,
          [0.9981, 0.9975, 0.9962,  ..., 0.9418, 0.9319, 0.9624],
          [0.9866, 0.9953, 0.9720,  ..., 0.9645, 0.9108, 0.9563],
          [0.9829, 0.9861, 0.9881,  ..., 0.9242, 0.9515, 0.9044]]],
        [[[0.9995, 0.9983, 0.9990,  ..., 0.9875, 0.9840, 0.9877],
          [0.9996, 0.9985, 0.9994,  ..., 0.9928, 0.9824, 0.9427],
          [0.9985, 0.9993, 0.9973,  ..., 0.9898, 0.9570, 0.9881],
          ...,
          [0.9950, 0.9961, 0.9982,  ..., 0.9333, 0.9688, 0.9321],
          [0.9926, 0.9877, 0.9865,  ..., 0.9450, 0.9291, 0.9067],
          [0.9876, 0.9926, 0.9933,  ..., 0.9691, 0.8925, 0.7183]],
         [[0.9990, 0.9977, 0.9995,  ..., 0.9865, 0.9778, 0.9142],
          [0.9983, 0.9990, 0.9994,  ..., 0.9878, 0.9867, 0.9293],
          [0.9990, 0.9983, 0.9993,  ..., 0.9930, 0.9778, 0.9401],
          ...,
          [0.9863, 0.9916, 0.9921,  ..., 0.9494, 0.9428, 0.8990],
          [0.9601, 0.9786, 0.9859,  ..., 0.9076, 0.8687, 0.7468],
          [0.9298, 0.9795, 0.9525,  ..., 0.9210, 0.7977, 0.7437]],
         [[0.9911, 0.9990, 0.9979,  ..., 0.9931, 0.9815, 0.9792],
          [0.9994, 0.9995, 0.9990,  ..., 0.9809, 0.9874, 0.9473],
          [0.9993, 0.9975, 0.9993,  ..., 0.9715, 0.9846, 0.9766],
          ...,
          [0.9979, 0.9981, 0.9973,  ..., 0.9442, 0.9419, 0.9201],
          [0.9891, 0.9950, 0.9459,  ..., 0.9575, 0.9263, 0.9620],
          [0.9778, 0.9828, 0.9803,  ..., 0.9045, 0.8888, 0.8495]]],
        [[[0.9996, 0.9983, 0.9990,  ..., 0.9873, 0.9840, 0.9877],
          [0.9996, 0.9984, 0.9994,  ..., 0.9927, 0.9828, 0.9438],
          [0.9986, 0.9992, 0.9974,  ..., 0.9895, 0.9566, 0.9881],
          ...,
          [0.9952, 0.9961, 0.9984,  ..., 0.9330, 0.9687, 0.9324],
          [0.9932, 0.9880, 0.9865,  ..., 0.9441, 0.9292, 0.9062],
          [0.9879, 0.9925, 0.9936,  ..., 0.9698, 0.8935, 0.7188]],
         [[0.9989, 0.9975, 0.9995,  ..., 0.9864, 0.9781, 0.9130],
          [0.9985, 0.9990, 0.9993,  ..., 0.9878, 0.9865, 0.9295],
          [0.9990, 0.9982, 0.9993,  ..., 0.9930, 0.9775, 0.9412],
          ...,
          [0.9865, 0.9920, 0.9921,  ..., 0.9494, 0.9431, 0.8984],
          [0.9604, 0.9781, 0.9861,  ..., 0.9057, 0.8687, 0.7457],
          [0.9290, 0.9803, 0.9502,  ..., 0.9212, 0.7980, 0.7423]],
         [[0.9907, 0.9990, 0.9979,  ..., 0.9929, 0.9816, 0.9793],
          [0.9994, 0.9995, 0.9989,  ..., 0.9810, 0.9872, 0.9484],
          [0.9993, 0.9975, 0.9993,  ..., 0.9715, 0.9847, 0.9770],
          ...,
          [0.9979, 0.9981, 0.9973,  ..., 0.9441, 0.9419, 0.9181],
          [0.9894, 0.9952, 0.9462,  ..., 0.9569, 0.9271, 0.9622],
          [0.9778, 0.9834, 0.9806,  ..., 0.9039, 0.8873, 0.8465]]],
        [[[0.9994, 0.9991, 0.9990,  ..., 0.9949, 0.9899, 0.9942],
          [0.9997, 0.9994, 0.9997,  ..., 0.9972, 0.9866, 0.9564],
          [0.9995, 0.9996, 0.9982,  ..., 0.9939, 0.9743, 0.9903],
          ...,
          [0.9941, 0.9977, 0.9980,  ..., 0.9580, 0.9544, 0.9315],
          [0.9944, 0.9906, 0.9904,  ..., 0.9589, 0.9264, 0.9209],
          [0.9863, 0.9955, 0.9919,  ..., 0.9679, 0.8500, 0.7440]],
         [[0.9994, 0.9994, 0.9993,  ..., 0.9953, 0.9874, 0.9534],
          [0.9970, 0.9994, 0.9997,  ..., 0.9916, 0.9925, 0.9493],
          [0.9994, 0.9993, 0.9997,  ..., 0.9961, 0.9846, 0.9374],
          ...,
          [0.9801, 0.9930, 0.9942,  ..., 0.9430, 0.9380, 0.9145],
          [0.9777, 0.9846, 0.9811,  ..., 0.9273, 0.8747, 0.7792],
          [0.9587, 0.9796, 0.9812,  ..., 0.9201, 0.8384, 0.7607]],
         [[0.9964, 0.9997, 0.9991,  ..., 0.9975, 0.9922, 0.9876],
          [0.9997, 0.9995, 0.9997,  ..., 0.9890, 0.9939, 0.9677],
          [0.9995, 0.9989, 0.9996,  ..., 0.9899, 0.9900, 0.9805],
          ...,
          [0.9982, 0.9978, 0.9970,  ..., 0.9418, 0.9333, 0.9547],
          [0.9863, 0.9954, 0.9599,  ..., 0.9626, 0.9133, 0.9548],
          [0.9823, 0.9840, 0.9850,  ..., 0.9149, 0.9356, 0.8916]]]],
       device='cuda:0', grad_fn=<TanhBackward0>))])
tensor_visual: torch.Size([1, 15, 256, 256])
image_numpy_visual: torch.Size([1, 15, 256, 256])
tensor_visual: torch.Size([1, 3, 256, 256])
image_numpy_visual: torch.Size([1, 3, 256, 256])
tensor_visual: torch.Size([1, 15, 256, 256])
image_numpy_visual: torch.Size([1, 15, 256, 256])
tensor_visual: torch.Size([5, 3, 256, 256])
image_numpy_visual: torch.Size([5, 3, 256, 256])
tensor_visual: torch.Size([5, 15, 256, 256])
image_numpy_visual: torch.Size([5, 15, 256, 256])
tensor_visual: torch.Size([5, 3, 256, 256])
image_numpy_visual: torch.Size([5, 3, 256, 256])
vim shape: (8,)
after mod vim shape: (8,)
/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/lib/python3.7/site-packages/PIL/Image.py:946: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  "Palette images with Transparency expressed in bytes should be "
/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/lib/python3.7/site-packages/PIL/Image.py:946: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  "Palette images with Transparency expressed in bytes should be "
/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/lib/python3.7/site-packages/PIL/Image.py:946: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  "Palette images with Transparency expressed in bytes should be "
/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/lib/python3.7/site-packages/PIL/Image.py:946: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  "Palette images with Transparency expressed in bytes should be "
/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/lib/python3.7/site-packages/visdom/__init__.py:366: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  return np.array(a)
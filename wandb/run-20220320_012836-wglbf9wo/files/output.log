/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
create web directory ./checkpoints/concatCG3rdloss/web...
learning rate 0.0002000 -> 0.0002000
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
(epoch: 1, iters: 100, time: 0.484, data: 1.597) D_A: 1.233 G_A: 1.886 D: 1.047 cycle_A: 9.284 idt_A: 0.000 D_B: 0.581 G_B: 0.561 cycle_B: 1.520 idt_B: 0.000
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
(epoch: 1, iters: 200, time: 0.490, data: 0.003) D_A: 0.422 G_A: 0.745 D: 0.522 cycle_A: 3.906 idt_A: 0.000 D_B: 0.368 G_B: 0.524 cycle_B: 0.625 idt_B: 0.000
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
(epoch: 1, iters: 300, time: 0.493, data: 0.003) D_A: 0.409 G_A: 0.404 D: 0.670 cycle_A: 6.238 idt_A: 0.000 D_B: 0.252 G_B: 0.557 cycle_B: 0.556 idt_B: 0.000
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
show all the images in one visdom panel
label & image_numpy: real_A (256, 256, 15)
/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/lib/python3.7/site-packages/PIL/Image.py:946: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  "Palette images with Transparency expressed in bytes should be "
/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/lib/python3.7/site-packages/PIL/Image.py:946: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  "Palette images with Transparency expressed in bytes should be "
/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/lib/python3.7/site-packages/PIL/Image.py:946: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  "Palette images with Transparency expressed in bytes should be "
create web directory ./checkpoints/concatCG3rdloss/web...
learning rate 0.0002000 -> 0.0002000
/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
(epoch: 1, iters: 100, time: 0.271, data: 1.108) D_A: 0.555 G_A: 1.048 D: 1.076 cycle_A: 4.423 idt_A: 0.977 D_B: 0.605 G_B: 0.809 cycle_B: 1.875 idt_B: 2.260
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
(epoch: 1, iters: 200, time: 0.273, data: 0.003) D_A: 1.104 G_A: 1.508 D: 0.606 cycle_A: 3.283 idt_A: 0.666 D_B: 0.536 G_B: 0.765 cycle_B: 1.299 idt_B: 1.596
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
(epoch: 1, iters: 300, time: 0.275, data: 0.004) D_A: 0.428 G_A: 0.169 D: 0.757 cycle_A: 3.554 idt_A: 0.877 D_B: 0.674 G_B: 0.745 cycle_B: 1.846 idt_B: 1.748
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([1, 15, 256, 256])
/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/lib/python3.7/site-packages/PIL/Image.py:946: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  "Palette images with Transparency expressed in bytes should be "
/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/lib/python3.7/site-packages/PIL/Image.py:946: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  "Palette images with Transparency expressed in bytes should be "
/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/lib/python3.7/site-packages/PIL/Image.py:946: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  "Palette images with Transparency expressed in bytes should be "
/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/lib/python3.7/site-packages/PIL/Image.py:946: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  "Palette images with Transparency expressed in bytes should be "
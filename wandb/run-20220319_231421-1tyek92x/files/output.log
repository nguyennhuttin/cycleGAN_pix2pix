/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
create web directory ./checkpoints/concatCG3rdloss/web...
learning rate 0.0002000 -> 0.0002000
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
(epoch: 1, iters: 100, time: 0.480, data: 0.856) D_A: 2.507 G_A: 3.393 D: 1.591 cycle_A: 5.747 idt_A: 0.000 D_B: 0.687 G_B: 0.553 cycle_B: 1.155 idt_B: 0.000
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
(epoch: 1, iters: 200, time: 0.487, data: 0.004) D_A: 0.273 G_A: 0.597 D: 0.612 cycle_A: 3.615 idt_A: 0.000 D_B: 0.312 G_B: 0.530 cycle_B: 0.556 idt_B: 0.000
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
(epoch: 1, iters: 300, time: 0.487, data: 0.003) D_A: 0.232 G_A: 0.309 D: 0.620 cycle_A: 4.123 idt_A: 0.000 D_B: 0.468 G_B: 0.550 cycle_B: 0.614 idt_B: 0.000
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
Aconcat: torch.Size([1, 15, 256, 256])
Bconcat: torch.Size([5, 3, 256, 256])
/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/lib/python3.7/site-packages/PIL/Image.py:946: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  "Palette images with Transparency expressed in bytes should be "
/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/lib/python3.7/site-packages/PIL/Image.py:946: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  "Palette images with Transparency expressed in bytes should be "
/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/lib/python3.7/site-packages/PIL/Image.py:946: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  "Palette images with Transparency expressed in bytes should be "
/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/lib/python3.7/site-packages/PIL/Image.py:946: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  "Palette images with Transparency expressed in bytes should be "
/fs02/zd26/collage_main/Tin2/cycleGAN_pix2pix/.venv/lib/python3.7/site-packages/visdom/__init__.py:366: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  return np.array(a)